24-11-25 14:57:45 | I | === Configurations ===
24-11-25 14:57:45 | I | LlmRunConfig(
24-11-25 14:57:45 | I |   model=LlmModelConfig(
24-11-25 14:57:45 | I |     name=Tinyllama-1.1b,
24-11-25 14:57:45 | I |     path=/data/gyy/TinyLlama,
24-11-25 14:57:45 | I |     root=/dataset/models,
24-11-25 14:57:45 | I |     local_path=/dataset/models/Tinyllama/Tinyllama-1.1b,
24-11-25 14:57:45 | I |     local_root=/dataset/models,
24-11-25 14:57:45 | I |     family=Tinyllama,
24-11-25 14:57:45 | I |     size=1.1),
24-11-25 14:57:45 | I |   eval=LlmEvalConfig(
24-11-25 14:57:45 | I |     num_gpus=1,
24-11-25 14:57:45 | I |     batch_size=8,
24-11-25 14:57:45 | I |     output_root=runs,
24-11-25 14:57:45 | I |     output_dirname=skip.y.[q]-krnl-rot-rodr.Seq.[fc2]-smth.xw.a0p3.b0p7.[AbsMax].[out+fc2].yx.a0p5.b0.[AbsMax].[qk]-pileval.128x1024.[0-0]-241125.145745,
24-11-25 14:57:45 | I |     attach_timestamp=True,
24-11-25 14:57:45 | I |     timestamp=241125.145745,
24-11-25 14:57:45 | I |     output_dirname_without_timestamp=skip.y.[q]-krnl-rot-rodr.Seq.[fc2]-smth.xw.a0p3.b0p7.[AbsMax].[out+fc2].yx.a0p5.b0.[AbsMax].[qk]-pileval.128x1024.[0-0],
24-11-25 14:57:45 | I |     tasks=['wikitext'],
24-11-25 14:57:45 | I |     max_seq_length=-4096,
24-11-25 14:57:45 | I |     evaluator=gptq),
24-11-25 14:57:45 | I |   calib=LlmCalibConfig(
24-11-25 14:57:45 | I |     data=pileval,
24-11-25 14:57:45 | I |     num_samples=128,
24-11-25 14:57:45 | I |     cache_root=runs,
24-11-25 14:57:45 | I |     cache_dirpath=runs/llm/cache/pileval.128x1024.[0-0],
24-11-25 14:57:45 | I |     dataset_path=mit-han-lab/pile-val-backup,
24-11-25 14:57:45 | I |     seq_length=1024,
24-11-25 14:57:45 | I |     min_seq_length=0,
24-11-25 14:57:45 | I |     max_seq_length=0,
24-11-25 14:57:45 | I |     local_dataset_path=/dataset/pile),
24-11-25 14:57:45 | I |   quant=LlmQuantConfig(
24-11-25 14:57:45 | I |     wgts=WeightQuantizerConfig(
24-11-25 14:57:45 | I |       dtype=zint4,
24-11-25 14:57:45 | I |       group_shapes=((1, -1, -1), (1, 128, -1)),
24-11-25 14:57:45 | I |       group_scale_dtypes=(torch.float16, sint8),
24-11-25 14:57:45 | I |       compute_dtype=sint8,
24-11-25 14:57:45 | I |       compute_group_level=0,
24-11-25 14:57:45 | I |       saturate_compute_dtype=False,
24-11-25 14:57:45 | I |       exponent_scaling_level=2,
24-11-25 14:57:45 | I |       skips=['embed', 'head', 'router'],
24-11-25 14:57:45 | I |       static=True,
24-11-25 14:57:45 | I |       calib_kernel=QuantizerKernelConfig(
24-11-25 14:57:45 | I |         _kernels={'proj_1st': QuantGPTQConfig(includes=['proj_1st', 'proj_2nd', 'proj_out', 'proj_qkv'], damp_percentage=0.01, block_size=128, num_inv_tries=250, hessian_block_size=512), 'proj_2nd': QuantGPTQConfig(includes=['proj_1st', 'proj_2nd', 'proj_out', 'proj_qkv'], damp_percentage=0.01, block_size=128, num_inv_tries=250, hessian_block_size=512), 'proj_out': QuantGPTQConfig(includes=['proj_1st', 'proj_2nd', 'proj_out', 'proj_qkv'], damp_percentage=0.01, block_size=128, num_inv_tries=250, hessian_block_size=512), 'proj_qkv': QuantGPTQConfig(includes=['proj_1st', 'proj_2nd', 'proj_out', 'proj_qkv'], damp_percentage=0.01, block_size=128, num_inv_tries=250, hessian_block_size=512)},
24-11-25 14:57:45 | I |         gptq=QuantGPTQConfig(
24-11-25 14:57:45 | I |           includes=['proj_1st', 'proj_2nd', 'proj_out', 'proj_qkv'],
24-11-25 14:57:45 | I |           damp_percentage=0.01,
24-11-25 14:57:45 | I |           block_size=128,
24-11-25 14:57:45 | I |           num_inv_tries=250,
24-11-25 14:57:45 | I |           hessian_block_size=512)),
24-11-25 14:57:45 | I |       calib_range=DynamicRangeCalibConfig(
24-11-25 14:57:45 | I |         degree=2,
24-11-25 14:57:45 | I |         skips=[],
24-11-25 14:57:45 | I |         objective=SearchBasedCalibObjective.OutputsError,
24-11-25 14:57:45 | I |         strategy=SearchBasedCalibStrategy.Manual,
24-11-25 14:57:45 | I |         granularity=SearchBasedCalibGranularity.Group,
24-11-25 14:57:45 | I |         element_batch_size=64,
24-11-25 14:57:45 | I |         sample_batch_size=-1,
24-11-25 14:57:45 | I |         element_size=512,
24-11-25 14:57:45 | I |         sample_size=-1,
24-11-25 14:57:45 | I |         pre_reshape=True,
24-11-25 14:57:45 | I |         outputs_device=cpu,
24-11-25 14:57:45 | I |         allow_kernel_calib=False,
24-11-25 14:57:45 | I |         ratio=1.0,
24-11-25 14:57:45 | I |         max_shrink=0.2,
24-11-25 14:57:45 | I |         max_expand=1.0,
24-11-25 14:57:45 | I |         num_grids=80)),
24-11-25 14:57:45 | I |     ipts=ActivationQuantizerConfig(
24-11-25 14:57:45 | I |       dtype=sint8,
24-11-25 14:57:45 | I |       group_shapes=((1, -1, -1),),
24-11-25 14:57:45 | I |       group_scale_dtypes=(torch.float16,),
24-11-25 14:57:45 | I |       compute_dtype=None,
24-11-25 14:57:45 | I |       compute_group_level=-1,
24-11-25 14:57:45 | I |       saturate_compute_dtype=False,
24-11-25 14:57:45 | I |       exponent_scaling_level=1,
24-11-25 14:57:45 | I |       skips=['embed', 'head', 'router'],
24-11-25 14:57:45 | I |       static=False,
24-11-25 14:57:45 | I |       calib_kernel=None,
24-11-25 14:57:45 | I |       calib_range=None),
24-11-25 14:57:45 | I |     opts=ActivationQuantizerConfig(
24-11-25 14:57:45 | I |       dtype=zint4,
24-11-25 14:57:45 | I |       group_shapes=((1, 128, -1),),
24-11-25 14:57:45 | I |       group_scale_dtypes=(torch.float16,),
24-11-25 14:57:45 | I |       compute_dtype=None,
24-11-25 14:57:45 | I |       compute_group_level=-1,
24-11-25 14:57:45 | I |       saturate_compute_dtype=False,
24-11-25 14:57:45 | I |       exponent_scaling_level=1,
24-11-25 14:57:45 | I |       skips=['attn_q'],
24-11-25 14:57:45 | I |       static=False,
24-11-25 14:57:45 | I |       calib_kernel=None,
24-11-25 14:57:45 | I |       calib_range=None),
24-11-25 14:57:45 | I |     rotation=QuantRotationConfig(
24-11-25 14:57:45 | I |       random=False,
24-11-25 14:57:45 | I |       transforms=[]),
24-11-25 14:57:45 | I |     reorder=QuantReorderConfig(
24-11-25 14:57:45 | I |       degree=2,
24-11-25 14:57:45 | I |       skips=['proj_out', 'proj_qkv', 'residual'],
24-11-25 14:57:45 | I |       objective=SearchBasedCalibObjective.OutputsError,
24-11-25 14:57:45 | I |       strategy=SearchBasedCalibStrategy.Manual,
24-11-25 14:57:45 | I |       granularity=SearchBasedCalibGranularity.Layer,
24-11-25 14:57:45 | I |       element_batch_size=-1,
24-11-25 14:57:45 | I |       sample_batch_size=-1,
24-11-25 14:57:45 | I |       element_size=-1,
24-11-25 14:57:45 | I |       sample_size=-1,
24-11-25 14:57:45 | I |       pre_reshape=True,
24-11-25 14:57:45 | I |       outputs_device=cpu,
24-11-25 14:57:45 | I |       allow_kernel_calib=False,
24-11-25 14:57:45 | I |       channel_metric=ChannelMetric.InputsAbsMax,
24-11-25 14:57:45 | I |       channel_index=ChannelIndex.Sequential,
24-11-25 14:57:45 | I |       dynamic=False),
24-11-25 14:57:45 | I |     smooth=QuantSmoothConfig(
24-11-25 14:57:45 | I |       xw=QuantSmoothCalibConfig(
24-11-25 14:57:45 | I |         degree=2,
24-11-25 14:57:45 | I |         skips=['proj_1st', 'proj_qkv'],
24-11-25 14:57:45 | I |         objective=SearchBasedCalibObjective.OutputsError,
24-11-25 14:57:45 | I |         strategy=SearchBasedCalibStrategy.Manual,
24-11-25 14:57:45 | I |         granularity=SearchBasedCalibGranularity.Layer,
24-11-25 14:57:45 | I |         element_batch_size=-1,
24-11-25 14:57:45 | I |         sample_batch_size=-1,
24-11-25 14:57:45 | I |         element_size=-1,
24-11-25 14:57:45 | I |         sample_size=-1,
24-11-25 14:57:45 | I |         pre_reshape=True,
24-11-25 14:57:45 | I |         outputs_device=cpu,
24-11-25 14:57:45 | I |         allow_kernel_calib=False,
24-11-25 14:57:45 | I |         ranges=[(<RangeMode.AbsMax: 1>, <RangeMode.AbsMax: 1>)],
24-11-25 14:57:45 | I |         x_ranges=[<RangeMode.AbsMax: 1>],
24-11-25 14:57:45 | I |         w_ranges=[<RangeMode.AbsMax: 1>],
24-11-25 14:57:45 | I |         alpha=0.3,
24-11-25 14:57:45 | I |         beta=0.7,
24-11-25 14:57:45 | I |         num_grids=20),
24-11-25 14:57:45 | I |       yx=QuantSmoothCalibConfig(
24-11-25 14:57:45 | I |         degree=2,
24-11-25 14:57:45 | I |         skips=[],
24-11-25 14:57:45 | I |         objective=SearchBasedCalibObjective.OutputsError,
24-11-25 14:57:45 | I |         strategy=SearchBasedCalibStrategy.Manual,
24-11-25 14:57:45 | I |         granularity=SearchBasedCalibGranularity.Layer,
24-11-25 14:57:45 | I |         element_batch_size=-1,
24-11-25 14:57:45 | I |         sample_batch_size=-1,
24-11-25 14:57:45 | I |         element_size=-1,
24-11-25 14:57:45 | I |         sample_size=-1,
24-11-25 14:57:45 | I |         pre_reshape=True,
24-11-25 14:57:45 | I |         outputs_device=cpu,
24-11-25 14:57:45 | I |         allow_kernel_calib=False,
24-11-25 14:57:45 | I |         ranges=[(<RangeMode.AbsMax: 1>, <RangeMode.AbsMax: 1>)],
24-11-25 14:57:45 | I |         x_ranges=[<RangeMode.AbsMax: 1>],
24-11-25 14:57:45 | I |         w_ranges=[<RangeMode.AbsMax: 1>],
24-11-25 14:57:45 | I |         alpha=0.5,
24-11-25 14:57:45 | I |         beta=0.0,
24-11-25 14:57:45 | I |         num_grids=20)),
24-11-25 14:57:45 | I |     bias_correction=False,
24-11-25 14:57:45 | I |     post_rotary=True,
24-11-25 14:57:45 | I |     develop_dtype=torch.float32,
24-11-25 14:57:45 | I |     select_wgts=None,
24-11-25 14:57:45 | I |     select_ipts=None,
24-11-25 14:57:45 | I |     select_opts=None,
24-11-25 14:57:45 | I |     keywords_i={'proj_qkv': ['q_proj', 'k_proj', 'v_proj'], 'proj_out': ['out_proj', 'o_proj'], 'proj_1st': ['fc1', 'up_proj', 'gate_proj', 'w1', 'w3'], 'proj_2nd': ['fc2', 'down_proj', 'w2'], 'head': ['output', 'score', 'qa_outputs'], 'embed': ['embed', 'lm_head', 'embed_out'], 'router': ['block_sparse_moe']},
24-11-25 14:57:45 | I |     keywords_w={'proj_qkv': ['q_proj', 'k_proj', 'v_proj'], 'proj_out': ['out_proj', 'o_proj'], 'proj_1st': ['fc1', 'up_proj', 'gate_proj', 'w1', 'w3'], 'proj_2nd': ['fc2', 'down_proj', 'w2'], 'head': ['output', 'score', 'qa_outputs'], 'embed': ['embed', 'lm_head', 'embed_out'], 'router': ['block_sparse_moe.gate']},
24-11-25 14:57:45 | I |     keywords_o={'attn_q': ['q_rotary_emb'], 'attn_k': ['k_rotary_emb'], 'attn_v': ['v_proj']},
24-11-25 14:57:45 | I |     module_types_i=(<class 'torch.nn.modules.linear.Linear'>, <class 'transformers.models.mixtral.modeling_mixtral.MixtralSparseMoeBlock'>),
24-11-25 14:57:45 | I |     module_types_w=(<class 'torch.nn.modules.linear.Linear'>,),
24-11-25 14:57:45 | I |     module_types_o=(<class 'torch.nn.modules.linear.Linear'>, <class 'lmquant.llm.nn.attention.RotaryEmbedding'>),
24-11-25 14:57:45 | I |     num_hidden_layers=-1),
24-11-25 14:57:45 | I |   seed=12345,
24-11-25 14:57:45 | I |   save_model=True,
24-11-25 14:57:45 | I |   output_dirpath=runs/llm/Tinyllama/Tinyllama-1.1b/w.4-x.8-y.4/w.zint4-x.sint8-y.zint4/w.gchn.fp16.g128.sint8.[gchn.sint8]-x.gchn.fp16-y.g128.fp16/rot-reorder-smooth.xw.yx-w.static.kernel/skip.y.[q]-krnl-rot-rodr.Seq.[fc2]-smth.xw.a0p3.b0p7.[AbsMax].[out+fc2].yx.a0p5.b0.[AbsMax].[qk]-pileval.128x1024.[0-0]-241125.145745,
24-11-25 14:57:45 | I |   cache_dirpath=LlmQuantCachePath(rotation='runs/llm/cache/rotation/hadamard', reorder='runs/llm/cache/pileval.128x1024.[0-0]/reorder/w.4-x.8-y.4/w.zint4-x.sint8-y.zint4/w.gchn.fp16.g128.sint8.[gchn.sint8]-x.gchn.fp16-y.g128.fp16/w.skip.[embed+head+router]-x.skip.[embed+head+router]-y.skip.[attn_q]/rotate.hadamard/reorder.OutputsError.Manual.Layer.d2.en1.sn1/reorder.InputsAbsMax.Sequential/reorder.skip.[proj_out+proj_qkv+residual]', smooth='runs/llm/cache/pileval.128x1024.[0-0]/smooth/w.4-x.8-y.4/w.zint4-x.sint8-y.zint4/w.gchn.fp16.g128.sint8.[gchn.sint8]-x.gchn.fp16-y.g128.fp16/w.skip.[embed+head+router]-x.skip.[embed+head+router]-y.skip.[attn_q]/rotate.hadamard/reorder.OutputsError.Manual.Layer.d2.en1.sn1/reorder.InputsAbsMax.Sequential/reorder.skip.[proj_out+proj_qkv+residual]/smooth.xw.OutputsError.Manual.Layer.d2.en1.sn1-yx.OutputsError.Manual.Layer.d2.en1.sn1/smooth.xw.[x.AbsMax.w.AbsMax]-yx.[x.AbsMax.w.AbsMax]/smooth.xw.a0p3.b0p7-yx.a0p5.b0/smooth.xw.skip.[proj_1st+proj_qkv]-yx.skip.[]', wgts='runs/llm/cache/pileval.128x1024.[0-0]/wgts/w.4-x.8-y.4/w.zint4-x.sint8-y.zint4/w.gchn.fp16.g128.sint8.[gchn.sint8]-x.gchn.fp16-y.g128.fp16/w.skip.[embed+head+router]-x.skip.[embed+head+router]-y.skip.[attn_q]/rotate.hadamard/reorder.OutputsError.Manual.Layer.d2.en1.sn1/reorder.InputsAbsMax.Sequential/reorder.skip.[proj_out+proj_qkv+residual]/smooth.xw.OutputsError.Manual.Layer.d2.en1.sn1-yx.OutputsError.Manual.Layer.d2.en1.sn1/smooth.xw.[x.AbsMax.w.AbsMax]-yx.[x.AbsMax.w.AbsMax]/smooth.xw.a0p3.b0p7-yx.a0p5.b0/smooth.xw.skip.[proj_1st+proj_qkv]-yx.skip.[]/w.kernel.gptq.d0p01.b128/w.kernel.gptq.include.[proj_1st+proj_2nd+proj_out+proj_qkv]/w.range.OutputsError.Manual.Group.d2.e512.sn1/w.range.r.[1].static/w.range.skip.[]', acts=''),
24-11-25 14:57:45 | I |   cache_path=LlmQuantCachePath(rotation='runs/llm/cache/rotation/hadamard/Tinyllama-1.1b.pt', reorder='runs/llm/cache/pileval.128x1024.[0-0]/reorder/w.4-x.8-y.4/w.zint4-x.sint8-y.zint4/w.gchn.fp16.g128.sint8.[gchn.sint8]-x.gchn.fp16-y.g128.fp16/w.skip.[embed+head+router]-x.skip.[embed+head+router]-y.skip.[attn_q]/rotate.hadamard/reorder.OutputsError.Manual.Layer.d2.en1.sn1/reorder.InputsAbsMax.Sequential/reorder.skip.[proj_out+proj_qkv+residual]/Tinyllama-1.1b.pt', smooth='runs/llm/cache/pileval.128x1024.[0-0]/smooth/w.4-x.8-y.4/w.zint4-x.sint8-y.zint4/w.gchn.fp16.g128.sint8.[gchn.sint8]-x.gchn.fp16-y.g128.fp16/w.skip.[embed+head+router]-x.skip.[embed+head+router]-y.skip.[attn_q]/rotate.hadamard/reorder.OutputsError.Manual.Layer.d2.en1.sn1/reorder.InputsAbsMax.Sequential/reorder.skip.[proj_out+proj_qkv+residual]/smooth.xw.OutputsError.Manual.Layer.d2.en1.sn1-yx.OutputsError.Manual.Layer.d2.en1.sn1/smooth.xw.[x.AbsMax.w.AbsMax]-yx.[x.AbsMax.w.AbsMax]/smooth.xw.a0p3.b0p7-yx.a0p5.b0/smooth.xw.skip.[proj_1st+proj_qkv]-yx.skip.[]/Tinyllama-1.1b.pt', wgts='runs/llm/cache/pileval.128x1024.[0-0]/wgts/w.4-x.8-y.4/w.zint4-x.sint8-y.zint4/w.gchn.fp16.g128.sint8.[gchn.sint8]-x.gchn.fp16-y.g128.fp16/w.skip.[embed+head+router]-x.skip.[embed+head+router]-y.skip.[attn_q]/rotate.hadamard/reorder.OutputsError.Manual.Layer.d2.en1.sn1/reorder.InputsAbsMax.Sequential/reorder.skip.[proj_out+proj_qkv+residual]/smooth.xw.OutputsError.Manual.Layer.d2.en1.sn1-yx.OutputsError.Manual.Layer.d2.en1.sn1/smooth.xw.[x.AbsMax.w.AbsMax]-yx.[x.AbsMax.w.AbsMax]/smooth.xw.a0p3.b0p7-yx.a0p5.b0/smooth.xw.skip.[proj_1st+proj_qkv]-yx.skip.[]/w.kernel.gptq.d0p01.b128/w.kernel.gptq.include.[proj_1st+proj_2nd+proj_out+proj_qkv]/w.range.OutputsError.Manual.Group.d2.e512.sn1/w.range.r.[1].static/w.range.skip.[]/Tinyllama-1.1b.pt', acts=''),
24-11-25 14:57:45 | I |   fairseq_args=/data/gyy/lmquant-main/projects/llm/configs/fairseq_args.json,
24-11-25 14:57:45 | I |   gen_teacher_opts=False,
24-11-25 14:57:45 | I |   enable_cache=False,
24-11-25 14:57:45 | I |   with_prepocess=False)
24-11-25 14:57:45 | I | === Dumped Configurations ===
24-11-25 14:57:45 | I | { 'calib': { 'cache_root': 'runs',
24-11-25 14:57:45 | I |              'data': 'pileval',
24-11-25 14:57:45 | I |              'dataset_path': 'mit-han-lab/pile-val-backup',
24-11-25 14:57:45 | I |              'local_dataset_path': '/dataset/pile',
24-11-25 14:57:45 | I |              'max_seq_length': 0,
24-11-25 14:57:45 | I |              'min_seq_length': 0,
24-11-25 14:57:45 | I |              'num_samples': 128,
24-11-25 14:57:45 | I |              'seq_length': 1024},
24-11-25 14:57:45 | I |   'enable_cache': False,
24-11-25 14:57:45 | I |   'eval': { 'attach_timestamp': True,
24-11-25 14:57:45 | I |             'batch_size': 8,
24-11-25 14:57:45 | I |             'evaluator': 'gptq',
24-11-25 14:57:45 | I |             'max_seq_length': -4096,
24-11-25 14:57:45 | I |             'num_gpus': 1,
24-11-25 14:57:45 | I |             'output_dirname': 'skip.y.[q]-krnl-rot-rodr.Seq.[fc2]-smth.xw.a0p3.b0p7.[AbsMax].[out+fc2].yx.a0p5.b0.[AbsMax].[qk]-pileval.128x1024.[0-0]-241125.145745',
24-11-25 14:57:45 | I |             'output_root': 'runs',
24-11-25 14:57:45 | I |             'tasks': ['wikitext']},
24-11-25 14:57:45 | I |   'fairseq_args': '/data/gyy/lmquant-main/projects/llm/configs/fairseq_args.json',
24-11-25 14:57:45 | I |   'gen_teacher_opts': False,
24-11-25 14:57:45 | I |   'model': { 'local_path': '/dataset/models/Tinyllama/Tinyllama-1.1b',
24-11-25 14:57:45 | I |              'local_root': '/dataset/models',
24-11-25 14:57:45 | I |              'name': 'Tinyllama-1.1b',
24-11-25 14:57:45 | I |              'path': '/data/gyy/TinyLlama',
24-11-25 14:57:45 | I |              'root': '/dataset/models'},
24-11-25 14:57:45 | I |   'quant': { 'bias_correction': False,
24-11-25 14:57:45 | I |              'develop_dtype': 'torch.float32',
24-11-25 14:57:45 | I |              'enable_reorder': True,
24-11-25 14:57:45 | I |              'enable_rotation': True,
24-11-25 14:57:45 | I |              'enable_select_ipts': False,
24-11-25 14:57:45 | I |              'enable_select_opts': False,
24-11-25 14:57:45 | I |              'enable_select_wgts': False,
24-11-25 14:57:45 | I |              'enable_smooth': True,
24-11-25 14:57:45 | I |              'ipts': { 'compute_dtype': None,
24-11-25 14:57:45 | I |                        'compute_group_level': -1,
24-11-25 14:57:45 | I |                        'dtype': 'sint8',
24-11-25 14:57:45 | I |                        'enable_calib_range': False,
24-11-25 14:57:45 | I |                        'group_scale_dtypes': ['torch.float16'],
24-11-25 14:57:45 | I |                        'group_shapes': [[1, -1, -1]],
24-11-25 14:57:45 | I |                        'saturate_compute_dtype': False,
24-11-25 14:57:45 | I |                        'skips': ['embed', 'head', 'router'],
24-11-25 14:57:45 | I |                        'static': False},
24-11-25 14:57:45 | I |              'opts': { 'compute_dtype': None,
24-11-25 14:57:45 | I |                        'compute_group_level': -1,
24-11-25 14:57:45 | I |                        'dtype': 'zint4',
24-11-25 14:57:45 | I |                        'enable_calib_range': False,
24-11-25 14:57:45 | I |                        'group_scale_dtypes': ['torch.float16'],
24-11-25 14:57:45 | I |                        'group_shapes': [[1, 128, -1]],
24-11-25 14:57:45 | I |                        'saturate_compute_dtype': False,
24-11-25 14:57:45 | I |                        'skips': ['attn_q'],
24-11-25 14:57:45 | I |                        'static': False},
24-11-25 14:57:45 | I |              'post_rotary': True,
24-11-25 14:57:45 | I |              'reorder': { 'allow_kernel_calib': False,
24-11-25 14:57:45 | I |                           'channel_index': 'Sequential',
24-11-25 14:57:45 | I |                           'channel_metric': 'InputsAbsMax',
24-11-25 14:57:45 | I |                           'degree': 2,
24-11-25 14:57:45 | I |                           'dynamic': False,
24-11-25 14:57:45 | I |                           'element_batch_size': -1,
24-11-25 14:57:45 | I |                           'element_size': -1,
24-11-25 14:57:45 | I |                           'outputs_device': 'cpu',
24-11-25 14:57:45 | I |                           'pre_reshape': True,
24-11-25 14:57:45 | I |                           'sample_batch_size': -1,
24-11-25 14:57:45 | I |                           'sample_size': -1,
24-11-25 14:57:45 | I |                           'skips': ['proj_out', 'proj_qkv', 'residual'],
24-11-25 14:57:45 | I |                           'strategy': 'Manual'},
24-11-25 14:57:45 | I |              'rotation': {'random': False, 'transforms': []},
24-11-25 14:57:45 | I |              'smooth': { 'enable_xw': True,
24-11-25 14:57:45 | I |                          'enable_yx': True,
24-11-25 14:57:45 | I |                          'xw': { 'allow_kernel_calib': False,
24-11-25 14:57:45 | I |                                  'alpha': 0.3,
24-11-25 14:57:45 | I |                                  'beta': 0.7,
24-11-25 14:57:45 | I |                                  'degree': 2,
24-11-25 14:57:45 | I |                                  'element_batch_size': -1,
24-11-25 14:57:45 | I |                                  'element_size': -1,
24-11-25 14:57:45 | I |                                  'granularity': 'Layer',
24-11-25 14:57:45 | I |                                  'num_grids': 20,
24-11-25 14:57:45 | I |                                  'objective': 'OutputsError',
24-11-25 14:57:45 | I |                                  'outputs_device': 'cpu',
24-11-25 14:57:45 | I |                                  'pre_reshape': True,
24-11-25 14:57:45 | I |                                  'ranges': [['AbsMax', 'AbsMax']],
24-11-25 14:57:45 | I |                                  'sample_batch_size': -1,
24-11-25 14:57:45 | I |                                  'sample_size': -1,
24-11-25 14:57:45 | I |                                  'skips': ['proj_1st', 'proj_qkv'],
24-11-25 14:57:45 | I |                                  'strategy': 'Manual'},
24-11-25 14:57:45 | I |                          'yx': { 'allow_kernel_calib': False,
24-11-25 14:57:45 | I |                                  'alpha': 0.5,
24-11-25 14:57:45 | I |                                  'beta': 0.0,
24-11-25 14:57:45 | I |                                  'degree': 2,
24-11-25 14:57:45 | I |                                  'element_batch_size': -1,
24-11-25 14:57:45 | I |                                  'element_size': -1,
24-11-25 14:57:45 | I |                                  'granularity': 'Layer',
24-11-25 14:57:45 | I |                                  'num_grids': 20,
24-11-25 14:57:45 | I |                                  'objective': 'OutputsError',
24-11-25 14:57:45 | I |                                  'outputs_device': 'cpu',
24-11-25 14:57:45 | I |                                  'pre_reshape': True,
24-11-25 14:57:45 | I |                                  'ranges': [['AbsMax', 'AbsMax']],
24-11-25 14:57:45 | I |                                  'sample_batch_size': -1,
24-11-25 14:57:45 | I |                                  'sample_size': -1,
24-11-25 14:57:45 | I |                                  'skips': [],
24-11-25 14:57:45 | I |                                  'strategy': 'Manual'}},
24-11-25 14:57:45 | I |              'wgts': { 'calib_kernel': { 'enable_gptq': True,
24-11-25 14:57:45 | I |                                          'gptq': { 'block_size': 128,
24-11-25 14:57:45 | I |                                                    'damp_percentage': 0.01,
24-11-25 14:57:45 | I |                                                    'hessian_block_size': 512,
24-11-25 14:57:45 | I |                                                    'includes': ['proj_1st', 'proj_2nd', 'proj_out', 'proj_qkv'],
24-11-25 14:57:45 | I |                                                    'num_inv_tries': 250}},
24-11-25 14:57:45 | I |                        'calib_range': { 'allow_kernel_calib': False,
24-11-25 14:57:45 | I |                                         'degree': 2,
24-11-25 14:57:45 | I |                                         'element_batch_size': 64,
24-11-25 14:57:45 | I |                                         'element_size': 512,
24-11-25 14:57:45 | I |                                         'granularity': 'Group',
24-11-25 14:57:45 | I |                                         'max_expand': 1.0,
24-11-25 14:57:45 | I |                                         'max_shrink': 0.2,
24-11-25 14:57:45 | I |                                         'num_grids': 80,
24-11-25 14:57:45 | I |                                         'objective': 'OutputsError',
24-11-25 14:57:45 | I |                                         'outputs_device': 'cpu',
24-11-25 14:57:45 | I |                                         'pre_reshape': True,
24-11-25 14:57:45 | I |                                         'ratio': 1.0,
24-11-25 14:57:45 | I |                                         'sample_batch_size': -1,
24-11-25 14:57:45 | I |                                         'sample_size': -1,
24-11-25 14:57:45 | I |                                         'skips': [],
24-11-25 14:57:45 | I |                                         'strategy': 'Manual'},
24-11-25 14:57:45 | I |                        'compute_dtype': 'sint8',
24-11-25 14:57:45 | I |                        'compute_group_level': 0,
24-11-25 14:57:45 | I |                        'dtype': 'zint4',
24-11-25 14:57:45 | I |                        'enable_calib_kernel': True,
24-11-25 14:57:45 | I |                        'enable_calib_range': True,
24-11-25 14:57:45 | I |                        'group_scale_dtypes': ['torch.float16', 'sint8'],
24-11-25 14:57:45 | I |                        'group_shapes': [[1, -1, -1], [1, 128, -1]],
24-11-25 14:57:45 | I |                        'saturate_compute_dtype': False,
24-11-25 14:57:45 | I |                        'skips': ['embed', 'head', 'router']}},
24-11-25 14:57:45 | I |   'save_model': True,
24-11-25 14:57:45 | I |   'seed': 12345,
24-11-25 14:57:45 | I |   'with_prepocess': False}
24-11-25 14:57:45 | I | === Output Directory ===
24-11-25 14:57:45 | I | runs/llm/Tinyllama/Tinyllama-1.1b/w.4-x.8-y.4/w.zint4-x.sint8-y.zint4/w.gchn.fp16.g128.sint8.[gchn.sint8]-x.gchn.fp16-y.g128.fp16/rot-reorder-smooth.xw.yx-w.static.kernel/skip.y.[q]-krnl-rot-rodr.Seq.[fc2]-smth.xw.a0p3.b0p7.[AbsMax].[out+fc2].yx.a0p5.b0.[AbsMax].[qk]-pileval.128x1024.[0-0]-241125.145745
24-11-25 14:57:45 | I | === Start Evaluating ===
24-11-25 14:57:45 | I | * Building model Tinyllama-1.1b from /data/gyy/TinyLlama
24-11-25 14:57:46 | I | We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
24-11-25 14:57:47 | I | - Patching LlamaSdpaAttention.forward in model.layers.0.self_attn
24-11-25 14:57:47 | I | - Patching LlamaSdpaAttention.forward in model.layers.1.self_attn
24-11-25 14:57:47 | I | - Patching LlamaSdpaAttention.forward in model.layers.2.self_attn
24-11-25 14:57:47 | I | - Patching LlamaSdpaAttention.forward in model.layers.3.self_attn
24-11-25 14:57:47 | I | - Patching LlamaSdpaAttention.forward in model.layers.4.self_attn
24-11-25 14:57:47 | I | - Patching LlamaSdpaAttention.forward in model.layers.5.self_attn
24-11-25 14:57:47 | I | - Patching LlamaSdpaAttention.forward in model.layers.6.self_attn
24-11-25 14:57:47 | I | - Patching LlamaSdpaAttention.forward in model.layers.7.self_attn
24-11-25 14:57:47 | I | - Patching LlamaSdpaAttention.forward in model.layers.8.self_attn
24-11-25 14:57:47 | I | - Patching LlamaSdpaAttention.forward in model.layers.9.self_attn
24-11-25 14:57:47 | I | - Patching LlamaSdpaAttention.forward in model.layers.10.self_attn
24-11-25 14:57:47 | I | - Patching LlamaSdpaAttention.forward in model.layers.11.self_attn
24-11-25 14:57:47 | I | - Patching LlamaSdpaAttention.forward in model.layers.12.self_attn
24-11-25 14:57:47 | I | - Patching LlamaSdpaAttention.forward in model.layers.13.self_attn
24-11-25 14:57:47 | I | - Patching LlamaSdpaAttention.forward in model.layers.14.self_attn
24-11-25 14:57:47 | I | - Patching LlamaSdpaAttention.forward in model.layers.15.self_attn
24-11-25 14:57:47 | I | - Patching LlamaSdpaAttention.forward in model.layers.16.self_attn
24-11-25 14:57:47 | I | - Patching LlamaSdpaAttention.forward in model.layers.17.self_attn
24-11-25 14:57:47 | I | - Patching LlamaSdpaAttention.forward in model.layers.18.self_attn
24-11-25 14:57:47 | I | - Patching LlamaSdpaAttention.forward in model.layers.19.self_attn
24-11-25 14:57:47 | I | - Patching LlamaSdpaAttention.forward in model.layers.20.self_attn
24-11-25 14:57:47 | I | - Patching LlamaSdpaAttention.forward in model.layers.21.self_attn
24-11-25 14:57:47 | I | * Development dtype is torch.float32
24-11-25 14:57:47 | I |   * Begin to QAT
24-11-25 14:57:47 | D | Setting JobRuntime:name=UNKNOWN_NAME
24-11-25 14:57:47 | D | Setting JobRuntime:name=utils
24-11-25 14:57:49 | I | distributed init (rank 0): env://
24-11-25 14:57:49 | I | initialized host 3fb0cc53fbf9 as rank 0
24-11-25 14:57:49 | I | nvidia-smi stats: {'gpu_0_mem_used_gb': 19.248046875, 'gpu_1_mem_used_gb': 0.001953125, 'gpu_2_mem_used_gb': 0.001953125, 'gpu_3_mem_used_gb': 0.0, 'gpu_4_mem_used_gb': 0.0, 'gpu_5_mem_used_gb': 0.0, 'gpu_6_mem_used_gb': 8.57421875, 'gpu_7_mem_used_gb': 0.001953125}
24-11-25 14:57:49 | I | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 1, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': 'layer_wise_quant', 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': True, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'log_nvidia_smi': False}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None, 'is_moe': False, 'is_model_parallel': False}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'zero_group_size': -1, 'save_zero_ckpt_fast': False, 'fp16': True, 'memory_efficient_fp16': True, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 1, 'num_workers_valid': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 32, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 20, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 32, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 100, 'stop_time_hours': 0.0, 'clip_norm': 2.0, 'sentence_avg': False, 'update_freq': [2], 'lr': [0.00015], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 1000, 'keep_interval_updates': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': True, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_best_checkpoints': False, 'no_save_optimizer_state': False, 'no_save_optimizer_state_on_training_finished': False, 'symlink_best_and_last_checkpoints': False, 'best_checkpoint_metric': 'loss_valid', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 's3_upload_path': None, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'input_quant_method': '', 'input_bits': -1, 'weight_quant_method': '', 'weight_bits': -1, 'smoothquant': False, 'smoothquant_alpha': 0.5, 'smoothquant_bitnet': False, 'input_bits_post': 8, 'hadamard_group': -1, 'cal_input_stat': 'none', 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807, 'stats_path': None, 'max_valid_steps': None}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'tiny_llama', 'load_ckpt': None, 'batch_size': 32, 'share_input_output_embed': False, 'sliding_window': None, 'rope_theta': 10000.0, 'checkpoint_activations': False, 'tokens_per_sample': 512, 'model_parallel_size': 1}, 'task': {'_name': 'kd', 'path_to_labels': None, 'data': '/data/gyy/YOCO/data_without_preprocess', 'tokens_per_sample': 512, 'batch_size_in_quant': 8, 'max_target_positions': None, 'llama_model': None, 'quant_acts_when_training': True, 'tiktoken_model': 'cl100k_base', 'batch_read_ahead': 1, 'pad_to_max_len': True, 'absolute_path': False, 'tokenizer_pad_to_multiple': 1, 'seed': 1, 'batch_size': 32}, 'criterion': {'_name': 'mse', 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.95)', 'adam_eps': 1e-06, 'weight_decay': 0.05, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'bf16': False, 'lr': [0.00015], 'block_wise': False}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 50, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 300000.0, 'lr': [0.00015]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None}
24-11-25 14:57:49 | I | LlamaModelDecoderLayer(
  (decoder): LlamaDecoderLayerInFairseq(
    (model): LlamaDecoderLayer(
      (self_attn): LlamaSdpaAttention(
        (q_proj): Linear(in_features=2048, out_features=2048, bias=False)
        (k_proj): Linear(in_features=2048, out_features=256, bias=False)
        (v_proj): Linear(in_features=2048, out_features=256, bias=False)
        (o_proj): Linear(in_features=2048, out_features=2048, bias=False)
        (rotary_emb): LlamaRotaryEmbedding()
        (q_rotary_emb): RotaryEmbedding()
        (k_rotary_emb): RotaryEmbedding()
      )
      (mlp): LlamaMLP(
        (gate_proj): Linear(in_features=2048, out_features=5632, bias=False)
        (up_proj): Linear(in_features=2048, out_features=5632, bias=False)
        (down_proj): Linear(in_features=5632, out_features=2048, bias=False)
        (act_fn): SiLU()
      )
      (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)
      (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)
    )
  )
  (model): LlamaDecoderLayerInFairseq(
    (model): LlamaDecoderLayer(
      (self_attn): LlamaSdpaAttention(
        (q_proj): Linear(in_features=2048, out_features=2048, bias=False)
        (k_proj): Linear(in_features=2048, out_features=256, bias=False)
        (v_proj): Linear(in_features=2048, out_features=256, bias=False)
        (o_proj): Linear(in_features=2048, out_features=2048, bias=False)
        (rotary_emb): LlamaRotaryEmbedding()
        (q_rotary_emb): RotaryEmbedding()
        (k_rotary_emb): RotaryEmbedding()
      )
      (mlp): LlamaMLP(
        (gate_proj): Linear(in_features=2048, out_features=5632, bias=False)
        (up_proj): Linear(in_features=2048, out_features=5632, bias=False)
        (down_proj): Linear(in_features=5632, out_features=2048, bias=False)
        (act_fn): SiLU()
      )
      (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)
      (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)
    )
  )
)
24-11-25 14:57:49 | I | task: KDTask
24-11-25 14:57:49 | I | model: LlamaModelDecoderLayer
24-11-25 14:57:49 | I | criterion: MSECriterion
24-11-25 14:57:49 | I | num. non-expert model params: 44,044,288 (num. trained: 44,044,288)
24-11-25 14:57:49 | I | num. expert model params: 0 (num. trained: 0)
24-11-25 14:57:50 | I | nvidia-smi stats: {'gpu_0_mem_used_gb': 19.248046875, 'gpu_1_mem_used_gb': 0.001953125, 'gpu_2_mem_used_gb': 0.001953125, 'gpu_3_mem_used_gb': 0.0, 'gpu_4_mem_used_gb': 0.0, 'gpu_5_mem_used_gb': 0.0, 'gpu_6_mem_used_gb': 10.7109375, 'gpu_7_mem_used_gb': 0.001953125}
24-11-25 14:57:50 | I | detected shared parameter: decoder.model.self_attn.q_proj.weight <- model.model.self_attn.q_proj.weight
24-11-25 14:57:50 | I | detected shared parameter: decoder.model.self_attn.q_proj.bias <- decoder.model.self_attn.k_proj.bias
24-11-25 14:57:50 | I | detected shared parameter: decoder.model.self_attn.q_proj.bias <- decoder.model.self_attn.v_proj.bias
24-11-25 14:57:50 | I | detected shared parameter: decoder.model.self_attn.q_proj.bias <- decoder.model.self_attn.o_proj.bias
24-11-25 14:57:50 | I | detected shared parameter: decoder.model.self_attn.q_proj.bias <- decoder.model.mlp.gate_proj.bias
24-11-25 14:57:50 | I | detected shared parameter: decoder.model.self_attn.q_proj.bias <- decoder.model.mlp.up_proj.bias
24-11-25 14:57:50 | I | detected shared parameter: decoder.model.self_attn.q_proj.bias <- decoder.model.mlp.down_proj.bias
24-11-25 14:57:50 | I | detected shared parameter: decoder.model.self_attn.q_proj.bias <- model.model.self_attn.q_proj.bias
24-11-25 14:57:50 | I | detected shared parameter: decoder.model.self_attn.q_proj.bias <- model.model.self_attn.k_proj.bias
24-11-25 14:57:50 | I | detected shared parameter: decoder.model.self_attn.q_proj.bias <- model.model.self_attn.v_proj.bias
24-11-25 14:57:50 | I | detected shared parameter: decoder.model.self_attn.q_proj.bias <- model.model.self_attn.o_proj.bias
24-11-25 14:57:50 | I | detected shared parameter: decoder.model.self_attn.q_proj.bias <- model.model.mlp.gate_proj.bias
24-11-25 14:57:50 | I | detected shared parameter: decoder.model.self_attn.q_proj.bias <- model.model.mlp.up_proj.bias
24-11-25 14:57:50 | I | detected shared parameter: decoder.model.self_attn.q_proj.bias <- model.model.mlp.down_proj.bias
24-11-25 14:57:50 | I | detected shared parameter: decoder.model.self_attn.k_proj.weight <- model.model.self_attn.k_proj.weight
24-11-25 14:57:50 | I | detected shared parameter: decoder.model.self_attn.v_proj.weight <- model.model.self_attn.v_proj.weight
24-11-25 14:57:50 | I | detected shared parameter: decoder.model.self_attn.o_proj.weight <- model.model.self_attn.o_proj.weight
24-11-25 14:57:50 | I | detected shared parameter: decoder.model.mlp.gate_proj.weight <- model.model.mlp.gate_proj.weight
24-11-25 14:57:50 | I | detected shared parameter: decoder.model.mlp.up_proj.weight <- model.model.mlp.up_proj.weight
24-11-25 14:57:50 | I | detected shared parameter: decoder.model.mlp.down_proj.weight <- model.model.mlp.down_proj.weight
24-11-25 14:57:50 | I | detected shared parameter: decoder.model.input_layernorm.weight <- model.model.input_layernorm.weight
24-11-25 14:57:50 | I | detected shared parameter: decoder.model.post_attention_layernorm.weight <- model.model.post_attention_layernorm.weight
24-11-25 14:57:50 | I | nvidia-smi stats: {'gpu_0_mem_used_gb': 19.248046875, 'gpu_1_mem_used_gb': 0.001953125, 'gpu_2_mem_used_gb': 0.001953125, 'gpu_3_mem_used_gb': 0.0, 'gpu_4_mem_used_gb': 0.0, 'gpu_5_mem_used_gb': 0.0, 'gpu_6_mem_used_gb': 10.751953125, 'gpu_7_mem_used_gb': 0.001953125}
24-11-25 14:57:50 | I | ***********************CUDA enviroments for all 1 workers***********************
24-11-25 14:57:50 | I | rank   0: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
24-11-25 14:57:50 | I | ***********************CUDA enviroments for all 1 workers***********************
24-11-25 14:57:50 | I | training on 1 devices (GPUs/TPUs)
24-11-25 14:57:50 | I | max tokens per GPU = None and batch size per GPU = 32
24-11-25 14:57:50 | I | nvidia-smi stats: {'gpu_0_mem_used_gb': 19.248046875, 'gpu_1_mem_used_gb': 0.001953125, 'gpu_2_mem_used_gb': 0.001953125, 'gpu_3_mem_used_gb': 0.0, 'gpu_4_mem_used_gb': 0.0, 'gpu_5_mem_used_gb': 0.0, 'gpu_6_mem_used_gb': 10.751953125, 'gpu_7_mem_used_gb': 0.001953125}
24-11-25 14:57:50 | I | loading train data for epoch 1
24-11-25 14:57:51 | I | *** 
 now in /data/gyy/YOCO/data_without_preprocess/shard/val/0.jsonl 
 ***
24-11-25 14:57:51 | I | *** 
 total_rows = 700 
 ***
24-11-25 14:57:51 | I | current row num = 0
24-11-25 14:57:51 | I | in forward_and_gen_teacher_outputs, Start iterating over samples
24-11-25 14:57:51 | I | current row num = 32
24-11-25 14:57:52 | I | current row num = 64
24-11-25 14:57:53 | I | current row num = 96
24-11-25 14:57:54 | I | current row num = 128
24-11-25 14:57:55 | I | current row num = 160
24-11-25 14:57:56 | I | current row num = 192
24-11-25 14:57:57 | I | current row num = 224
24-11-25 14:57:58 | I | current row num = 256
24-11-25 14:57:59 | I | current row num = 288
24-11-25 14:57:59 | I | current row num = 320
24-11-25 14:58:00 | I | current row num = 352
24-11-25 14:58:01 | I | current row num = 384
24-11-25 14:58:02 | I | current row num = 416
24-11-25 14:58:03 | I | current row num = 448
24-11-25 14:58:04 | I | current row num = 480
24-11-25 14:58:05 | I | current row num = 512
24-11-25 14:58:05 | I | current row num = 544
24-11-25 14:58:06 | I | current row num = 576
24-11-25 14:58:07 | I | current row num = 608
24-11-25 14:58:08 | I | current row num = 640
24-11-25 14:58:09 | I | *** 
 now in /data/gyy/YOCO/data_without_preprocess/shard/val/1.jsonl 
 ***
24-11-25 14:58:09 | I | *** 
 total_rows = 241 
 ***
24-11-25 14:58:09 | I | current row num = 0
24-11-25 14:58:10 | I | current row num = 32
24-11-25 14:58:11 | I | current row num = 64
24-11-25 14:58:11 | I | current row num = 96
24-11-25 14:58:12 | I | current row num = 128
24-11-25 14:58:13 | I | current row num = 160
24-11-25 14:58:14 | I | current row num = 192
24-11-25 14:58:15 | I | current row num = 224
24-11-25 14:58:17 | I | *** 
 now in /data/gyy/YOCO/data_without_preprocess/shard/val/2.jsonl 
 ***
24-11-25 14:58:17 | I | *** 
 total_rows = 509 
 ***
24-11-25 14:58:17 | I | current row num = 0
24-11-25 14:58:17 | I | current row num = 32
24-11-25 14:58:18 | I | current row num = 64
24-11-25 14:58:19 | I | current row num = 96
24-11-25 14:58:20 | I | current row num = 128
24-11-25 14:58:21 | I | current row num = 160
24-11-25 14:58:22 | I | current row num = 192
24-11-25 14:58:22 | I | current row num = 224
24-11-25 14:58:23 | I | current row num = 256
24-11-25 14:58:24 | I | current row num = 288
24-11-25 14:58:25 | I | current row num = 320
24-11-25 14:58:26 | I | current row num = 352
24-11-25 14:58:27 | I | current row num = 384
24-11-25 14:58:28 | I | current row num = 416
24-11-25 14:58:28 | I | current row num = 448
24-11-25 14:58:29 | I | current row num = 480
24-11-25 14:58:31 | I | *** 
 now in /data/gyy/YOCO/data_without_preprocess/shard/val/3.jsonl 
 ***
24-11-25 14:58:31 | I | *** 
 total_rows = 274 
 ***
24-11-25 14:58:31 | I | current row num = 0
24-11-25 14:58:31 | I | current row num = 32
24-11-25 14:58:32 | I | current row num = 64
24-11-25 14:58:33 | I | current row num = 96
24-11-25 14:58:35 | I | current row num = 128
24-11-25 14:58:36 | I | current row num = 160
24-11-25 14:58:37 | I | current row num = 192
24-11-25 14:58:40 | I | current row num = 224
24-11-25 14:58:43 | I | *** 
 now in /data/gyy/YOCO/data_without_preprocess/shard/val/4.jsonl 
 ***
24-11-25 14:58:43 | I | *** 
 total_rows = 191 
 ***
24-11-25 14:58:43 | I | current row num = 0
24-11-25 14:58:43 | I | current row num = 32
24-11-25 14:58:44 | I | current row num = 64
24-11-25 14:58:47 | I | current row num = 96
24-11-25 14:58:48 | I | current row num = 128
24-11-25 14:58:49 | I | current row num = 160
24-11-25 14:58:50 | I | *** 
 now in /data/gyy/YOCO/data_without_preprocess/shard/val/5.jsonl 
 ***
24-11-25 14:58:50 | I | *** 
 total_rows = 211 
 ***
24-11-25 14:58:50 | I | current row num = 0
24-11-25 14:58:50 | I | current row num = 32
24-11-25 14:58:51 | I | current row num = 64
24-11-25 14:58:54 | I | current row num = 96
24-11-25 14:58:55 | I | current row num = 128
24-11-25 14:58:58 | I | current row num = 160
24-11-25 14:58:58 | I | current row num = 192
24-11-25 14:59:01 | I | *** 
 now in /data/gyy/YOCO/data_without_preprocess/shard/val/6.jsonl 
 ***
24-11-25 14:59:01 | I | *** 
 total_rows = 241 
 ***
24-11-25 14:59:01 | I | current row num = 0
24-11-25 14:59:02 | I | current row num = 32
24-11-25 14:59:03 | I | current row num = 64
24-11-25 14:59:04 | I | current row num = 96
24-11-25 14:59:05 | I | current row num = 128
24-11-25 14:59:07 | I | current row num = 160
24-11-25 14:59:08 | I | current row num = 192
24-11-25 14:59:10 | I | *** 
 now in /data/gyy/YOCO/data_without_preprocess/shard/val/7.jsonl 
 ***
24-11-25 14:59:10 | I | *** 
 total_rows = 279 
 ***
24-11-25 14:59:10 | I | current row num = 0
24-11-25 14:59:10 | I | current row num = 32
24-11-25 14:59:11 | I | current row num = 64
24-11-25 14:59:12 | I | current row num = 96
24-11-25 14:59:13 | I | current row num = 128
24-11-25 14:59:14 | I | current row num = 160
24-11-25 14:59:15 | I | current row num = 192
24-11-25 14:59:16 | I | current row num = 224
24-11-25 14:59:16 | I | current row num = 256
24-11-25 14:59:18 | I | *** 
 now in /data/gyy/YOCO/data_without_preprocess/shard/val/8.jsonl 
 ***
24-11-25 14:59:18 | I | *** 
 total_rows = 186 
 ***
24-11-25 14:59:18 | I | current row num = 0
24-11-25 14:59:18 | I | current row num = 32
24-11-25 14:59:19 | I | current row num = 64
24-11-25 14:59:22 | I | current row num = 96
24-11-25 14:59:22 | I | current row num = 128
24-11-25 14:59:24 | I | current row num = 160
24-11-25 14:59:27 | I | *** 
 now in /data/gyy/YOCO/data_without_preprocess/shard/val/9.jsonl 
 ***
24-11-25 14:59:27 | I | *** 
 total_rows = 770 
 ***
24-11-25 14:59:27 | I | current row num = 0
24-11-25 14:59:27 | I | current row num = 32
24-11-25 14:59:30 | I | current row num = 64
24-11-25 14:59:31 | I | current row num = 96
24-11-25 14:59:32 | I | current row num = 128
24-11-25 14:59:34 | I | current row num = 160
24-11-25 14:59:35 | I | current row num = 192
24-11-25 14:59:36 | I | current row num = 224
24-11-25 14:59:37 | I | current row num = 256
24-11-25 14:59:38 | I | current row num = 288
24-11-25 14:59:39 | I | current row num = 320
24-11-25 14:59:42 | I | current row num = 352
24-11-25 14:59:43 | I | current row num = 384
24-11-25 14:59:43 | I | current row num = 416
24-11-25 14:59:46 | I | current row num = 448
24-11-25 14:59:47 | I | current row num = 480
24-11-25 14:59:49 | I | current row num = 512
24-11-25 14:59:50 | I | current row num = 544
24-11-25 14:59:51 | I | current row num = 576
24-11-25 14:59:51 | I | current row num = 608
24-11-25 14:59:52 | I | current row num = 640
24-11-25 14:59:53 | I | current row num = 672
24-11-25 14:59:54 | I | current row num = 704
24-11-25 14:59:55 | I | current row num = 736
24-11-25 14:59:56 | I | *** 
 now in /data/gyy/YOCO/data_without_preprocess/shard/val/10.jsonl 
 ***
24-11-25 14:59:56 | I | *** 
 total_rows = 271 
 ***
24-11-25 14:59:56 | I | current row num = 0
24-11-25 14:59:57 | I | current row num = 32
24-11-25 14:59:59 | I | current row num = 64
24-11-25 15:00:00 | I | current row num = 96
24-11-25 15:00:03 | I | current row num = 128
24-11-25 15:00:04 | I | current row num = 160
24-11-25 15:00:05 | I | current row num = 192
24-11-25 15:00:05 | I | current row num = 224
24-11-25 15:00:08 | I | current row num = 256
24-11-25 15:00:10 | I | *** 
 now in /data/gyy/YOCO/data_without_preprocess/shard/val/11.jsonl 
 ***
24-11-25 15:00:10 | I | *** 
 total_rows = 273 
 ***
24-11-25 15:00:10 | I | current row num = 0
24-11-25 15:00:10 | I | current row num = 32
24-11-25 15:00:11 | I | current row num = 64
24-11-25 15:00:12 | I | current row num = 96
24-11-25 15:00:13 | I | current row num = 128
24-11-25 15:00:14 | I | current row num = 160
24-11-25 15:00:15 | I | current row num = 192
24-11-25 15:00:16 | I | current row num = 224
24-11-25 15:00:17 | I | *** 
 now in /data/gyy/YOCO/data_without_preprocess/shard/val/12.jsonl 
 ***
24-11-25 15:00:17 | I | *** 
 total_rows = 301 
 ***
24-11-25 15:00:17 | I | current row num = 0
24-11-25 15:00:17 | I | current row num = 32
24-11-25 15:00:18 | I | current row num = 64
24-11-25 15:00:20 | I | current row num = 96
24-11-25 15:00:21 | I | current row num = 128
24-11-25 15:00:22 | I | current row num = 160
24-11-25 15:00:22 | I | current row num = 192
24-11-25 15:00:23 | I | current row num = 224
24-11-25 15:00:24 | I | current row num = 256
24-11-25 15:00:27 | I | *** 
 now in /data/gyy/YOCO/data_without_preprocess/shard/val/13.jsonl 
 ***
24-11-25 15:00:27 | I | *** 
 total_rows = 239 
 ***
24-11-25 15:00:27 | I | current row num = 0
24-11-25 15:00:28 | I | current row num = 32
24-11-25 15:00:30 | I | current row num = 64
24-11-25 15:00:31 | I | current row num = 96
24-11-25 15:00:32 | I | current row num = 128
24-11-25 15:00:34 | I | current row num = 160
24-11-25 15:00:35 | I | current row num = 192
24-11-25 15:00:36 | I | current row num = 224
24-11-25 15:00:37 | I | *** 
 now in /data/gyy/YOCO/data_without_preprocess/shard/val/14.jsonl 
 ***
24-11-25 15:00:37 | I | *** 
 total_rows = 262 
 ***
24-11-25 15:00:37 | I | current row num = 0
24-11-25 15:00:39 | I | current row num = 32
24-11-25 15:00:40 | I | current row num = 64
24-11-25 15:00:41 | I | current row num = 96
24-11-25 15:00:42 | I | current row num = 128
24-11-25 15:00:43 | I | current row num = 160
24-11-25 15:00:44 | I | current row num = 192
24-11-25 15:00:45 | I | current row num = 224
24-11-25 15:00:46 | I | *** 
 now in /data/gyy/YOCO/data_without_preprocess/shard/val/15.jsonl 
 ***
24-11-25 15:00:46 | I | *** 
 total_rows = 253 
 ***
24-11-25 15:00:46 | I | current row num = 0
24-11-25 15:00:46 | I | current row num = 32
24-11-25 15:00:47 | I | current row num = 64
24-11-25 15:00:48 | I | current row num = 96
24-11-25 15:00:49 | I | current row num = 128
24-11-25 15:00:50 | I | current row num = 160
24-11-25 15:00:51 | I | current row num = 192
24-11-25 15:00:53 | I | current row num = 224
24-11-25 15:00:55 | I | *** 
 now in /data/gyy/YOCO/data_without_preprocess/shard/val/16.jsonl 
 ***
24-11-25 15:00:55 | I | *** 
 total_rows = 523 
 ***
24-11-25 15:00:55 | I | current row num = 0
24-11-25 15:00:56 | I | current row num = 32
24-11-25 15:00:57 | I | current row num = 64
24-11-25 15:00:59 | I | current row num = 96
24-11-25 15:01:00 | I | current row num = 128
24-11-25 15:01:03 | I | current row num = 160
24-11-25 15:01:04 | I | current row num = 192
24-11-25 15:01:04 | I | current row num = 224
24-11-25 15:01:05 | I | current row num = 256
24-11-25 15:01:06 | I | current row num = 288
24-11-25 15:01:08 | I | current row num = 320
24-11-25 15:01:09 | I | current row num = 352
24-11-25 15:01:10 | I | current row num = 384
24-11-25 15:01:11 | I | current row num = 416
24-11-25 15:01:13 | I | current row num = 448
24-11-25 15:01:14 | I | current row num = 480
24-11-25 15:01:17 | I | *** 
 now in /data/gyy/YOCO/data_without_preprocess/shard/val/17.jsonl 
 ***
24-11-25 15:01:17 | I | *** 
 total_rows = 251 
 ***
24-11-25 15:01:17 | I | current row num = 0
24-11-25 15:01:18 | I | current row num = 32
24-11-25 15:01:18 | I | current row num = 64
24-11-25 15:01:19 | I | current row num = 96
24-11-25 15:01:20 | I | current row num = 128
24-11-25 15:01:21 | I | current row num = 160
24-11-25 15:01:22 | I | current row num = 192
24-11-25 15:01:23 | I | current row num = 224
24-11-25 15:01:26 | I | *** 
 now in /data/gyy/YOCO/data_without_preprocess/shard/val/18.jsonl 
 ***
24-11-25 15:01:26 | I | *** 
 total_rows = 274 
 ***
24-11-25 15:01:26 | I | current row num = 0
24-11-25 15:01:28 | I | current row num = 32
24-11-25 15:01:31 | I | current row num = 64
24-11-25 15:01:32 | I | current row num = 96
24-11-25 15:01:33 | I | current row num = 128
24-11-25 15:01:34 | I | current row num = 160
24-11-25 15:01:35 | I | current row num = 192
24-11-25 15:01:37 | I | current row num = 224
24-11-25 15:01:38 | I | current row num = 256
24-11-25 15:01:40 | I | *** 
 now in /data/gyy/YOCO/data_without_preprocess/shard/val/19.jsonl 
 ***
24-11-25 15:01:40 | I | *** 
 total_rows = 315 
 ***
24-11-25 15:01:40 | I | current row num = 0
24-11-25 15:01:40 | I | current row num = 32
24-11-25 15:01:41 | I | current row num = 64
24-11-25 15:01:43 | I | current row num = 96
24-11-25 15:01:46 | I | current row num = 128
24-11-25 15:01:47 | I | current row num = 160
24-11-25 15:01:48 | I | current row num = 192
24-11-25 15:01:49 | I | current row num = 224
24-11-25 15:01:50 | I | current row num = 256
24-11-25 15:01:50 | I | current row num = 288
24-11-25 15:01:52 | I | current row num = 320
24-11-25 15:01:54 | I | loading train data for epoch 1
24-11-25 15:01:55 | I | *** 
 now in /data/gyy/YOCO/data_without_preprocess/shard/val/0.jsonl 
 ***
24-11-25 15:01:55 | I | *** 
 total_rows = 700 
 ***
24-11-25 15:01:55 | I | current row num = 0
24-11-25 15:01:55 | I | in forward_and_gen_args_and_kwargs, Start iterating over samples
24-11-25 15:01:55 | I | No existing checkpoint found checkpoints/checkpoint_last.pt
24-11-25 15:01:55 | I | loading train data for epoch 1
24-11-25 15:01:55 | I | loading valid data for epoch 1
24-11-25 15:02:03 | I | begin training epoch 1
24-11-25 15:02:03 | I | Start iterating over samples
24-11-25 15:02:03 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 15:02:03 | I | in layer model.layers.0
24-11-25 15:02:03 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 15:02:03 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 15:02:03 | I | - Evaluator: gptq
24-11-25 15:02:03 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 15:02:03 | I | - Batch_size: 8
24-11-25 15:02:03 | I |   + Max_seq_length: 2048
24-11-25 15:02:41 | I |     - Results:
24-11-25 15:02:41 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 15:02:41 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 15:02:41 | I |       |wikitext |      1|word_perplexity|7.7077|  |7.7077|
24-11-25 15:02:41 | I |       |val_valid|      1|word_perplexity|8.9799|  |8.9799|
24-11-25 15:02:41 | I |       
24-11-25 15:02:41 | I | quantizing weights for layer model.layers.0
24-11-25 15:02:41 | I | collecting info in model.layers.0
24-11-25 15:02:41 | I | collecting info in model.layers.0
24-11-25 15:02:41 | I | collecting info in model.layers.0
24-11-25 15:02:41 | I | collecting info in model.layers.0
24-11-25 15:02:42 | I | collecting calibration activations in model.layers.0
24-11-25 15:02:42 | I | collecting calibration activations in model.layers.0
24-11-25 15:02:42 | I | collecting calibration activations in model.layers.0
24-11-25 15:02:42 | I | collecting calibration activations in model.layers.0
24-11-25 15:02:43 | I | - Quantizing decoder layer model.layers.0
24-11-25 15:02:43 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 15:02:43 | I |       - range scale = [    1.0000]
24-11-25 15:02:43 | I |         sum  error  = [    0.0587]
24-11-25 15:02:43 | I |         best error  = [    0.0587]
24-11-25 15:02:43 | I |     + error = [0.0587]
24-11-25 15:02:44 | I |       - range scale = [    1.0000]
24-11-25 15:02:44 | I |         sum  error  = [    0.5987]
24-11-25 15:02:44 | I |         best error  = [    0.5987]
24-11-25 15:02:44 | I |     + error = [0.5987]
24-11-25 15:02:44 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 15:02:45 | I |       - range scale = [    1.0000]
24-11-25 15:02:45 | I |         sum  error  = [    0.0736]
24-11-25 15:02:45 | I |         best error  = [    0.0736]
24-11-25 15:02:45 | I |     + error = [0.0736]
24-11-25 15:02:46 | I |       - range scale = [    1.0000]
24-11-25 15:02:46 | I |         sum  error  = [    0.5123]
24-11-25 15:02:46 | I |         best error  = [    0.5123]
24-11-25 15:02:46 | I |     + error = [0.5123]
24-11-25 15:02:46 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 15:02:47 | I |       - range scale = [    1.0000]
24-11-25 15:02:47 | I |         sum  error  = [    0.2509]
24-11-25 15:02:47 | I |         best error  = [    0.2509]
24-11-25 15:02:47 | I |     + error = [0.2509]
24-11-25 15:02:48 | I |       - range scale = [    1.0000]
24-11-25 15:02:48 | I |         sum  error  = [    1.8308]
24-11-25 15:02:48 | I |         best error  = [    1.8308]
24-11-25 15:02:48 | I |     + error = [1.8308]
24-11-25 15:02:48 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 15:02:49 | I |       - range scale = [    1.0000]
24-11-25 15:02:49 | I |         sum  error  = [    0.0565]
24-11-25 15:02:49 | I |         best error  = [    0.0565]
24-11-25 15:02:49 | I |     + error = [0.0565]
24-11-25 15:02:50 | I |       - range scale = [    1.0000]
24-11-25 15:02:50 | I |         sum  error  = [    0.5486]
24-11-25 15:02:50 | I |         best error  = [    0.5486]
24-11-25 15:02:50 | I |     + error = [0.5486]
24-11-25 15:02:50 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 15:02:50 | I |       - range scale = [    1.0000]
24-11-25 15:02:50 | I |         sum  error  = [    1.0465]
24-11-25 15:02:50 | I |         best error  = [    1.0465]
24-11-25 15:02:50 | I |     + error = [1.0465]
24-11-25 15:02:52 | I |       - range scale = [    1.0000]
24-11-25 15:02:52 | I |         sum  error  = [   11.5890]
24-11-25 15:02:52 | I |         best error  = [   11.5890]
24-11-25 15:02:52 | I |     + error = [11.5890]
24-11-25 15:02:52 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 15:02:53 | I |       - range scale = [    1.0000]
24-11-25 15:02:53 | I |         sum  error  = [    1.2126]
24-11-25 15:02:53 | I |         best error  = [    1.2126]
24-11-25 15:02:53 | I |     + error = [1.2126]
24-11-25 15:02:53 | I |       - range scale = [    1.0000]
24-11-25 15:02:53 | I |         sum  error  = [   11.9613]
24-11-25 15:02:53 | I |         best error  = [   11.9613]
24-11-25 15:02:53 | I |     + error = [11.9613]
24-11-25 15:02:54 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 15:02:55 | I |       - range scale = [    1.0000]
24-11-25 15:02:55 | I |         sum  error  = [    2.3671]
24-11-25 15:02:55 | I |         best error  = [    2.3671]
24-11-25 15:02:55 | I |     + error = [2.3671]
24-11-25 15:02:55 | I |       - range scale = [    1.0000]
24-11-25 15:02:55 | I |         sum  error  = [   12.0711]
24-11-25 15:02:55 | I |         best error  = [   12.0711]
24-11-25 15:02:55 | I |     + error = [12.0711]
24-11-25 15:02:56 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 15:02:58 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 15:02:59 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 15:03:01 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 15:03:02 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 15:03:04 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 15:03:06 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 15:03:09 | I | quantizing activations for layer model.layers.0
24-11-25 15:03:09 | I | collecting info in model.layers.0
24-11-25 15:03:09 | I | collecting info in model.layers.0
24-11-25 15:03:09 | I | collecting info in model.layers.0
24-11-25 15:03:09 | I | collecting info in model.layers.0
24-11-25 15:03:10 | I | collecting calibration activations in model.layers.0
24-11-25 15:03:10 | I | collecting calibration activations in model.layers.0
24-11-25 15:03:10 | I | collecting calibration activations in model.layers.0
24-11-25 15:03:10 | I | collecting calibration activations in model.layers.0
24-11-25 15:03:13 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 15:03:13 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 15:03:13 | I | - Evaluator: gptq
24-11-25 15:03:13 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 15:03:13 | I | - Batch_size: 8
24-11-25 15:03:13 | I |   + Max_seq_length: 2048
24-11-25 15:03:55 | I |     - Results:
24-11-25 15:03:55 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 15:03:55 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 15:03:55 | I |       |wikitext |      1|word_perplexity|7.7948|  |7.7948|
24-11-25 15:03:55 | I |       |val_valid|      1|word_perplexity|9.0822|  |9.0822|
24-11-25 15:03:55 | I |       
24-11-25 15:03:55 | I | forward this layer
24-11-25 15:03:55 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/00.pt
24-11-25 15:03:55 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/00.pt
24-11-25 15:03:55 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: True
24-11-25 15:03:55 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 15:03:55 | I | nan: first position tensor([0, 0], device='cuda:0')
24-11-25 15:03:55 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: True
24-11-25 15:03:55 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 15:03:55 | I | nan: first position tensor([0, 0], device='cuda:0')
24-11-25 15:03:55 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: True
24-11-25 15:03:55 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 15:03:55 | I | nan: first position tensor([0, 0], device='cuda:0')
24-11-25 15:03:55 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: True
24-11-25 15:03:55 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 15:03:55 | I | nan: first position tensor([0, 0], device='cuda:0')
24-11-25 15:03:55 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: True
24-11-25 15:03:55 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: True
24-11-25 15:03:55 | I | inf: first position tensor([197,   8], device='cuda:0')
24-11-25 15:03:55 | I | nan: first position tensor([5007,    0], device='cuda:0')
24-11-25 15:03:55 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: True
24-11-25 15:03:55 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: True
24-11-25 15:03:55 | I | inf: first position tensor([197, 165], device='cuda:0')
24-11-25 15:03:55 | I | nan: first position tensor([5007,    0], device='cuda:0')
24-11-25 15:03:55 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 15:03:55 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: True
24-11-25 15:03:55 | I | inf: first position tensor([   4, 5007], device='cuda:0')
24-11-25 15:03:55 | I | in layer model.layers.0
24-11-25 15:03:55 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 15:03:55 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 15:03:55 | I | - Evaluator: gptq
24-11-25 15:03:55 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 15:03:55 | I | - Batch_size: 8
24-11-25 15:03:55 | I |   + Max_seq_length: 2048
24-11-25 15:04:34 | I |     - Results:
24-11-25 15:04:34 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 15:04:34 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 15:04:34 | I |       |wikitext |      1|word_perplexity|7.7077|  |7.7077|
24-11-25 15:04:34 | I |       |val_valid|      1|word_perplexity|8.9799|  |8.9799|
24-11-25 15:04:34 | I |       
24-11-25 15:04:34 | I | quantizing weights for layer model.layers.0
24-11-25 15:04:34 | I | collecting info in model.layers.0
24-11-25 15:04:34 | I | collecting info in model.layers.0
24-11-25 15:04:34 | I | collecting info in model.layers.0
24-11-25 15:04:34 | I | collecting info in model.layers.0
24-11-25 15:04:34 | I | collecting calibration activations in model.layers.0
24-11-25 15:04:34 | I | collecting calibration activations in model.layers.0
24-11-25 15:04:34 | I | collecting calibration activations in model.layers.0
24-11-25 15:04:34 | I | collecting calibration activations in model.layers.0
24-11-25 15:04:35 | I | - Quantizing decoder layer model.layers.0
24-11-25 15:04:35 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 15:04:35 | I |       - range scale = [    1.0000]
24-11-25 15:04:35 | I |         sum  error  = [    0.0599]
24-11-25 15:04:35 | I |         best error  = [    0.0599]
24-11-25 15:04:35 | I |     + error = [0.0599]
24-11-25 15:04:36 | I |       - range scale = [    1.0000]
24-11-25 15:04:36 | I |         sum  error  = [    0.6232]
24-11-25 15:04:36 | I |         best error  = [    0.6232]
24-11-25 15:04:36 | I |     + error = [0.6232]
24-11-25 15:04:36 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 15:04:37 | I |       - range scale = [    1.0000]
24-11-25 15:04:37 | I |         sum  error  = [    0.0748]
24-11-25 15:04:37 | I |         best error  = [    0.0748]
24-11-25 15:04:37 | I |     + error = [0.0748]
24-11-25 15:04:38 | I |       - range scale = [    1.0000]
24-11-25 15:04:38 | I |         sum  error  = [    0.5184]
24-11-25 15:04:38 | I |         best error  = [    0.5184]
24-11-25 15:04:38 | I |     + error = [0.5184]
24-11-25 15:04:38 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 15:04:39 | I |       - range scale = [    1.0000]
24-11-25 15:04:39 | I |         sum  error  = [    0.2527]
24-11-25 15:04:39 | I |         best error  = [    0.2527]
24-11-25 15:04:39 | I |     + error = [0.2527]
24-11-25 15:04:39 | I |       - range scale = [    1.0000]
24-11-25 15:04:39 | I |         sum  error  = [    1.8332]
24-11-25 15:04:39 | I |         best error  = [    1.8332]
24-11-25 15:04:39 | I |     + error = [1.8332]
24-11-25 15:04:39 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 15:04:40 | I |       - range scale = [    1.0000]
24-11-25 15:04:40 | I |         sum  error  = [    0.0589]
24-11-25 15:04:40 | I |         best error  = [    0.0589]
24-11-25 15:04:40 | I |     + error = [0.0589]
24-11-25 15:04:41 | I |       - range scale = [    1.0000]
24-11-25 15:04:41 | I |         sum  error  = [    0.5645]
24-11-25 15:04:41 | I |         best error  = [    0.5645]
24-11-25 15:04:41 | I |     + error = [0.5645]
24-11-25 15:04:41 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 15:04:42 | I |       - range scale = [    1.0000]
24-11-25 15:04:42 | I |         sum  error  = [    1.0447]
24-11-25 15:04:42 | I |         best error  = [    1.0447]
24-11-25 15:04:42 | I |     + error = [1.0447]
24-11-25 15:04:42 | I |       - range scale = [    1.0000]
24-11-25 15:04:42 | I |         sum  error  = [   11.5777]
24-11-25 15:04:42 | I |         best error  = [   11.5777]
24-11-25 15:04:42 | I |     + error = [11.5777]
24-11-25 15:04:43 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 15:04:43 | I |       - range scale = [    1.0000]
24-11-25 15:04:43 | I |         sum  error  = [    1.2106]
24-11-25 15:04:43 | I |         best error  = [    1.2106]
24-11-25 15:04:43 | I |     + error = [1.2106]
24-11-25 15:04:44 | I |       - range scale = [    1.0000]
24-11-25 15:04:44 | I |         sum  error  = [   11.9537]
24-11-25 15:04:44 | I |         best error  = [   11.9537]
24-11-25 15:04:44 | I |     + error = [11.9537]
24-11-25 15:04:44 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 15:04:45 | I |       - range scale = [    1.0000]
24-11-25 15:04:45 | I |         sum  error  = [    3.2576]
24-11-25 15:04:45 | I |         best error  = [    3.2576]
24-11-25 15:04:45 | I |     + error = [3.2576]
24-11-25 15:04:46 | I |       - range scale = [    1.0000]
24-11-25 15:04:46 | I |         sum  error  = [   16.3244]
24-11-25 15:04:46 | I |         best error  = [   16.3244]
24-11-25 15:04:46 | I |     + error = [16.3244]
24-11-25 15:04:46 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 15:04:47 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 15:04:49 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 15:04:50 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 15:04:51 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 15:04:53 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 15:04:54 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 15:04:58 | I | quantizing activations for layer model.layers.0
24-11-25 15:04:58 | I | collecting info in model.layers.0
24-11-25 15:04:58 | I | collecting info in model.layers.0
24-11-25 15:04:58 | I | collecting info in model.layers.0
24-11-25 15:04:58 | I | collecting info in model.layers.0
24-11-25 15:04:58 | I | collecting calibration activations in model.layers.0
24-11-25 15:04:58 | I | collecting calibration activations in model.layers.0
24-11-25 15:04:58 | I | collecting calibration activations in model.layers.0
24-11-25 15:04:58 | I | collecting calibration activations in model.layers.0
24-11-25 15:05:00 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 15:05:00 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 15:05:00 | I | - Evaluator: gptq
24-11-25 15:05:00 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 15:05:00 | I | - Batch_size: 8
24-11-25 15:05:00 | I |   + Max_seq_length: 2048
24-11-25 15:05:42 | I |     - Results:
24-11-25 15:05:42 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 15:05:42 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 15:05:43 | I |       |wikitext |      1|word_perplexity|7.7755|  |7.7755|
24-11-25 15:05:43 | I |       |val_valid|      1|word_perplexity|9.0547|  |9.0547|
24-11-25 15:05:43 | I |       
24-11-25 15:05:43 | I | forward this layer
24-11-25 15:05:43 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/01.pt
24-11-25 15:05:43 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/01.pt
24-11-25 15:05:43 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: True
24-11-25 15:05:43 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 15:05:43 | I | nan: first position tensor([0, 0], device='cuda:0')
24-11-25 15:05:43 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: True
24-11-25 15:05:43 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 15:05:43 | I | nan: first position tensor([0, 0], device='cuda:0')
24-11-25 15:05:43 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: True
24-11-25 15:05:43 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 15:05:43 | I | nan: first position tensor([0, 0], device='cuda:0')
24-11-25 15:05:43 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: True
24-11-25 15:05:43 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 15:05:43 | I | nan: first position tensor([0, 0], device='cuda:0')
24-11-25 15:05:43 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: True
24-11-25 15:05:43 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: True
24-11-25 15:05:43 | I | inf: first position tensor([197,  17], device='cuda:0')
24-11-25 15:05:43 | I | nan: first position tensor([5007,    0], device='cuda:0')
24-11-25 15:05:43 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: True
24-11-25 15:05:43 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: True
24-11-25 15:05:43 | I | inf: first position tensor([197, 165], device='cuda:0')
24-11-25 15:05:43 | I | nan: first position tensor([5007,    0], device='cuda:0')
24-11-25 15:05:43 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 15:05:43 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: True
24-11-25 15:05:43 | I | inf: first position tensor([   4, 5007], device='cuda:0')
24-11-25 15:05:43 | I | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
24-11-25 15:05:43 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 15:05:43 | I | in layer model.layers.0
24-11-25 15:05:43 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 15:05:43 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 15:05:43 | I | - Evaluator: gptq
24-11-25 15:05:43 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 15:05:43 | I | - Batch_size: 8
24-11-25 15:05:43 | I |   + Max_seq_length: 2048
24-11-25 15:06:21 | I |     - Results:
24-11-25 15:06:21 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 15:06:21 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 15:06:21 | I |       |wikitext |      1|word_perplexity|7.7077|  |7.7077|
24-11-25 15:06:21 | I |       |val_valid|      1|word_perplexity|8.9799|  |8.9799|
24-11-25 15:06:21 | I |       
24-11-25 15:06:21 | I | quantizing weights for layer model.layers.0
24-11-25 15:06:21 | I | collecting info in model.layers.0
24-11-25 15:06:21 | I | collecting info in model.layers.0
24-11-25 15:06:21 | I | collecting info in model.layers.0
24-11-25 15:06:21 | I | collecting info in model.layers.0
24-11-25 15:06:22 | I | collecting calibration activations in model.layers.0
24-11-25 15:06:22 | I | collecting calibration activations in model.layers.0
24-11-25 15:06:22 | I | collecting calibration activations in model.layers.0
24-11-25 15:06:22 | I | collecting calibration activations in model.layers.0
24-11-25 15:06:23 | I | - Quantizing decoder layer model.layers.0
24-11-25 15:06:23 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 15:06:23 | I |       - range scale = [    1.0000]
24-11-25 15:06:23 | I |         sum  error  = [    0.0602]
24-11-25 15:06:23 | I |         best error  = [    0.0602]
24-11-25 15:06:23 | I |     + error = [0.0602]
24-11-25 15:06:24 | I |       - range scale = [    1.0000]
24-11-25 15:06:24 | I |         sum  error  = [    0.6180]
24-11-25 15:06:24 | I |         best error  = [    0.6180]
24-11-25 15:06:24 | I |     + error = [0.6180]
24-11-25 15:06:24 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 15:06:25 | I |       - range scale = [    1.0000]
24-11-25 15:06:25 | I |         sum  error  = [    0.0757]
24-11-25 15:06:25 | I |         best error  = [    0.0757]
24-11-25 15:06:25 | I |     + error = [0.0757]
24-11-25 15:06:26 | I |       - range scale = [    1.0000]
24-11-25 15:06:26 | I |         sum  error  = [    0.5145]
24-11-25 15:06:26 | I |         best error  = [    0.5145]
24-11-25 15:06:26 | I |     + error = [0.5145]
24-11-25 15:06:26 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 15:06:26 | I |       - range scale = [    1.0000]
24-11-25 15:06:26 | I |         sum  error  = [    0.2537]
24-11-25 15:06:26 | I |         best error  = [    0.2537]
24-11-25 15:06:26 | I |     + error = [0.2537]
24-11-25 15:06:27 | I |       - range scale = [    1.0000]
24-11-25 15:06:27 | I |         sum  error  = [    1.8361]
24-11-25 15:06:27 | I |         best error  = [    1.8361]
24-11-25 15:06:27 | I |     + error = [1.8361]
24-11-25 15:06:27 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 15:06:28 | I |       - range scale = [    1.0000]
24-11-25 15:06:28 | I |         sum  error  = [    0.0582]
24-11-25 15:06:28 | I |         best error  = [    0.0582]
24-11-25 15:06:28 | I |     + error = [0.0582]
24-11-25 15:06:29 | I |       - range scale = [    1.0000]
24-11-25 15:06:29 | I |         sum  error  = [    0.5600]
24-11-25 15:06:29 | I |         best error  = [    0.5600]
24-11-25 15:06:29 | I |     + error = [0.5600]
24-11-25 15:06:29 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 15:06:30 | I |       - range scale = [    1.0000]
24-11-25 15:06:30 | I |         sum  error  = [    1.0364]
24-11-25 15:06:30 | I |         best error  = [    1.0364]
24-11-25 15:06:30 | I |     + error = [1.0364]
24-11-25 15:06:30 | I |       - range scale = [    1.0000]
24-11-25 15:06:30 | I |         sum  error  = [   11.4794]
24-11-25 15:06:30 | I |         best error  = [   11.4794]
24-11-25 15:06:30 | I |     + error = [11.4794]
24-11-25 15:06:30 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 15:06:31 | I |       - range scale = [    1.0000]
24-11-25 15:06:31 | I |         sum  error  = [    1.1999]
24-11-25 15:06:31 | I |         best error  = [    1.1999]
24-11-25 15:06:31 | I |     + error = [1.1999]
24-11-25 15:06:32 | I |       - range scale = [    1.0000]
24-11-25 15:06:32 | I |         sum  error  = [   11.8527]
24-11-25 15:06:32 | I |         best error  = [   11.8527]
24-11-25 15:06:32 | I |     + error = [11.8527]
24-11-25 15:06:32 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 15:06:33 | I |       - range scale = [    1.0000]
24-11-25 15:06:33 | I |         sum  error  = [    3.1467]
24-11-25 15:06:33 | I |         best error  = [    3.1467]
24-11-25 15:06:33 | I |     + error = [3.1467]
24-11-25 15:06:34 | I |       - range scale = [    1.0000]
24-11-25 15:06:34 | I |         sum  error  = [   16.2229]
24-11-25 15:06:34 | I |         best error  = [   16.2229]
24-11-25 15:06:34 | I |     + error = [16.2229]
24-11-25 15:06:34 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 15:06:35 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 15:06:37 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 15:06:38 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 15:06:40 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 15:06:41 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 15:06:42 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 15:06:46 | I | quantizing activations for layer model.layers.0
24-11-25 15:06:46 | I | collecting info in model.layers.0
24-11-25 15:06:46 | I | collecting info in model.layers.0
24-11-25 15:06:46 | I | collecting info in model.layers.0
24-11-25 15:06:46 | I | collecting info in model.layers.0
24-11-25 15:06:46 | I | collecting calibration activations in model.layers.0
24-11-25 15:06:46 | I | collecting calibration activations in model.layers.0
24-11-25 15:06:47 | I | collecting calibration activations in model.layers.0
24-11-25 15:06:47 | I | collecting calibration activations in model.layers.0
24-11-25 15:06:48 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 15:06:48 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 15:06:48 | I | - Evaluator: gptq
24-11-25 15:06:48 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 15:06:48 | I | - Batch_size: 8
24-11-25 15:06:48 | I |   + Max_seq_length: 2048
24-11-25 15:07:30 | I |     - Results:
24-11-25 15:07:30 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 15:07:30 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 15:07:30 | I |       |wikitext |      1|word_perplexity|7.7664|  |7.7664|
24-11-25 15:07:30 | I |       |val_valid|      1|word_perplexity|9.0552|  |9.0552|
24-11-25 15:07:30 | I |       
24-11-25 15:07:30 | I | forward this layer
24-11-25 15:07:30 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/02.pt
24-11-25 15:07:30 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/02.pt
24-11-25 15:07:30 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: True
24-11-25 15:07:30 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 15:07:30 | I | nan: first position tensor([0, 0], device='cuda:0')
24-11-25 15:07:30 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: True
24-11-25 15:07:30 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 15:07:30 | I | nan: first position tensor([0, 0], device='cuda:0')
24-11-25 15:07:30 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: True
24-11-25 15:07:30 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 15:07:30 | I | nan: first position tensor([0, 0], device='cuda:0')
24-11-25 15:07:30 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: True
24-11-25 15:07:30 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 15:07:30 | I | nan: first position tensor([0, 0], device='cuda:0')
24-11-25 15:07:30 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: True
24-11-25 15:07:30 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: True
24-11-25 15:07:30 | I | inf: first position tensor([197,  85], device='cuda:0')
24-11-25 15:07:30 | I | nan: first position tensor([5007,    0], device='cuda:0')
24-11-25 15:07:30 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: True
24-11-25 15:07:30 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: True
24-11-25 15:07:30 | I | inf: first position tensor([197, 480], device='cuda:0')
24-11-25 15:07:30 | I | nan: first position tensor([5007,    0], device='cuda:0')
24-11-25 15:07:30 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 15:07:30 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: True
24-11-25 15:07:30 | I | inf: first position tensor([  69, 5007], device='cuda:0')
24-11-25 15:07:30 | I | in layer model.layers.0
24-11-25 15:07:30 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 15:07:30 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 15:07:30 | I | - Evaluator: gptq
24-11-25 15:07:30 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 15:07:30 | I | - Batch_size: 8
24-11-25 15:07:30 | I |   + Max_seq_length: 2048
24-11-25 15:08:08 | I |     - Results:
24-11-25 15:08:09 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 15:08:09 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 15:08:09 | I |       |wikitext |      1|word_perplexity|7.7077|  |7.7077|
24-11-25 15:08:09 | I |       |val_valid|      1|word_perplexity|8.9799|  |8.9799|
24-11-25 15:08:09 | I |       
24-11-25 15:08:09 | I | quantizing weights for layer model.layers.0
24-11-25 15:08:09 | I | collecting info in model.layers.0
24-11-25 15:08:09 | I | collecting info in model.layers.0
24-11-25 15:08:09 | I | collecting info in model.layers.0
24-11-25 15:08:09 | I | collecting info in model.layers.0
24-11-25 15:08:09 | I | collecting calibration activations in model.layers.0
24-11-25 15:08:09 | I | collecting calibration activations in model.layers.0
24-11-25 15:08:09 | I | collecting calibration activations in model.layers.0
24-11-25 15:08:09 | I | collecting calibration activations in model.layers.0
24-11-25 15:08:10 | I | - Quantizing decoder layer model.layers.0
24-11-25 15:08:10 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 15:08:10 | I |       - range scale = [    1.0000]
24-11-25 15:08:10 | I |         sum  error  = [    0.0600]
24-11-25 15:08:10 | I |         best error  = [    0.0600]
24-11-25 15:08:10 | I |     + error = [0.0600]
24-11-25 15:08:11 | I |       - range scale = [    1.0000]
24-11-25 15:08:11 | I |         sum  error  = [    0.6166]
24-11-25 15:08:11 | I |         best error  = [    0.6166]
24-11-25 15:08:11 | I |     + error = [0.6166]
24-11-25 15:08:11 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 15:08:12 | I |       - range scale = [    1.0000]
24-11-25 15:08:12 | I |         sum  error  = [    0.0754]
24-11-25 15:08:12 | I |         best error  = [    0.0754]
24-11-25 15:08:12 | I |     + error = [0.0754]
24-11-25 15:08:13 | I |       - range scale = [    1.0000]
24-11-25 15:08:13 | I |         sum  error  = [    0.5173]
24-11-25 15:08:13 | I |         best error  = [    0.5173]
24-11-25 15:08:13 | I |     + error = [0.5173]
24-11-25 15:08:13 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 15:08:14 | I |       - range scale = [    1.0000]
24-11-25 15:08:14 | I |         sum  error  = [    0.2486]
24-11-25 15:08:14 | I |         best error  = [    0.2486]
24-11-25 15:08:14 | I |     + error = [0.2486]
24-11-25 15:08:14 | I |       - range scale = [    1.0000]
24-11-25 15:08:14 | I |         sum  error  = [    1.8164]
24-11-25 15:08:14 | I |         best error  = [    1.8164]
24-11-25 15:08:14 | I |     + error = [1.8164]
24-11-25 15:08:14 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 15:08:15 | I |       - range scale = [    1.0000]
24-11-25 15:08:15 | I |         sum  error  = [    0.0556]
24-11-25 15:08:15 | I |         best error  = [    0.0556]
24-11-25 15:08:15 | I |     + error = [0.0556]
24-11-25 15:08:16 | I |       - range scale = [    1.0000]
24-11-25 15:08:16 | I |         sum  error  = [    0.5325]
24-11-25 15:08:16 | I |         best error  = [    0.5325]
24-11-25 15:08:16 | I |     + error = [0.5325]
24-11-25 15:08:16 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 15:08:17 | I |       - range scale = [    1.0000]
24-11-25 15:08:17 | I |         sum  error  = [    1.0416]
24-11-25 15:08:17 | I |         best error  = [    1.0416]
24-11-25 15:08:17 | I |     + error = [1.0416]
24-11-25 15:08:17 | I |       - range scale = [    1.0000]
24-11-25 15:08:17 | I |         sum  error  = [   11.5416]
24-11-25 15:08:17 | I |         best error  = [   11.5416]
24-11-25 15:08:17 | I |     + error = [11.5416]
24-11-25 15:08:18 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 15:08:18 | I |       - range scale = [    1.0000]
24-11-25 15:08:18 | I |         sum  error  = [    1.2071]
24-11-25 15:08:18 | I |         best error  = [    1.2071]
24-11-25 15:08:18 | I |     + error = [1.2071]
24-11-25 15:08:19 | I |       - range scale = [    1.0000]
24-11-25 15:08:19 | I |         sum  error  = [   11.9032]
24-11-25 15:08:19 | I |         best error  = [   11.9032]
24-11-25 15:08:19 | I |     + error = [11.9032]
24-11-25 15:08:19 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 15:08:20 | I |       - range scale = [    1.0000]
24-11-25 15:08:20 | I |         sum  error  = [    2.6734]
24-11-25 15:08:20 | I |         best error  = [    2.6734]
24-11-25 15:08:20 | I |     + error = [2.6734]
24-11-25 15:08:21 | I |       - range scale = [    1.0000]
24-11-25 15:08:21 | I |         sum  error  = [   14.3282]
24-11-25 15:08:21 | I |         best error  = [   14.3282]
24-11-25 15:08:21 | I |     + error = [14.3282]
24-11-25 15:08:21 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 15:08:22 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 15:08:24 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 15:08:25 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 15:08:26 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 15:08:28 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 15:08:29 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 15:08:32 | I | quantizing activations for layer model.layers.0
24-11-25 15:08:32 | I | collecting info in model.layers.0
24-11-25 15:08:32 | I | collecting info in model.layers.0
24-11-25 15:08:32 | I | collecting info in model.layers.0
24-11-25 15:08:32 | I | collecting info in model.layers.0
24-11-25 15:08:33 | I | collecting calibration activations in model.layers.0
24-11-25 15:08:33 | I | collecting calibration activations in model.layers.0
24-11-25 15:08:33 | I | collecting calibration activations in model.layers.0
24-11-25 15:08:33 | I | collecting calibration activations in model.layers.0
24-11-25 15:08:35 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 15:08:35 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 15:08:35 | I | - Evaluator: gptq
24-11-25 15:08:35 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 15:08:35 | I | - Batch_size: 8
24-11-25 15:08:35 | I |   + Max_seq_length: 2048
24-11-25 15:09:16 | I |     - Results:
24-11-25 15:09:17 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 15:09:17 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 15:09:17 | I |       |wikitext |      1|word_perplexity|7.7580|  |7.7580|
24-11-25 15:09:17 | I |       |val_valid|      1|word_perplexity|9.0516|  |9.0516|
24-11-25 15:09:17 | I |       
24-11-25 15:09:17 | I | forward this layer
24-11-25 15:09:17 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/03.pt
24-11-25 15:09:17 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/03.pt
24-11-25 15:09:17 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: True
24-11-25 15:09:17 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 15:09:17 | I | nan: first position tensor([0, 0], device='cuda:0')
24-11-25 15:09:17 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: True
24-11-25 15:09:17 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 15:09:17 | I | nan: first position tensor([0, 0], device='cuda:0')
24-11-25 15:09:17 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: True
24-11-25 15:09:17 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 15:09:17 | I | nan: first position tensor([0, 0], device='cuda:0')
24-11-25 15:09:17 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: True
24-11-25 15:09:17 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 15:09:17 | I | nan: first position tensor([0, 0], device='cuda:0')
24-11-25 15:09:17 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: True
24-11-25 15:09:17 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: True
24-11-25 15:09:17 | I | inf: first position tensor([197, 112], device='cuda:0')
24-11-25 15:09:17 | I | nan: first position tensor([5007,    0], device='cuda:0')
24-11-25 15:09:17 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: True
24-11-25 15:09:17 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: True
24-11-25 15:09:17 | I | inf: first position tensor([197, 480], device='cuda:0')
24-11-25 15:09:17 | I | nan: first position tensor([5007,    0], device='cuda:0')
24-11-25 15:09:17 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 15:09:17 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: True
24-11-25 15:09:17 | I | inf: first position tensor([  69, 5007], device='cuda:0')
24-11-25 15:09:17 | I | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
24-11-25 15:09:17 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 15:09:17 | I | in layer model.layers.0
24-11-25 15:09:17 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 15:09:17 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 15:09:17 | I | - Evaluator: gptq
24-11-25 15:09:17 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 15:09:17 | I | - Batch_size: 8
24-11-25 15:09:17 | I |   + Max_seq_length: 2048
24-11-25 15:09:55 | I |     - Results:
24-11-25 15:09:55 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 15:09:55 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 15:09:55 | I |       |wikitext |      1|word_perplexity|7.7077|  |7.7077|
24-11-25 15:09:55 | I |       |val_valid|      1|word_perplexity|8.9799|  |8.9799|
24-11-25 15:09:55 | I |       
24-11-25 15:09:55 | I | quantizing weights for layer model.layers.0
24-11-25 15:09:55 | I | collecting info in model.layers.0
24-11-25 15:09:55 | I | collecting info in model.layers.0
24-11-25 15:09:55 | I | collecting info in model.layers.0
24-11-25 15:09:55 | I | collecting info in model.layers.0
24-11-25 15:09:56 | I | collecting calibration activations in model.layers.0
24-11-25 15:09:56 | I | collecting calibration activations in model.layers.0
24-11-25 15:09:56 | I | collecting calibration activations in model.layers.0
24-11-25 15:09:56 | I | collecting calibration activations in model.layers.0
24-11-25 15:09:56 | I | - Quantizing decoder layer model.layers.0
24-11-25 15:09:56 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 15:09:57 | I |       - range scale = [    1.0000]
24-11-25 15:09:57 | I |         sum  error  = [    0.0596]
24-11-25 15:09:57 | I |         best error  = [    0.0596]
24-11-25 15:09:57 | I |     + error = [0.0596]
24-11-25 15:09:58 | I |       - range scale = [    1.0000]
24-11-25 15:09:58 | I |         sum  error  = [    0.6182]
24-11-25 15:09:58 | I |         best error  = [    0.6182]
24-11-25 15:09:58 | I |     + error = [0.6182]
24-11-25 15:09:58 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 15:09:59 | I |       - range scale = [    1.0000]
24-11-25 15:09:59 | I |         sum  error  = [    0.0757]
24-11-25 15:09:59 | I |         best error  = [    0.0757]
24-11-25 15:09:59 | I |     + error = [0.0757]
24-11-25 15:09:59 | I |       - range scale = [    1.0000]
24-11-25 15:09:59 | I |         sum  error  = [    0.5261]
24-11-25 15:09:59 | I |         best error  = [    0.5261]
24-11-25 15:09:59 | I |     + error = [0.5261]
24-11-25 15:10:00 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 15:10:00 | I |       - range scale = [    1.0000]
24-11-25 15:10:00 | I |         sum  error  = [    0.2484]
24-11-25 15:10:00 | I |         best error  = [    0.2484]
24-11-25 15:10:00 | I |     + error = [0.2484]
24-11-25 15:10:01 | I |       - range scale = [    1.0000]
24-11-25 15:10:01 | I |         sum  error  = [    1.8174]
24-11-25 15:10:01 | I |         best error  = [    1.8174]
24-11-25 15:10:01 | I |     + error = [1.8174]
24-11-25 15:10:01 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 15:10:02 | I |       - range scale = [    1.0000]
24-11-25 15:10:02 | I |         sum  error  = [    0.0560]
24-11-25 15:10:02 | I |         best error  = [    0.0560]
24-11-25 15:10:02 | I |     + error = [0.0560]
24-11-25 15:10:03 | I |       - range scale = [    1.0000]
24-11-25 15:10:03 | I |         sum  error  = [    0.5319]
24-11-25 15:10:03 | I |         best error  = [    0.5319]
24-11-25 15:10:03 | I |     + error = [0.5319]
24-11-25 15:10:03 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 15:10:03 | I |       - range scale = [    1.0000]
24-11-25 15:10:03 | I |         sum  error  = [    1.0157]
24-11-25 15:10:03 | I |         best error  = [    1.0157]
24-11-25 15:10:03 | I |     + error = [1.0157]
24-11-25 15:10:04 | I |       - range scale = [    1.0000]
24-11-25 15:10:04 | I |         sum  error  = [   11.2536]
24-11-25 15:10:04 | I |         best error  = [   11.2536]
24-11-25 15:10:04 | I |     + error = [11.2536]
24-11-25 15:10:04 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 15:10:05 | I |       - range scale = [    1.0000]
24-11-25 15:10:05 | I |         sum  error  = [    1.1788]
24-11-25 15:10:05 | I |         best error  = [    1.1788]
24-11-25 15:10:05 | I |     + error = [1.1788]
24-11-25 15:10:06 | I |       - range scale = [    1.0000]
24-11-25 15:10:06 | I |         sum  error  = [   11.5924]
24-11-25 15:10:06 | I |         best error  = [   11.5924]
24-11-25 15:10:06 | I |     + error = [11.5924]
24-11-25 15:10:06 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 15:10:07 | I |       - range scale = [    1.0000]
24-11-25 15:10:07 | I |         sum  error  = [    2.0091]
24-11-25 15:10:07 | I |         best error  = [    2.0091]
24-11-25 15:10:07 | I |     + error = [2.0091]
24-11-25 15:10:08 | I |       - range scale = [    1.0000]
24-11-25 15:10:08 | I |         sum  error  = [   11.7803]
24-11-25 15:10:08 | I |         best error  = [   11.7803]
24-11-25 15:10:08 | I |     + error = [11.7803]
24-11-25 15:10:08 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 15:10:09 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 15:10:10 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 15:10:12 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 15:10:13 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 15:10:15 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 15:10:16 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 15:10:19 | I | quantizing activations for layer model.layers.0
24-11-25 15:10:19 | I | collecting info in model.layers.0
24-11-25 15:10:19 | I | collecting info in model.layers.0
24-11-25 15:10:19 | I | collecting info in model.layers.0
24-11-25 15:10:19 | I | collecting info in model.layers.0
24-11-25 15:10:20 | I | collecting calibration activations in model.layers.0
24-11-25 15:10:20 | I | collecting calibration activations in model.layers.0
24-11-25 15:10:20 | I | collecting calibration activations in model.layers.0
24-11-25 15:10:20 | I | collecting calibration activations in model.layers.0
24-11-25 15:10:22 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 15:10:22 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 15:10:22 | I | - Evaluator: gptq
24-11-25 15:10:22 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 15:10:22 | I | - Batch_size: 8
24-11-25 15:10:22 | I |   + Max_seq_length: 2048
24-11-25 15:11:03 | I |     - Results:
24-11-25 15:11:03 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 15:11:03 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 15:11:03 | I |       |wikitext |      1|word_perplexity|7.7699|  |7.7699|
24-11-25 15:11:04 | I |       |val_valid|      1|word_perplexity|9.0503|  |9.0503|
24-11-25 15:11:04 | I |       
24-11-25 15:11:04 | I | forward this layer
24-11-25 15:11:04 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/04.pt
24-11-25 15:11:04 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/04.pt
24-11-25 15:11:04 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: True
24-11-25 15:11:04 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 15:11:04 | I | nan: first position tensor([0, 0], device='cuda:0')
24-11-25 15:11:04 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: True
24-11-25 15:11:04 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 15:11:04 | I | nan: first position tensor([0, 0], device='cuda:0')
24-11-25 15:11:04 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: True
24-11-25 15:11:04 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 15:11:04 | I | nan: first position tensor([0, 0], device='cuda:0')
24-11-25 15:11:04 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: True
24-11-25 15:11:04 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 15:11:04 | I | nan: first position tensor([0, 0], device='cuda:0')
24-11-25 15:11:04 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: True
24-11-25 15:11:04 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: True
24-11-25 15:11:04 | I | inf: first position tensor([197, 112], device='cuda:0')
24-11-25 15:11:04 | I | nan: first position tensor([5007,    0], device='cuda:0')
24-11-25 15:11:04 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: True
24-11-25 15:11:04 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: True
24-11-25 15:11:04 | I | inf: first position tensor([371, 165], device='cuda:0')
24-11-25 15:11:04 | I | nan: first position tensor([5007,    1], device='cuda:0')
24-11-25 15:11:04 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 15:11:04 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: True
24-11-25 15:11:04 | I | inf: first position tensor([  94, 5007], device='cuda:0')
24-11-25 15:11:04 | I | in layer model.layers.0
24-11-25 15:11:04 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 15:11:04 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 15:11:04 | I | - Evaluator: gptq
24-11-25 15:11:04 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 15:11:04 | I | - Batch_size: 8
24-11-25 15:11:04 | I |   + Max_seq_length: 2048
24-11-25 15:11:42 | I |     - Results:
24-11-25 15:11:42 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 15:11:42 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 15:11:42 | I |       |wikitext |      1|word_perplexity|7.7077|  |7.7077|
24-11-25 15:11:42 | I |       |val_valid|      1|word_perplexity|8.9799|  |8.9799|
24-11-25 15:11:42 | I |       
24-11-25 15:11:42 | I | quantizing weights for layer model.layers.0
24-11-25 15:11:42 | I | collecting info in model.layers.0
24-11-25 15:11:42 | I | collecting info in model.layers.0
24-11-25 15:11:42 | I | collecting info in model.layers.0
24-11-25 15:11:42 | I | collecting info in model.layers.0
24-11-25 15:11:43 | I | collecting calibration activations in model.layers.0
24-11-25 15:11:43 | I | collecting calibration activations in model.layers.0
24-11-25 15:11:43 | I | collecting calibration activations in model.layers.0
24-11-25 15:11:43 | I | collecting calibration activations in model.layers.0
24-11-25 15:11:43 | I | - Quantizing decoder layer model.layers.0
24-11-25 15:11:43 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 15:11:44 | I |       - range scale = [    1.0000]
24-11-25 15:11:44 | I |         sum  error  = [    0.0605]
24-11-25 15:11:44 | I |         best error  = [    0.0605]
24-11-25 15:11:44 | I |     + error = [0.0605]
24-11-25 15:11:45 | I |       - range scale = [    1.0000]
24-11-25 15:11:45 | I |         sum  error  = [    0.6248]
24-11-25 15:11:45 | I |         best error  = [    0.6248]
24-11-25 15:11:45 | I |     + error = [0.6248]
24-11-25 15:11:45 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 15:11:46 | I |       - range scale = [    1.0000]
24-11-25 15:11:46 | I |         sum  error  = [    0.0750]
24-11-25 15:11:46 | I |         best error  = [    0.0750]
24-11-25 15:11:46 | I |     + error = [0.0750]
24-11-25 15:11:46 | I |       - range scale = [    1.0000]
24-11-25 15:11:46 | I |         sum  error  = [    0.5162]
24-11-25 15:11:46 | I |         best error  = [    0.5162]
24-11-25 15:11:46 | I |     + error = [0.5162]
24-11-25 15:11:47 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 15:11:47 | I |       - range scale = [    1.0000]
24-11-25 15:11:47 | I |         sum  error  = [    0.2512]
24-11-25 15:11:47 | I |         best error  = [    0.2512]
24-11-25 15:11:47 | I |     + error = [0.2512]
24-11-25 15:11:48 | I |       - range scale = [    1.0000]
24-11-25 15:11:48 | I |         sum  error  = [    1.8297]
24-11-25 15:11:48 | I |         best error  = [    1.8297]
24-11-25 15:11:48 | I |     + error = [1.8297]
24-11-25 15:11:48 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 15:11:49 | I |       - range scale = [    1.0000]
24-11-25 15:11:49 | I |         sum  error  = [    0.0572]
24-11-25 15:11:49 | I |         best error  = [    0.0572]
24-11-25 15:11:49 | I |     + error = [0.0572]
24-11-25 15:11:50 | I |       - range scale = [    1.0000]
24-11-25 15:11:50 | I |         sum  error  = [    0.5536]
24-11-25 15:11:50 | I |         best error  = [    0.5536]
24-11-25 15:11:50 | I |     + error = [0.5536]
24-11-25 15:11:50 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 15:11:50 | I |       - range scale = [    1.0000]
24-11-25 15:11:50 | I |         sum  error  = [    1.0385]
24-11-25 15:11:50 | I |         best error  = [    1.0385]
24-11-25 15:11:50 | I |     + error = [1.0385]
24-11-25 15:11:51 | I |       - range scale = [    1.0000]
24-11-25 15:11:51 | I |         sum  error  = [   11.4990]
24-11-25 15:11:51 | I |         best error  = [   11.4990]
24-11-25 15:11:51 | I |     + error = [11.4990]
24-11-25 15:11:51 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 15:11:52 | I |       - range scale = [    1.0000]
24-11-25 15:11:52 | I |         sum  error  = [    1.2037]
24-11-25 15:11:52 | I |         best error  = [    1.2037]
24-11-25 15:11:52 | I |     + error = [1.2037]
24-11-25 15:11:53 | I |       - range scale = [    1.0000]
24-11-25 15:11:53 | I |         sum  error  = [   11.8565]
24-11-25 15:11:53 | I |         best error  = [   11.8565]
24-11-25 15:11:53 | I |     + error = [11.8565]
24-11-25 15:11:53 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 15:11:54 | I |       - range scale = [    1.0000]
24-11-25 15:11:54 | I |         sum  error  = [    2.3115]
24-11-25 15:11:54 | I |         best error  = [    2.3115]
24-11-25 15:11:54 | I |     + error = [2.3115]
24-11-25 15:11:55 | I |       - range scale = [    1.0000]
24-11-25 15:11:55 | I |         sum  error  = [   12.0578]
24-11-25 15:11:55 | I |         best error  = [   12.0578]
24-11-25 15:11:55 | I |     + error = [12.0578]
24-11-25 15:11:55 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 15:11:56 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 15:11:57 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 15:11:59 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 15:12:00 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 15:12:02 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 15:12:03 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 15:12:06 | I | quantizing activations for layer model.layers.0
24-11-25 15:12:06 | I | collecting info in model.layers.0
24-11-25 15:12:06 | I | collecting info in model.layers.0
24-11-25 15:12:06 | I | collecting info in model.layers.0
24-11-25 15:12:06 | I | collecting info in model.layers.0
24-11-25 15:12:07 | I | collecting calibration activations in model.layers.0
24-11-25 15:12:07 | I | collecting calibration activations in model.layers.0
24-11-25 15:12:07 | I | collecting calibration activations in model.layers.0
24-11-25 15:12:07 | I | collecting calibration activations in model.layers.0
24-11-25 15:12:09 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 15:12:09 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 15:12:09 | I | - Evaluator: gptq
24-11-25 15:12:09 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 15:12:09 | I | - Batch_size: 8
24-11-25 15:12:09 | I |   + Max_seq_length: 2048
24-11-25 15:12:51 | I |     - Results:
24-11-25 15:12:51 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 15:12:51 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 15:12:51 | I |       |wikitext |      1|word_perplexity|7.7759|  |7.7759|
24-11-25 15:12:51 | I |       |val_valid|      1|word_perplexity|9.0560|  |9.0560|
24-11-25 15:12:51 | I |       
24-11-25 15:12:51 | I | forward this layer
24-11-25 15:12:51 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/05.pt
24-11-25 15:12:51 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/05.pt
24-11-25 15:12:51 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: True
24-11-25 15:12:51 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 15:12:51 | I | nan: first position tensor([0, 0], device='cuda:0')
24-11-25 15:12:51 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: True
24-11-25 15:12:51 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 15:12:51 | I | nan: first position tensor([0, 0], device='cuda:0')
24-11-25 15:12:51 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: True
24-11-25 15:12:51 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 15:12:51 | I | nan: first position tensor([0, 0], device='cuda:0')
24-11-25 15:12:51 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: True
24-11-25 15:12:51 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 15:12:51 | I | nan: first position tensor([0, 0], device='cuda:0')
24-11-25 15:12:51 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: True
24-11-25 15:12:51 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: True
24-11-25 15:12:51 | I | inf: first position tensor([197, 165], device='cuda:0')
24-11-25 15:12:51 | I | nan: first position tensor([5007,    0], device='cuda:0')
24-11-25 15:12:51 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: True
24-11-25 15:12:51 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: True
24-11-25 15:12:51 | I | inf: first position tensor([371, 165], device='cuda:0')
24-11-25 15:12:51 | I | nan: first position tensor([5007,    1], device='cuda:0')
24-11-25 15:12:51 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 15:12:51 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: True
24-11-25 15:12:51 | I | inf: first position tensor([  94, 5007], device='cuda:0')
24-11-25 15:12:51 | I | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
24-11-25 15:12:52 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 15:12:52 | I | in layer model.layers.0
24-11-25 15:12:52 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 15:12:52 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 15:12:52 | I | - Evaluator: gptq
24-11-25 15:12:52 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 15:12:52 | I | - Batch_size: 8
24-11-25 15:12:52 | I |   + Max_seq_length: 2048
24-11-25 15:13:30 | I |     - Results:
24-11-25 15:13:30 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 15:13:30 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 15:13:30 | I |       |wikitext |      1|word_perplexity|7.7077|  |7.7077|
24-11-25 15:13:30 | I |       |val_valid|      1|word_perplexity|8.9799|  |8.9799|
24-11-25 15:13:30 | I |       
24-11-25 15:13:30 | I | quantizing weights for layer model.layers.0
24-11-25 15:13:30 | I | collecting info in model.layers.0
24-11-25 15:13:30 | I | collecting info in model.layers.0
24-11-25 15:13:30 | I | collecting info in model.layers.0
24-11-25 15:13:30 | I | collecting info in model.layers.0
24-11-25 15:13:30 | I | collecting calibration activations in model.layers.0
24-11-25 15:13:31 | I | collecting calibration activations in model.layers.0
24-11-25 15:13:31 | I | collecting calibration activations in model.layers.0
24-11-25 15:13:31 | I | collecting calibration activations in model.layers.0
24-11-25 15:13:31 | I | - Quantizing decoder layer model.layers.0
24-11-25 15:13:31 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 15:13:32 | I |       - range scale = [    1.0000]
24-11-25 15:13:32 | I |         sum  error  = [    0.0624]
24-11-25 15:13:32 | I |         best error  = [    0.0624]
24-11-25 15:13:32 | I |     + error = [0.0624]
24-11-25 15:13:32 | I |       - range scale = [    1.0000]
24-11-25 15:13:32 | I |         sum  error  = [    0.6134]
24-11-25 15:13:32 | I |         best error  = [    0.6134]
24-11-25 15:13:32 | I |     + error = [0.6134]
24-11-25 15:13:33 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 15:13:33 | I |       - range scale = [    1.0000]
24-11-25 15:13:33 | I |         sum  error  = [    0.0749]
24-11-25 15:13:33 | I |         best error  = [    0.0749]
24-11-25 15:13:33 | I |     + error = [0.0749]
24-11-25 15:13:34 | I |       - range scale = [    1.0000]
24-11-25 15:13:34 | I |         sum  error  = [    0.5176]
24-11-25 15:13:34 | I |         best error  = [    0.5176]
24-11-25 15:13:34 | I |     + error = [0.5176]
24-11-25 15:13:34 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 15:13:35 | I |       - range scale = [    1.0000]
24-11-25 15:13:35 | I |         sum  error  = [    0.2543]
24-11-25 15:13:35 | I |         best error  = [    0.2543]
24-11-25 15:13:35 | I |     + error = [0.2543]
24-11-25 15:13:36 | I |       - range scale = [    1.0000]
24-11-25 15:13:36 | I |         sum  error  = [    1.8393]
24-11-25 15:13:36 | I |         best error  = [    1.8393]
24-11-25 15:13:36 | I |     + error = [1.8393]
24-11-25 15:13:36 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 15:13:36 | I |       - range scale = [    1.0000]
24-11-25 15:13:36 | I |         sum  error  = [    0.0588]
24-11-25 15:13:36 | I |         best error  = [    0.0588]
24-11-25 15:13:36 | I |     + error = [0.0588]
24-11-25 15:13:37 | I |       - range scale = [    1.0000]
24-11-25 15:13:37 | I |         sum  error  = [    0.5696]
24-11-25 15:13:37 | I |         best error  = [    0.5696]
24-11-25 15:13:37 | I |     + error = [0.5696]
24-11-25 15:13:37 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 15:13:38 | I |       - range scale = [    1.0000]
24-11-25 15:13:38 | I |         sum  error  = [    1.0229]
24-11-25 15:13:38 | I |         best error  = [    1.0229]
24-11-25 15:13:38 | I |     + error = [1.0229]
24-11-25 15:13:39 | I |       - range scale = [    1.0000]
24-11-25 15:13:39 | I |         sum  error  = [   11.3396]
24-11-25 15:13:39 | I |         best error  = [   11.3396]
24-11-25 15:13:39 | I |     + error = [11.3396]
24-11-25 15:13:39 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 15:13:40 | I |       - range scale = [    1.0000]
24-11-25 15:13:40 | I |         sum  error  = [    1.1844]
24-11-25 15:13:40 | I |         best error  = [    1.1844]
24-11-25 15:13:40 | I |     + error = [1.1844]
24-11-25 15:13:40 | I |       - range scale = [    1.0000]
24-11-25 15:13:40 | I |         sum  error  = [   11.6957]
24-11-25 15:13:40 | I |         best error  = [   11.6957]
24-11-25 15:13:40 | I |     + error = [11.6957]
24-11-25 15:13:41 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 15:13:41 | I |       - range scale = [    1.0000]
24-11-25 15:13:41 | I |         sum  error  = [    2.9462]
24-11-25 15:13:41 | I |         best error  = [    2.9462]
24-11-25 15:13:41 | I |     + error = [2.9462]
24-11-25 15:13:42 | I |       - range scale = [    1.0000]
24-11-25 15:13:42 | I |         sum  error  = [   15.3139]
24-11-25 15:13:42 | I |         best error  = [   15.3139]
24-11-25 15:13:42 | I |     + error = [15.3139]
24-11-25 15:13:42 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 15:13:44 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 15:13:45 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 15:13:47 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 15:13:48 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 15:13:50 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 15:13:51 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 15:13:54 | I | quantizing activations for layer model.layers.0
24-11-25 15:13:54 | I | collecting info in model.layers.0
24-11-25 15:13:54 | I | collecting info in model.layers.0
24-11-25 15:13:54 | I | collecting info in model.layers.0
24-11-25 15:13:54 | I | collecting info in model.layers.0
24-11-25 15:13:55 | I | collecting calibration activations in model.layers.0
24-11-25 15:13:55 | I | collecting calibration activations in model.layers.0
24-11-25 15:13:55 | I | collecting calibration activations in model.layers.0
24-11-25 15:13:55 | I | collecting calibration activations in model.layers.0
24-11-25 15:13:57 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 15:13:57 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 15:13:57 | I | - Evaluator: gptq
24-11-25 15:13:57 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 15:13:57 | I | - Batch_size: 8
24-11-25 15:13:57 | I |   + Max_seq_length: 2048
24-11-25 15:14:38 | I |     - Results:
24-11-25 15:14:38 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 15:14:38 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 15:14:38 | I |       |wikitext |      1|word_perplexity|7.7652|  |7.7652|
24-11-25 15:14:38 | I |       |val_valid|      1|word_perplexity|9.0463|  |9.0463|
24-11-25 15:14:38 | I |       
24-11-25 15:14:38 | I | forward this layer
24-11-25 15:14:38 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/06.pt
24-11-25 15:14:38 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/06.pt
24-11-25 15:14:39 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: True
24-11-25 15:14:39 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 15:14:39 | I | nan: first position tensor([0, 0], device='cuda:0')
24-11-25 15:14:39 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: True
24-11-25 15:14:39 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 15:14:39 | I | nan: first position tensor([0, 0], device='cuda:0')
24-11-25 15:14:39 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: True
24-11-25 15:14:39 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 15:14:39 | I | nan: first position tensor([0, 0], device='cuda:0')
24-11-25 15:14:39 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: True
24-11-25 15:14:39 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 15:14:39 | I | nan: first position tensor([0, 0], device='cuda:0')
24-11-25 15:14:39 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: True
24-11-25 15:14:39 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: True
24-11-25 15:14:39 | I | inf: first position tensor([2029,  165], device='cuda:0')
24-11-25 15:14:39 | I | nan: first position tensor([5007,    1], device='cuda:0')
24-11-25 15:14:39 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 15:14:39 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: True
24-11-25 15:14:39 | I | inf: first position tensor([2029,  712], device='cuda:0')
24-11-25 15:14:39 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 15:14:39 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: True
24-11-25 15:14:39 | I | inf: first position tensor([ 112, 5007], device='cuda:0')
24-11-25 15:14:39 | I | in layer model.layers.0
24-11-25 15:14:39 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 15:14:39 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 15:14:39 | I | - Evaluator: gptq
24-11-25 15:14:39 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 15:14:39 | I | - Batch_size: 8
24-11-25 15:14:39 | I |   + Max_seq_length: 2048
24-11-25 15:15:17 | I |     - Results:
24-11-25 15:15:17 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 15:15:17 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 15:15:17 | I |       |wikitext |      1|word_perplexity|7.7077|  |7.7077|
24-11-25 15:15:17 | I |       |val_valid|      1|word_perplexity|8.9799|  |8.9799|
24-11-25 15:15:17 | I |       
24-11-25 15:15:17 | I | quantizing weights for layer model.layers.0
24-11-25 15:15:17 | I | collecting info in model.layers.0
24-11-25 15:15:17 | I | collecting info in model.layers.0
24-11-25 15:15:17 | I | collecting info in model.layers.0
24-11-25 15:15:17 | I | collecting info in model.layers.0
24-11-25 15:15:17 | I | collecting calibration activations in model.layers.0
24-11-25 15:15:17 | I | collecting calibration activations in model.layers.0
24-11-25 15:15:18 | I | collecting calibration activations in model.layers.0
24-11-25 15:15:18 | I | collecting calibration activations in model.layers.0
24-11-25 15:15:18 | I | - Quantizing decoder layer model.layers.0
24-11-25 15:15:18 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 15:15:19 | I |       - range scale = [    1.0000]
24-11-25 15:15:19 | I |         sum  error  = [    0.0600]
24-11-25 15:15:19 | I |         best error  = [    0.0600]
24-11-25 15:15:19 | I |     + error = [0.0600]
24-11-25 15:15:19 | I |       - range scale = [    1.0000]
24-11-25 15:15:19 | I |         sum  error  = [    0.6030]
24-11-25 15:15:19 | I |         best error  = [    0.6030]
24-11-25 15:15:19 | I |     + error = [0.6030]
24-11-25 15:15:20 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 15:15:20 | I |       - range scale = [    1.0000]
24-11-25 15:15:20 | I |         sum  error  = [    0.0725]
24-11-25 15:15:20 | I |         best error  = [    0.0725]
24-11-25 15:15:20 | I |     + error = [0.0725]
24-11-25 15:15:21 | I |       - range scale = [    1.0000]
24-11-25 15:15:21 | I |         sum  error  = [    0.5141]
24-11-25 15:15:21 | I |         best error  = [    0.5141]
24-11-25 15:15:21 | I |     + error = [0.5141]
24-11-25 15:15:21 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 15:15:22 | I |       - range scale = [    1.0000]
24-11-25 15:15:22 | I |         sum  error  = [    0.2491]
24-11-25 15:15:22 | I |         best error  = [    0.2491]
24-11-25 15:15:22 | I |     + error = [0.2491]
24-11-25 15:15:22 | I |       - range scale = [    1.0000]
24-11-25 15:15:22 | I |         sum  error  = [    1.8116]
24-11-25 15:15:22 | I |         best error  = [    1.8116]
24-11-25 15:15:22 | I |     + error = [1.8116]
24-11-25 15:15:23 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 15:15:23 | I |       - range scale = [    1.0000]
24-11-25 15:15:23 | I |         sum  error  = [    0.0617]
24-11-25 15:15:23 | I |         best error  = [    0.0617]
24-11-25 15:15:23 | I |     + error = [0.0617]
24-11-25 15:15:24 | I |       - range scale = [    1.0000]
24-11-25 15:15:24 | I |         sum  error  = [    0.5971]
24-11-25 15:15:24 | I |         best error  = [    0.5971]
24-11-25 15:15:24 | I |     + error = [0.5971]
24-11-25 15:15:24 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 15:15:25 | I |       - range scale = [    1.0000]
24-11-25 15:15:25 | I |         sum  error  = [    1.0844]
24-11-25 15:15:25 | I |         best error  = [    1.0844]
24-11-25 15:15:25 | I |     + error = [1.0844]
24-11-25 15:15:26 | I |       - range scale = [    1.0000]
24-11-25 15:15:26 | I |         sum  error  = [   12.0277]
24-11-25 15:15:26 | I |         best error  = [   12.0277]
24-11-25 15:15:26 | I |     + error = [12.0277]
24-11-25 15:15:26 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 15:15:26 | I |       - range scale = [    1.0000]
24-11-25 15:15:26 | I |         sum  error  = [    1.2563]
24-11-25 15:15:26 | I |         best error  = [    1.2563]
24-11-25 15:15:26 | I |     + error = [1.2563]
24-11-25 15:15:27 | I |       - range scale = [    1.0000]
24-11-25 15:15:27 | I |         sum  error  = [   12.4292]
24-11-25 15:15:27 | I |         best error  = [   12.4292]
24-11-25 15:15:27 | I |     + error = [12.4292]
24-11-25 15:15:27 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 15:15:28 | I |       - range scale = [    1.0000]
24-11-25 15:15:28 | I |         sum  error  = [    2.7174]
24-11-25 15:15:28 | I |         best error  = [    2.7174]
24-11-25 15:15:28 | I |     + error = [2.7174]
24-11-25 15:15:29 | I |       - range scale = [    1.0000]
24-11-25 15:15:29 | I |         sum  error  = [   13.8107]
24-11-25 15:15:29 | I |         best error  = [   13.8107]
24-11-25 15:15:29 | I |     + error = [13.8107]
24-11-25 15:15:29 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 15:15:30 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 15:15:32 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 15:15:33 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 15:15:34 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 15:15:36 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 15:15:37 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 15:15:41 | I | quantizing activations for layer model.layers.0
24-11-25 15:15:41 | I | collecting info in model.layers.0
24-11-25 15:15:41 | I | collecting info in model.layers.0
24-11-25 15:15:41 | I | collecting info in model.layers.0
24-11-25 15:15:41 | I | collecting info in model.layers.0
24-11-25 15:15:41 | I | collecting calibration activations in model.layers.0
24-11-25 15:15:41 | I | collecting calibration activations in model.layers.0
24-11-25 15:15:41 | I | collecting calibration activations in model.layers.0
24-11-25 15:15:41 | I | collecting calibration activations in model.layers.0
24-11-25 15:15:43 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 15:15:43 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 15:15:43 | I | - Evaluator: gptq
24-11-25 15:15:43 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 15:15:43 | I | - Batch_size: 8
24-11-25 15:15:43 | I |   + Max_seq_length: 2048
24-11-25 15:16:25 | I |     - Results:
24-11-25 15:16:25 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 15:16:25 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 15:16:25 | I |       |wikitext |      1|word_perplexity|7.7743|  |7.7743|
24-11-25 15:16:25 | I |       |val_valid|      1|word_perplexity|9.0573|  |9.0573|
24-11-25 15:16:25 | I |       
24-11-25 15:16:25 | I | forward this layer
24-11-25 15:16:25 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/07.pt
24-11-25 15:16:25 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/07.pt
24-11-25 15:16:25 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: True
24-11-25 15:16:25 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 15:16:25 | I | nan: first position tensor([0, 0], device='cuda:0')
24-11-25 15:16:25 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: True
24-11-25 15:16:25 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 15:16:25 | I | nan: first position tensor([0, 0], device='cuda:0')
24-11-25 15:16:25 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: True
24-11-25 15:16:25 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 15:16:25 | I | nan: first position tensor([0, 0], device='cuda:0')
24-11-25 15:16:25 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: True
24-11-25 15:16:25 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 15:16:25 | I | nan: first position tensor([0, 0], device='cuda:0')
24-11-25 15:16:25 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: True
24-11-25 15:16:25 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: True
24-11-25 15:16:25 | I | inf: first position tensor([2029,  165], device='cuda:0')
24-11-25 15:16:25 | I | nan: first position tensor([5007,    1], device='cuda:0')
24-11-25 15:16:25 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 15:16:25 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: True
24-11-25 15:16:25 | I | inf: first position tensor([2029, 1619], device='cuda:0')
24-11-25 15:16:25 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 15:16:25 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: True
24-11-25 15:16:25 | I | inf: first position tensor([1327, 2029], device='cuda:0')
24-11-25 15:16:25 | I | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
24-11-25 15:16:25 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 15:16:25 | I | in layer model.layers.0
24-11-25 15:16:25 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 15:16:25 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 15:16:25 | I | - Evaluator: gptq
24-11-25 15:16:25 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 15:16:25 | I | - Batch_size: 8
24-11-25 15:16:25 | I |   + Max_seq_length: 2048
24-11-25 15:17:03 | I |     - Results:
24-11-25 15:17:03 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 15:17:03 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 15:17:03 | I |       |wikitext |      1|word_perplexity|7.7077|  |7.7077|
24-11-25 15:17:03 | I |       |val_valid|      1|word_perplexity|8.9799|  |8.9799|
24-11-25 15:17:03 | I |       
24-11-25 15:17:03 | I | quantizing weights for layer model.layers.0
24-11-25 15:17:03 | I | collecting info in model.layers.0
24-11-25 15:17:03 | I | collecting info in model.layers.0
24-11-25 15:17:03 | I | collecting info in model.layers.0
24-11-25 15:17:03 | I | collecting info in model.layers.0
24-11-25 15:17:04 | I | collecting calibration activations in model.layers.0
24-11-25 15:17:04 | I | collecting calibration activations in model.layers.0
24-11-25 15:17:04 | I | collecting calibration activations in model.layers.0
24-11-25 15:17:04 | I | collecting calibration activations in model.layers.0
24-11-25 15:17:05 | I | - Quantizing decoder layer model.layers.0
24-11-25 15:17:05 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 15:17:05 | I |       - range scale = [    1.0000]
24-11-25 15:17:05 | I |         sum  error  = [    0.0619]
24-11-25 15:17:05 | I |         best error  = [    0.0619]
24-11-25 15:17:05 | I |     + error = [0.0619]
24-11-25 15:17:06 | I |       - range scale = [    1.0000]
24-11-25 15:17:06 | I |         sum  error  = [    0.6072]
24-11-25 15:17:06 | I |         best error  = [    0.6072]
24-11-25 15:17:06 | I |     + error = [0.6072]
24-11-25 15:17:06 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 15:17:07 | I |       - range scale = [    1.0000]
24-11-25 15:17:07 | I |         sum  error  = [    0.0703]
24-11-25 15:17:07 | I |         best error  = [    0.0703]
24-11-25 15:17:07 | I |     + error = [0.0703]
24-11-25 15:17:08 | I |       - range scale = [    1.0000]
24-11-25 15:17:08 | I |         sum  error  = [    0.5038]
24-11-25 15:17:08 | I |         best error  = [    0.5038]
24-11-25 15:17:08 | I |     + error = [0.5038]
24-11-25 15:17:08 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 15:17:08 | I |       - range scale = [    1.0000]
24-11-25 15:17:08 | I |         sum  error  = [    0.2470]
24-11-25 15:17:08 | I |         best error  = [    0.2470]
24-11-25 15:17:08 | I |     + error = [0.2470]
24-11-25 15:17:09 | I |       - range scale = [    1.0000]
24-11-25 15:17:09 | I |         sum  error  = [    1.7889]
24-11-25 15:17:09 | I |         best error  = [    1.7889]
24-11-25 15:17:09 | I |     + error = [1.7889]
24-11-25 15:17:09 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 15:17:10 | I |       - range scale = [    1.0000]
24-11-25 15:17:10 | I |         sum  error  = [    0.0589]
24-11-25 15:17:10 | I |         best error  = [    0.0589]
24-11-25 15:17:10 | I |     + error = [0.0589]
24-11-25 15:17:11 | I |       - range scale = [    1.0000]
24-11-25 15:17:11 | I |         sum  error  = [    0.5660]
24-11-25 15:17:11 | I |         best error  = [    0.5660]
24-11-25 15:17:11 | I |     + error = [0.5660]
24-11-25 15:17:11 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 15:17:11 | I |       - range scale = [    1.0000]
24-11-25 15:17:11 | I |         sum  error  = [    1.0625]
24-11-25 15:17:11 | I |         best error  = [    1.0625]
24-11-25 15:17:11 | I |     + error = [1.0625]
24-11-25 15:17:12 | I |       - range scale = [    1.0000]
24-11-25 15:17:12 | I |         sum  error  = [   11.7796]
24-11-25 15:17:12 | I |         best error  = [   11.7796]
24-11-25 15:17:12 | I |     + error = [11.7796]
24-11-25 15:17:12 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 15:17:13 | I |       - range scale = [    1.0000]
24-11-25 15:17:13 | I |         sum  error  = [    1.2294]
24-11-25 15:17:13 | I |         best error  = [    1.2294]
24-11-25 15:17:13 | I |     + error = [1.2294]
24-11-25 15:17:14 | I |       - range scale = [    1.0000]
24-11-25 15:17:14 | I |         sum  error  = [   12.1635]
24-11-25 15:17:14 | I |         best error  = [   12.1635]
24-11-25 15:17:14 | I |     + error = [12.1635]
24-11-25 15:17:14 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 15:17:15 | I |       - range scale = [    1.0000]
24-11-25 15:17:15 | I |         sum  error  = [    3.8522]
24-11-25 15:17:15 | I |         best error  = [    3.8522]
24-11-25 15:17:15 | I |     + error = [3.8522]
24-11-25 15:17:16 | I |       - range scale = [    1.0000]
24-11-25 15:17:16 | I |         sum  error  = [   18.9112]
24-11-25 15:17:16 | I |         best error  = [   18.9112]
24-11-25 15:17:16 | I |     + error = [18.9112]
24-11-25 15:17:16 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 15:17:17 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 15:17:19 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 15:17:20 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 15:17:21 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 15:17:23 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 15:17:24 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 15:17:27 | I | quantizing activations for layer model.layers.0
24-11-25 15:17:27 | I | collecting info in model.layers.0
24-11-25 15:17:27 | I | collecting info in model.layers.0
24-11-25 15:17:27 | I | collecting info in model.layers.0
24-11-25 15:17:27 | I | collecting info in model.layers.0
24-11-25 15:17:28 | I | collecting calibration activations in model.layers.0
24-11-25 15:17:28 | I | collecting calibration activations in model.layers.0
24-11-25 15:17:28 | I | collecting calibration activations in model.layers.0
24-11-25 15:17:28 | I | collecting calibration activations in model.layers.0
24-11-25 15:17:30 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 15:17:30 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 15:17:30 | I | - Evaluator: gptq
24-11-25 15:17:30 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 15:17:30 | I | - Batch_size: 8
24-11-25 15:17:30 | I |   + Max_seq_length: 2048
24-11-25 15:18:11 | I |     - Results:
24-11-25 15:18:11 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 15:18:11 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 15:18:11 | I |       |wikitext |      1|word_perplexity|7.7885|  |7.7885|
24-11-25 15:18:11 | I |       |val_valid|      1|word_perplexity|9.0586|  |9.0586|
24-11-25 15:18:11 | I |       
24-11-25 15:18:11 | I | forward this layer
24-11-25 15:18:11 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/08.pt
24-11-25 15:18:11 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/08.pt
24-11-25 15:18:12 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: True
24-11-25 15:18:12 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 15:18:12 | I | nan: first position tensor([0, 0], device='cuda:0')
24-11-25 15:18:12 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: True
24-11-25 15:18:12 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 15:18:12 | I | nan: first position tensor([0, 0], device='cuda:0')
24-11-25 15:18:12 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: True
24-11-25 15:18:12 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 15:18:12 | I | nan: first position tensor([0, 0], device='cuda:0')
24-11-25 15:18:12 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: True
24-11-25 15:18:12 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: True
24-11-25 15:18:12 | I | inf: first position tensor([17, 15], device='cuda:0')
24-11-25 15:18:12 | I | nan: first position tensor([17,  0], device='cuda:0')
24-11-25 15:18:12 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 15:18:12 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: True
24-11-25 15:18:12 | I | inf: first position tensor([2029, 1619], device='cuda:0')
24-11-25 15:18:12 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 15:18:12 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 15:18:12 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 15:18:12 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: True
24-11-25 15:18:12 | I | inf: first position tensor([1327, 2029], device='cuda:0')
24-11-25 15:18:12 | I | in layer model.layers.0
24-11-25 15:18:12 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 15:18:12 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 15:18:12 | I | - Evaluator: gptq
24-11-25 15:18:12 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 15:18:12 | I | - Batch_size: 8
24-11-25 15:18:12 | I |   + Max_seq_length: 2048
24-11-25 15:18:50 | I |     - Results:
24-11-25 15:18:50 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 15:18:50 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 15:18:50 | I |       |wikitext |      1|word_perplexity|7.7077|  |7.7077|
24-11-25 15:18:50 | I |       |val_valid|      1|word_perplexity|8.9799|  |8.9799|
24-11-25 15:18:50 | I |       
24-11-25 15:18:50 | I | quantizing weights for layer model.layers.0
24-11-25 15:18:50 | I | collecting info in model.layers.0
24-11-25 15:18:50 | I | collecting info in model.layers.0
24-11-25 15:18:50 | I | collecting info in model.layers.0
24-11-25 15:18:50 | I | collecting info in model.layers.0
24-11-25 15:18:50 | I | collecting calibration activations in model.layers.0
24-11-25 15:18:51 | I | collecting calibration activations in model.layers.0
24-11-25 15:18:51 | I | collecting calibration activations in model.layers.0
24-11-25 15:18:51 | I | collecting calibration activations in model.layers.0
24-11-25 15:18:51 | I | - Quantizing decoder layer model.layers.0
24-11-25 15:18:51 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 15:18:52 | I |       - range scale = [    1.0000]
24-11-25 15:18:52 | I |         sum  error  = [    0.0583]
24-11-25 15:18:52 | I |         best error  = [    0.0583]
24-11-25 15:18:52 | I |     + error = [0.0583]
24-11-25 15:18:52 | I |       - range scale = [    1.0000]
24-11-25 15:18:52 | I |         sum  error  = [    0.5960]
24-11-25 15:18:52 | I |         best error  = [    0.5960]
24-11-25 15:18:52 | I |     + error = [0.5960]
24-11-25 15:18:53 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 15:18:53 | I |       - range scale = [    1.0000]
24-11-25 15:18:53 | I |         sum  error  = [    0.0730]
24-11-25 15:18:53 | I |         best error  = [    0.0730]
24-11-25 15:18:53 | I |     + error = [0.0730]
24-11-25 15:18:54 | I |       - range scale = [    1.0000]
24-11-25 15:18:54 | I |         sum  error  = [    0.5159]
24-11-25 15:18:54 | I |         best error  = [    0.5159]
24-11-25 15:18:54 | I |     + error = [0.5159]
24-11-25 15:18:54 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 15:18:55 | I |       - range scale = [    1.0000]
24-11-25 15:18:55 | I |         sum  error  = [    0.2456]
24-11-25 15:18:55 | I |         best error  = [    0.2456]
24-11-25 15:18:55 | I |     + error = [0.2456]
24-11-25 15:18:55 | I |       - range scale = [    1.0000]
24-11-25 15:18:55 | I |         sum  error  = [    1.7641]
24-11-25 15:18:55 | I |         best error  = [    1.7641]
24-11-25 15:18:55 | I |     + error = [1.7641]
24-11-25 15:18:56 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 15:18:56 | I |       - range scale = [    1.0000]
24-11-25 15:18:56 | I |         sum  error  = [    0.0628]
24-11-25 15:18:56 | I |         best error  = [    0.0628]
24-11-25 15:18:56 | I |     + error = [0.0628]
24-11-25 15:18:57 | I |       - range scale = [    1.0000]
24-11-25 15:18:57 | I |         sum  error  = [    0.6035]
24-11-25 15:18:57 | I |         best error  = [    0.6035]
24-11-25 15:18:57 | I |     + error = [0.6035]
24-11-25 15:18:57 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 15:18:58 | I |       - range scale = [    1.0000]
24-11-25 15:18:58 | I |         sum  error  = [    1.0783]
24-11-25 15:18:58 | I |         best error  = [    1.0783]
24-11-25 15:18:58 | I |     + error = [1.0783]
24-11-25 15:18:59 | I |       - range scale = [    1.0000]
24-11-25 15:18:59 | I |         sum  error  = [   11.9432]
24-11-25 15:18:59 | I |         best error  = [   11.9432]
24-11-25 15:18:59 | I |     + error = [11.9432]
24-11-25 15:18:59 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 15:18:59 | I |       - range scale = [    1.0000]
24-11-25 15:18:59 | I |         sum  error  = [    1.2462]
24-11-25 15:18:59 | I |         best error  = [    1.2462]
24-11-25 15:18:59 | I |     + error = [1.2462]
24-11-25 15:19:00 | I |       - range scale = [    1.0000]
24-11-25 15:19:00 | I |         sum  error  = [   12.3608]
24-11-25 15:19:00 | I |         best error  = [   12.3608]
24-11-25 15:19:00 | I |     + error = [12.3608]
24-11-25 15:19:00 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 15:19:01 | I |       - range scale = [    1.0000]
24-11-25 15:19:01 | I |         sum  error  = [    3.8848]
24-11-25 15:19:01 | I |         best error  = [    3.8848]
24-11-25 15:19:01 | I |     + error = [3.8848]
24-11-25 15:19:02 | I |       - range scale = [    1.0000]
24-11-25 15:19:02 | I |         sum  error  = [   19.1576]
24-11-25 15:19:02 | I |         best error  = [   19.1576]
24-11-25 15:19:02 | I |     + error = [19.1576]
24-11-25 15:19:02 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 15:19:03 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 15:19:05 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 15:19:06 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 15:19:07 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 15:19:09 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 15:19:10 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 15:19:14 | I | quantizing activations for layer model.layers.0
24-11-25 15:19:14 | I | collecting info in model.layers.0
24-11-25 15:19:14 | I | collecting info in model.layers.0
24-11-25 15:19:14 | I | collecting info in model.layers.0
24-11-25 15:19:14 | I | collecting info in model.layers.0
24-11-25 15:19:14 | I | collecting calibration activations in model.layers.0
24-11-25 15:19:14 | I | collecting calibration activations in model.layers.0
24-11-25 15:19:14 | I | collecting calibration activations in model.layers.0
24-11-25 15:19:14 | I | collecting calibration activations in model.layers.0
24-11-25 15:19:16 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 15:19:16 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 15:19:16 | I | - Evaluator: gptq
24-11-25 15:19:16 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 15:19:16 | I | - Batch_size: 8
24-11-25 15:19:16 | I |   + Max_seq_length: 2048
24-11-25 15:19:58 | I |     - Results:
24-11-25 15:19:58 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 15:19:58 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 15:19:58 | I |       |wikitext |      1|word_perplexity|7.7931|  |7.7931|
24-11-25 15:19:58 | I |       |val_valid|      1|word_perplexity|9.0747|  |9.0747|
24-11-25 15:19:58 | I |       
24-11-25 15:19:58 | I | forward this layer
24-11-25 15:19:58 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/09.pt
24-11-25 15:19:58 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/09.pt
24-11-25 15:19:58 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: True
24-11-25 15:19:58 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 15:19:58 | I | nan: first position tensor([0, 0], device='cuda:0')
24-11-25 15:19:58 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: True
24-11-25 15:19:58 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 15:19:58 | I | nan: first position tensor([0, 0], device='cuda:0')
24-11-25 15:19:58 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: True
24-11-25 15:19:58 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 15:19:58 | I | nan: first position tensor([0, 0], device='cuda:0')
24-11-25 15:19:58 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: True
24-11-25 15:19:58 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: True
24-11-25 15:19:58 | I | inf: first position tensor([  6, 125], device='cuda:0')
24-11-25 15:19:58 | I | nan: first position tensor([17,  0], device='cuda:0')
24-11-25 15:19:58 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 15:19:58 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: True
24-11-25 15:19:58 | I | inf: first position tensor([2029,  712], device='cuda:0')
24-11-25 15:19:58 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 15:19:58 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: True
24-11-25 15:19:58 | I | inf: first position tensor([5007,  165], device='cuda:0')
24-11-25 15:19:58 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 15:19:58 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: True
24-11-25 15:19:58 | I | inf: first position tensor([1327, 5007], device='cuda:0')
24-11-25 15:19:58 | I | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
24-11-25 15:19:58 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 15:19:58 | I | in layer model.layers.0
24-11-25 15:19:58 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 15:19:58 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 15:19:58 | I | - Evaluator: gptq
24-11-25 15:19:58 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 15:19:58 | I | - Batch_size: 8
24-11-25 15:19:58 | I |   + Max_seq_length: 2048
24-11-25 15:20:36 | I |     - Results:
24-11-25 15:20:37 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 15:20:37 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 15:20:37 | I |       |wikitext |      1|word_perplexity|7.7077|  |7.7077|
24-11-25 15:20:37 | I |       |val_valid|      1|word_perplexity|8.9799|  |8.9799|
24-11-25 15:20:37 | I |       
24-11-25 15:20:37 | I | quantizing weights for layer model.layers.0
24-11-25 15:20:37 | I | collecting info in model.layers.0
24-11-25 15:20:37 | I | collecting info in model.layers.0
24-11-25 15:20:37 | I | collecting info in model.layers.0
24-11-25 15:20:37 | I | collecting info in model.layers.0
24-11-25 15:20:37 | I | collecting calibration activations in model.layers.0
24-11-25 15:20:37 | I | collecting calibration activations in model.layers.0
24-11-25 15:20:37 | I | collecting calibration activations in model.layers.0
24-11-25 15:20:37 | I | collecting calibration activations in model.layers.0
24-11-25 15:20:38 | I | - Quantizing decoder layer model.layers.0
24-11-25 15:20:38 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 15:20:38 | I |       - range scale = [    1.0000]
24-11-25 15:20:38 | I |         sum  error  = [    0.0584]
24-11-25 15:20:38 | I |         best error  = [    0.0584]
24-11-25 15:20:38 | I |     + error = [0.0584]
24-11-25 15:20:39 | I |       - range scale = [    1.0000]
24-11-25 15:20:39 | I |         sum  error  = [    0.5839]
24-11-25 15:20:39 | I |         best error  = [    0.5839]
24-11-25 15:20:39 | I |     + error = [0.5839]
24-11-25 15:20:39 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 15:20:40 | I |       - range scale = [    1.0000]
24-11-25 15:20:40 | I |         sum  error  = [    0.0695]
24-11-25 15:20:40 | I |         best error  = [    0.0695]
24-11-25 15:20:40 | I |     + error = [0.0695]
24-11-25 15:20:41 | I |       - range scale = [    1.0000]
24-11-25 15:20:41 | I |         sum  error  = [    0.4852]
24-11-25 15:20:41 | I |         best error  = [    0.4852]
24-11-25 15:20:41 | I |     + error = [0.4852]
24-11-25 15:20:41 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 15:20:41 | I |       - range scale = [    1.0000]
24-11-25 15:20:41 | I |         sum  error  = [    0.2435]
24-11-25 15:20:41 | I |         best error  = [    0.2435]
24-11-25 15:20:41 | I |     + error = [0.2435]
24-11-25 15:20:42 | I |       - range scale = [    1.0000]
24-11-25 15:20:42 | I |         sum  error  = [    1.7660]
24-11-25 15:20:42 | I |         best error  = [    1.7660]
24-11-25 15:20:42 | I |     + error = [1.7660]
24-11-25 15:20:42 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 15:20:43 | I |       - range scale = [    1.0000]
24-11-25 15:20:43 | I |         sum  error  = [    0.0556]
24-11-25 15:20:43 | I |         best error  = [    0.0556]
24-11-25 15:20:43 | I |     + error = [0.0556]
24-11-25 15:20:44 | I |       - range scale = [    1.0000]
24-11-25 15:20:44 | I |         sum  error  = [    0.5464]
24-11-25 15:20:44 | I |         best error  = [    0.5464]
24-11-25 15:20:44 | I |     + error = [0.5464]
24-11-25 15:20:44 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 15:20:45 | I |       - range scale = [    1.0000]
24-11-25 15:20:45 | I |         sum  error  = [    1.0695]
24-11-25 15:20:45 | I |         best error  = [    1.0695]
24-11-25 15:20:45 | I |     + error = [1.0695]
24-11-25 15:20:45 | I |       - range scale = [    1.0000]
24-11-25 15:20:45 | I |         sum  error  = [   11.8507]
24-11-25 15:20:45 | I |         best error  = [   11.8507]
24-11-25 15:20:45 | I |     + error = [11.8507]
24-11-25 15:20:46 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 15:20:46 | I |       - range scale = [    1.0000]
24-11-25 15:20:46 | I |         sum  error  = [    1.2360]
24-11-25 15:20:46 | I |         best error  = [    1.2360]
24-11-25 15:20:46 | I |     + error = [1.2360]
24-11-25 15:20:47 | I |       - range scale = [    1.0000]
24-11-25 15:20:47 | I |         sum  error  = [   12.2531]
24-11-25 15:20:47 | I |         best error  = [   12.2531]
24-11-25 15:20:47 | I |     + error = [12.2531]
24-11-25 15:20:47 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 15:20:48 | I |       - range scale = [    1.0000]
24-11-25 15:20:48 | I |         sum  error  = [    2.9601]
24-11-25 15:20:48 | I |         best error  = [    2.9601]
24-11-25 15:20:48 | I |     + error = [2.9601]
24-11-25 15:20:49 | I |       - range scale = [    1.0000]
24-11-25 15:20:49 | I |         sum  error  = [   14.5903]
24-11-25 15:20:49 | I |         best error  = [   14.5903]
24-11-25 15:20:49 | I |     + error = [14.5903]
24-11-25 15:20:49 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 15:20:50 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 15:20:52 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 15:20:53 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 15:20:54 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 15:20:56 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 15:20:57 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 15:21:00 | I | quantizing activations for layer model.layers.0
24-11-25 15:21:00 | I | collecting info in model.layers.0
24-11-25 15:21:00 | I | collecting info in model.layers.0
24-11-25 15:21:01 | I | collecting info in model.layers.0
24-11-25 15:21:01 | I | collecting info in model.layers.0
24-11-25 15:21:01 | I | collecting calibration activations in model.layers.0
24-11-25 15:21:01 | I | collecting calibration activations in model.layers.0
24-11-25 15:21:01 | I | collecting calibration activations in model.layers.0
24-11-25 15:21:01 | I | collecting calibration activations in model.layers.0
24-11-25 15:21:03 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 15:21:03 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 15:21:03 | I | - Evaluator: gptq
24-11-25 15:21:03 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 15:21:03 | I | - Batch_size: 8
24-11-25 15:21:03 | I |   + Max_seq_length: 2048
24-11-25 15:21:45 | I |     - Results:
24-11-25 15:21:45 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 15:21:45 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 15:21:45 | I |       |wikitext |      1|word_perplexity|7.7706|  |7.7706|
24-11-25 15:21:45 | I |       |val_valid|      1|word_perplexity|9.0597|  |9.0597|
24-11-25 15:21:45 | I |       
24-11-25 15:21:45 | I | forward this layer
24-11-25 15:21:45 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/10.pt
24-11-25 15:21:45 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/10.pt
24-11-25 15:21:45 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: True
24-11-25 15:21:45 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 15:21:45 | I | nan: first position tensor([0, 0], device='cuda:0')
24-11-25 15:21:45 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: True
24-11-25 15:21:45 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 15:21:45 | I | nan: first position tensor([0, 0], device='cuda:0')
24-11-25 15:21:45 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: True
24-11-25 15:21:45 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 15:21:45 | I | nan: first position tensor([0, 0], device='cuda:0')
24-11-25 15:21:45 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: True
24-11-25 15:21:45 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: True
24-11-25 15:21:45 | I | inf: first position tensor([ 17, 125], device='cuda:0')
24-11-25 15:21:45 | I | nan: first position tensor([94,  0], device='cuda:0')
24-11-25 15:21:45 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 15:21:45 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: True
24-11-25 15:21:45 | I | inf: first position tensor([5007,  165], device='cuda:0')
24-11-25 15:21:45 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 15:21:45 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: True
24-11-25 15:21:45 | I | inf: first position tensor([5007,  165], device='cuda:0')
24-11-25 15:21:45 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 15:21:45 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: True
24-11-25 15:21:45 | I | inf: first position tensor([1465, 5007], device='cuda:0')
24-11-25 15:21:45 | I | in layer model.layers.0
24-11-25 15:21:45 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 15:21:45 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 15:21:45 | I | - Evaluator: gptq
24-11-25 15:21:45 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 15:21:45 | I | - Batch_size: 8
24-11-25 15:21:45 | I |   + Max_seq_length: 2048
24-11-25 15:22:23 | I |     - Results:
24-11-25 15:22:23 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 15:22:23 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 15:22:23 | I |       |wikitext |      1|word_perplexity|7.7077|  |7.7077|
24-11-25 15:22:23 | I |       |val_valid|      1|word_perplexity|8.9799|  |8.9799|
24-11-25 15:22:23 | I |       
24-11-25 15:22:23 | I | quantizing weights for layer model.layers.0
24-11-25 15:22:23 | I | collecting info in model.layers.0
24-11-25 15:22:23 | I | collecting info in model.layers.0
24-11-25 15:22:23 | I | collecting info in model.layers.0
24-11-25 15:22:23 | I | collecting info in model.layers.0
24-11-25 15:22:24 | I | collecting calibration activations in model.layers.0
24-11-25 15:22:24 | I | collecting calibration activations in model.layers.0
24-11-25 15:22:24 | I | collecting calibration activations in model.layers.0
24-11-25 15:22:24 | I | collecting calibration activations in model.layers.0
24-11-25 15:22:24 | I | - Quantizing decoder layer model.layers.0
24-11-25 15:22:24 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 15:22:25 | I |       - range scale = [    1.0000]
24-11-25 15:22:25 | I |         sum  error  = [    0.0647]
24-11-25 15:22:25 | I |         best error  = [    0.0647]
24-11-25 15:22:25 | I |     + error = [0.0647]
24-11-25 15:22:26 | I |       - range scale = [    1.0000]
24-11-25 15:22:26 | I |         sum  error  = [    0.6039]
24-11-25 15:22:26 | I |         best error  = [    0.6039]
24-11-25 15:22:26 | I |     + error = [0.6039]
24-11-25 15:22:26 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 15:22:27 | I |       - range scale = [    1.0000]
24-11-25 15:22:27 | I |         sum  error  = [    0.0721]
24-11-25 15:22:27 | I |         best error  = [    0.0721]
24-11-25 15:22:27 | I |     + error = [0.0721]
24-11-25 15:22:27 | I |       - range scale = [    1.0000]
24-11-25 15:22:27 | I |         sum  error  = [    0.5086]
24-11-25 15:22:27 | I |         best error  = [    0.5086]
24-11-25 15:22:27 | I |     + error = [0.5086]
24-11-25 15:22:28 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 15:22:28 | I |       - range scale = [    1.0000]
24-11-25 15:22:28 | I |         sum  error  = [    0.2507]
24-11-25 15:22:28 | I |         best error  = [    0.2507]
24-11-25 15:22:28 | I |     + error = [0.2507]
24-11-25 15:22:29 | I |       - range scale = [    1.0000]
24-11-25 15:22:29 | I |         sum  error  = [    1.8294]
24-11-25 15:22:29 | I |         best error  = [    1.8294]
24-11-25 15:22:29 | I |     + error = [1.8294]
24-11-25 15:22:29 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 15:22:30 | I |       - range scale = [    1.0000]
24-11-25 15:22:30 | I |         sum  error  = [    0.0568]
24-11-25 15:22:30 | I |         best error  = [    0.0568]
24-11-25 15:22:30 | I |     + error = [0.0568]
24-11-25 15:22:30 | I |       - range scale = [    1.0000]
24-11-25 15:22:30 | I |         sum  error  = [    0.5516]
24-11-25 15:22:30 | I |         best error  = [    0.5516]
24-11-25 15:22:30 | I |     + error = [0.5516]
24-11-25 15:22:31 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 15:22:31 | I |       - range scale = [    1.0000]
24-11-25 15:22:31 | I |         sum  error  = [    1.0535]
24-11-25 15:22:31 | I |         best error  = [    1.0535]
24-11-25 15:22:31 | I |     + error = [1.0535]
24-11-25 15:22:32 | I |       - range scale = [    1.0000]
24-11-25 15:22:32 | I |         sum  error  = [   11.6600]
24-11-25 15:22:32 | I |         best error  = [   11.6600]
24-11-25 15:22:32 | I |     + error = [11.6600]
24-11-25 15:22:32 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 15:22:33 | I |       - range scale = [    1.0000]
24-11-25 15:22:33 | I |         sum  error  = [    1.2178]
24-11-25 15:22:33 | I |         best error  = [    1.2178]
24-11-25 15:22:33 | I |     + error = [1.2178]
24-11-25 15:22:34 | I |       - range scale = [    1.0000]
24-11-25 15:22:34 | I |         sum  error  = [   12.0364]
24-11-25 15:22:34 | I |         best error  = [   12.0364]
24-11-25 15:22:34 | I |     + error = [12.0364]
24-11-25 15:22:34 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 15:22:35 | I |       - range scale = [    1.0000]
24-11-25 15:22:35 | I |         sum  error  = [    3.4353]
24-11-25 15:22:35 | I |         best error  = [    3.4353]
24-11-25 15:22:35 | I |     + error = [3.4353]
24-11-25 15:22:35 | I |       - range scale = [    1.0000]
24-11-25 15:22:35 | I |         sum  error  = [   16.7866]
24-11-25 15:22:35 | I |         best error  = [   16.7866]
24-11-25 15:22:35 | I |     + error = [16.7866]
24-11-25 15:22:36 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 15:22:37 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 15:22:38 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 15:22:40 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 15:22:41 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 15:22:42 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 15:22:44 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 15:22:47 | I | quantizing activations for layer model.layers.0
24-11-25 15:22:47 | I | collecting info in model.layers.0
24-11-25 15:22:47 | I | collecting info in model.layers.0
24-11-25 15:22:47 | I | collecting info in model.layers.0
24-11-25 15:22:47 | I | collecting info in model.layers.0
24-11-25 15:22:48 | I | collecting calibration activations in model.layers.0
24-11-25 15:22:48 | I | collecting calibration activations in model.layers.0
24-11-25 15:22:48 | I | collecting calibration activations in model.layers.0
24-11-25 15:22:48 | I | collecting calibration activations in model.layers.0
24-11-25 15:22:50 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 15:22:50 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 15:22:50 | I | - Evaluator: gptq
24-11-25 15:22:50 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 15:22:50 | I | - Batch_size: 8
24-11-25 15:22:50 | I |   + Max_seq_length: 2048
24-11-25 15:23:31 | I |     - Results:
24-11-25 15:23:31 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 15:23:31 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 15:23:31 | I |       |wikitext |      1|word_perplexity|7.7696|  |7.7696|
24-11-25 15:23:31 | I |       |val_valid|      1|word_perplexity|9.0574|  |9.0574|
24-11-25 15:23:31 | I |       
24-11-25 15:23:31 | I | forward this layer
24-11-25 15:23:31 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/11.pt
24-11-25 15:23:31 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/11.pt
24-11-25 15:23:32 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: True
24-11-25 15:23:32 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 15:23:32 | I | nan: first position tensor([0, 0], device='cuda:0')
24-11-25 15:23:32 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: True
24-11-25 15:23:32 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 15:23:32 | I | nan: first position tensor([0, 0], device='cuda:0')
24-11-25 15:23:32 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: True
24-11-25 15:23:32 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 15:23:32 | I | nan: first position tensor([0, 0], device='cuda:0')
24-11-25 15:23:32 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 15:23:32 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 15:23:32 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 15:23:32 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 15:23:32 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 15:23:32 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 15:23:32 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 15:23:32 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: True
24-11-25 15:23:32 | I | inf: first position tensor([1327, 5007], device='cuda:0')
24-11-25 15:23:32 | I | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
24-11-25 15:23:32 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 15:23:32 | I | in layer model.layers.0
24-11-25 15:23:32 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 15:23:32 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 15:23:32 | I | - Evaluator: gptq
24-11-25 15:23:32 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 15:23:32 | I | - Batch_size: 8
24-11-25 15:23:32 | I |   + Max_seq_length: 2048
24-11-25 15:24:10 | I |     - Results:
24-11-25 15:24:10 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 15:24:10 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 15:24:10 | I |       |wikitext |      1|word_perplexity|7.7077|  |7.7077|
24-11-25 15:24:10 | I |       |val_valid|      1|word_perplexity|8.9799|  |8.9799|
24-11-25 15:24:10 | I |       
24-11-25 15:24:10 | I | quantizing weights for layer model.layers.0
24-11-25 15:24:10 | I | collecting info in model.layers.0
24-11-25 15:24:10 | I | collecting info in model.layers.0
24-11-25 15:24:10 | I | collecting info in model.layers.0
24-11-25 15:24:10 | I | collecting info in model.layers.0
24-11-25 15:24:11 | I | collecting calibration activations in model.layers.0
24-11-25 15:24:11 | I | collecting calibration activations in model.layers.0
24-11-25 15:24:11 | I | collecting calibration activations in model.layers.0
24-11-25 15:24:11 | I | collecting calibration activations in model.layers.0
24-11-25 15:24:11 | I | - Quantizing decoder layer model.layers.0
24-11-25 15:24:11 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 15:24:12 | I |       - range scale = [    1.0000]
24-11-25 15:24:12 | I |         sum  error  = [    0.0653]
24-11-25 15:24:12 | I |         best error  = [    0.0653]
24-11-25 15:24:12 | I |     + error = [0.0653]
24-11-25 15:24:13 | I |       - range scale = [    1.0000]
24-11-25 15:24:13 | I |         sum  error  = [    0.6014]
24-11-25 15:24:13 | I |         best error  = [    0.6014]
24-11-25 15:24:13 | I |     + error = [0.6014]
24-11-25 15:24:13 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 15:24:14 | I |       - range scale = [    1.0000]
24-11-25 15:24:14 | I |         sum  error  = [    0.0685]
24-11-25 15:24:14 | I |         best error  = [    0.0685]
24-11-25 15:24:14 | I |     + error = [0.0685]
24-11-25 15:24:14 | I |       - range scale = [    1.0000]
24-11-25 15:24:14 | I |         sum  error  = [    0.4932]
24-11-25 15:24:14 | I |         best error  = [    0.4932]
24-11-25 15:24:14 | I |     + error = [0.4932]
24-11-25 15:24:15 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 15:24:15 | I |       - range scale = [    1.0000]
24-11-25 15:24:15 | I |         sum  error  = [    0.2463]
24-11-25 15:24:15 | I |         best error  = [    0.2463]
24-11-25 15:24:15 | I |     + error = [0.2463]
24-11-25 15:24:16 | I |       - range scale = [    1.0000]
24-11-25 15:24:16 | I |         sum  error  = [    1.8089]
24-11-25 15:24:16 | I |         best error  = [    1.8089]
24-11-25 15:24:16 | I |     + error = [1.8089]
24-11-25 15:24:16 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 15:24:17 | I |       - range scale = [    1.0000]
24-11-25 15:24:17 | I |         sum  error  = [    0.0600]
24-11-25 15:24:17 | I |         best error  = [    0.0600]
24-11-25 15:24:17 | I |     + error = [0.0600]
24-11-25 15:24:17 | I |       - range scale = [    1.0000]
24-11-25 15:24:17 | I |         sum  error  = [    0.5841]
24-11-25 15:24:17 | I |         best error  = [    0.5841]
24-11-25 15:24:17 | I |     + error = [0.5841]
24-11-25 15:24:18 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 15:24:18 | I |       - range scale = [    1.0000]
24-11-25 15:24:18 | I |         sum  error  = [    1.0799]
24-11-25 15:24:18 | I |         best error  = [    1.0799]
24-11-25 15:24:18 | I |     + error = [1.0799]
24-11-25 15:24:19 | I |       - range scale = [    1.0000]
24-11-25 15:24:19 | I |         sum  error  = [   11.9630]
24-11-25 15:24:19 | I |         best error  = [   11.9630]
24-11-25 15:24:19 | I |     + error = [11.9630]
24-11-25 15:24:19 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 15:24:20 | I |       - range scale = [    1.0000]
24-11-25 15:24:20 | I |         sum  error  = [    1.2510]
24-11-25 15:24:20 | I |         best error  = [    1.2510]
24-11-25 15:24:20 | I |     + error = [1.2510]
24-11-25 15:24:21 | I |       - range scale = [    1.0000]
24-11-25 15:24:21 | I |         sum  error  = [   12.3695]
24-11-25 15:24:21 | I |         best error  = [   12.3695]
24-11-25 15:24:21 | I |     + error = [12.3695]
24-11-25 15:24:21 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 15:24:22 | I |       - range scale = [    1.0000]
24-11-25 15:24:22 | I |         sum  error  = [    3.0531]
24-11-25 15:24:22 | I |         best error  = [    3.0531]
24-11-25 15:24:22 | I |     + error = [3.0531]
24-11-25 15:24:22 | I |       - range scale = [    1.0000]
24-11-25 15:24:22 | I |         sum  error  = [   14.7334]
24-11-25 15:24:22 | I |         best error  = [   14.7334]
24-11-25 15:24:22 | I |     + error = [14.7334]
24-11-25 15:24:23 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 15:24:24 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 15:24:25 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 15:24:27 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 15:24:28 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 15:24:29 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 15:24:31 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 15:24:34 | I | quantizing activations for layer model.layers.0
24-11-25 15:24:34 | I | collecting info in model.layers.0
24-11-25 15:24:34 | I | collecting info in model.layers.0
24-11-25 15:24:34 | I | collecting info in model.layers.0
24-11-25 15:24:34 | I | collecting info in model.layers.0
24-11-25 15:24:35 | I | collecting calibration activations in model.layers.0
24-11-25 15:24:35 | I | collecting calibration activations in model.layers.0
24-11-25 15:24:35 | I | collecting calibration activations in model.layers.0
24-11-25 15:24:35 | I | collecting calibration activations in model.layers.0
24-11-25 15:24:37 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 15:24:37 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 15:24:37 | I | - Evaluator: gptq
24-11-25 15:24:37 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 15:24:37 | I | - Batch_size: 8
24-11-25 15:24:37 | I |   + Max_seq_length: 2048
24-11-25 15:25:18 | I |     - Results:
24-11-25 15:25:18 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 15:25:18 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 15:25:18 | I |       |wikitext |      1|word_perplexity|7.7793|  |7.7793|
24-11-25 15:25:18 | I |       |val_valid|      1|word_perplexity|9.0611|  |9.0611|
24-11-25 15:25:18 | I |       
24-11-25 15:25:18 | I | forward this layer
24-11-25 15:25:18 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/12.pt
24-11-25 15:25:18 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/12.pt
24-11-25 15:25:19 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: True
24-11-25 15:25:19 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 15:25:19 | I | nan: first position tensor([0, 0], device='cuda:0')
24-11-25 15:25:19 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: True
24-11-25 15:25:19 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 15:25:19 | I | nan: first position tensor([0, 0], device='cuda:0')
24-11-25 15:25:19 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: True
24-11-25 15:25:19 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 15:25:19 | I | nan: first position tensor([0, 0], device='cuda:0')
24-11-25 15:25:19 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 15:25:19 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 15:25:19 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 15:25:19 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 15:25:19 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 15:25:19 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 15:25:19 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 15:25:19 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 15:25:19 | I | in layer model.layers.0
24-11-25 15:25:19 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 15:25:19 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 15:25:19 | I | - Evaluator: gptq
24-11-25 15:25:19 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 15:25:19 | I | - Batch_size: 8
24-11-25 15:25:19 | I |   + Max_seq_length: 2048
24-11-25 15:25:57 | I |     - Results:
24-11-25 15:25:57 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 15:25:57 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 15:25:57 | I |       |wikitext |      1|word_perplexity|7.7077|  |7.7077|
24-11-25 15:25:57 | I |       |val_valid|      1|word_perplexity|8.9799|  |8.9799|
24-11-25 15:25:57 | I |       
24-11-25 15:25:57 | I | quantizing weights for layer model.layers.0
24-11-25 15:25:57 | I | collecting info in model.layers.0
24-11-25 15:25:57 | I | collecting info in model.layers.0
24-11-25 15:25:57 | I | collecting info in model.layers.0
24-11-25 15:25:57 | I | collecting info in model.layers.0
24-11-25 15:25:57 | I | collecting calibration activations in model.layers.0
24-11-25 15:25:58 | I | collecting calibration activations in model.layers.0
24-11-25 15:25:58 | I | collecting calibration activations in model.layers.0
24-11-25 15:25:58 | I | collecting calibration activations in model.layers.0
24-11-25 15:25:58 | I | - Quantizing decoder layer model.layers.0
24-11-25 15:25:58 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 15:25:59 | I |       - range scale = [    1.0000]
24-11-25 15:25:59 | I |         sum  error  = [    0.0659]
24-11-25 15:25:59 | I |         best error  = [    0.0659]
24-11-25 15:25:59 | I |     + error = [0.0659]
24-11-25 15:25:59 | I |       - range scale = [    1.0000]
24-11-25 15:25:59 | I |         sum  error  = [    0.6136]
24-11-25 15:25:59 | I |         best error  = [    0.6136]
24-11-25 15:25:59 | I |     + error = [0.6136]
24-11-25 15:26:00 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 15:26:00 | I |       - range scale = [    1.0000]
24-11-25 15:26:00 | I |         sum  error  = [    0.0707]
24-11-25 15:26:00 | I |         best error  = [    0.0707]
24-11-25 15:26:00 | I |     + error = [0.0707]
24-11-25 15:26:01 | I |       - range scale = [    1.0000]
24-11-25 15:26:01 | I |         sum  error  = [    0.5014]
24-11-25 15:26:01 | I |         best error  = [    0.5014]
24-11-25 15:26:01 | I |     + error = [0.5014]
24-11-25 15:26:01 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 15:26:02 | I |       - range scale = [    1.0000]
24-11-25 15:26:02 | I |         sum  error  = [    0.2472]
24-11-25 15:26:02 | I |         best error  = [    0.2472]
24-11-25 15:26:02 | I |     + error = [0.2472]
24-11-25 15:26:03 | I |       - range scale = [    1.0000]
24-11-25 15:26:03 | I |         sum  error  = [    1.8048]
24-11-25 15:26:03 | I |         best error  = [    1.8048]
24-11-25 15:26:03 | I |     + error = [1.8048]
24-11-25 15:26:03 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 15:26:04 | I |       - range scale = [    1.0000]
24-11-25 15:26:04 | I |         sum  error  = [    0.0575]
24-11-25 15:26:04 | I |         best error  = [    0.0575]
24-11-25 15:26:04 | I |     + error = [0.0575]
24-11-25 15:26:04 | I |       - range scale = [    1.0000]
24-11-25 15:26:04 | I |         sum  error  = [    0.5567]
24-11-25 15:26:04 | I |         best error  = [    0.5567]
24-11-25 15:26:04 | I |     + error = [0.5567]
24-11-25 15:26:04 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 15:26:05 | I |       - range scale = [    1.0000]
24-11-25 15:26:05 | I |         sum  error  = [    1.0737]
24-11-25 15:26:05 | I |         best error  = [    1.0737]
24-11-25 15:26:05 | I |     + error = [1.0737]
24-11-25 15:26:06 | I |       - range scale = [    1.0000]
24-11-25 15:26:06 | I |         sum  error  = [   11.8765]
24-11-25 15:26:06 | I |         best error  = [   11.8765]
24-11-25 15:26:06 | I |     + error = [11.8765]
24-11-25 15:26:06 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 15:26:07 | I |       - range scale = [    1.0000]
24-11-25 15:26:07 | I |         sum  error  = [    1.2407]
24-11-25 15:26:07 | I |         best error  = [    1.2407]
24-11-25 15:26:07 | I |     + error = [1.2407]
24-11-25 15:26:08 | I |       - range scale = [    1.0000]
24-11-25 15:26:08 | I |         sum  error  = [   12.2872]
24-11-25 15:26:08 | I |         best error  = [   12.2872]
24-11-25 15:26:08 | I |     + error = [12.2872]
24-11-25 15:26:08 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 15:26:08 | I |       - range scale = [    1.0000]
24-11-25 15:26:08 | I |         sum  error  = [    3.3762]
24-11-25 15:26:08 | I |         best error  = [    3.3762]
24-11-25 15:26:08 | I |     + error = [3.3762]
24-11-25 15:26:09 | I |       - range scale = [    1.0000]
24-11-25 15:26:09 | I |         sum  error  = [   16.5898]
24-11-25 15:26:09 | I |         best error  = [   16.5898]
24-11-25 15:26:09 | I |     + error = [16.5898]
24-11-25 15:26:09 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 15:26:11 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 15:26:12 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 15:26:14 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 15:26:15 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 15:26:16 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 15:26:18 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 15:26:21 | I | quantizing activations for layer model.layers.0
24-11-25 15:26:21 | I | collecting info in model.layers.0
24-11-25 15:26:21 | I | collecting info in model.layers.0
24-11-25 15:26:21 | I | collecting info in model.layers.0
24-11-25 15:26:21 | I | collecting info in model.layers.0
24-11-25 15:26:22 | I | collecting calibration activations in model.layers.0
24-11-25 15:26:22 | I | collecting calibration activations in model.layers.0
24-11-25 15:26:22 | I | collecting calibration activations in model.layers.0
24-11-25 15:26:22 | I | collecting calibration activations in model.layers.0
24-11-25 15:26:24 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 15:26:24 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 15:26:24 | I | - Evaluator: gptq
24-11-25 15:26:24 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 15:26:24 | I | - Batch_size: 8
24-11-25 15:26:24 | I |   + Max_seq_length: 2048
24-11-25 15:27:05 | I |     - Results:
24-11-25 15:27:05 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 15:27:05 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 15:27:05 | I |       |wikitext |      1|word_perplexity|7.7875|  |7.7875|
24-11-25 15:27:05 | I |       |val_valid|      1|word_perplexity|9.0578|  |9.0578|
24-11-25 15:27:05 | I |       
24-11-25 15:27:05 | I | forward this layer
24-11-25 15:27:05 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/13.pt
24-11-25 15:27:05 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/13.pt
24-11-25 15:27:05 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: True
24-11-25 15:27:05 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 15:27:05 | I | nan: first position tensor([0, 0], device='cuda:0')
24-11-25 15:27:05 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: True
24-11-25 15:27:05 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 15:27:05 | I | nan: first position tensor([0, 0], device='cuda:0')
24-11-25 15:27:05 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: True
24-11-25 15:27:05 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 15:27:05 | I | nan: first position tensor([0, 0], device='cuda:0')
24-11-25 15:27:05 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 15:27:05 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 15:27:05 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 15:27:05 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 15:27:05 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 15:27:05 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 15:27:05 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 15:27:05 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 15:27:06 | I | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
24-11-25 15:27:06 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 15:27:06 | I | in layer model.layers.0
24-11-25 15:27:06 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 15:27:06 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 15:27:06 | I | - Evaluator: gptq
24-11-25 15:27:06 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 15:27:06 | I | - Batch_size: 8
24-11-25 15:27:06 | I |   + Max_seq_length: 2048
24-11-25 15:27:44 | I |     - Results:
24-11-25 15:27:44 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 15:27:44 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 15:27:44 | I |       |wikitext |      1|word_perplexity|7.7077|  |7.7077|
24-11-25 15:27:44 | I |       |val_valid|      1|word_perplexity|8.9799|  |8.9799|
24-11-25 15:27:44 | I |       
24-11-25 15:27:44 | I | quantizing weights for layer model.layers.0
24-11-25 15:27:44 | I | collecting info in model.layers.0
24-11-25 15:27:44 | I | collecting info in model.layers.0
24-11-25 15:27:44 | I | collecting info in model.layers.0
24-11-25 15:27:44 | I | collecting info in model.layers.0
24-11-25 15:27:45 | I | collecting calibration activations in model.layers.0
24-11-25 15:27:45 | I | collecting calibration activations in model.layers.0
24-11-25 15:27:45 | I | collecting calibration activations in model.layers.0
24-11-25 15:27:45 | I | collecting calibration activations in model.layers.0
24-11-25 15:27:45 | I | - Quantizing decoder layer model.layers.0
24-11-25 15:27:45 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 15:27:46 | I |       - range scale = [    1.0000]
24-11-25 15:27:46 | I |         sum  error  = [    0.0655]
24-11-25 15:27:46 | I |         best error  = [    0.0655]
24-11-25 15:27:46 | I |     + error = [0.0655]
24-11-25 15:27:47 | I |       - range scale = [    1.0000]
24-11-25 15:27:47 | I |         sum  error  = [    0.6127]
24-11-25 15:27:47 | I |         best error  = [    0.6127]
24-11-25 15:27:47 | I |     + error = [0.6127]
24-11-25 15:27:47 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 15:27:48 | I |       - range scale = [    1.0000]
24-11-25 15:27:48 | I |         sum  error  = [    0.0711]
24-11-25 15:27:48 | I |         best error  = [    0.0711]
24-11-25 15:27:48 | I |     + error = [0.0711]
24-11-25 15:27:48 | I |       - range scale = [    1.0000]
24-11-25 15:27:48 | I |         sum  error  = [    0.5053]
24-11-25 15:27:48 | I |         best error  = [    0.5053]
24-11-25 15:27:48 | I |     + error = [0.5053]
24-11-25 15:27:48 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 15:27:49 | I |       - range scale = [    1.0000]
24-11-25 15:27:49 | I |         sum  error  = [    0.2503]
24-11-25 15:27:49 | I |         best error  = [    0.2503]
24-11-25 15:27:49 | I |     + error = [0.2503]
24-11-25 15:27:50 | I |       - range scale = [    1.0000]
24-11-25 15:27:50 | I |         sum  error  = [    1.8336]
24-11-25 15:27:50 | I |         best error  = [    1.8336]
24-11-25 15:27:50 | I |     + error = [1.8336]
24-11-25 15:27:50 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 15:27:51 | I |       - range scale = [    1.0000]
24-11-25 15:27:51 | I |         sum  error  = [    0.0594]
24-11-25 15:27:51 | I |         best error  = [    0.0594]
24-11-25 15:27:51 | I |     + error = [0.0594]
24-11-25 15:27:51 | I |       - range scale = [    1.0000]
24-11-25 15:27:51 | I |         sum  error  = [    0.5722]
24-11-25 15:27:51 | I |         best error  = [    0.5722]
24-11-25 15:27:51 | I |     + error = [0.5722]
24-11-25 15:27:52 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 15:27:52 | I |       - range scale = [    1.0000]
24-11-25 15:27:52 | I |         sum  error  = [    1.0777]
24-11-25 15:27:52 | I |         best error  = [    1.0777]
24-11-25 15:27:52 | I |     + error = [1.0777]
24-11-25 15:27:53 | I |       - range scale = [    1.0000]
24-11-25 15:27:53 | I |         sum  error  = [   11.9280]
24-11-25 15:27:53 | I |         best error  = [   11.9280]
24-11-25 15:27:53 | I |     + error = [11.9280]
24-11-25 15:27:53 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 15:27:54 | I |       - range scale = [    1.0000]
24-11-25 15:27:54 | I |         sum  error  = [    1.2475]
24-11-25 15:27:54 | I |         best error  = [    1.2475]
24-11-25 15:27:54 | I |     + error = [1.2475]
24-11-25 15:27:55 | I |       - range scale = [    1.0000]
24-11-25 15:27:55 | I |         sum  error  = [   12.3302]
24-11-25 15:27:55 | I |         best error  = [   12.3302]
24-11-25 15:27:55 | I |     + error = [12.3302]
24-11-25 15:27:55 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 15:27:56 | I |       - range scale = [    1.0000]
24-11-25 15:27:56 | I |         sum  error  = [    3.7156]
24-11-25 15:27:56 | I |         best error  = [    3.7156]
24-11-25 15:27:56 | I |     + error = [3.7156]
24-11-25 15:27:56 | I |       - range scale = [    1.0000]
24-11-25 15:27:56 | I |         sum  error  = [   18.1756]
24-11-25 15:27:56 | I |         best error  = [   18.1756]
24-11-25 15:27:56 | I |     + error = [18.1756]
24-11-25 15:27:57 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 15:27:58 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 15:27:59 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 15:28:01 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 15:28:02 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 15:28:03 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 15:28:05 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 15:28:08 | I | quantizing activations for layer model.layers.0
24-11-25 15:28:08 | I | collecting info in model.layers.0
24-11-25 15:28:08 | I | collecting info in model.layers.0
24-11-25 15:28:08 | I | collecting info in model.layers.0
24-11-25 15:28:08 | I | collecting info in model.layers.0
24-11-25 15:28:09 | I | collecting calibration activations in model.layers.0
24-11-25 15:28:09 | I | collecting calibration activations in model.layers.0
24-11-25 15:28:09 | I | collecting calibration activations in model.layers.0
24-11-25 15:28:09 | I | collecting calibration activations in model.layers.0
24-11-25 15:28:11 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 15:28:11 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 15:28:11 | I | - Evaluator: gptq
24-11-25 15:28:11 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 15:28:11 | I | - Batch_size: 8
24-11-25 15:28:11 | I |   + Max_seq_length: 2048
24-11-25 15:28:52 | I |     - Results:
24-11-25 15:28:52 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 15:28:52 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 15:28:52 | I |       |wikitext |      1|word_perplexity|7.7758|  |7.7758|
24-11-25 15:28:52 | I |       |val_valid|      1|word_perplexity|9.0580|  |9.0580|
24-11-25 15:28:52 | I |       
24-11-25 15:28:52 | I | forward this layer
24-11-25 15:28:52 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/14.pt
24-11-25 15:28:52 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/14.pt
24-11-25 15:28:52 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 15:28:52 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 15:28:52 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 15:28:52 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 15:28:52 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 15:28:52 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: True
24-11-25 15:28:52 | I | inf: first position tensor([ 21, 712], device='cuda:0')
24-11-25 15:28:52 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 15:28:52 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 15:28:52 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 15:28:52 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 15:28:52 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 15:28:52 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 15:28:52 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 15:28:52 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 15:28:53 | I | in layer model.layers.0
24-11-25 15:28:53 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 15:28:53 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 15:28:53 | I | - Evaluator: gptq
24-11-25 15:28:53 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 15:28:53 | I | - Batch_size: 8
24-11-25 15:28:53 | I |   + Max_seq_length: 2048
24-11-25 15:29:31 | I |     - Results:
24-11-25 15:29:31 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 15:29:31 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 15:29:31 | I |       |wikitext |      1|word_perplexity|7.7077|  |7.7077|
24-11-25 15:29:31 | I |       |val_valid|      1|word_perplexity|8.9799|  |8.9799|
24-11-25 15:29:31 | I |       
24-11-25 15:29:31 | I | quantizing weights for layer model.layers.0
24-11-25 15:29:31 | I | collecting info in model.layers.0
24-11-25 15:29:31 | I | collecting info in model.layers.0
24-11-25 15:29:31 | I | collecting info in model.layers.0
24-11-25 15:29:31 | I | collecting info in model.layers.0
24-11-25 15:29:31 | I | collecting calibration activations in model.layers.0
24-11-25 15:29:31 | I | collecting calibration activations in model.layers.0
24-11-25 15:29:32 | I | collecting calibration activations in model.layers.0
24-11-25 15:29:32 | I | collecting calibration activations in model.layers.0
24-11-25 15:29:32 | I | - Quantizing decoder layer model.layers.0
24-11-25 15:29:32 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 15:29:33 | I |       - range scale = [    1.0000]
24-11-25 15:29:33 | I |         sum  error  = [    0.0668]
24-11-25 15:29:33 | I |         best error  = [    0.0668]
24-11-25 15:29:33 | I |     + error = [0.0668]
24-11-25 15:29:33 | I |       - range scale = [    1.0000]
24-11-25 15:29:33 | I |         sum  error  = [    0.6149]
24-11-25 15:29:33 | I |         best error  = [    0.6149]
24-11-25 15:29:33 | I |     + error = [0.6149]
24-11-25 15:29:34 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 15:29:34 | I |       - range scale = [    1.0000]
24-11-25 15:29:34 | I |         sum  error  = [    0.0712]
24-11-25 15:29:34 | I |         best error  = [    0.0712]
24-11-25 15:29:34 | I |     + error = [0.0712]
24-11-25 15:29:35 | I |       - range scale = [    1.0000]
24-11-25 15:29:35 | I |         sum  error  = [    0.5070]
24-11-25 15:29:35 | I |         best error  = [    0.5070]
24-11-25 15:29:35 | I |     + error = [0.5070]
24-11-25 15:29:35 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 15:29:36 | I |       - range scale = [    1.0000]
24-11-25 15:29:36 | I |         sum  error  = [    0.2496]
24-11-25 15:29:36 | I |         best error  = [    0.2496]
24-11-25 15:29:36 | I |     + error = [0.2496]
24-11-25 15:29:37 | I |       - range scale = [    1.0000]
24-11-25 15:29:37 | I |         sum  error  = [    1.8301]
24-11-25 15:29:37 | I |         best error  = [    1.8301]
24-11-25 15:29:37 | I |     + error = [1.8301]
24-11-25 15:29:37 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 15:29:38 | I |       - range scale = [    1.0000]
24-11-25 15:29:38 | I |         sum  error  = [    0.0617]
24-11-25 15:29:38 | I |         best error  = [    0.0617]
24-11-25 15:29:38 | I |     + error = [0.0617]
24-11-25 15:29:38 | I |       - range scale = [    1.0000]
24-11-25 15:29:38 | I |         sum  error  = [    0.5979]
24-11-25 15:29:38 | I |         best error  = [    0.5979]
24-11-25 15:29:38 | I |     + error = [0.5979]
24-11-25 15:29:38 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 15:29:39 | I |       - range scale = [    1.0000]
24-11-25 15:29:39 | I |         sum  error  = [    1.0629]
24-11-25 15:29:39 | I |         best error  = [    1.0629]
24-11-25 15:29:39 | I |     + error = [1.0629]
24-11-25 15:29:40 | I |       - range scale = [    1.0000]
24-11-25 15:29:40 | I |         sum  error  = [   11.7536]
24-11-25 15:29:40 | I |         best error  = [   11.7536]
24-11-25 15:29:40 | I |     + error = [11.7536]
24-11-25 15:29:40 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 15:29:41 | I |       - range scale = [    1.0000]
24-11-25 15:29:41 | I |         sum  error  = [    1.2294]
24-11-25 15:29:41 | I |         best error  = [    1.2294]
24-11-25 15:29:41 | I |     + error = [1.2294]
24-11-25 15:29:42 | I |       - range scale = [    1.0000]
24-11-25 15:29:42 | I |         sum  error  = [   12.1402]
24-11-25 15:29:42 | I |         best error  = [   12.1402]
24-11-25 15:29:42 | I |     + error = [12.1402]
24-11-25 15:29:42 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 15:29:43 | I |       - range scale = [    1.0000]
24-11-25 15:29:43 | I |         sum  error  = [    3.5224]
24-11-25 15:29:43 | I |         best error  = [    3.5224]
24-11-25 15:29:43 | I |     + error = [3.5224]
24-11-25 15:29:43 | I |       - range scale = [    1.0000]
24-11-25 15:29:43 | I |         sum  error  = [   16.8945]
24-11-25 15:29:43 | I |         best error  = [   16.8945]
24-11-25 15:29:43 | I |     + error = [16.8945]
24-11-25 15:29:44 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 15:29:45 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 15:29:46 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 15:29:48 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 15:29:49 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 15:29:51 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 15:29:52 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 15:29:55 | I | quantizing activations for layer model.layers.0
24-11-25 15:29:55 | I | collecting info in model.layers.0
24-11-25 15:29:55 | I | collecting info in model.layers.0
24-11-25 15:29:55 | I | collecting info in model.layers.0
24-11-25 15:29:55 | I | collecting info in model.layers.0
24-11-25 15:29:56 | I | collecting calibration activations in model.layers.0
24-11-25 15:29:56 | I | collecting calibration activations in model.layers.0
24-11-25 15:29:56 | I | collecting calibration activations in model.layers.0
24-11-25 15:29:56 | I | collecting calibration activations in model.layers.0
24-11-25 15:29:58 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 15:29:58 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 15:29:58 | I | - Evaluator: gptq
24-11-25 15:29:58 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 15:29:58 | I | - Batch_size: 8
24-11-25 15:29:58 | I |   + Max_seq_length: 2048
24-11-25 15:30:39 | I |     - Results:
24-11-25 15:30:39 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 15:30:39 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 15:30:39 | I |       |wikitext |      1|word_perplexity|7.7835|  |7.7835|
24-11-25 15:30:39 | I |       |val_valid|      1|word_perplexity|9.0585|  |9.0585|
24-11-25 15:30:39 | I |       
24-11-25 15:30:39 | I | forward this layer
24-11-25 15:30:39 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/15.pt
24-11-25 15:30:39 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/15.pt
24-11-25 15:30:40 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 15:30:40 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 15:30:40 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 15:30:40 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 15:30:40 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 15:30:40 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: True
24-11-25 15:30:40 | I | inf: first position tensor([ 21, 712], device='cuda:0')
24-11-25 15:30:40 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 15:30:40 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 15:30:40 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 15:30:40 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 15:30:40 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 15:30:40 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 15:30:40 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 15:30:40 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 15:30:40 | I | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
24-11-25 15:30:40 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 15:30:40 | I | in layer model.layers.0
24-11-25 15:30:40 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 15:30:40 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 15:30:40 | I | - Evaluator: gptq
24-11-25 15:30:40 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 15:30:40 | I | - Batch_size: 8
24-11-25 15:30:40 | I |   + Max_seq_length: 2048
24-11-25 15:31:18 | I |     - Results:
24-11-25 15:31:18 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 15:31:18 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 15:31:18 | I |       |wikitext |      1|word_perplexity|7.7077|  |7.7077|
24-11-25 15:31:18 | I |       |val_valid|      1|word_perplexity|8.9799|  |8.9799|
24-11-25 15:31:18 | I |       
24-11-25 15:31:18 | I | quantizing weights for layer model.layers.0
24-11-25 15:31:18 | I | collecting info in model.layers.0
24-11-25 15:31:18 | I | collecting info in model.layers.0
24-11-25 15:31:18 | I | collecting info in model.layers.0
24-11-25 15:31:18 | I | collecting info in model.layers.0
24-11-25 15:31:19 | I | collecting calibration activations in model.layers.0
24-11-25 15:31:19 | I | collecting calibration activations in model.layers.0
24-11-25 15:31:19 | I | collecting calibration activations in model.layers.0
24-11-25 15:31:19 | I | collecting calibration activations in model.layers.0
24-11-25 15:31:19 | I | - Quantizing decoder layer model.layers.0
24-11-25 15:31:19 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 15:31:20 | I |       - range scale = [    1.0000]
24-11-25 15:31:20 | I |         sum  error  = [    0.0655]
24-11-25 15:31:20 | I |         best error  = [    0.0655]
24-11-25 15:31:20 | I |     + error = [0.0655]
24-11-25 15:31:21 | I |       - range scale = [    1.0000]
24-11-25 15:31:21 | I |         sum  error  = [    0.6081]
24-11-25 15:31:21 | I |         best error  = [    0.6081]
24-11-25 15:31:21 | I |     + error = [0.6081]
24-11-25 15:31:21 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 15:31:22 | I |       - range scale = [    1.0000]
24-11-25 15:31:22 | I |         sum  error  = [    0.0712]
24-11-25 15:31:22 | I |         best error  = [    0.0712]
24-11-25 15:31:22 | I |     + error = [0.0712]
24-11-25 15:31:22 | I |       - range scale = [    1.0000]
24-11-25 15:31:22 | I |         sum  error  = [    0.5005]
24-11-25 15:31:22 | I |         best error  = [    0.5005]
24-11-25 15:31:22 | I |     + error = [0.5005]
24-11-25 15:31:23 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 15:31:23 | I |       - range scale = [    1.0000]
24-11-25 15:31:23 | I |         sum  error  = [    0.2488]
24-11-25 15:31:23 | I |         best error  = [    0.2488]
24-11-25 15:31:23 | I |     + error = [0.2488]
24-11-25 15:31:24 | I |       - range scale = [    1.0000]
24-11-25 15:31:24 | I |         sum  error  = [    1.8173]
24-11-25 15:31:24 | I |         best error  = [    1.8173]
24-11-25 15:31:24 | I |     + error = [1.8173]
24-11-25 15:31:24 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 15:31:25 | I |       - range scale = [    1.0000]
24-11-25 15:31:25 | I |         sum  error  = [    0.0600]
24-11-25 15:31:25 | I |         best error  = [    0.0600]
24-11-25 15:31:25 | I |     + error = [0.0600]
24-11-25 15:31:26 | I |       - range scale = [    1.0000]
24-11-25 15:31:26 | I |         sum  error  = [    0.5763]
24-11-25 15:31:26 | I |         best error  = [    0.5763]
24-11-25 15:31:26 | I |     + error = [0.5763]
24-11-25 15:31:26 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 15:31:26 | I |       - range scale = [    1.0000]
24-11-25 15:31:26 | I |         sum  error  = [    1.0729]
24-11-25 15:31:26 | I |         best error  = [    1.0729]
24-11-25 15:31:26 | I |     + error = [1.0729]
24-11-25 15:31:27 | I |       - range scale = [    1.0000]
24-11-25 15:31:27 | I |         sum  error  = [   11.8676]
24-11-25 15:31:27 | I |         best error  = [   11.8676]
24-11-25 15:31:27 | I |     + error = [11.8676]
24-11-25 15:31:27 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 15:31:28 | I |       - range scale = [    1.0000]
24-11-25 15:31:28 | I |         sum  error  = [    1.2409]
24-11-25 15:31:28 | I |         best error  = [    1.2409]
24-11-25 15:31:28 | I |     + error = [1.2409]
24-11-25 15:31:29 | I |       - range scale = [    1.0000]
24-11-25 15:31:29 | I |         sum  error  = [   12.2766]
24-11-25 15:31:29 | I |         best error  = [   12.2766]
24-11-25 15:31:29 | I |     + error = [12.2766]
24-11-25 15:31:29 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 15:31:30 | I |       - range scale = [    1.0000]
24-11-25 15:31:30 | I |         sum  error  = [    3.5948]
24-11-25 15:31:30 | I |         best error  = [    3.5948]
24-11-25 15:31:30 | I |     + error = [3.5948]
24-11-25 15:31:31 | I |       - range scale = [    1.0000]
24-11-25 15:31:31 | I |         sum  error  = [   17.4509]
24-11-25 15:31:31 | I |         best error  = [   17.4509]
24-11-25 15:31:31 | I |     + error = [17.4509]
24-11-25 15:31:31 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 15:31:32 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 15:31:34 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 15:31:35 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 15:31:36 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 15:31:38 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 15:31:39 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 15:31:43 | I | quantizing activations for layer model.layers.0
24-11-25 15:31:43 | I | collecting info in model.layers.0
24-11-25 15:31:43 | I | collecting info in model.layers.0
24-11-25 15:31:43 | I | collecting info in model.layers.0
24-11-25 15:31:43 | I | collecting info in model.layers.0
24-11-25 15:31:43 | I | collecting calibration activations in model.layers.0
24-11-25 15:31:43 | I | collecting calibration activations in model.layers.0
24-11-25 15:31:43 | I | collecting calibration activations in model.layers.0
24-11-25 15:31:43 | I | collecting calibration activations in model.layers.0
24-11-25 15:31:45 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 15:31:45 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 15:31:45 | I | - Evaluator: gptq
24-11-25 15:31:45 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 15:31:45 | I | - Batch_size: 8
24-11-25 15:31:45 | I |   + Max_seq_length: 2048
24-11-25 15:32:27 | I |     - Results:
24-11-25 15:32:27 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 15:32:27 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 15:32:27 | I |       |wikitext |      1|word_perplexity|7.7798|  |7.7798|
24-11-25 15:32:27 | I |       |val_valid|      1|word_perplexity|9.0587|  |9.0587|
24-11-25 15:32:27 | I |       
24-11-25 15:32:27 | I | forward this layer
24-11-25 15:32:27 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/16.pt
24-11-25 15:32:27 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/16.pt
24-11-25 15:32:27 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 15:32:27 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 15:32:27 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 15:32:27 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 15:32:27 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 15:32:27 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: True
24-11-25 15:32:27 | I | inf: first position tensor([ 21, 712], device='cuda:0')
24-11-25 15:32:27 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 15:32:27 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 15:32:27 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 15:32:27 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 15:32:27 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 15:32:27 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 15:32:27 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 15:32:27 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 15:32:27 | I | in layer model.layers.0
24-11-25 15:32:27 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 15:32:27 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 15:32:27 | I | - Evaluator: gptq
24-11-25 15:32:27 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 15:32:27 | I | - Batch_size: 8
24-11-25 15:32:27 | I |   + Max_seq_length: 2048
24-11-25 15:33:05 | I |     - Results:
24-11-25 15:33:05 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 15:33:05 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 15:33:05 | I |       |wikitext |      1|word_perplexity|7.7077|  |7.7077|
24-11-25 15:33:05 | I |       |val_valid|      1|word_perplexity|8.9799|  |8.9799|
24-11-25 15:33:05 | I |       
24-11-25 15:33:05 | I | quantizing weights for layer model.layers.0
24-11-25 15:33:05 | I | collecting info in model.layers.0
24-11-25 15:33:05 | I | collecting info in model.layers.0
24-11-25 15:33:05 | I | collecting info in model.layers.0
24-11-25 15:33:05 | I | collecting info in model.layers.0
24-11-25 15:33:06 | I | collecting calibration activations in model.layers.0
24-11-25 15:33:06 | I | collecting calibration activations in model.layers.0
24-11-25 15:33:06 | I | collecting calibration activations in model.layers.0
24-11-25 15:33:06 | I | collecting calibration activations in model.layers.0
24-11-25 15:33:06 | I | - Quantizing decoder layer model.layers.0
24-11-25 15:33:06 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 15:33:07 | I |       - range scale = [    1.0000]
24-11-25 15:33:07 | I |         sum  error  = [    0.0619]
24-11-25 15:33:07 | I |         best error  = [    0.0619]
24-11-25 15:33:07 | I |     + error = [0.0619]
24-11-25 15:33:08 | I |       - range scale = [    1.0000]
24-11-25 15:33:08 | I |         sum  error  = [    0.6380]
24-11-25 15:33:08 | I |         best error  = [    0.6380]
24-11-25 15:33:08 | I |     + error = [0.6380]
24-11-25 15:33:08 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 15:33:09 | I |       - range scale = [    1.0000]
24-11-25 15:33:09 | I |         sum  error  = [    0.0735]
24-11-25 15:33:09 | I |         best error  = [    0.0735]
24-11-25 15:33:09 | I |     + error = [0.0735]
24-11-25 15:33:09 | I |       - range scale = [    1.0000]
24-11-25 15:33:09 | I |         sum  error  = [    0.5176]
24-11-25 15:33:09 | I |         best error  = [    0.5176]
24-11-25 15:33:09 | I |     + error = [0.5176]
24-11-25 15:33:10 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 15:33:10 | I |       - range scale = [    1.0000]
24-11-25 15:33:10 | I |         sum  error  = [    0.2431]
24-11-25 15:33:10 | I |         best error  = [    0.2431]
24-11-25 15:33:10 | I |     + error = [0.2431]
24-11-25 15:33:11 | I |       - range scale = [    1.0000]
24-11-25 15:33:11 | I |         sum  error  = [    1.7847]
24-11-25 15:33:11 | I |         best error  = [    1.7847]
24-11-25 15:33:11 | I |     + error = [1.7847]
24-11-25 15:33:11 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 15:33:12 | I |       - range scale = [    1.0000]
24-11-25 15:33:12 | I |         sum  error  = [    0.0586]
24-11-25 15:33:12 | I |         best error  = [    0.0586]
24-11-25 15:33:12 | I |     + error = [0.0586]
24-11-25 15:33:12 | I |       - range scale = [    1.0000]
24-11-25 15:33:12 | I |         sum  error  = [    0.5682]
24-11-25 15:33:12 | I |         best error  = [    0.5682]
24-11-25 15:33:12 | I |     + error = [0.5682]
24-11-25 15:33:13 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 15:33:13 | I |       - range scale = [    1.0000]
24-11-25 15:33:13 | I |         sum  error  = [    1.0500]
24-11-25 15:33:13 | I |         best error  = [    1.0500]
24-11-25 15:33:13 | I |     + error = [1.0500]
24-11-25 15:33:14 | I |       - range scale = [    1.0000]
24-11-25 15:33:14 | I |         sum  error  = [   11.6369]
24-11-25 15:33:14 | I |         best error  = [   11.6369]
24-11-25 15:33:14 | I |     + error = [11.6369]
24-11-25 15:33:14 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 15:33:15 | I |       - range scale = [    1.0000]
24-11-25 15:33:15 | I |         sum  error  = [    1.2153]
24-11-25 15:33:15 | I |         best error  = [    1.2153]
24-11-25 15:33:15 | I |     + error = [1.2153]
24-11-25 15:33:16 | I |       - range scale = [    1.0000]
24-11-25 15:33:16 | I |         sum  error  = [   12.0065]
24-11-25 15:33:16 | I |         best error  = [   12.0065]
24-11-25 15:33:16 | I |     + error = [12.0065]
24-11-25 15:33:16 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 15:33:17 | I |       - range scale = [    1.0000]
24-11-25 15:33:17 | I |         sum  error  = [    3.0091]
24-11-25 15:33:17 | I |         best error  = [    3.0091]
24-11-25 15:33:17 | I |     + error = [3.0091]
24-11-25 15:33:17 | I |       - range scale = [    1.0000]
24-11-25 15:33:17 | I |         sum  error  = [   15.4396]
24-11-25 15:33:17 | I |         best error  = [   15.4396]
24-11-25 15:33:17 | I |     + error = [15.4396]
24-11-25 15:33:18 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 15:33:19 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 15:33:20 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 15:33:22 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 15:33:23 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 15:33:25 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 15:33:26 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 15:33:29 | I | quantizing activations for layer model.layers.0
24-11-25 15:33:29 | I | collecting info in model.layers.0
24-11-25 15:33:29 | I | collecting info in model.layers.0
24-11-25 15:33:29 | I | collecting info in model.layers.0
24-11-25 15:33:29 | I | collecting info in model.layers.0
24-11-25 15:33:30 | I | collecting calibration activations in model.layers.0
24-11-25 15:33:30 | I | collecting calibration activations in model.layers.0
24-11-25 15:33:30 | I | collecting calibration activations in model.layers.0
24-11-25 15:33:30 | I | collecting calibration activations in model.layers.0
24-11-25 15:33:32 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 15:33:32 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 15:33:32 | I | - Evaluator: gptq
24-11-25 15:33:32 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 15:33:32 | I | - Batch_size: 8
24-11-25 15:33:32 | I |   + Max_seq_length: 2048
24-11-25 15:34:13 | I |     - Results:
24-11-25 15:34:13 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 15:34:13 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 15:34:13 | I |       |wikitext |      1|word_perplexity|7.7645|  |7.7645|
24-11-25 15:34:13 | I |       |val_valid|      1|word_perplexity|9.0514|  |9.0514|
24-11-25 15:34:13 | I |       
24-11-25 15:34:13 | I | forward this layer
24-11-25 15:34:13 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/17.pt
24-11-25 15:34:13 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/17.pt
24-11-25 15:34:14 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: True
24-11-25 15:34:14 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 15:34:14 | I | nan: first position tensor([0, 0], device='cuda:0')
24-11-25 15:34:14 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: True
24-11-25 15:34:14 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 15:34:14 | I | nan: first position tensor([0, 0], device='cuda:0')
24-11-25 15:34:14 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: True
24-11-25 15:34:14 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 15:34:14 | I | nan: first position tensor([0, 0], device='cuda:0')
24-11-25 15:34:14 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 15:34:14 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 15:34:14 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 15:34:14 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 15:34:14 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 15:34:14 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 15:34:14 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 15:34:14 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 15:34:14 | I | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
24-11-25 15:34:14 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 15:34:14 | I | in layer model.layers.0
24-11-25 15:34:14 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 15:34:14 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 15:34:14 | I | - Evaluator: gptq
24-11-25 15:34:14 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 15:34:14 | I | - Batch_size: 8
24-11-25 15:34:14 | I |   + Max_seq_length: 2048
24-11-25 15:34:52 | I |     - Results:
24-11-25 15:34:52 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 15:34:52 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 15:34:52 | I |       |wikitext |      1|word_perplexity|7.7077|  |7.7077|
24-11-25 15:34:52 | I |       |val_valid|      1|word_perplexity|8.9799|  |8.9799|
24-11-25 15:34:52 | I |       
24-11-25 15:34:52 | I | quantizing weights for layer model.layers.0
24-11-25 15:34:52 | I | collecting info in model.layers.0
24-11-25 15:34:52 | I | collecting info in model.layers.0
24-11-25 15:34:52 | I | collecting info in model.layers.0
24-11-25 15:34:52 | I | collecting info in model.layers.0
24-11-25 15:34:53 | I | collecting calibration activations in model.layers.0
24-11-25 15:34:53 | I | collecting calibration activations in model.layers.0
24-11-25 15:34:53 | I | collecting calibration activations in model.layers.0
24-11-25 15:34:53 | I | collecting calibration activations in model.layers.0
24-11-25 15:34:53 | I | - Quantizing decoder layer model.layers.0
24-11-25 15:34:53 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 15:34:54 | I |       - range scale = [    1.0000]
24-11-25 15:34:54 | I |         sum  error  = [    0.0595]
24-11-25 15:34:54 | I |         best error  = [    0.0595]
24-11-25 15:34:54 | I |     + error = [0.0595]
24-11-25 15:34:55 | I |       - range scale = [    1.0000]
24-11-25 15:34:55 | I |         sum  error  = [    0.5852]
24-11-25 15:34:55 | I |         best error  = [    0.5852]
24-11-25 15:34:55 | I |     + error = [0.5852]
24-11-25 15:34:55 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 15:34:56 | I |       - range scale = [    1.0000]
24-11-25 15:34:56 | I |         sum  error  = [    0.0690]
24-11-25 15:34:56 | I |         best error  = [    0.0690]
24-11-25 15:34:56 | I |     + error = [0.0690]
24-11-25 15:34:56 | I |       - range scale = [    1.0000]
24-11-25 15:34:56 | I |         sum  error  = [    0.5113]
24-11-25 15:34:56 | I |         best error  = [    0.5113]
24-11-25 15:34:56 | I |     + error = [0.5113]
24-11-25 15:34:57 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 15:34:57 | I |       - range scale = [    1.0000]
24-11-25 15:34:57 | I |         sum  error  = [    0.2565]
24-11-25 15:34:57 | I |         best error  = [    0.2565]
24-11-25 15:34:57 | I |     + error = [0.2565]
24-11-25 15:34:58 | I |       - range scale = [    1.0000]
24-11-25 15:34:58 | I |         sum  error  = [    1.7891]
24-11-25 15:34:58 | I |         best error  = [    1.7891]
24-11-25 15:34:58 | I |     + error = [1.7891]
24-11-25 15:34:58 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 15:34:59 | I |       - range scale = [    1.0000]
24-11-25 15:34:59 | I |         sum  error  = [    0.0615]
24-11-25 15:34:59 | I |         best error  = [    0.0615]
24-11-25 15:34:59 | I |     + error = [0.0615]
24-11-25 15:35:00 | I |       - range scale = [    1.0000]
24-11-25 15:35:00 | I |         sum  error  = [    0.5919]
24-11-25 15:35:00 | I |         best error  = [    0.5919]
24-11-25 15:35:00 | I |     + error = [0.5919]
24-11-25 15:35:00 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 15:35:00 | I |       - range scale = [    1.0000]
24-11-25 15:35:00 | I |         sum  error  = [    0.9668]
24-11-25 15:35:00 | I |         best error  = [    0.9668]
24-11-25 15:35:00 | I |     + error = [0.9668]
24-11-25 15:35:01 | I |       - range scale = [    1.0000]
24-11-25 15:35:01 | I |         sum  error  = [   10.7207]
24-11-25 15:35:01 | I |         best error  = [   10.7207]
24-11-25 15:35:01 | I |     + error = [10.7207]
24-11-25 15:35:01 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 15:35:02 | I |       - range scale = [    1.0000]
24-11-25 15:35:02 | I |         sum  error  = [    1.1190]
24-11-25 15:35:02 | I |         best error  = [    1.1190]
24-11-25 15:35:02 | I |     + error = [1.1190]
24-11-25 15:35:03 | I |       - range scale = [    1.0000]
24-11-25 15:35:03 | I |         sum  error  = [   11.0625]
24-11-25 15:35:03 | I |         best error  = [   11.0625]
24-11-25 15:35:03 | I |     + error = [11.0625]
24-11-25 15:35:03 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 15:35:04 | I |       - range scale = [    1.0000]
24-11-25 15:35:04 | I |         sum  error  = [    3.2107]
24-11-25 15:35:04 | I |         best error  = [    3.2107]
24-11-25 15:35:04 | I |     + error = [3.2107]
24-11-25 15:35:05 | I |       - range scale = [    1.0000]
24-11-25 15:35:05 | I |         sum  error  = [   15.5970]
24-11-25 15:35:05 | I |         best error  = [   15.5970]
24-11-25 15:35:05 | I |     + error = [15.5970]
24-11-25 15:35:05 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 15:35:06 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 15:35:08 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 15:35:09 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 15:35:10 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 15:35:12 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 15:35:13 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 15:35:16 | I | quantizing activations for layer model.layers.0
24-11-25 15:35:16 | I | collecting info in model.layers.0
24-11-25 15:35:16 | I | collecting info in model.layers.0
24-11-25 15:35:16 | I | collecting info in model.layers.0
24-11-25 15:35:16 | I | collecting info in model.layers.0
24-11-25 15:35:17 | I | collecting calibration activations in model.layers.0
24-11-25 15:35:17 | I | collecting calibration activations in model.layers.0
24-11-25 15:35:17 | I | collecting calibration activations in model.layers.0
24-11-25 15:35:17 | I | collecting calibration activations in model.layers.0
24-11-25 15:35:19 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 15:35:19 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 15:35:19 | I | - Evaluator: gptq
24-11-25 15:35:19 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 15:35:19 | I | - Batch_size: 8
24-11-25 15:35:19 | I |   + Max_seq_length: 2048
24-11-25 15:36:00 | I |     - Results:
24-11-25 15:36:00 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 15:36:00 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 15:36:00 | I |       |wikitext |      1|word_perplexity|7.7689|  |7.7689|
24-11-25 15:36:00 | I |       |val_valid|      1|word_perplexity|9.0586|  |9.0586|
24-11-25 15:36:00 | I |       
24-11-25 15:36:00 | I | forward this layer
24-11-25 15:36:00 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/18.pt
24-11-25 15:36:00 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/18.pt
24-11-25 15:36:01 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 15:36:01 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 15:36:01 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 15:36:01 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 15:36:01 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 15:36:01 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: True
24-11-25 15:36:01 | I | inf: first position tensor([ 61, 712], device='cuda:0')
24-11-25 15:36:01 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 15:36:01 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 15:36:01 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 15:36:01 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 15:36:01 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 15:36:01 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 15:36:01 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 15:36:01 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 15:36:01 | I | in layer model.layers.0
24-11-25 15:36:01 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 15:36:01 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 15:36:01 | I | - Evaluator: gptq
24-11-25 15:36:01 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 15:36:01 | I | - Batch_size: 8
24-11-25 15:36:01 | I |   + Max_seq_length: 2048
24-11-25 15:36:39 | I |     - Results:
24-11-25 15:36:39 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 15:36:39 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 15:36:39 | I |       |wikitext |      1|word_perplexity|7.7077|  |7.7077|
24-11-25 15:36:39 | I |       |val_valid|      1|word_perplexity|8.9799|  |8.9799|
24-11-25 15:36:39 | I |       
24-11-25 15:36:39 | I | quantizing weights for layer model.layers.0
24-11-25 15:36:39 | I | collecting info in model.layers.0
24-11-25 15:36:39 | I | collecting info in model.layers.0
24-11-25 15:36:39 | I | collecting info in model.layers.0
24-11-25 15:36:39 | I | collecting info in model.layers.0
24-11-25 15:36:40 | I | collecting calibration activations in model.layers.0
24-11-25 15:36:40 | I | collecting calibration activations in model.layers.0
24-11-25 15:36:40 | I | collecting calibration activations in model.layers.0
24-11-25 15:36:40 | I | collecting calibration activations in model.layers.0
24-11-25 15:36:40 | I | - Quantizing decoder layer model.layers.0
24-11-25 15:36:40 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 15:36:41 | I |       - range scale = [    1.0000]
24-11-25 15:36:41 | I |         sum  error  = [    0.0598]
24-11-25 15:36:41 | I |         best error  = [    0.0598]
24-11-25 15:36:41 | I |     + error = [0.0598]
24-11-25 15:36:42 | I |       - range scale = [    1.0000]
24-11-25 15:36:42 | I |         sum  error  = [    0.5859]
24-11-25 15:36:42 | I |         best error  = [    0.5859]
24-11-25 15:36:42 | I |     + error = [0.5859]
24-11-25 15:36:42 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 15:36:42 | I |       - range scale = [    1.0000]
24-11-25 15:36:42 | I |         sum  error  = [    0.0649]
24-11-25 15:36:42 | I |         best error  = [    0.0649]
24-11-25 15:36:42 | I |     + error = [0.0649]
24-11-25 15:36:43 | I |       - range scale = [    1.0000]
24-11-25 15:36:43 | I |         sum  error  = [    0.4724]
24-11-25 15:36:43 | I |         best error  = [    0.4724]
24-11-25 15:36:43 | I |     + error = [0.4724]
24-11-25 15:36:43 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 15:36:44 | I |       - range scale = [    1.0000]
24-11-25 15:36:44 | I |         sum  error  = [    0.2481]
24-11-25 15:36:44 | I |         best error  = [    0.2481]
24-11-25 15:36:44 | I |     + error = [0.2481]
24-11-25 15:36:45 | I |       - range scale = [    1.0000]
24-11-25 15:36:45 | I |         sum  error  = [    1.7799]
24-11-25 15:36:45 | I |         best error  = [    1.7799]
24-11-25 15:36:45 | I |     + error = [1.7799]
24-11-25 15:36:45 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 15:36:46 | I |       - range scale = [    1.0000]
24-11-25 15:36:46 | I |         sum  error  = [    0.0562]
24-11-25 15:36:46 | I |         best error  = [    0.0562]
24-11-25 15:36:46 | I |     + error = [0.0562]
24-11-25 15:36:46 | I |       - range scale = [    1.0000]
24-11-25 15:36:46 | I |         sum  error  = [    0.5369]
24-11-25 15:36:46 | I |         best error  = [    0.5369]
24-11-25 15:36:46 | I |     + error = [0.5369]
24-11-25 15:36:46 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 15:36:47 | I |       - range scale = [    1.0000]
24-11-25 15:36:47 | I |         sum  error  = [    1.0254]
24-11-25 15:36:47 | I |         best error  = [    1.0254]
24-11-25 15:36:47 | I |     + error = [1.0254]
24-11-25 15:36:48 | I |       - range scale = [    1.0000]
24-11-25 15:36:48 | I |         sum  error  = [   11.3504]
24-11-25 15:36:48 | I |         best error  = [   11.3504]
24-11-25 15:36:48 | I |     + error = [11.3504]
24-11-25 15:36:48 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 15:36:49 | I |       - range scale = [    1.0000]
24-11-25 15:36:49 | I |         sum  error  = [    1.1843]
24-11-25 15:36:49 | I |         best error  = [    1.1843]
24-11-25 15:36:49 | I |     + error = [1.1843]
24-11-25 15:36:50 | I |       - range scale = [    1.0000]
24-11-25 15:36:50 | I |         sum  error  = [   11.7164]
24-11-25 15:36:50 | I |         best error  = [   11.7164]
24-11-25 15:36:50 | I |     + error = [11.7164]
24-11-25 15:36:50 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 15:36:50 | I |       - range scale = [    1.0000]
24-11-25 15:36:50 | I |         sum  error  = [    3.3296]
24-11-25 15:36:50 | I |         best error  = [    3.3296]
24-11-25 15:36:50 | I |     + error = [3.3296]
24-11-25 15:36:51 | I |       - range scale = [    1.0000]
24-11-25 15:36:51 | I |         sum  error  = [   16.7850]
24-11-25 15:36:51 | I |         best error  = [   16.7850]
24-11-25 15:36:51 | I |     + error = [16.7850]
24-11-25 15:36:51 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 15:36:53 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 15:36:54 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 15:36:56 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 15:36:57 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 15:36:58 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 15:37:00 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 15:37:03 | I | quantizing activations for layer model.layers.0
24-11-25 15:37:03 | I | collecting info in model.layers.0
24-11-25 15:37:03 | I | collecting info in model.layers.0
24-11-25 15:37:03 | I | collecting info in model.layers.0
24-11-25 15:37:03 | I | collecting info in model.layers.0
24-11-25 15:37:04 | I | collecting calibration activations in model.layers.0
24-11-25 15:37:04 | I | collecting calibration activations in model.layers.0
24-11-25 15:37:04 | I | collecting calibration activations in model.layers.0
24-11-25 15:37:04 | I | collecting calibration activations in model.layers.0
24-11-25 15:37:06 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 15:37:06 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 15:37:06 | I | - Evaluator: gptq
24-11-25 15:37:06 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 15:37:06 | I | - Batch_size: 8
24-11-25 15:37:06 | I |   + Max_seq_length: 2048
24-11-25 15:37:47 | I |     - Results:
24-11-25 15:37:47 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 15:37:47 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 15:37:47 | I |       |wikitext |      1|word_perplexity|7.7805|  |7.7805|
24-11-25 15:37:47 | I |       |val_valid|      1|word_perplexity|9.0596|  |9.0596|
24-11-25 15:37:47 | I |       
24-11-25 15:37:47 | I | forward this layer
24-11-25 15:37:47 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/19.pt
24-11-25 15:37:47 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/19.pt
24-11-25 15:37:47 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 15:37:47 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 15:37:47 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 15:37:47 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 15:37:47 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 15:37:47 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: True
24-11-25 15:37:47 | I | inf: first position tensor([ 45, 294], device='cuda:0')
24-11-25 15:37:47 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 15:37:47 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 15:37:47 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 15:37:47 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 15:37:47 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 15:37:47 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 15:37:47 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 15:37:47 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 15:37:47 | I | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.125
24-11-25 15:37:48 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 15:37:48 | I | in layer model.layers.0
24-11-25 15:37:48 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 15:37:48 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 15:37:48 | I | - Evaluator: gptq
24-11-25 15:37:48 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 15:37:48 | I | - Batch_size: 8
24-11-25 15:37:48 | I |   + Max_seq_length: 2048
24-11-25 15:38:26 | I |     - Results:
24-11-25 15:38:26 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 15:38:26 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 15:38:26 | I |       |wikitext |      1|word_perplexity|7.7077|  |7.7077|
24-11-25 15:38:26 | I |       |val_valid|      1|word_perplexity|8.9799|  |8.9799|
24-11-25 15:38:26 | I |       
24-11-25 15:38:26 | I | quantizing weights for layer model.layers.0
24-11-25 15:38:26 | I | collecting info in model.layers.0
24-11-25 15:38:26 | I | collecting info in model.layers.0
24-11-25 15:38:26 | I | collecting info in model.layers.0
24-11-25 15:38:26 | I | collecting info in model.layers.0
24-11-25 15:38:26 | I | collecting calibration activations in model.layers.0
24-11-25 15:38:27 | I | collecting calibration activations in model.layers.0
24-11-25 15:38:27 | I | collecting calibration activations in model.layers.0
24-11-25 15:38:27 | I | collecting calibration activations in model.layers.0
24-11-25 15:38:27 | I | - Quantizing decoder layer model.layers.0
24-11-25 15:38:27 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 15:38:28 | I |       - range scale = [    1.0000]
24-11-25 15:38:28 | I |         sum  error  = [    0.0639]
24-11-25 15:38:28 | I |         best error  = [    0.0639]
24-11-25 15:38:28 | I |     + error = [0.0639]
24-11-25 15:38:28 | I |       - range scale = [    1.0000]
24-11-25 15:38:28 | I |         sum  error  = [    0.6239]
24-11-25 15:38:28 | I |         best error  = [    0.6239]
24-11-25 15:38:28 | I |     + error = [0.6239]
24-11-25 15:38:29 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 15:38:29 | I |       - range scale = [    1.0000]
24-11-25 15:38:29 | I |         sum  error  = [    0.0730]
24-11-25 15:38:29 | I |         best error  = [    0.0730]
24-11-25 15:38:29 | I |     + error = [0.0730]
24-11-25 15:38:30 | I |       - range scale = [    1.0000]
24-11-25 15:38:30 | I |         sum  error  = [    0.5070]
24-11-25 15:38:30 | I |         best error  = [    0.5070]
24-11-25 15:38:30 | I |     + error = [0.5070]
24-11-25 15:38:30 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 15:38:31 | I |       - range scale = [    1.0000]
24-11-25 15:38:31 | I |         sum  error  = [    0.2488]
24-11-25 15:38:31 | I |         best error  = [    0.2488]
24-11-25 15:38:31 | I |     + error = [0.2488]
24-11-25 15:38:32 | I |       - range scale = [    1.0000]
24-11-25 15:38:32 | I |         sum  error  = [    1.8081]
24-11-25 15:38:32 | I |         best error  = [    1.8081]
24-11-25 15:38:32 | I |     + error = [1.8081]
24-11-25 15:38:32 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 15:38:33 | I |       - range scale = [    1.0000]
24-11-25 15:38:33 | I |         sum  error  = [    0.0609]
24-11-25 15:38:33 | I |         best error  = [    0.0609]
24-11-25 15:38:33 | I |     + error = [0.0609]
24-11-25 15:38:33 | I |       - range scale = [    1.0000]
24-11-25 15:38:33 | I |         sum  error  = [    0.5854]
24-11-25 15:38:33 | I |         best error  = [    0.5854]
24-11-25 15:38:33 | I |     + error = [0.5854]
24-11-25 15:38:33 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 15:38:34 | I |       - range scale = [    1.0000]
24-11-25 15:38:34 | I |         sum  error  = [    1.0686]
24-11-25 15:38:34 | I |         best error  = [    1.0686]
24-11-25 15:38:34 | I |     + error = [1.0686]
24-11-25 15:38:35 | I |       - range scale = [    1.0000]
24-11-25 15:38:35 | I |         sum  error  = [   11.8317]
24-11-25 15:38:35 | I |         best error  = [   11.8317]
24-11-25 15:38:35 | I |     + error = [11.8317]
24-11-25 15:38:35 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 15:38:36 | I |       - range scale = [    1.0000]
24-11-25 15:38:36 | I |         sum  error  = [    1.2348]
24-11-25 15:38:36 | I |         best error  = [    1.2348]
24-11-25 15:38:36 | I |     + error = [1.2348]
24-11-25 15:38:37 | I |       - range scale = [    1.0000]
24-11-25 15:38:37 | I |         sum  error  = [   12.2306]
24-11-25 15:38:37 | I |         best error  = [   12.2306]
24-11-25 15:38:37 | I |     + error = [12.2306]
24-11-25 15:38:37 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 15:38:37 | I |       - range scale = [    1.0000]
24-11-25 15:38:37 | I |         sum  error  = [    3.8618]
24-11-25 15:38:37 | I |         best error  = [    3.8618]
24-11-25 15:38:37 | I |     + error = [3.8618]
24-11-25 15:38:38 | I |       - range scale = [    1.0000]
24-11-25 15:38:38 | I |         sum  error  = [   19.1688]
24-11-25 15:38:38 | I |         best error  = [   19.1688]
24-11-25 15:38:38 | I |     + error = [19.1688]
24-11-25 15:38:38 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 15:38:40 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 15:38:41 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 15:38:43 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 15:38:44 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 15:38:45 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 15:38:47 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 15:38:50 | I | quantizing activations for layer model.layers.0
24-11-25 15:38:50 | I | collecting info in model.layers.0
24-11-25 15:38:50 | I | collecting info in model.layers.0
24-11-25 15:38:50 | I | collecting info in model.layers.0
24-11-25 15:38:50 | I | collecting info in model.layers.0
24-11-25 15:38:51 | I | collecting calibration activations in model.layers.0
24-11-25 15:38:51 | I | collecting calibration activations in model.layers.0
24-11-25 15:38:51 | I | collecting calibration activations in model.layers.0
24-11-25 15:38:51 | I | collecting calibration activations in model.layers.0
24-11-25 15:38:53 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 15:38:53 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 15:38:53 | I | - Evaluator: gptq
24-11-25 15:38:53 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 15:38:53 | I | - Batch_size: 8
24-11-25 15:38:53 | I |   + Max_seq_length: 2048
24-11-25 15:39:34 | I |     - Results:
24-11-25 15:39:34 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 15:39:34 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 15:39:34 | I |       |wikitext |      1|word_perplexity|7.7683|  |7.7683|
24-11-25 15:39:34 | I |       |val_valid|      1|word_perplexity|9.0540|  |9.0540|
24-11-25 15:39:34 | I |       
24-11-25 15:39:34 | I | forward this layer
24-11-25 15:39:34 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/20.pt
24-11-25 15:39:34 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/20.pt
24-11-25 15:39:34 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 15:39:34 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 15:39:35 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 15:39:35 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 15:39:35 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 15:39:35 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: True
24-11-25 15:39:35 | I | inf: first position tensor([ 45, 712], device='cuda:0')
24-11-25 15:39:35 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 15:39:35 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 15:39:35 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 15:39:35 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 15:39:35 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 15:39:35 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 15:39:35 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 15:39:35 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 15:39:35 | I | in layer model.layers.0
24-11-25 15:39:35 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 15:39:35 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 15:39:35 | I | - Evaluator: gptq
24-11-25 15:39:35 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 15:39:35 | I | - Batch_size: 8
24-11-25 15:39:35 | I |   + Max_seq_length: 2048
24-11-25 15:40:13 | I |     - Results:
24-11-25 15:40:13 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 15:40:13 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 15:40:13 | I |       |wikitext |      1|word_perplexity|7.7077|  |7.7077|
24-11-25 15:40:13 | I |       |val_valid|      1|word_perplexity|8.9799|  |8.9799|
24-11-25 15:40:13 | I |       
24-11-25 15:40:13 | I | quantizing weights for layer model.layers.0
24-11-25 15:40:13 | I | collecting info in model.layers.0
24-11-25 15:40:13 | I | collecting info in model.layers.0
24-11-25 15:40:13 | I | collecting info in model.layers.0
24-11-25 15:40:13 | I | collecting info in model.layers.0
24-11-25 15:40:13 | I | collecting calibration activations in model.layers.0
24-11-25 15:40:14 | I | collecting calibration activations in model.layers.0
24-11-25 15:40:14 | I | collecting calibration activations in model.layers.0
24-11-25 15:40:14 | I | collecting calibration activations in model.layers.0
24-11-25 15:40:14 | I | - Quantizing decoder layer model.layers.0
24-11-25 15:40:14 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 15:40:15 | I |       - range scale = [    1.0000]
24-11-25 15:40:15 | I |         sum  error  = [    0.0637]
24-11-25 15:40:15 | I |         best error  = [    0.0637]
24-11-25 15:40:15 | I |     + error = [0.0637]
24-11-25 15:40:15 | I |       - range scale = [    1.0000]
24-11-25 15:40:15 | I |         sum  error  = [    0.6304]
24-11-25 15:40:15 | I |         best error  = [    0.6304]
24-11-25 15:40:15 | I |     + error = [0.6304]
24-11-25 15:40:16 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 15:40:16 | I |       - range scale = [    1.0000]
24-11-25 15:40:16 | I |         sum  error  = [    0.0753]
24-11-25 15:40:16 | I |         best error  = [    0.0753]
24-11-25 15:40:16 | I |     + error = [0.0753]
24-11-25 15:40:17 | I |       - range scale = [    1.0000]
24-11-25 15:40:17 | I |         sum  error  = [    0.5127]
24-11-25 15:40:17 | I |         best error  = [    0.5127]
24-11-25 15:40:17 | I |     + error = [0.5127]
24-11-25 15:40:17 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 15:40:18 | I |       - range scale = [    1.0000]
24-11-25 15:40:18 | I |         sum  error  = [    0.2515]
24-11-25 15:40:18 | I |         best error  = [    0.2515]
24-11-25 15:40:18 | I |     + error = [0.2515]
24-11-25 15:40:19 | I |       - range scale = [    1.0000]
24-11-25 15:40:19 | I |         sum  error  = [    1.8136]
24-11-25 15:40:19 | I |         best error  = [    1.8136]
24-11-25 15:40:19 | I |     + error = [1.8136]
24-11-25 15:40:19 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 15:40:20 | I |       - range scale = [    1.0000]
24-11-25 15:40:20 | I |         sum  error  = [    0.0599]
24-11-25 15:40:20 | I |         best error  = [    0.0599]
24-11-25 15:40:20 | I |     + error = [0.0599]
24-11-25 15:40:20 | I |       - range scale = [    1.0000]
24-11-25 15:40:20 | I |         sum  error  = [    0.5765]
24-11-25 15:40:20 | I |         best error  = [    0.5765]
24-11-25 15:40:20 | I |     + error = [0.5765]
24-11-25 15:40:20 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 15:40:21 | I |       - range scale = [    1.0000]
24-11-25 15:40:21 | I |         sum  error  = [    1.0550]
24-11-25 15:40:21 | I |         best error  = [    1.0550]
24-11-25 15:40:21 | I |     + error = [1.0550]
24-11-25 15:40:22 | I |       - range scale = [    1.0000]
24-11-25 15:40:22 | I |         sum  error  = [   11.6891]
24-11-25 15:40:22 | I |         best error  = [   11.6891]
24-11-25 15:40:22 | I |     + error = [11.6891]
24-11-25 15:40:22 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 15:40:23 | I |       - range scale = [    1.0000]
24-11-25 15:40:23 | I |         sum  error  = [    1.2193]
24-11-25 15:40:23 | I |         best error  = [    1.2193]
24-11-25 15:40:23 | I |     + error = [1.2193]
24-11-25 15:40:24 | I |       - range scale = [    1.0000]
24-11-25 15:40:24 | I |         sum  error  = [   12.0762]
24-11-25 15:40:24 | I |         best error  = [   12.0762]
24-11-25 15:40:24 | I |     + error = [12.0762]
24-11-25 15:40:24 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 15:40:24 | I |       - range scale = [    1.0000]
24-11-25 15:40:24 | I |         sum  error  = [    3.3135]
24-11-25 15:40:24 | I |         best error  = [    3.3135]
24-11-25 15:40:24 | I |     + error = [3.3135]
24-11-25 15:40:25 | I |       - range scale = [    1.0000]
24-11-25 15:40:25 | I |         sum  error  = [   16.4919]
24-11-25 15:40:25 | I |         best error  = [   16.4919]
24-11-25 15:40:25 | I |     + error = [16.4919]
24-11-25 15:40:25 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 15:40:27 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 15:40:28 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 15:40:30 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 15:40:31 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 15:40:33 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 15:40:34 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 15:40:37 | I | quantizing activations for layer model.layers.0
24-11-25 15:40:37 | I | collecting info in model.layers.0
24-11-25 15:40:37 | I | collecting info in model.layers.0
24-11-25 15:40:37 | I | collecting info in model.layers.0
24-11-25 15:40:37 | I | collecting info in model.layers.0
24-11-25 15:40:38 | I | collecting calibration activations in model.layers.0
24-11-25 15:40:38 | I | collecting calibration activations in model.layers.0
24-11-25 15:40:38 | I | collecting calibration activations in model.layers.0
24-11-25 15:40:38 | I | collecting calibration activations in model.layers.0
24-11-25 15:40:40 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 15:40:40 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 15:40:40 | I | - Evaluator: gptq
24-11-25 15:40:40 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 15:40:40 | I | - Batch_size: 8
24-11-25 15:40:40 | I |   + Max_seq_length: 2048
24-11-25 15:41:21 | I |     - Results:
24-11-25 15:41:21 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 15:41:21 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 15:41:21 | I |       |wikitext |      1|word_perplexity|7.7750|  |7.7750|
24-11-25 15:41:21 | I |       |val_valid|      1|word_perplexity|9.0541|  |9.0541|
24-11-25 15:41:21 | I |       
24-11-25 15:41:21 | I | forward this layer
24-11-25 15:41:21 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/21.pt
24-11-25 15:41:21 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/21.pt
24-11-25 15:41:22 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 15:41:22 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 15:41:22 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 15:41:22 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 15:41:22 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 15:41:22 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: True
24-11-25 15:41:22 | I | inf: first position tensor([ 45, 712], device='cuda:0')
24-11-25 15:41:22 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 15:41:22 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 15:41:22 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 15:41:22 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 15:41:22 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 15:41:22 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 15:41:22 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 15:41:22 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 15:41:22 | I | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.0625
24-11-25 15:41:22 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 15:41:22 | I | in layer model.layers.0
24-11-25 15:41:22 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 15:41:22 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 15:41:22 | I | - Evaluator: gptq
24-11-25 15:41:22 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 15:41:22 | I | - Batch_size: 8
24-11-25 15:41:22 | I |   + Max_seq_length: 2048
24-11-25 15:42:00 | I |     - Results:
24-11-25 15:42:00 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 15:42:00 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 15:42:00 | I |       |wikitext |      1|word_perplexity|7.7077|  |7.7077|
24-11-25 15:42:00 | I |       |val_valid|      1|word_perplexity|8.9799|  |8.9799|
24-11-25 15:42:00 | I |       
24-11-25 15:42:00 | I | quantizing weights for layer model.layers.0
24-11-25 15:42:00 | I | collecting info in model.layers.0
24-11-25 15:42:00 | I | collecting info in model.layers.0
24-11-25 15:42:00 | I | collecting info in model.layers.0
24-11-25 15:42:00 | I | collecting info in model.layers.0
24-11-25 15:42:01 | I | collecting calibration activations in model.layers.0
24-11-25 15:42:01 | I | collecting calibration activations in model.layers.0
24-11-25 15:42:01 | I | collecting calibration activations in model.layers.0
24-11-25 15:42:01 | I | collecting calibration activations in model.layers.0
24-11-25 15:42:01 | I | - Quantizing decoder layer model.layers.0
24-11-25 15:42:01 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 15:42:02 | I |       - range scale = [    1.0000]
24-11-25 15:42:02 | I |         sum  error  = [    0.0583]
24-11-25 15:42:02 | I |         best error  = [    0.0583]
24-11-25 15:42:02 | I |     + error = [0.0583]
24-11-25 15:42:03 | I |       - range scale = [    1.0000]
24-11-25 15:42:03 | I |         sum  error  = [    0.5877]
24-11-25 15:42:03 | I |         best error  = [    0.5877]
24-11-25 15:42:03 | I |     + error = [0.5877]
24-11-25 15:42:03 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 15:42:04 | I |       - range scale = [    1.0000]
24-11-25 15:42:04 | I |         sum  error  = [    0.0712]
24-11-25 15:42:04 | I |         best error  = [    0.0712]
24-11-25 15:42:04 | I |     + error = [0.0712]
24-11-25 15:42:04 | I |       - range scale = [    1.0000]
24-11-25 15:42:04 | I |         sum  error  = [    0.4949]
24-11-25 15:42:04 | I |         best error  = [    0.4949]
24-11-25 15:42:04 | I |     + error = [0.4949]
24-11-25 15:42:05 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 15:42:05 | I |       - range scale = [    1.0000]
24-11-25 15:42:05 | I |         sum  error  = [    0.2498]
24-11-25 15:42:05 | I |         best error  = [    0.2498]
24-11-25 15:42:05 | I |     + error = [0.2498]
24-11-25 15:42:06 | I |       - range scale = [    1.0000]
24-11-25 15:42:06 | I |         sum  error  = [    1.7959]
24-11-25 15:42:06 | I |         best error  = [    1.7959]
24-11-25 15:42:06 | I |     + error = [1.7959]
24-11-25 15:42:06 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 15:42:07 | I |       - range scale = [    1.0000]
24-11-25 15:42:07 | I |         sum  error  = [    0.0637]
24-11-25 15:42:07 | I |         best error  = [    0.0637]
24-11-25 15:42:07 | I |     + error = [0.0637]
24-11-25 15:42:08 | I |       - range scale = [    1.0000]
24-11-25 15:42:08 | I |         sum  error  = [    0.6142]
24-11-25 15:42:08 | I |         best error  = [    0.6142]
24-11-25 15:42:08 | I |     + error = [0.6142]
24-11-25 15:42:08 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 15:42:09 | I |       - range scale = [    1.0000]
24-11-25 15:42:09 | I |         sum  error  = [    1.0464]
24-11-25 15:42:09 | I |         best error  = [    1.0464]
24-11-25 15:42:09 | I |     + error = [1.0464]
24-11-25 15:42:09 | I |       - range scale = [    1.0000]
24-11-25 15:42:09 | I |         sum  error  = [   11.5887]
24-11-25 15:42:09 | I |         best error  = [   11.5887]
24-11-25 15:42:09 | I |     + error = [11.5887]
24-11-25 15:42:10 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 15:42:10 | I |       - range scale = [    1.0000]
24-11-25 15:42:10 | I |         sum  error  = [    1.2100]
24-11-25 15:42:10 | I |         best error  = [    1.2100]
24-11-25 15:42:10 | I |     + error = [1.2100]
24-11-25 15:42:11 | I |       - range scale = [    1.0000]
24-11-25 15:42:11 | I |         sum  error  = [   11.9761]
24-11-25 15:42:11 | I |         best error  = [   11.9761]
24-11-25 15:42:11 | I |     + error = [11.9761]
24-11-25 15:42:11 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 15:42:12 | I |       - range scale = [    1.0000]
24-11-25 15:42:12 | I |         sum  error  = [    3.1310]
24-11-25 15:42:12 | I |         best error  = [    3.1310]
24-11-25 15:42:12 | I |     + error = [3.1310]
24-11-25 15:42:13 | I |       - range scale = [    1.0000]
24-11-25 15:42:13 | I |         sum  error  = [   15.3598]
24-11-25 15:42:13 | I |         best error  = [   15.3598]
24-11-25 15:42:13 | I |     + error = [15.3598]
24-11-25 15:42:13 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 15:42:14 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 15:42:16 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 15:42:17 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 15:42:18 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 15:42:20 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 15:42:21 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 15:42:25 | I | quantizing activations for layer model.layers.0
24-11-25 15:42:25 | I | collecting info in model.layers.0
24-11-25 15:42:25 | I | collecting info in model.layers.0
24-11-25 15:42:25 | I | collecting info in model.layers.0
24-11-25 15:42:25 | I | collecting info in model.layers.0
24-11-25 15:42:25 | I | collecting calibration activations in model.layers.0
24-11-25 15:42:25 | I | collecting calibration activations in model.layers.0
24-11-25 15:42:25 | I | collecting calibration activations in model.layers.0
24-11-25 15:42:25 | I | collecting calibration activations in model.layers.0
24-11-25 15:42:27 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 15:42:27 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 15:42:27 | I | - Evaluator: gptq
24-11-25 15:42:27 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 15:42:27 | I | - Batch_size: 8
24-11-25 15:42:27 | I |   + Max_seq_length: 2048
24-11-25 15:43:09 | I |     - Results:
24-11-25 15:43:09 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 15:43:09 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 15:43:09 | I |       |wikitext |      1|word_perplexity|7.7784|  |7.7784|
24-11-25 15:43:09 | I |       |val_valid|      1|word_perplexity|9.0793|  |9.0793|
24-11-25 15:43:09 | I |       
24-11-25 15:43:09 | I | forward this layer
24-11-25 15:43:09 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/22.pt
24-11-25 15:43:09 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/22.pt
24-11-25 15:43:09 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 15:43:09 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 15:43:09 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 15:43:09 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 15:43:09 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 15:43:09 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: True
24-11-25 15:43:09 | I | inf: first position tensor([ 45, 712], device='cuda:0')
24-11-25 15:43:09 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 15:43:09 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 15:43:09 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 15:43:09 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 15:43:09 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 15:43:09 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 15:43:09 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 15:43:09 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 15:43:09 | I | in layer model.layers.0
24-11-25 15:43:09 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 15:43:09 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 15:43:09 | I | - Evaluator: gptq
24-11-25 15:43:09 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 15:43:09 | I | - Batch_size: 8
24-11-25 15:43:09 | I |   + Max_seq_length: 2048
24-11-25 15:43:47 | I |     - Results:
24-11-25 15:43:47 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 15:43:47 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 15:43:47 | I |       |wikitext |      1|word_perplexity|7.7077|  |7.7077|
24-11-25 15:43:47 | I |       |val_valid|      1|word_perplexity|8.9799|  |8.9799|
24-11-25 15:43:47 | I |       
24-11-25 15:43:47 | I | quantizing weights for layer model.layers.0
24-11-25 15:43:47 | I | collecting info in model.layers.0
24-11-25 15:43:47 | I | collecting info in model.layers.0
24-11-25 15:43:47 | I | collecting info in model.layers.0
24-11-25 15:43:47 | I | collecting info in model.layers.0
24-11-25 15:43:48 | I | collecting calibration activations in model.layers.0
24-11-25 15:43:48 | I | collecting calibration activations in model.layers.0
24-11-25 15:43:48 | I | collecting calibration activations in model.layers.0
24-11-25 15:43:48 | I | collecting calibration activations in model.layers.0
24-11-25 15:43:48 | I | - Quantizing decoder layer model.layers.0
24-11-25 15:43:48 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 15:43:49 | I |       - range scale = [    1.0000]
24-11-25 15:43:49 | I |         sum  error  = [    0.0606]
24-11-25 15:43:49 | I |         best error  = [    0.0606]
24-11-25 15:43:49 | I |     + error = [0.0606]
24-11-25 15:43:50 | I |       - range scale = [    1.0000]
24-11-25 15:43:50 | I |         sum  error  = [    0.5889]
24-11-25 15:43:50 | I |         best error  = [    0.5889]
24-11-25 15:43:50 | I |     + error = [0.5889]
24-11-25 15:43:50 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 15:43:51 | I |       - range scale = [    1.0000]
24-11-25 15:43:51 | I |         sum  error  = [    0.0695]
24-11-25 15:43:51 | I |         best error  = [    0.0695]
24-11-25 15:43:51 | I |     + error = [0.0695]
24-11-25 15:43:51 | I |       - range scale = [    1.0000]
24-11-25 15:43:51 | I |         sum  error  = [    0.4934]
24-11-25 15:43:51 | I |         best error  = [    0.4934]
24-11-25 15:43:51 | I |     + error = [0.4934]
24-11-25 15:43:52 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 15:43:52 | I |       - range scale = [    1.0000]
24-11-25 15:43:52 | I |         sum  error  = [    0.2458]
24-11-25 15:43:52 | I |         best error  = [    0.2458]
24-11-25 15:43:52 | I |     + error = [0.2458]
24-11-25 15:43:53 | I |       - range scale = [    1.0000]
24-11-25 15:43:53 | I |         sum  error  = [    1.7773]
24-11-25 15:43:53 | I |         best error  = [    1.7773]
24-11-25 15:43:53 | I |     + error = [1.7773]
24-11-25 15:43:53 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 15:43:54 | I |       - range scale = [    1.0000]
24-11-25 15:43:54 | I |         sum  error  = [    0.0611]
24-11-25 15:43:54 | I |         best error  = [    0.0611]
24-11-25 15:43:54 | I |     + error = [0.0611]
24-11-25 15:43:55 | I |       - range scale = [    1.0000]
24-11-25 15:43:55 | I |         sum  error  = [    0.5910]
24-11-25 15:43:55 | I |         best error  = [    0.5910]
24-11-25 15:43:55 | I |     + error = [0.5910]
24-11-25 15:43:55 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 15:43:56 | I |       - range scale = [    1.0000]
24-11-25 15:43:56 | I |         sum  error  = [    1.0532]
24-11-25 15:43:56 | I |         best error  = [    1.0532]
24-11-25 15:43:56 | I |     + error = [1.0532]
24-11-25 15:43:56 | I |       - range scale = [    1.0000]
24-11-25 15:43:56 | I |         sum  error  = [   11.6695]
24-11-25 15:43:56 | I |         best error  = [   11.6695]
24-11-25 15:43:56 | I |     + error = [11.6695]
24-11-25 15:43:57 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 15:43:57 | I |       - range scale = [    1.0000]
24-11-25 15:43:57 | I |         sum  error  = [    1.2201]
24-11-25 15:43:57 | I |         best error  = [    1.2201]
24-11-25 15:43:57 | I |     + error = [1.2201]
24-11-25 15:43:58 | I |       - range scale = [    1.0000]
24-11-25 15:43:58 | I |         sum  error  = [   12.0632]
24-11-25 15:43:58 | I |         best error  = [   12.0632]
24-11-25 15:43:58 | I |     + error = [12.0632]
24-11-25 15:43:58 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 15:43:59 | I |       - range scale = [    1.0000]
24-11-25 15:43:59 | I |         sum  error  = [    2.8125]
24-11-25 15:43:59 | I |         best error  = [    2.8125]
24-11-25 15:43:59 | I |     + error = [2.8125]
24-11-25 15:44:00 | I |       - range scale = [    1.0000]
24-11-25 15:44:00 | I |         sum  error  = [   14.1794]
24-11-25 15:44:00 | I |         best error  = [   14.1794]
24-11-25 15:44:00 | I |     + error = [14.1794]
24-11-25 15:44:00 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 15:44:01 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 15:44:03 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 15:44:04 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 15:44:05 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 15:44:07 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 15:44:08 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 15:44:12 | I | quantizing activations for layer model.layers.0
24-11-25 15:44:12 | I | collecting info in model.layers.0
24-11-25 15:44:12 | I | collecting info in model.layers.0
24-11-25 15:44:12 | I | collecting info in model.layers.0
24-11-25 15:44:12 | I | collecting info in model.layers.0
24-11-25 15:44:12 | I | collecting calibration activations in model.layers.0
24-11-25 15:44:12 | I | collecting calibration activations in model.layers.0
24-11-25 15:44:12 | I | collecting calibration activations in model.layers.0
24-11-25 15:44:12 | I | collecting calibration activations in model.layers.0
24-11-25 15:44:14 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 15:44:14 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 15:44:14 | I | - Evaluator: gptq
24-11-25 15:44:14 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 15:44:14 | I | - Batch_size: 8
24-11-25 15:44:14 | I |   + Max_seq_length: 2048
24-11-25 15:44:56 | I |     - Results:
24-11-25 15:44:56 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 15:44:56 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 15:44:56 | I |       |wikitext |      1|word_perplexity|7.7748|  |7.7748|
24-11-25 15:44:56 | I |       |val_valid|      1|word_perplexity|9.0648|  |9.0648|
24-11-25 15:44:56 | I |       
24-11-25 15:44:56 | I | forward this layer
24-11-25 15:44:56 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/23.pt
24-11-25 15:44:56 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/23.pt
24-11-25 15:44:56 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 15:44:56 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 15:44:56 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 15:44:56 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 15:44:56 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 15:44:56 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: True
24-11-25 15:44:56 | I | inf: first position tensor([ 45, 712], device='cuda:0')
24-11-25 15:44:56 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 15:44:56 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 15:44:56 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 15:44:56 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 15:44:56 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 15:44:56 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 15:44:56 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 15:44:56 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 15:44:56 | I | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.03125
24-11-25 15:44:56 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 15:44:56 | I | in layer model.layers.0
24-11-25 15:44:56 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 15:44:56 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 15:44:56 | I | - Evaluator: gptq
24-11-25 15:44:56 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 15:44:56 | I | - Batch_size: 8
24-11-25 15:44:56 | I |   + Max_seq_length: 2048
24-11-25 15:45:34 | I |     - Results:
24-11-25 15:45:34 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 15:45:34 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 15:45:34 | I |       |wikitext |      1|word_perplexity|7.7077|  |7.7077|
24-11-25 15:45:34 | I |       |val_valid|      1|word_perplexity|8.9799|  |8.9799|
24-11-25 15:45:34 | I |       
24-11-25 15:45:34 | I | quantizing weights for layer model.layers.0
24-11-25 15:45:35 | I | collecting info in model.layers.0
24-11-25 15:45:35 | I | collecting info in model.layers.0
24-11-25 15:45:35 | I | collecting info in model.layers.0
24-11-25 15:45:35 | I | collecting info in model.layers.0
24-11-25 15:45:35 | I | collecting calibration activations in model.layers.0
24-11-25 15:45:35 | I | collecting calibration activations in model.layers.0
24-11-25 15:45:35 | I | collecting calibration activations in model.layers.0
24-11-25 15:45:35 | I | collecting calibration activations in model.layers.0
24-11-25 15:45:36 | I | - Quantizing decoder layer model.layers.0
24-11-25 15:45:36 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 15:45:36 | I |       - range scale = [    1.0000]
24-11-25 15:45:36 | I |         sum  error  = [    0.0641]
24-11-25 15:45:36 | I |         best error  = [    0.0641]
24-11-25 15:45:36 | I |     + error = [0.0641]
24-11-25 15:45:37 | I |       - range scale = [    1.0000]
24-11-25 15:45:37 | I |         sum  error  = [    0.6453]
24-11-25 15:45:37 | I |         best error  = [    0.6453]
24-11-25 15:45:37 | I |     + error = [0.6453]
24-11-25 15:45:37 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 15:45:38 | I |       - range scale = [    1.0000]
24-11-25 15:45:38 | I |         sum  error  = [    0.0733]
24-11-25 15:45:38 | I |         best error  = [    0.0733]
24-11-25 15:45:38 | I |     + error = [0.0733]
24-11-25 15:45:39 | I |       - range scale = [    1.0000]
24-11-25 15:45:39 | I |         sum  error  = [    0.5164]
24-11-25 15:45:39 | I |         best error  = [    0.5164]
24-11-25 15:45:39 | I |     + error = [0.5164]
24-11-25 15:45:39 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 15:45:40 | I |       - range scale = [    1.0000]
24-11-25 15:45:40 | I |         sum  error  = [    0.2547]
24-11-25 15:45:40 | I |         best error  = [    0.2547]
24-11-25 15:45:40 | I |     + error = [0.2547]
24-11-25 15:45:40 | I |       - range scale = [    1.0000]
24-11-25 15:45:40 | I |         sum  error  = [    1.8266]
24-11-25 15:45:40 | I |         best error  = [    1.8266]
24-11-25 15:45:40 | I |     + error = [1.8266]
24-11-25 15:45:40 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 15:45:41 | I |       - range scale = [    1.0000]
24-11-25 15:45:41 | I |         sum  error  = [    0.0645]
24-11-25 15:45:41 | I |         best error  = [    0.0645]
24-11-25 15:45:41 | I |     + error = [0.0645]
24-11-25 15:45:42 | I |       - range scale = [    1.0000]
24-11-25 15:45:42 | I |         sum  error  = [    0.6160]
24-11-25 15:45:42 | I |         best error  = [    0.6160]
24-11-25 15:45:42 | I |     + error = [0.6160]
24-11-25 15:45:42 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 15:45:43 | I |       - range scale = [    1.0000]
24-11-25 15:45:43 | I |         sum  error  = [    1.0983]
24-11-25 15:45:43 | I |         best error  = [    1.0983]
24-11-25 15:45:43 | I |     + error = [1.0983]
24-11-25 15:45:43 | I |       - range scale = [    1.0000]
24-11-25 15:45:43 | I |         sum  error  = [   12.1559]
24-11-25 15:45:43 | I |         best error  = [   12.1559]
24-11-25 15:45:43 | I |     + error = [12.1559]
24-11-25 15:45:44 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 15:45:44 | I |       - range scale = [    1.0000]
24-11-25 15:45:44 | I |         sum  error  = [    1.2687]
24-11-25 15:45:44 | I |         best error  = [    1.2687]
24-11-25 15:45:44 | I |     + error = [1.2687]
24-11-25 15:45:45 | I |       - range scale = [    1.0000]
24-11-25 15:45:45 | I |         sum  error  = [   12.5971]
24-11-25 15:45:45 | I |         best error  = [   12.5971]
24-11-25 15:45:45 | I |     + error = [12.5971]
24-11-25 15:45:45 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 15:45:46 | I |       - range scale = [    1.0000]
24-11-25 15:45:46 | I |         sum  error  = [    3.4806]
24-11-25 15:45:46 | I |         best error  = [    3.4806]
24-11-25 15:45:46 | I |     + error = [3.4806]
24-11-25 15:45:47 | I |       - range scale = [    1.0000]
24-11-25 15:45:47 | I |         sum  error  = [   16.9137]
24-11-25 15:45:47 | I |         best error  = [   16.9137]
24-11-25 15:45:47 | I |     + error = [16.9137]
24-11-25 15:45:47 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 15:45:48 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 15:45:50 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 15:45:51 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 15:45:53 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 15:45:54 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 15:45:55 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 15:45:59 | I | quantizing activations for layer model.layers.0
24-11-25 15:45:59 | I | collecting info in model.layers.0
24-11-25 15:45:59 | I | collecting info in model.layers.0
24-11-25 15:45:59 | I | collecting info in model.layers.0
24-11-25 15:45:59 | I | collecting info in model.layers.0
24-11-25 15:45:59 | I | collecting calibration activations in model.layers.0
24-11-25 15:45:59 | I | collecting calibration activations in model.layers.0
24-11-25 15:45:59 | I | collecting calibration activations in model.layers.0
24-11-25 15:45:59 | I | collecting calibration activations in model.layers.0
24-11-25 15:46:01 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 15:46:01 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 15:46:01 | I | - Evaluator: gptq
24-11-25 15:46:01 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 15:46:01 | I | - Batch_size: 8
24-11-25 15:46:01 | I |   + Max_seq_length: 2048
24-11-25 15:46:43 | I |     - Results:
24-11-25 15:46:43 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 15:46:43 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 15:46:43 | I |       |wikitext |      1|word_perplexity|7.7774|  |7.7774|
24-11-25 15:46:43 | I |       |val_valid|      1|word_perplexity|9.0585|  |9.0585|
24-11-25 15:46:43 | I |       
24-11-25 15:46:43 | I | forward this layer
24-11-25 15:46:43 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/24.pt
24-11-25 15:46:43 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/24.pt
24-11-25 15:46:43 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 15:46:43 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 15:46:43 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 15:46:43 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 15:46:43 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 15:46:43 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 15:46:43 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 15:46:43 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 15:46:43 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 15:46:43 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 15:46:43 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 15:46:43 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 15:46:43 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 15:46:43 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 15:46:43 | I | in layer model.layers.0
24-11-25 15:46:43 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 15:46:43 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 15:46:43 | I | - Evaluator: gptq
24-11-25 15:46:43 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 15:46:43 | I | - Batch_size: 8
24-11-25 15:46:43 | I |   + Max_seq_length: 2048
24-11-25 15:47:21 | I |     - Results:
24-11-25 15:47:21 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 15:47:21 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 15:47:21 | I |       |wikitext |      1|word_perplexity|7.7077|  |7.7077|
24-11-25 15:47:21 | I |       |val_valid|      1|word_perplexity|8.9799|  |8.9799|
24-11-25 15:47:21 | I |       
24-11-25 15:47:21 | I | quantizing weights for layer model.layers.0
24-11-25 15:47:21 | I | collecting info in model.layers.0
24-11-25 15:47:21 | I | collecting info in model.layers.0
24-11-25 15:47:21 | I | collecting info in model.layers.0
24-11-25 15:47:21 | I | collecting info in model.layers.0
24-11-25 15:47:22 | I | collecting calibration activations in model.layers.0
24-11-25 15:47:22 | I | collecting calibration activations in model.layers.0
24-11-25 15:47:22 | I | collecting calibration activations in model.layers.0
24-11-25 15:47:22 | I | collecting calibration activations in model.layers.0
24-11-25 15:47:22 | I | - Quantizing decoder layer model.layers.0
24-11-25 15:47:22 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 15:47:23 | I |       - range scale = [    1.0000]
24-11-25 15:47:23 | I |         sum  error  = [    0.0582]
24-11-25 15:47:23 | I |         best error  = [    0.0582]
24-11-25 15:47:23 | I |     + error = [0.0582]
24-11-25 15:47:24 | I |       - range scale = [    1.0000]
24-11-25 15:47:24 | I |         sum  error  = [    0.6233]
24-11-25 15:47:24 | I |         best error  = [    0.6233]
24-11-25 15:47:24 | I |     + error = [0.6233]
24-11-25 15:47:24 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 15:47:25 | I |       - range scale = [    1.0000]
24-11-25 15:47:25 | I |         sum  error  = [    0.0731]
24-11-25 15:47:25 | I |         best error  = [    0.0731]
24-11-25 15:47:25 | I |     + error = [0.0731]
24-11-25 15:47:25 | I |       - range scale = [    1.0000]
24-11-25 15:47:25 | I |         sum  error  = [    0.5134]
24-11-25 15:47:25 | I |         best error  = [    0.5134]
24-11-25 15:47:25 | I |     + error = [0.5134]
24-11-25 15:47:26 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 15:47:26 | I |       - range scale = [    1.0000]
24-11-25 15:47:26 | I |         sum  error  = [    0.2489]
24-11-25 15:47:26 | I |         best error  = [    0.2489]
24-11-25 15:47:26 | I |     + error = [0.2489]
24-11-25 15:47:27 | I |       - range scale = [    1.0000]
24-11-25 15:47:27 | I |         sum  error  = [    1.8121]
24-11-25 15:47:27 | I |         best error  = [    1.8121]
24-11-25 15:47:27 | I |     + error = [1.8121]
24-11-25 15:47:27 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 15:47:28 | I |       - range scale = [    1.0000]
24-11-25 15:47:28 | I |         sum  error  = [    0.0640]
24-11-25 15:47:28 | I |         best error  = [    0.0640]
24-11-25 15:47:28 | I |     + error = [0.0640]
24-11-25 15:47:28 | I |       - range scale = [    1.0000]
24-11-25 15:47:28 | I |         sum  error  = [    0.6267]
24-11-25 15:47:28 | I |         best error  = [    0.6267]
24-11-25 15:47:28 | I |     + error = [0.6267]
24-11-25 15:47:29 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 15:47:29 | I |       - range scale = [    1.0000]
24-11-25 15:47:29 | I |         sum  error  = [    1.1445]
24-11-25 15:47:29 | I |         best error  = [    1.1445]
24-11-25 15:47:29 | I |     + error = [1.1445]
24-11-25 15:47:30 | I |       - range scale = [    1.0000]
24-11-25 15:47:30 | I |         sum  error  = [   12.6917]
24-11-25 15:47:30 | I |         best error  = [   12.6917]
24-11-25 15:47:30 | I |     + error = [12.6917]
24-11-25 15:47:30 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 15:47:31 | I |       - range scale = [    1.0000]
24-11-25 15:47:31 | I |         sum  error  = [    1.3258]
24-11-25 15:47:31 | I |         best error  = [    1.3258]
24-11-25 15:47:31 | I |     + error = [1.3258]
24-11-25 15:47:32 | I |       - range scale = [    1.0000]
24-11-25 15:47:32 | I |         sum  error  = [   13.1657]
24-11-25 15:47:32 | I |         best error  = [   13.1657]
24-11-25 15:47:32 | I |     + error = [13.1657]
24-11-25 15:47:32 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 15:47:33 | I |       - range scale = [    1.0000]
24-11-25 15:47:33 | I |         sum  error  = [    3.2149]
24-11-25 15:47:33 | I |         best error  = [    3.2149]
24-11-25 15:47:33 | I |     + error = [3.2149]
24-11-25 15:47:33 | I |       - range scale = [    1.0000]
24-11-25 15:47:33 | I |         sum  error  = [   15.8532]
24-11-25 15:47:33 | I |         best error  = [   15.8532]
24-11-25 15:47:33 | I |     + error = [15.8532]
24-11-25 15:47:34 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 15:47:35 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 15:47:36 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 15:47:38 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 15:47:39 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 15:47:41 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 15:47:42 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 15:47:45 | I | quantizing activations for layer model.layers.0
24-11-25 15:47:45 | I | collecting info in model.layers.0
24-11-25 15:47:45 | I | collecting info in model.layers.0
24-11-25 15:47:45 | I | collecting info in model.layers.0
24-11-25 15:47:45 | I | collecting info in model.layers.0
24-11-25 15:47:46 | I | collecting calibration activations in model.layers.0
24-11-25 15:47:46 | I | collecting calibration activations in model.layers.0
24-11-25 15:47:46 | I | collecting calibration activations in model.layers.0
24-11-25 15:47:46 | I | collecting calibration activations in model.layers.0
24-11-25 15:47:48 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 15:47:48 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 15:47:48 | I | - Evaluator: gptq
24-11-25 15:47:48 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 15:47:48 | I | - Batch_size: 8
24-11-25 15:47:48 | I |   + Max_seq_length: 2048
24-11-25 15:48:29 | I |     - Results:
24-11-25 15:48:29 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 15:48:29 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 15:48:29 | I |       |wikitext |      1|word_perplexity|7.7553|  |7.7553|
24-11-25 15:48:29 | I |       |val_valid|      1|word_perplexity|9.0573|  |9.0573|
24-11-25 15:48:29 | I |       
24-11-25 15:48:29 | I | forward this layer
24-11-25 15:48:29 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/25.pt
24-11-25 15:48:29 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/25.pt
24-11-25 15:48:30 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 15:48:30 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 15:48:30 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 15:48:30 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 15:48:30 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 15:48:30 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: True
24-11-25 15:48:30 | I | inf: first position tensor([ 45, 712], device='cuda:0')
24-11-25 15:48:30 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 15:48:30 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 15:48:30 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 15:48:30 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 15:48:30 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 15:48:30 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 15:48:30 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 15:48:30 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 15:48:30 | I | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.015625
24-11-25 15:48:30 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 15:48:30 | I | in layer model.layers.0
24-11-25 15:48:30 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 15:48:30 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 15:48:30 | I | - Evaluator: gptq
24-11-25 15:48:30 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 15:48:30 | I | - Batch_size: 8
24-11-25 15:48:30 | I |   + Max_seq_length: 2048
24-11-25 15:49:08 | I |     - Results:
24-11-25 15:49:08 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 15:49:08 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 15:49:08 | I |       |wikitext |      1|word_perplexity|7.7077|  |7.7077|
24-11-25 15:49:08 | I |       |val_valid|      1|word_perplexity|8.9799|  |8.9799|
24-11-25 15:49:08 | I |       
24-11-25 15:49:08 | I | quantizing weights for layer model.layers.0
24-11-25 15:49:08 | I | collecting info in model.layers.0
24-11-25 15:49:08 | I | collecting info in model.layers.0
24-11-25 15:49:08 | I | collecting info in model.layers.0
24-11-25 15:49:08 | I | collecting info in model.layers.0
24-11-25 15:49:09 | I | collecting calibration activations in model.layers.0
24-11-25 15:49:09 | I | collecting calibration activations in model.layers.0
24-11-25 15:49:09 | I | collecting calibration activations in model.layers.0
24-11-25 15:49:09 | I | collecting calibration activations in model.layers.0
24-11-25 15:49:09 | I | - Quantizing decoder layer model.layers.0
24-11-25 15:49:09 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 15:49:10 | I |       - range scale = [    1.0000]
24-11-25 15:49:10 | I |         sum  error  = [    0.0581]
24-11-25 15:49:10 | I |         best error  = [    0.0581]
24-11-25 15:49:10 | I |     + error = [0.0581]
24-11-25 15:49:11 | I |       - range scale = [    1.0000]
24-11-25 15:49:11 | I |         sum  error  = [    0.5951]
24-11-25 15:49:11 | I |         best error  = [    0.5951]
24-11-25 15:49:11 | I |     + error = [0.5951]
24-11-25 15:49:11 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 15:49:12 | I |       - range scale = [    1.0000]
24-11-25 15:49:12 | I |         sum  error  = [    0.0739]
24-11-25 15:49:12 | I |         best error  = [    0.0739]
24-11-25 15:49:12 | I |     + error = [0.0739]
24-11-25 15:49:12 | I |       - range scale = [    1.0000]
24-11-25 15:49:12 | I |         sum  error  = [    0.5112]
24-11-25 15:49:12 | I |         best error  = [    0.5112]
24-11-25 15:49:12 | I |     + error = [0.5112]
24-11-25 15:49:13 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 15:49:13 | I |       - range scale = [    1.0000]
24-11-25 15:49:13 | I |         sum  error  = [    0.2457]
24-11-25 15:49:13 | I |         best error  = [    0.2457]
24-11-25 15:49:13 | I |     + error = [0.2457]
24-11-25 15:49:14 | I |       - range scale = [    1.0000]
24-11-25 15:49:14 | I |         sum  error  = [    1.7767]
24-11-25 15:49:14 | I |         best error  = [    1.7767]
24-11-25 15:49:14 | I |     + error = [1.7767]
24-11-25 15:49:14 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 15:49:15 | I |       - range scale = [    1.0000]
24-11-25 15:49:15 | I |         sum  error  = [    0.0604]
24-11-25 15:49:15 | I |         best error  = [    0.0604]
24-11-25 15:49:15 | I |     + error = [0.0604]
24-11-25 15:49:15 | I |       - range scale = [    1.0000]
24-11-25 15:49:15 | I |         sum  error  = [    0.5899]
24-11-25 15:49:15 | I |         best error  = [    0.5899]
24-11-25 15:49:15 | I |     + error = [0.5899]
24-11-25 15:49:16 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 15:49:16 | I |       - range scale = [    1.0000]
24-11-25 15:49:16 | I |         sum  error  = [    1.0915]
24-11-25 15:49:16 | I |         best error  = [    1.0915]
24-11-25 15:49:16 | I |     + error = [1.0915]
24-11-25 15:49:17 | I |       - range scale = [    1.0000]
24-11-25 15:49:17 | I |         sum  error  = [   12.1001]
24-11-25 15:49:17 | I |         best error  = [   12.1001]
24-11-25 15:49:17 | I |     + error = [12.1001]
24-11-25 15:49:17 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 15:49:18 | I |       - range scale = [    1.0000]
24-11-25 15:49:18 | I |         sum  error  = [    1.2624]
24-11-25 15:49:18 | I |         best error  = [    1.2624]
24-11-25 15:49:18 | I |     + error = [1.2624]
24-11-25 15:49:19 | I |       - range scale = [    1.0000]
24-11-25 15:49:19 | I |         sum  error  = [   12.5238]
24-11-25 15:49:19 | I |         best error  = [   12.5238]
24-11-25 15:49:19 | I |     + error = [12.5238]
24-11-25 15:49:19 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 15:49:20 | I |       - range scale = [    1.0000]
24-11-25 15:49:20 | I |         sum  error  = [    2.8580]
24-11-25 15:49:20 | I |         best error  = [    2.8580]
24-11-25 15:49:20 | I |     + error = [2.8580]
24-11-25 15:49:20 | I |       - range scale = [    1.0000]
24-11-25 15:49:20 | I |         sum  error  = [   14.5223]
24-11-25 15:49:20 | I |         best error  = [   14.5223]
24-11-25 15:49:20 | I |     + error = [14.5223]
24-11-25 15:49:21 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 15:49:22 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 15:49:23 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 15:49:25 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 15:49:26 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 15:49:28 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 15:49:29 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 15:49:33 | I | quantizing activations for layer model.layers.0
24-11-25 15:49:33 | I | collecting info in model.layers.0
24-11-25 15:49:33 | I | collecting info in model.layers.0
24-11-25 15:49:33 | I | collecting info in model.layers.0
24-11-25 15:49:33 | I | collecting info in model.layers.0
24-11-25 15:49:34 | I | collecting calibration activations in model.layers.0
24-11-25 15:49:34 | I | collecting calibration activations in model.layers.0
24-11-25 15:49:34 | I | collecting calibration activations in model.layers.0
24-11-25 15:49:34 | I | collecting calibration activations in model.layers.0
24-11-25 15:49:36 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 15:49:36 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 15:49:36 | I | - Evaluator: gptq
24-11-25 15:49:36 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 15:49:36 | I | - Batch_size: 8
24-11-25 15:49:36 | I |   + Max_seq_length: 2048
24-11-25 15:50:18 | I |     - Results:
24-11-25 15:50:18 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 15:50:18 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 15:50:18 | I |       |wikitext |      1|word_perplexity|7.7721|  |7.7721|
24-11-25 15:50:18 | I |       |val_valid|      1|word_perplexity|9.0605|  |9.0605|
24-11-25 15:50:18 | I |       
24-11-25 15:50:18 | I | forward this layer
24-11-25 15:50:18 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/26.pt
24-11-25 15:50:18 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/26.pt
24-11-25 15:50:18 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 15:50:18 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 15:50:18 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 15:50:18 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 15:50:18 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 15:50:18 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 15:50:18 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 15:50:18 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 15:50:18 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 15:50:18 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 15:50:18 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 15:50:18 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 15:50:18 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 15:50:18 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 15:50:19 | I | in layer model.layers.0
24-11-25 15:50:19 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 15:50:19 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 15:50:19 | I | - Evaluator: gptq
24-11-25 15:50:19 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 15:50:19 | I | - Batch_size: 8
24-11-25 15:50:19 | I |   + Max_seq_length: 2048
24-11-25 15:50:57 | I |     - Results:
24-11-25 15:50:57 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 15:50:57 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 15:50:57 | I |       |wikitext |      1|word_perplexity|7.7077|  |7.7077|
24-11-25 15:50:57 | I |       |val_valid|      1|word_perplexity|8.9799|  |8.9799|
24-11-25 15:50:57 | I |       
24-11-25 15:50:57 | I | quantizing weights for layer model.layers.0
24-11-25 15:50:57 | I | collecting info in model.layers.0
24-11-25 15:50:57 | I | collecting info in model.layers.0
24-11-25 15:50:57 | I | collecting info in model.layers.0
24-11-25 15:50:57 | I | collecting info in model.layers.0
24-11-25 15:50:57 | I | collecting calibration activations in model.layers.0
24-11-25 15:50:57 | I | collecting calibration activations in model.layers.0
24-11-25 15:50:57 | I | collecting calibration activations in model.layers.0
24-11-25 15:50:57 | I | collecting calibration activations in model.layers.0
24-11-25 15:50:58 | I | - Quantizing decoder layer model.layers.0
24-11-25 15:50:58 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 15:50:58 | I |       - range scale = [    1.0000]
24-11-25 15:50:58 | I |         sum  error  = [    0.0631]
24-11-25 15:50:58 | I |         best error  = [    0.0631]
24-11-25 15:50:58 | I |     + error = [0.0631]
24-11-25 15:50:59 | I |       - range scale = [    1.0000]
24-11-25 15:50:59 | I |         sum  error  = [    0.6636]
24-11-25 15:50:59 | I |         best error  = [    0.6636]
24-11-25 15:50:59 | I |     + error = [0.6636]
24-11-25 15:50:59 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 15:51:00 | I |       - range scale = [    1.0000]
24-11-25 15:51:00 | I |         sum  error  = [    0.0719]
24-11-25 15:51:00 | I |         best error  = [    0.0719]
24-11-25 15:51:00 | I |     + error = [0.0719]
24-11-25 15:51:01 | I |       - range scale = [    1.0000]
24-11-25 15:51:01 | I |         sum  error  = [    0.5197]
24-11-25 15:51:01 | I |         best error  = [    0.5197]
24-11-25 15:51:01 | I |     + error = [0.5197]
24-11-25 15:51:01 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 15:51:02 | I |       - range scale = [    1.0000]
24-11-25 15:51:02 | I |         sum  error  = [    0.2456]
24-11-25 15:51:02 | I |         best error  = [    0.2456]
24-11-25 15:51:02 | I |     + error = [0.2456]
24-11-25 15:51:02 | I |       - range scale = [    1.0000]
24-11-25 15:51:02 | I |         sum  error  = [    1.7819]
24-11-25 15:51:02 | I |         best error  = [    1.7819]
24-11-25 15:51:02 | I |     + error = [1.7819]
24-11-25 15:51:02 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 15:51:03 | I |       - range scale = [    1.0000]
24-11-25 15:51:03 | I |         sum  error  = [    0.0579]
24-11-25 15:51:03 | I |         best error  = [    0.0579]
24-11-25 15:51:03 | I |     + error = [0.0579]
24-11-25 15:51:04 | I |       - range scale = [    1.0000]
24-11-25 15:51:04 | I |         sum  error  = [    0.5499]
24-11-25 15:51:04 | I |         best error  = [    0.5499]
24-11-25 15:51:04 | I |     + error = [0.5499]
24-11-25 15:51:04 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 15:51:05 | I |       - range scale = [    1.0000]
24-11-25 15:51:05 | I |         sum  error  = [    1.0376]
24-11-25 15:51:05 | I |         best error  = [    1.0376]
24-11-25 15:51:05 | I |     + error = [1.0376]
24-11-25 15:51:05 | I |       - range scale = [    1.0000]
24-11-25 15:51:05 | I |         sum  error  = [   11.4971]
24-11-25 15:51:05 | I |         best error  = [   11.4971]
24-11-25 15:51:05 | I |     + error = [11.4971]
24-11-25 15:51:06 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 15:51:06 | I |       - range scale = [    1.0000]
24-11-25 15:51:06 | I |         sum  error  = [    1.1997]
24-11-25 15:51:06 | I |         best error  = [    1.1997]
24-11-25 15:51:06 | I |     + error = [1.1997]
24-11-25 15:51:07 | I |       - range scale = [    1.0000]
24-11-25 15:51:07 | I |         sum  error  = [   11.8750]
24-11-25 15:51:07 | I |         best error  = [   11.8750]
24-11-25 15:51:07 | I |     + error = [11.8750]
24-11-25 15:51:07 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 15:51:08 | I |       - range scale = [    1.0000]
24-11-25 15:51:08 | I |         sum  error  = [    3.4447]
24-11-25 15:51:08 | I |         best error  = [    3.4447]
24-11-25 15:51:08 | I |     + error = [3.4447]
24-11-25 15:51:09 | I |       - range scale = [    1.0000]
24-11-25 15:51:09 | I |         sum  error  = [   17.8509]
24-11-25 15:51:09 | I |         best error  = [   17.8509]
24-11-25 15:51:09 | I |     + error = [17.8509]
24-11-25 15:51:09 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 15:51:11 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 15:51:12 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 15:51:14 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 15:51:16 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 15:51:17 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 15:51:19 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 15:51:23 | I | quantizing activations for layer model.layers.0
24-11-25 15:51:23 | I | collecting info in model.layers.0
24-11-25 15:51:23 | I | collecting info in model.layers.0
24-11-25 15:51:23 | I | collecting info in model.layers.0
24-11-25 15:51:23 | I | collecting info in model.layers.0
24-11-25 15:51:24 | I | collecting calibration activations in model.layers.0
24-11-25 15:51:24 | I | collecting calibration activations in model.layers.0
24-11-25 15:51:24 | I | collecting calibration activations in model.layers.0
24-11-25 15:51:24 | I | collecting calibration activations in model.layers.0
24-11-25 15:51:26 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 15:51:26 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 15:51:26 | I | - Evaluator: gptq
24-11-25 15:51:26 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 15:51:26 | I | - Batch_size: 8
24-11-25 15:51:26 | I |   + Max_seq_length: 2048
24-11-25 15:52:08 | I |     - Results:
24-11-25 15:52:08 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 15:52:08 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 15:52:08 | I |       |wikitext |      1|word_perplexity|7.7767|  |7.7767|
24-11-25 15:52:08 | I |       |val_valid|      1|word_perplexity|9.0614|  |9.0614|
24-11-25 15:52:08 | I |       
24-11-25 15:52:08 | I | forward this layer
24-11-25 15:52:08 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/27.pt
24-11-25 15:52:08 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/27.pt
24-11-25 15:52:08 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 15:52:08 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 15:52:08 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 15:52:08 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 15:52:08 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 15:52:08 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 15:52:08 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 15:52:08 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 15:52:08 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 15:52:08 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 15:52:08 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 15:52:08 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 15:52:08 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 15:52:08 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 15:52:08 | I | [0] done with optimizer step
24-11-25 15:52:08 | I | epoch 001:     14 / 409600000 loss=0.00248518, loss_per_token=5.08965, loss_sum=166778, wps=0, ups=0, wpb=32768, bsz=64, num_updates=1, lr=3e-06, gnorm=251.806, clip=100, loss_scale=0.0156, train_wall=3002, cuda_gb_allocated=11.9, cuda_gb_reserved=13.5, cuda_gb_free=11.8, wall=3259, lmquant_ppl_result_wikitext_in_train_no_quant=7.70766, lmquant_ppl_result_val_in_train_no_quant=8.97994, lmquant_ppl_result_wikitext_in_train_with_quant=7.77675, lmquant_ppl_result_val_in_train_with_quant=9.0614
24-11-25 15:52:09 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 15:52:09 | I | in layer model.layers.0
24-11-25 15:52:09 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 15:52:09 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 15:52:09 | I | - Evaluator: gptq
24-11-25 15:52:09 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 15:52:09 | I | - Batch_size: 8
24-11-25 15:52:09 | I |   + Max_seq_length: 2048
24-11-25 15:52:47 | I |     - Results:
24-11-25 15:52:47 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 15:52:47 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 15:52:47 | I |       |wikitext |      1|word_perplexity|7.7077|  |7.7077|
24-11-25 15:52:47 | I |       |val_valid|      1|word_perplexity|8.9799|  |8.9799|
24-11-25 15:52:47 | I |       
24-11-25 15:52:47 | I | quantizing weights for layer model.layers.0
24-11-25 15:52:47 | I | collecting info in model.layers.0
24-11-25 15:52:47 | I | collecting info in model.layers.0
24-11-25 15:52:47 | I | collecting info in model.layers.0
24-11-25 15:52:47 | I | collecting info in model.layers.0
24-11-25 15:52:47 | I | collecting calibration activations in model.layers.0
24-11-25 15:52:47 | I | collecting calibration activations in model.layers.0
24-11-25 15:52:48 | I | collecting calibration activations in model.layers.0
24-11-25 15:52:48 | I | collecting calibration activations in model.layers.0
24-11-25 15:52:48 | I | - Quantizing decoder layer model.layers.0
24-11-25 15:52:48 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 15:52:49 | I |       - range scale = [    1.0000]
24-11-25 15:52:49 | I |         sum  error  = [    0.0604]
24-11-25 15:52:49 | I |         best error  = [    0.0604]
24-11-25 15:52:49 | I |     + error = [0.0604]
24-11-25 15:52:49 | I |       - range scale = [    1.0000]
24-11-25 15:52:49 | I |         sum  error  = [    0.6568]
24-11-25 15:52:49 | I |         best error  = [    0.6568]
24-11-25 15:52:49 | I |     + error = [0.6568]
24-11-25 15:52:50 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 15:52:50 | I |       - range scale = [    1.0000]
24-11-25 15:52:50 | I |         sum  error  = [    0.0719]
24-11-25 15:52:50 | I |         best error  = [    0.0719]
24-11-25 15:52:50 | I |     + error = [0.0719]
24-11-25 15:52:51 | I |       - range scale = [    1.0000]
24-11-25 15:52:51 | I |         sum  error  = [    0.5386]
24-11-25 15:52:51 | I |         best error  = [    0.5386]
24-11-25 15:52:51 | I |     + error = [0.5386]
24-11-25 15:52:51 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 15:52:52 | I |       - range scale = [    1.0000]
24-11-25 15:52:52 | I |         sum  error  = [    0.2477]
24-11-25 15:52:52 | I |         best error  = [    0.2477]
24-11-25 15:52:52 | I |     + error = [0.2477]
24-11-25 15:52:52 | I |       - range scale = [    1.0000]
24-11-25 15:52:52 | I |         sum  error  = [    1.7940]
24-11-25 15:52:52 | I |         best error  = [    1.7940]
24-11-25 15:52:52 | I |     + error = [1.7940]
24-11-25 15:52:53 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 15:52:53 | I |       - range scale = [    1.0000]
24-11-25 15:52:53 | I |         sum  error  = [    0.0651]
24-11-25 15:52:53 | I |         best error  = [    0.0651]
24-11-25 15:52:53 | I |     + error = [0.0651]
24-11-25 15:52:54 | I |       - range scale = [    1.0000]
24-11-25 15:52:54 | I |         sum  error  = [    0.6282]
24-11-25 15:52:54 | I |         best error  = [    0.6282]
24-11-25 15:52:54 | I |     + error = [0.6282]
24-11-25 15:52:54 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 15:52:55 | I |       - range scale = [    1.0000]
24-11-25 15:52:55 | I |         sum  error  = [    1.0757]
24-11-25 15:52:55 | I |         best error  = [    1.0757]
24-11-25 15:52:55 | I |     + error = [1.0757]
24-11-25 15:52:56 | I |       - range scale = [    1.0000]
24-11-25 15:52:56 | I |         sum  error  = [   11.9286]
24-11-25 15:52:56 | I |         best error  = [   11.9286]
24-11-25 15:52:56 | I |     + error = [11.9286]
24-11-25 15:52:56 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 15:52:57 | I |       - range scale = [    1.0000]
24-11-25 15:52:57 | I |         sum  error  = [    1.2467]
24-11-25 15:52:57 | I |         best error  = [    1.2467]
24-11-25 15:52:57 | I |     + error = [1.2467]
24-11-25 15:52:57 | I |       - range scale = [    1.0000]
24-11-25 15:52:57 | I |         sum  error  = [   12.3518]
24-11-25 15:52:57 | I |         best error  = [   12.3518]
24-11-25 15:52:57 | I |     + error = [12.3518]
24-11-25 15:52:58 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 15:52:58 | I |       - range scale = [    1.0000]
24-11-25 15:52:58 | I |         sum  error  = [    3.1140]
24-11-25 15:52:58 | I |         best error  = [    3.1140]
24-11-25 15:52:58 | I |     + error = [3.1140]
24-11-25 15:52:59 | I |       - range scale = [    1.0000]
24-11-25 15:52:59 | I |         sum  error  = [   15.3349]
24-11-25 15:52:59 | I |         best error  = [   15.3349]
24-11-25 15:52:59 | I |     + error = [15.3349]
24-11-25 15:52:59 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 15:53:01 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 15:53:02 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 15:53:03 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 15:53:05 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 15:53:06 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 15:53:07 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 15:53:11 | I | quantizing activations for layer model.layers.0
24-11-25 15:53:11 | I | collecting info in model.layers.0
24-11-25 15:53:11 | I | collecting info in model.layers.0
24-11-25 15:53:11 | I | collecting info in model.layers.0
24-11-25 15:53:11 | I | collecting info in model.layers.0
24-11-25 15:53:11 | I | collecting calibration activations in model.layers.0
24-11-25 15:53:11 | I | collecting calibration activations in model.layers.0
24-11-25 15:53:11 | I | collecting calibration activations in model.layers.0
24-11-25 15:53:12 | I | collecting calibration activations in model.layers.0
24-11-25 15:53:13 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 15:53:13 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 15:53:13 | I | - Evaluator: gptq
24-11-25 15:53:13 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 15:53:13 | I | - Batch_size: 8
24-11-25 15:53:13 | I |   + Max_seq_length: 2048
24-11-25 15:53:55 | I |     - Results:
24-11-25 15:53:55 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 15:53:55 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 15:53:55 | I |       |wikitext |      1|word_perplexity|7.7809|  |7.7809|
24-11-25 15:53:55 | I |       |val_valid|      1|word_perplexity|9.0579|  |9.0579|
24-11-25 15:53:55 | I |       
24-11-25 15:53:55 | I | forward this layer
24-11-25 15:53:55 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/28.pt
24-11-25 15:53:55 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/28.pt
24-11-25 15:53:55 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 15:53:55 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 15:53:55 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 15:53:55 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 15:53:55 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 15:53:55 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 15:53:55 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 15:53:55 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 15:53:55 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 15:53:55 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 15:53:55 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 15:53:55 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 15:53:55 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 15:53:55 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 15:53:55 | I | in layer model.layers.0
24-11-25 15:53:55 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 15:53:55 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 15:53:55 | I | - Evaluator: gptq
24-11-25 15:53:55 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 15:53:55 | I | - Batch_size: 8
24-11-25 15:53:55 | I |   + Max_seq_length: 2048
24-11-25 15:54:33 | I |     - Results:
24-11-25 15:54:33 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 15:54:33 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 15:54:33 | I |       |wikitext |      1|word_perplexity|7.7077|  |7.7077|
24-11-25 15:54:33 | I |       |val_valid|      1|word_perplexity|8.9799|  |8.9799|
24-11-25 15:54:33 | I |       
24-11-25 15:54:33 | I | quantizing weights for layer model.layers.0
24-11-25 15:54:33 | I | collecting info in model.layers.0
24-11-25 15:54:33 | I | collecting info in model.layers.0
24-11-25 15:54:33 | I | collecting info in model.layers.0
24-11-25 15:54:33 | I | collecting info in model.layers.0
24-11-25 15:54:34 | I | collecting calibration activations in model.layers.0
24-11-25 15:54:34 | I | collecting calibration activations in model.layers.0
24-11-25 15:54:34 | I | collecting calibration activations in model.layers.0
24-11-25 15:54:34 | I | collecting calibration activations in model.layers.0
24-11-25 15:54:35 | I | - Quantizing decoder layer model.layers.0
24-11-25 15:54:35 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 15:54:35 | I |       - range scale = [    1.0000]
24-11-25 15:54:35 | I |         sum  error  = [    0.0578]
24-11-25 15:54:35 | I |         best error  = [    0.0578]
24-11-25 15:54:35 | I |     + error = [0.0578]
24-11-25 15:54:36 | I |       - range scale = [    1.0000]
24-11-25 15:54:36 | I |         sum  error  = [    0.6068]
24-11-25 15:54:36 | I |         best error  = [    0.6068]
24-11-25 15:54:36 | I |     + error = [0.6068]
24-11-25 15:54:36 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 15:54:37 | I |       - range scale = [    1.0000]
24-11-25 15:54:37 | I |         sum  error  = [    0.0689]
24-11-25 15:54:37 | I |         best error  = [    0.0689]
24-11-25 15:54:37 | I |     + error = [0.0689]
24-11-25 15:54:38 | I |       - range scale = [    1.0000]
24-11-25 15:54:38 | I |         sum  error  = [    0.5235]
24-11-25 15:54:38 | I |         best error  = [    0.5235]
24-11-25 15:54:38 | I |     + error = [0.5235]
24-11-25 15:54:38 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 15:54:38 | I |       - range scale = [    1.0000]
24-11-25 15:54:38 | I |         sum  error  = [    0.2471]
24-11-25 15:54:38 | I |         best error  = [    0.2471]
24-11-25 15:54:38 | I |     + error = [0.2471]
24-11-25 15:54:39 | I |       - range scale = [    1.0000]
24-11-25 15:54:39 | I |         sum  error  = [    1.8133]
24-11-25 15:54:39 | I |         best error  = [    1.8133]
24-11-25 15:54:39 | I |     + error = [1.8133]
24-11-25 15:54:39 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 15:54:40 | I |       - range scale = [    1.0000]
24-11-25 15:54:40 | I |         sum  error  = [    0.0671]
24-11-25 15:54:40 | I |         best error  = [    0.0671]
24-11-25 15:54:40 | I |     + error = [0.0671]
24-11-25 15:54:41 | I |       - range scale = [    1.0000]
24-11-25 15:54:41 | I |         sum  error  = [    0.6679]
24-11-25 15:54:41 | I |         best error  = [    0.6679]
24-11-25 15:54:41 | I |     + error = [0.6679]
24-11-25 15:54:41 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 15:54:42 | I |       - range scale = [    1.0000]
24-11-25 15:54:42 | I |         sum  error  = [    1.1695]
24-11-25 15:54:42 | I |         best error  = [    1.1695]
24-11-25 15:54:42 | I |     + error = [1.1695]
24-11-25 15:54:42 | I |       - range scale = [    1.0000]
24-11-25 15:54:42 | I |         sum  error  = [   12.9696]
24-11-25 15:54:42 | I |         best error  = [   12.9696]
24-11-25 15:54:42 | I |     + error = [12.9696]
24-11-25 15:54:43 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 15:54:43 | I |       - range scale = [    1.0000]
24-11-25 15:54:43 | I |         sum  error  = [    1.3575]
24-11-25 15:54:43 | I |         best error  = [    1.3575]
24-11-25 15:54:43 | I |     + error = [1.3575]
24-11-25 15:54:44 | I |       - range scale = [    1.0000]
24-11-25 15:54:44 | I |         sum  error  = [   13.4387]
24-11-25 15:54:44 | I |         best error  = [   13.4387]
24-11-25 15:54:44 | I |     + error = [13.4387]
24-11-25 15:54:44 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 15:54:45 | I |       - range scale = [    1.0000]
24-11-25 15:54:45 | I |         sum  error  = [    2.9866]
24-11-25 15:54:45 | I |         best error  = [    2.9866]
24-11-25 15:54:45 | I |     + error = [2.9866]
24-11-25 15:54:46 | I |       - range scale = [    1.0000]
24-11-25 15:54:46 | I |         sum  error  = [   14.3535]
24-11-25 15:54:46 | I |         best error  = [   14.3535]
24-11-25 15:54:46 | I |     + error = [14.3535]
24-11-25 15:54:46 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 15:54:47 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 15:54:49 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 15:54:50 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 15:54:52 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 15:54:53 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 15:54:54 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 15:54:58 | I | quantizing activations for layer model.layers.0
24-11-25 15:54:58 | I | collecting info in model.layers.0
24-11-25 15:54:58 | I | collecting info in model.layers.0
24-11-25 15:54:58 | I | collecting info in model.layers.0
24-11-25 15:54:58 | I | collecting info in model.layers.0
24-11-25 15:54:58 | I | collecting calibration activations in model.layers.0
24-11-25 15:54:58 | I | collecting calibration activations in model.layers.0
24-11-25 15:54:58 | I | collecting calibration activations in model.layers.0
24-11-25 15:54:58 | I | collecting calibration activations in model.layers.0
24-11-25 15:55:00 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 15:55:00 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 15:55:00 | I | - Evaluator: gptq
24-11-25 15:55:00 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 15:55:00 | I | - Batch_size: 8
24-11-25 15:55:00 | I |   + Max_seq_length: 2048
24-11-25 15:55:42 | I |     - Results:
24-11-25 15:55:42 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 15:55:42 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 15:55:42 | I |       |wikitext |      1|word_perplexity|7.7667|  |7.7667|
24-11-25 15:55:42 | I |       |val_valid|      1|word_perplexity|9.0612|  |9.0612|
24-11-25 15:55:42 | I |       
24-11-25 15:55:42 | I | forward this layer
24-11-25 15:55:42 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/29.pt
24-11-25 15:55:42 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/29.pt
24-11-25 15:55:42 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 15:55:42 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 15:55:42 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 15:55:42 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 15:55:42 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 15:55:42 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 15:55:42 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 15:55:42 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 15:55:42 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 15:55:42 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 15:55:42 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 15:55:42 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 15:55:42 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 15:55:42 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 15:55:42 | I | [1] done with optimizer step
24-11-25 15:55:42 | I | epoch 001:     15 / 409600000 loss=0.00127023, loss_per_token=2.60143, loss_sum=85243.8, wps=153.4, ups=0, wpb=32768, bsz=64, num_updates=2, lr=6e-06, gnorm=99.09, clip=100, loss_scale=0.0156, train_wall=213, cuda_gb_allocated=12.3, cuda_gb_reserved=13.7, cuda_gb_free=11.4, wall=3472, lmquant_ppl_result_wikitext_in_train_no_quant=7.70766, lmquant_ppl_result_val_in_train_no_quant=8.97994, lmquant_ppl_result_wikitext_in_train_with_quant=7.7667, lmquant_ppl_result_val_in_train_with_quant=9.06124
24-11-25 15:55:42 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 15:55:42 | I | in layer model.layers.0
24-11-25 15:55:42 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 15:55:42 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 15:55:42 | I | - Evaluator: gptq
24-11-25 15:55:42 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 15:55:42 | I | - Batch_size: 8
24-11-25 15:55:42 | I |   + Max_seq_length: 2048
24-11-25 15:56:20 | I |     - Results:
24-11-25 15:56:20 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 15:56:20 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 15:56:20 | I |       |wikitext |      1|word_perplexity|7.7076|  |7.7076|
24-11-25 15:56:20 | I |       |val_valid|      1|word_perplexity|8.9798|  |8.9798|
24-11-25 15:56:20 | I |       
24-11-25 15:56:20 | I | quantizing weights for layer model.layers.0
24-11-25 15:56:20 | I | collecting info in model.layers.0
24-11-25 15:56:20 | I | collecting info in model.layers.0
24-11-25 15:56:20 | I | collecting info in model.layers.0
24-11-25 15:56:20 | I | collecting info in model.layers.0
24-11-25 15:56:21 | I | collecting calibration activations in model.layers.0
24-11-25 15:56:21 | I | collecting calibration activations in model.layers.0
24-11-25 15:56:21 | I | collecting calibration activations in model.layers.0
24-11-25 15:56:21 | I | collecting calibration activations in model.layers.0
24-11-25 15:56:22 | I | - Quantizing decoder layer model.layers.0
24-11-25 15:56:22 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 15:56:22 | I |       - range scale = [    1.0000]
24-11-25 15:56:22 | I |         sum  error  = [    0.0580]
24-11-25 15:56:22 | I |         best error  = [    0.0580]
24-11-25 15:56:22 | I |     + error = [0.0580]
24-11-25 15:56:23 | I |       - range scale = [    1.0000]
24-11-25 15:56:23 | I |         sum  error  = [    0.5854]
24-11-25 15:56:23 | I |         best error  = [    0.5854]
24-11-25 15:56:23 | I |     + error = [0.5854]
24-11-25 15:56:23 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 15:56:24 | I |       - range scale = [    1.0000]
24-11-25 15:56:24 | I |         sum  error  = [    0.0680]
24-11-25 15:56:24 | I |         best error  = [    0.0680]
24-11-25 15:56:24 | I |     + error = [0.0680]
24-11-25 15:56:25 | I |       - range scale = [    1.0000]
24-11-25 15:56:25 | I |         sum  error  = [    0.5181]
24-11-25 15:56:25 | I |         best error  = [    0.5181]
24-11-25 15:56:25 | I |     + error = [0.5181]
24-11-25 15:56:25 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 15:56:25 | I |       - range scale = [    1.0000]
24-11-25 15:56:25 | I |         sum  error  = [    0.2437]
24-11-25 15:56:25 | I |         best error  = [    0.2437]
24-11-25 15:56:25 | I |     + error = [0.2437]
24-11-25 15:56:26 | I |       - range scale = [    1.0000]
24-11-25 15:56:26 | I |         sum  error  = [    1.7743]
24-11-25 15:56:26 | I |         best error  = [    1.7743]
24-11-25 15:56:26 | I |     + error = [1.7743]
24-11-25 15:56:26 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 15:56:27 | I |       - range scale = [    1.0000]
24-11-25 15:56:27 | I |         sum  error  = [    0.0615]
24-11-25 15:56:27 | I |         best error  = [    0.0615]
24-11-25 15:56:27 | I |     + error = [0.0615]
24-11-25 15:56:28 | I |       - range scale = [    1.0000]
24-11-25 15:56:28 | I |         sum  error  = [    0.5977]
24-11-25 15:56:28 | I |         best error  = [    0.5977]
24-11-25 15:56:28 | I |     + error = [0.5977]
24-11-25 15:56:28 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 15:56:29 | I |       - range scale = [    1.0000]
24-11-25 15:56:29 | I |         sum  error  = [    1.0705]
24-11-25 15:56:29 | I |         best error  = [    1.0705]
24-11-25 15:56:29 | I |     + error = [1.0705]
24-11-25 15:56:29 | I |       - range scale = [    1.0000]
24-11-25 15:56:29 | I |         sum  error  = [   11.8574]
24-11-25 15:56:29 | I |         best error  = [   11.8574]
24-11-25 15:56:29 | I |     + error = [11.8574]
24-11-25 15:56:30 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 15:56:30 | I |       - range scale = [    1.0000]
24-11-25 15:56:30 | I |         sum  error  = [    1.2400]
24-11-25 15:56:30 | I |         best error  = [    1.2400]
24-11-25 15:56:30 | I |     + error = [1.2400]
24-11-25 15:56:31 | I |       - range scale = [    1.0000]
24-11-25 15:56:31 | I |         sum  error  = [   12.2458]
24-11-25 15:56:31 | I |         best error  = [   12.2458]
24-11-25 15:56:31 | I |     + error = [12.2458]
24-11-25 15:56:31 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 15:56:32 | I |       - range scale = [    1.0000]
24-11-25 15:56:32 | I |         sum  error  = [    2.4001]
24-11-25 15:56:32 | I |         best error  = [    2.4001]
24-11-25 15:56:32 | I |     + error = [2.4001]
24-11-25 15:56:33 | I |       - range scale = [    1.0000]
24-11-25 15:56:33 | I |         sum  error  = [   12.1250]
24-11-25 15:56:33 | I |         best error  = [   12.1250]
24-11-25 15:56:33 | I |     + error = [12.1250]
24-11-25 15:56:33 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 15:56:34 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 15:56:36 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 15:56:37 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 15:56:38 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 15:56:40 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 15:56:41 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 15:56:44 | I | quantizing activations for layer model.layers.0
24-11-25 15:56:44 | I | collecting info in model.layers.0
24-11-25 15:56:44 | I | collecting info in model.layers.0
24-11-25 15:56:44 | I | collecting info in model.layers.0
24-11-25 15:56:44 | I | collecting info in model.layers.0
24-11-25 15:56:45 | I | collecting calibration activations in model.layers.0
24-11-25 15:56:45 | I | collecting calibration activations in model.layers.0
24-11-25 15:56:45 | I | collecting calibration activations in model.layers.0
24-11-25 15:56:45 | I | collecting calibration activations in model.layers.0
24-11-25 15:56:47 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 15:56:47 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 15:56:47 | I | - Evaluator: gptq
24-11-25 15:56:47 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 15:56:47 | I | - Batch_size: 8
24-11-25 15:56:47 | I |   + Max_seq_length: 2048
24-11-25 15:57:28 | I |     - Results:
24-11-25 15:57:29 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 15:57:29 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 15:57:29 | I |       |wikitext |      1|word_perplexity|7.7735|  |7.7735|
24-11-25 15:57:29 | I |       |val_valid|      1|word_perplexity|9.0554|  |9.0554|
24-11-25 15:57:29 | I |       
24-11-25 15:57:29 | I | forward this layer
24-11-25 15:57:29 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/30.pt
24-11-25 15:57:29 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/30.pt
24-11-25 15:57:29 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 15:57:29 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 15:57:29 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 15:57:29 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 15:57:29 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 15:57:29 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 15:57:29 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 15:57:29 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 15:57:29 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 15:57:29 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 15:57:29 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 15:57:29 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 15:57:29 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 15:57:29 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 15:57:29 | I | in layer model.layers.0
24-11-25 15:57:29 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 15:57:29 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 15:57:29 | I | - Evaluator: gptq
24-11-25 15:57:29 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 15:57:29 | I | - Batch_size: 8
24-11-25 15:57:29 | I |   + Max_seq_length: 2048
24-11-25 15:58:07 | I |     - Results:
24-11-25 15:58:07 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 15:58:07 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 15:58:07 | I |       |wikitext |      1|word_perplexity|7.7076|  |7.7076|
24-11-25 15:58:07 | I |       |val_valid|      1|word_perplexity|8.9798|  |8.9798|
24-11-25 15:58:07 | I |       
24-11-25 15:58:07 | I | quantizing weights for layer model.layers.0
24-11-25 15:58:07 | I | collecting info in model.layers.0
24-11-25 15:58:07 | I | collecting info in model.layers.0
24-11-25 15:58:07 | I | collecting info in model.layers.0
24-11-25 15:58:07 | I | collecting info in model.layers.0
24-11-25 15:58:08 | I | collecting calibration activations in model.layers.0
24-11-25 15:58:08 | I | collecting calibration activations in model.layers.0
24-11-25 15:58:08 | I | collecting calibration activations in model.layers.0
24-11-25 15:58:08 | I | collecting calibration activations in model.layers.0
24-11-25 15:58:08 | I | - Quantizing decoder layer model.layers.0
24-11-25 15:58:08 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 15:58:09 | I |       - range scale = [    1.0000]
24-11-25 15:58:09 | I |         sum  error  = [    0.0595]
24-11-25 15:58:09 | I |         best error  = [    0.0595]
24-11-25 15:58:09 | I |     + error = [0.0595]
24-11-25 15:58:10 | I |       - range scale = [    1.0000]
24-11-25 15:58:10 | I |         sum  error  = [    0.6179]
24-11-25 15:58:10 | I |         best error  = [    0.6179]
24-11-25 15:58:10 | I |     + error = [0.6179]
24-11-25 15:58:10 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 15:58:10 | I |       - range scale = [    1.0000]
24-11-25 15:58:10 | I |         sum  error  = [    0.0729]
24-11-25 15:58:10 | I |         best error  = [    0.0729]
24-11-25 15:58:10 | I |     + error = [0.0729]
24-11-25 15:58:11 | I |       - range scale = [    1.0000]
24-11-25 15:58:11 | I |         sum  error  = [    0.5194]
24-11-25 15:58:11 | I |         best error  = [    0.5194]
24-11-25 15:58:11 | I |     + error = [0.5194]
24-11-25 15:58:11 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 15:58:12 | I |       - range scale = [    1.0000]
24-11-25 15:58:12 | I |         sum  error  = [    0.2492]
24-11-25 15:58:12 | I |         best error  = [    0.2492]
24-11-25 15:58:12 | I |     + error = [0.2492]
24-11-25 15:58:13 | I |       - range scale = [    1.0000]
24-11-25 15:58:13 | I |         sum  error  = [    1.8215]
24-11-25 15:58:13 | I |         best error  = [    1.8215]
24-11-25 15:58:13 | I |     + error = [1.8215]
24-11-25 15:58:13 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 15:58:14 | I |       - range scale = [    1.0000]
24-11-25 15:58:14 | I |         sum  error  = [    0.0648]
24-11-25 15:58:14 | I |         best error  = [    0.0648]
24-11-25 15:58:14 | I |     + error = [0.0648]
24-11-25 15:58:14 | I |       - range scale = [    1.0000]
24-11-25 15:58:14 | I |         sum  error  = [    0.6164]
24-11-25 15:58:14 | I |         best error  = [    0.6164]
24-11-25 15:58:14 | I |     + error = [0.6164]
24-11-25 15:58:15 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 15:58:15 | I |       - range scale = [    1.0000]
24-11-25 15:58:15 | I |         sum  error  = [    1.1004]
24-11-25 15:58:15 | I |         best error  = [    1.1004]
24-11-25 15:58:15 | I |     + error = [1.1004]
24-11-25 15:58:16 | I |       - range scale = [    1.0000]
24-11-25 15:58:16 | I |         sum  error  = [   12.2012]
24-11-25 15:58:16 | I |         best error  = [   12.2012]
24-11-25 15:58:16 | I |     + error = [12.2012]
24-11-25 15:58:16 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 15:58:17 | I |       - range scale = [    1.0000]
24-11-25 15:58:17 | I |         sum  error  = [    1.2741]
24-11-25 15:58:17 | I |         best error  = [    1.2741]
24-11-25 15:58:17 | I |     + error = [1.2741]
24-11-25 15:58:18 | I |       - range scale = [    1.0000]
24-11-25 15:58:18 | I |         sum  error  = [   12.6345]
24-11-25 15:58:18 | I |         best error  = [   12.6345]
24-11-25 15:58:18 | I |     + error = [12.6345]
24-11-25 15:58:18 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 15:58:19 | I |       - range scale = [    1.0000]
24-11-25 15:58:19 | I |         sum  error  = [    3.1634]
24-11-25 15:58:19 | I |         best error  = [    3.1634]
24-11-25 15:58:19 | I |     + error = [3.1634]
24-11-25 15:58:19 | I |       - range scale = [    1.0000]
24-11-25 15:58:19 | I |         sum  error  = [   16.4402]
24-11-25 15:58:19 | I |         best error  = [   16.4402]
24-11-25 15:58:19 | I |     + error = [16.4402]
24-11-25 15:58:20 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 15:58:21 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 15:58:22 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 15:58:24 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 15:58:25 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 15:58:26 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 15:58:28 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 15:58:31 | I | quantizing activations for layer model.layers.0
24-11-25 15:58:31 | I | collecting info in model.layers.0
24-11-25 15:58:31 | I | collecting info in model.layers.0
24-11-25 15:58:31 | I | collecting info in model.layers.0
24-11-25 15:58:31 | I | collecting info in model.layers.0
24-11-25 15:58:32 | I | collecting calibration activations in model.layers.0
24-11-25 15:58:32 | I | collecting calibration activations in model.layers.0
24-11-25 15:58:32 | I | collecting calibration activations in model.layers.0
24-11-25 15:58:32 | I | collecting calibration activations in model.layers.0
24-11-25 15:58:34 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 15:58:34 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 15:58:34 | I | - Evaluator: gptq
24-11-25 15:58:34 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 15:58:34 | I | - Batch_size: 8
24-11-25 15:58:34 | I |   + Max_seq_length: 2048
24-11-25 15:59:15 | I |     - Results:
24-11-25 15:59:15 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 15:59:15 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 15:59:15 | I |       |wikitext |      1|word_perplexity|7.7752|  |7.7752|
24-11-25 15:59:15 | I |       |val_valid|      1|word_perplexity|9.0548|  |9.0548|
24-11-25 15:59:15 | I |       
24-11-25 15:59:15 | I | forward this layer
24-11-25 15:59:15 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/31.pt
24-11-25 15:59:15 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/31.pt
24-11-25 15:59:16 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 15:59:16 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 15:59:16 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 15:59:16 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 15:59:16 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 15:59:16 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: True
24-11-25 15:59:16 | I | inf: first position tensor([ 61, 712], device='cuda:0')
24-11-25 15:59:16 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 15:59:16 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 15:59:16 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 15:59:16 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 15:59:16 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 15:59:16 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 15:59:16 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 15:59:16 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 15:59:16 | I | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.0078125
24-11-25 15:59:16 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 15:59:16 | I | in layer model.layers.0
24-11-25 15:59:16 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 15:59:16 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 15:59:16 | I | - Evaluator: gptq
24-11-25 15:59:16 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 15:59:16 | I | - Batch_size: 8
24-11-25 15:59:16 | I |   + Max_seq_length: 2048
24-11-25 15:59:54 | I |     - Results:
24-11-25 15:59:54 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 15:59:54 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 15:59:54 | I |       |wikitext |      1|word_perplexity|7.7076|  |7.7076|
24-11-25 15:59:54 | I |       |val_valid|      1|word_perplexity|8.9798|  |8.9798|
24-11-25 15:59:54 | I |       
24-11-25 15:59:54 | I | quantizing weights for layer model.layers.0
24-11-25 15:59:54 | I | collecting info in model.layers.0
24-11-25 15:59:54 | I | collecting info in model.layers.0
24-11-25 15:59:54 | I | collecting info in model.layers.0
24-11-25 15:59:54 | I | collecting info in model.layers.0
24-11-25 15:59:55 | I | collecting calibration activations in model.layers.0
24-11-25 15:59:55 | I | collecting calibration activations in model.layers.0
24-11-25 15:59:55 | I | collecting calibration activations in model.layers.0
24-11-25 15:59:55 | I | collecting calibration activations in model.layers.0
24-11-25 15:59:55 | I | - Quantizing decoder layer model.layers.0
24-11-25 15:59:55 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 15:59:56 | I |       - range scale = [    1.0000]
24-11-25 15:59:56 | I |         sum  error  = [    0.0644]
24-11-25 15:59:56 | I |         best error  = [    0.0644]
24-11-25 15:59:56 | I |     + error = [0.0644]
24-11-25 15:59:57 | I |       - range scale = [    1.0000]
24-11-25 15:59:57 | I |         sum  error  = [    0.6673]
24-11-25 15:59:57 | I |         best error  = [    0.6673]
24-11-25 15:59:57 | I |     + error = [0.6673]
24-11-25 15:59:57 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 15:59:58 | I |       - range scale = [    1.0000]
24-11-25 15:59:58 | I |         sum  error  = [    0.0721]
24-11-25 15:59:58 | I |         best error  = [    0.0721]
24-11-25 15:59:58 | I |     + error = [0.0721]
24-11-25 15:59:58 | I |       - range scale = [    1.0000]
24-11-25 15:59:58 | I |         sum  error  = [    0.5248]
24-11-25 15:59:58 | I |         best error  = [    0.5248]
24-11-25 15:59:58 | I |     + error = [0.5248]
24-11-25 15:59:58 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 15:59:59 | I |       - range scale = [    1.0000]
24-11-25 15:59:59 | I |         sum  error  = [    0.2457]
24-11-25 15:59:59 | I |         best error  = [    0.2457]
24-11-25 15:59:59 | I |     + error = [0.2457]
24-11-25 16:00:00 | I |       - range scale = [    1.0000]
24-11-25 16:00:00 | I |         sum  error  = [    1.8074]
24-11-25 16:00:00 | I |         best error  = [    1.8074]
24-11-25 16:00:00 | I |     + error = [1.8074]
24-11-25 16:00:00 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 16:00:01 | I |       - range scale = [    1.0000]
24-11-25 16:00:01 | I |         sum  error  = [    0.0595]
24-11-25 16:00:01 | I |         best error  = [    0.0595]
24-11-25 16:00:01 | I |     + error = [0.0595]
24-11-25 16:00:01 | I |       - range scale = [    1.0000]
24-11-25 16:00:01 | I |         sum  error  = [    0.5703]
24-11-25 16:00:01 | I |         best error  = [    0.5703]
24-11-25 16:00:01 | I |     + error = [0.5703]
24-11-25 16:00:02 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 16:00:02 | I |       - range scale = [    1.0000]
24-11-25 16:00:02 | I |         sum  error  = [    1.0489]
24-11-25 16:00:02 | I |         best error  = [    1.0489]
24-11-25 16:00:02 | I |     + error = [1.0489]
24-11-25 16:00:03 | I |       - range scale = [    1.0000]
24-11-25 16:00:03 | I |         sum  error  = [   11.6042]
24-11-25 16:00:03 | I |         best error  = [   11.6042]
24-11-25 16:00:03 | I |     + error = [11.6042]
24-11-25 16:00:03 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 16:00:04 | I |       - range scale = [    1.0000]
24-11-25 16:00:04 | I |         sum  error  = [    1.2151]
24-11-25 16:00:04 | I |         best error  = [    1.2151]
24-11-25 16:00:04 | I |     + error = [1.2151]
24-11-25 16:00:05 | I |       - range scale = [    1.0000]
24-11-25 16:00:05 | I |         sum  error  = [   11.9917]
24-11-25 16:00:05 | I |         best error  = [   11.9917]
24-11-25 16:00:05 | I |     + error = [11.9917]
24-11-25 16:00:05 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 16:00:06 | I |       - range scale = [    1.0000]
24-11-25 16:00:06 | I |         sum  error  = [    3.4968]
24-11-25 16:00:06 | I |         best error  = [    3.4968]
24-11-25 16:00:06 | I |     + error = [3.4968]
24-11-25 16:00:06 | I |       - range scale = [    1.0000]
24-11-25 16:00:06 | I |         sum  error  = [   18.1692]
24-11-25 16:00:06 | I |         best error  = [   18.1692]
24-11-25 16:00:06 | I |     + error = [18.1692]
24-11-25 16:00:07 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 16:00:08 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 16:00:09 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 16:00:11 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 16:00:12 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 16:00:13 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 16:00:15 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 16:00:18 | I | quantizing activations for layer model.layers.0
24-11-25 16:00:18 | I | collecting info in model.layers.0
24-11-25 16:00:18 | I | collecting info in model.layers.0
24-11-25 16:00:18 | I | collecting info in model.layers.0
24-11-25 16:00:18 | I | collecting info in model.layers.0
24-11-25 16:00:19 | I | collecting calibration activations in model.layers.0
24-11-25 16:00:19 | I | collecting calibration activations in model.layers.0
24-11-25 16:00:19 | I | collecting calibration activations in model.layers.0
24-11-25 16:00:19 | I | collecting calibration activations in model.layers.0
24-11-25 16:00:21 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 16:00:21 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 16:00:21 | I | - Evaluator: gptq
24-11-25 16:00:21 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 16:00:21 | I | - Batch_size: 8
24-11-25 16:00:21 | I |   + Max_seq_length: 2048
24-11-25 16:01:02 | I |     - Results:
24-11-25 16:01:02 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 16:01:02 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 16:01:02 | I |       |wikitext |      1|word_perplexity|7.7786|  |7.7786|
24-11-25 16:01:02 | I |       |val_valid|      1|word_perplexity|9.0573|  |9.0573|
24-11-25 16:01:02 | I |       
24-11-25 16:01:02 | I | forward this layer
24-11-25 16:01:02 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/32.pt
24-11-25 16:01:02 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/32.pt
24-11-25 16:01:03 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 16:01:03 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 16:01:03 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 16:01:03 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 16:01:03 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 16:01:03 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 16:01:03 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 16:01:03 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 16:01:03 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 16:01:03 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 16:01:03 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 16:01:03 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 16:01:03 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 16:01:03 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 16:01:03 | I | in layer model.layers.0
24-11-25 16:01:03 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 16:01:03 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 16:01:03 | I | - Evaluator: gptq
24-11-25 16:01:03 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 16:01:03 | I | - Batch_size: 8
24-11-25 16:01:03 | I |   + Max_seq_length: 2048
24-11-25 16:01:41 | I |     - Results:
24-11-25 16:01:41 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 16:01:41 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 16:01:41 | I |       |wikitext |      1|word_perplexity|7.7076|  |7.7076|
24-11-25 16:01:41 | I |       |val_valid|      1|word_perplexity|8.9798|  |8.9798|
24-11-25 16:01:41 | I |       
24-11-25 16:01:41 | I | quantizing weights for layer model.layers.0
24-11-25 16:01:41 | I | collecting info in model.layers.0
24-11-25 16:01:41 | I | collecting info in model.layers.0
24-11-25 16:01:41 | I | collecting info in model.layers.0
24-11-25 16:01:41 | I | collecting info in model.layers.0
24-11-25 16:01:41 | I | collecting calibration activations in model.layers.0
24-11-25 16:01:42 | I | collecting calibration activations in model.layers.0
24-11-25 16:01:42 | I | collecting calibration activations in model.layers.0
24-11-25 16:01:42 | I | collecting calibration activations in model.layers.0
24-11-25 16:01:42 | I | - Quantizing decoder layer model.layers.0
24-11-25 16:01:42 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 16:01:43 | I |       - range scale = [    1.0000]
24-11-25 16:01:43 | I |         sum  error  = [    0.0658]
24-11-25 16:01:43 | I |         best error  = [    0.0658]
24-11-25 16:01:43 | I |     + error = [0.0658]
24-11-25 16:01:43 | I |       - range scale = [    1.0000]
24-11-25 16:01:43 | I |         sum  error  = [    0.6871]
24-11-25 16:01:43 | I |         best error  = [    0.6871]
24-11-25 16:01:43 | I |     + error = [0.6871]
24-11-25 16:01:44 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 16:01:44 | I |       - range scale = [    1.0000]
24-11-25 16:01:44 | I |         sum  error  = [    0.0725]
24-11-25 16:01:44 | I |         best error  = [    0.0725]
24-11-25 16:01:44 | I |     + error = [0.0725]
24-11-25 16:01:45 | I |       - range scale = [    1.0000]
24-11-25 16:01:45 | I |         sum  error  = [    0.5363]
24-11-25 16:01:45 | I |         best error  = [    0.5363]
24-11-25 16:01:45 | I |     + error = [0.5363]
24-11-25 16:01:45 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 16:01:46 | I |       - range scale = [    1.0000]
24-11-25 16:01:46 | I |         sum  error  = [    0.2501]
24-11-25 16:01:46 | I |         best error  = [    0.2501]
24-11-25 16:01:46 | I |     + error = [0.2501]
24-11-25 16:01:47 | I |       - range scale = [    1.0000]
24-11-25 16:01:47 | I |         sum  error  = [    1.8485]
24-11-25 16:01:47 | I |         best error  = [    1.8485]
24-11-25 16:01:47 | I |     + error = [1.8485]
24-11-25 16:01:47 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 16:01:47 | I |       - range scale = [    1.0000]
24-11-25 16:01:47 | I |         sum  error  = [    0.0611]
24-11-25 16:01:47 | I |         best error  = [    0.0611]
24-11-25 16:01:47 | I |     + error = [0.0611]
24-11-25 16:01:48 | I |       - range scale = [    1.0000]
24-11-25 16:01:48 | I |         sum  error  = [    0.5812]
24-11-25 16:01:48 | I |         best error  = [    0.5812]
24-11-25 16:01:48 | I |     + error = [0.5812]
24-11-25 16:01:48 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 16:01:49 | I |       - range scale = [    1.0000]
24-11-25 16:01:49 | I |         sum  error  = [    1.0532]
24-11-25 16:01:49 | I |         best error  = [    1.0532]
24-11-25 16:01:49 | I |     + error = [1.0532]
24-11-25 16:01:50 | I |       - range scale = [    1.0000]
24-11-25 16:01:50 | I |         sum  error  = [   11.6476]
24-11-25 16:01:50 | I |         best error  = [   11.6476]
24-11-25 16:01:50 | I |     + error = [11.6476]
24-11-25 16:01:50 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 16:01:51 | I |       - range scale = [    1.0000]
24-11-25 16:01:51 | I |         sum  error  = [    1.2206]
24-11-25 16:01:51 | I |         best error  = [    1.2206]
24-11-25 16:01:51 | I |     + error = [1.2206]
24-11-25 16:01:51 | I |       - range scale = [    1.0000]
24-11-25 16:01:51 | I |         sum  error  = [   12.0490]
24-11-25 16:01:51 | I |         best error  = [   12.0490]
24-11-25 16:01:51 | I |     + error = [12.0490]
24-11-25 16:01:52 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 16:01:52 | I |       - range scale = [    1.0000]
24-11-25 16:01:52 | I |         sum  error  = [    4.0625]
24-11-25 16:01:52 | I |         best error  = [    4.0625]
24-11-25 16:01:52 | I |     + error = [4.0625]
24-11-25 16:01:53 | I |       - range scale = [    1.0000]
24-11-25 16:01:53 | I |         sum  error  = [   20.3370]
24-11-25 16:01:53 | I |         best error  = [   20.3370]
24-11-25 16:01:53 | I |     + error = [20.3370]
24-11-25 16:01:53 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 16:01:55 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 16:01:56 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 16:01:57 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 16:01:59 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 16:02:00 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 16:02:02 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 16:02:05 | I | quantizing activations for layer model.layers.0
24-11-25 16:02:05 | I | collecting info in model.layers.0
24-11-25 16:02:05 | I | collecting info in model.layers.0
24-11-25 16:02:05 | I | collecting info in model.layers.0
24-11-25 16:02:05 | I | collecting info in model.layers.0
24-11-25 16:02:05 | I | collecting calibration activations in model.layers.0
24-11-25 16:02:05 | I | collecting calibration activations in model.layers.0
24-11-25 16:02:06 | I | collecting calibration activations in model.layers.0
24-11-25 16:02:06 | I | collecting calibration activations in model.layers.0
24-11-25 16:02:07 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 16:02:07 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 16:02:07 | I | - Evaluator: gptq
24-11-25 16:02:07 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 16:02:07 | I | - Batch_size: 8
24-11-25 16:02:07 | I |   + Max_seq_length: 2048
24-11-25 16:02:49 | I |     - Results:
24-11-25 16:02:49 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 16:02:49 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 16:02:49 | I |       |wikitext |      1|word_perplexity|7.7712|  |7.7712|
24-11-25 16:02:49 | I |       |val_valid|      1|word_perplexity|9.0626|  |9.0626|
24-11-25 16:02:49 | I |       
24-11-25 16:02:49 | I | forward this layer
24-11-25 16:02:49 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/33.pt
24-11-25 16:02:49 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/33.pt
24-11-25 16:02:49 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 16:02:49 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 16:02:49 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 16:02:49 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 16:02:49 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 16:02:49 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 16:02:49 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 16:02:49 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 16:02:49 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 16:02:49 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 16:02:49 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 16:02:49 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 16:02:49 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 16:02:49 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 16:02:49 | I | [2] done with optimizer step
24-11-25 16:02:49 | I | epoch 001:     17 / 409600000 loss=0.00409203, loss_per_token=8.38048, loss_sum=274612, wps=76.7, ups=0, wpb=32768, bsz=64, num_updates=3, lr=9e-06, gnorm=455.375, clip=100, loss_scale=0.0078, train_wall=427, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=3900, lmquant_ppl_result_wikitext_in_train_no_quant=7.70761, lmquant_ppl_result_val_in_train_no_quant=8.97983, lmquant_ppl_result_wikitext_in_train_with_quant=7.77116, lmquant_ppl_result_val_in_train_with_quant=9.06256
24-11-25 16:02:49 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 16:02:49 | I | in layer model.layers.0
24-11-25 16:02:49 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 16:02:50 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 16:02:50 | I | - Evaluator: gptq
24-11-25 16:02:50 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 16:02:50 | I | - Batch_size: 8
24-11-25 16:02:50 | I |   + Max_seq_length: 2048
24-11-25 16:03:28 | I |     - Results:
24-11-25 16:03:28 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 16:03:28 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 16:03:28 | I |       |wikitext |      1|word_perplexity|7.7075|  |7.7075|
24-11-25 16:03:28 | I |       |val_valid|      1|word_perplexity|8.9794|  |8.9794|
24-11-25 16:03:28 | I |       
24-11-25 16:03:28 | I | quantizing weights for layer model.layers.0
24-11-25 16:03:28 | I | collecting info in model.layers.0
24-11-25 16:03:28 | I | collecting info in model.layers.0
24-11-25 16:03:28 | I | collecting info in model.layers.0
24-11-25 16:03:28 | I | collecting info in model.layers.0
24-11-25 16:03:28 | I | collecting calibration activations in model.layers.0
24-11-25 16:03:28 | I | collecting calibration activations in model.layers.0
24-11-25 16:03:28 | I | collecting calibration activations in model.layers.0
24-11-25 16:03:29 | I | collecting calibration activations in model.layers.0
24-11-25 16:03:29 | I | - Quantizing decoder layer model.layers.0
24-11-25 16:03:29 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 16:03:30 | I |       - range scale = [    1.0000]
24-11-25 16:03:30 | I |         sum  error  = [    0.0674]
24-11-25 16:03:30 | I |         best error  = [    0.0674]
24-11-25 16:03:30 | I |     + error = [0.0674]
24-11-25 16:03:30 | I |       - range scale = [    1.0000]
24-11-25 16:03:30 | I |         sum  error  = [    0.6763]
24-11-25 16:03:30 | I |         best error  = [    0.6763]
24-11-25 16:03:30 | I |     + error = [0.6763]
24-11-25 16:03:31 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 16:03:31 | I |       - range scale = [    1.0000]
24-11-25 16:03:31 | I |         sum  error  = [    0.0721]
24-11-25 16:03:31 | I |         best error  = [    0.0721]
24-11-25 16:03:31 | I |     + error = [0.0721]
24-11-25 16:03:32 | I |       - range scale = [    1.0000]
24-11-25 16:03:32 | I |         sum  error  = [    0.5249]
24-11-25 16:03:32 | I |         best error  = [    0.5249]
24-11-25 16:03:32 | I |     + error = [0.5249]
24-11-25 16:03:32 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 16:03:33 | I |       - range scale = [    1.0000]
24-11-25 16:03:33 | I |         sum  error  = [    0.2458]
24-11-25 16:03:33 | I |         best error  = [    0.2458]
24-11-25 16:03:33 | I |     + error = [0.2458]
24-11-25 16:03:33 | I |       - range scale = [    1.0000]
24-11-25 16:03:33 | I |         sum  error  = [    1.8413]
24-11-25 16:03:33 | I |         best error  = [    1.8413]
24-11-25 16:03:33 | I |     + error = [1.8413]
24-11-25 16:03:34 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 16:03:34 | I |       - range scale = [    1.0000]
24-11-25 16:03:34 | I |         sum  error  = [    0.0614]
24-11-25 16:03:34 | I |         best error  = [    0.0614]
24-11-25 16:03:34 | I |     + error = [0.0614]
24-11-25 16:03:35 | I |       - range scale = [    1.0000]
24-11-25 16:03:35 | I |         sum  error  = [    0.5842]
24-11-25 16:03:35 | I |         best error  = [    0.5842]
24-11-25 16:03:35 | I |     + error = [0.5842]
24-11-25 16:03:35 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 16:03:36 | I |       - range scale = [    1.0000]
24-11-25 16:03:36 | I |         sum  error  = [    1.0561]
24-11-25 16:03:36 | I |         best error  = [    1.0561]
24-11-25 16:03:36 | I |     + error = [1.0561]
24-11-25 16:03:37 | I |       - range scale = [    1.0000]
24-11-25 16:03:37 | I |         sum  error  = [   11.6778]
24-11-25 16:03:37 | I |         best error  = [   11.6778]
24-11-25 16:03:37 | I |     + error = [11.6778]
24-11-25 16:03:37 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 16:03:38 | I |       - range scale = [    1.0000]
24-11-25 16:03:38 | I |         sum  error  = [    1.2238]
24-11-25 16:03:38 | I |         best error  = [    1.2238]
24-11-25 16:03:38 | I |     + error = [1.2238]
24-11-25 16:03:38 | I |       - range scale = [    1.0000]
24-11-25 16:03:38 | I |         sum  error  = [   12.0801]
24-11-25 16:03:38 | I |         best error  = [   12.0801]
24-11-25 16:03:38 | I |     + error = [12.0801]
24-11-25 16:03:39 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 16:03:39 | I |       - range scale = [    1.0000]
24-11-25 16:03:39 | I |         sum  error  = [    3.8513]
24-11-25 16:03:39 | I |         best error  = [    3.8513]
24-11-25 16:03:39 | I |     + error = [3.8513]
24-11-25 16:03:40 | I |       - range scale = [    1.0000]
24-11-25 16:03:40 | I |         sum  error  = [   19.4744]
24-11-25 16:03:40 | I |         best error  = [   19.4744]
24-11-25 16:03:40 | I |     + error = [19.4744]
24-11-25 16:03:40 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 16:03:42 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 16:03:43 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 16:03:44 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 16:03:46 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 16:03:47 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 16:03:49 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 16:03:52 | I | quantizing activations for layer model.layers.0
24-11-25 16:03:52 | I | collecting info in model.layers.0
24-11-25 16:03:52 | I | collecting info in model.layers.0
24-11-25 16:03:52 | I | collecting info in model.layers.0
24-11-25 16:03:52 | I | collecting info in model.layers.0
24-11-25 16:03:53 | I | collecting calibration activations in model.layers.0
24-11-25 16:03:53 | I | collecting calibration activations in model.layers.0
24-11-25 16:03:53 | I | collecting calibration activations in model.layers.0
24-11-25 16:03:53 | I | collecting calibration activations in model.layers.0
24-11-25 16:03:55 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 16:03:55 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 16:03:55 | I | - Evaluator: gptq
24-11-25 16:03:55 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 16:03:55 | I | - Batch_size: 8
24-11-25 16:03:55 | I |   + Max_seq_length: 2048
24-11-25 16:04:36 | I |     - Results:
24-11-25 16:04:36 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 16:04:36 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 16:04:36 | I |       |wikitext |      1|word_perplexity|7.7812|  |7.7812|
24-11-25 16:04:36 | I |       |val_valid|      1|word_perplexity|9.0614|  |9.0614|
24-11-25 16:04:36 | I |       
24-11-25 16:04:36 | I | forward this layer
24-11-25 16:04:36 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/34.pt
24-11-25 16:04:36 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/34.pt
24-11-25 16:04:36 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 16:04:36 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 16:04:36 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 16:04:36 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 16:04:36 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 16:04:36 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 16:04:36 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 16:04:36 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 16:04:36 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 16:04:36 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 16:04:36 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 16:04:36 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 16:04:36 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 16:04:36 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 16:04:36 | I | in layer model.layers.0
24-11-25 16:04:36 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 16:04:36 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 16:04:36 | I | - Evaluator: gptq
24-11-25 16:04:36 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 16:04:36 | I | - Batch_size: 8
24-11-25 16:04:36 | I |   + Max_seq_length: 2048
24-11-25 16:05:15 | I |     - Results:
24-11-25 16:05:15 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 16:05:15 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 16:05:15 | I |       |wikitext |      1|word_perplexity|7.7075|  |7.7075|
24-11-25 16:05:15 | I |       |val_valid|      1|word_perplexity|8.9794|  |8.9794|
24-11-25 16:05:15 | I |       
24-11-25 16:05:15 | I | quantizing weights for layer model.layers.0
24-11-25 16:05:15 | I | collecting info in model.layers.0
24-11-25 16:05:15 | I | collecting info in model.layers.0
24-11-25 16:05:15 | I | collecting info in model.layers.0
24-11-25 16:05:15 | I | collecting info in model.layers.0
24-11-25 16:05:15 | I | collecting calibration activations in model.layers.0
24-11-25 16:05:15 | I | collecting calibration activations in model.layers.0
24-11-25 16:05:15 | I | collecting calibration activations in model.layers.0
24-11-25 16:05:15 | I | collecting calibration activations in model.layers.0
24-11-25 16:05:16 | I | - Quantizing decoder layer model.layers.0
24-11-25 16:05:16 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 16:05:16 | I |       - range scale = [    1.0000]
24-11-25 16:05:16 | I |         sum  error  = [    0.0683]
24-11-25 16:05:16 | I |         best error  = [    0.0683]
24-11-25 16:05:16 | I |     + error = [0.0683]
24-11-25 16:05:17 | I |       - range scale = [    1.0000]
24-11-25 16:05:17 | I |         sum  error  = [    0.6875]
24-11-25 16:05:17 | I |         best error  = [    0.6875]
24-11-25 16:05:17 | I |     + error = [0.6875]
24-11-25 16:05:17 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 16:05:18 | I |       - range scale = [    1.0000]
24-11-25 16:05:18 | I |         sum  error  = [    0.0719]
24-11-25 16:05:18 | I |         best error  = [    0.0719]
24-11-25 16:05:18 | I |     + error = [0.0719]
24-11-25 16:05:19 | I |       - range scale = [    1.0000]
24-11-25 16:05:19 | I |         sum  error  = [    0.5359]
24-11-25 16:05:19 | I |         best error  = [    0.5359]
24-11-25 16:05:19 | I |     + error = [0.5359]
24-11-25 16:05:19 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 16:05:20 | I |       - range scale = [    1.0000]
24-11-25 16:05:20 | I |         sum  error  = [    0.2437]
24-11-25 16:05:20 | I |         best error  = [    0.2437]
24-11-25 16:05:20 | I |     + error = [0.2437]
24-11-25 16:05:20 | I |       - range scale = [    1.0000]
24-11-25 16:05:20 | I |         sum  error  = [    1.8368]
24-11-25 16:05:20 | I |         best error  = [    1.8368]
24-11-25 16:05:20 | I |     + error = [1.8368]
24-11-25 16:05:21 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 16:05:21 | I |       - range scale = [    1.0000]
24-11-25 16:05:21 | I |         sum  error  = [    0.0610]
24-11-25 16:05:21 | I |         best error  = [    0.0610]
24-11-25 16:05:21 | I |     + error = [0.0610]
24-11-25 16:05:22 | I |       - range scale = [    1.0000]
24-11-25 16:05:22 | I |         sum  error  = [    0.5809]
24-11-25 16:05:22 | I |         best error  = [    0.5809]
24-11-25 16:05:22 | I |     + error = [0.5809]
24-11-25 16:05:22 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 16:05:23 | I |       - range scale = [    1.0000]
24-11-25 16:05:23 | I |         sum  error  = [    1.0476]
24-11-25 16:05:23 | I |         best error  = [    1.0476]
24-11-25 16:05:23 | I |     + error = [1.0476]
24-11-25 16:05:24 | I |       - range scale = [    1.0000]
24-11-25 16:05:24 | I |         sum  error  = [   11.5971]
24-11-25 16:05:24 | I |         best error  = [   11.5971]
24-11-25 16:05:24 | I |     + error = [11.5971]
24-11-25 16:05:24 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 16:05:25 | I |       - range scale = [    1.0000]
24-11-25 16:05:25 | I |         sum  error  = [    1.2145]
24-11-25 16:05:25 | I |         best error  = [    1.2145]
24-11-25 16:05:25 | I |     + error = [1.2145]
24-11-25 16:05:25 | I |       - range scale = [    1.0000]
24-11-25 16:05:25 | I |         sum  error  = [   11.9869]
24-11-25 16:05:25 | I |         best error  = [   11.9869]
24-11-25 16:05:25 | I |     + error = [11.9869]
24-11-25 16:05:25 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 16:05:26 | I |       - range scale = [    1.0000]
24-11-25 16:05:26 | I |         sum  error  = [    3.9472]
24-11-25 16:05:26 | I |         best error  = [    3.9472]
24-11-25 16:05:26 | I |     + error = [3.9472]
24-11-25 16:05:27 | I |       - range scale = [    1.0000]
24-11-25 16:05:27 | I |         sum  error  = [   20.1337]
24-11-25 16:05:27 | I |         best error  = [   20.1337]
24-11-25 16:05:27 | I |     + error = [20.1337]
24-11-25 16:05:27 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 16:05:28 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 16:05:30 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 16:05:31 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 16:05:33 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 16:05:34 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 16:05:35 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 16:05:39 | I | quantizing activations for layer model.layers.0
24-11-25 16:05:39 | I | collecting info in model.layers.0
24-11-25 16:05:39 | I | collecting info in model.layers.0
24-11-25 16:05:39 | I | collecting info in model.layers.0
24-11-25 16:05:39 | I | collecting info in model.layers.0
24-11-25 16:05:39 | I | collecting calibration activations in model.layers.0
24-11-25 16:05:39 | I | collecting calibration activations in model.layers.0
24-11-25 16:05:39 | I | collecting calibration activations in model.layers.0
24-11-25 16:05:39 | I | collecting calibration activations in model.layers.0
24-11-25 16:05:41 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 16:05:41 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 16:05:41 | I | - Evaluator: gptq
24-11-25 16:05:41 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 16:05:41 | I | - Batch_size: 8
24-11-25 16:05:41 | I |   + Max_seq_length: 2048
24-11-25 16:06:23 | I |     - Results:
24-11-25 16:06:23 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 16:06:23 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 16:06:23 | I |       |wikitext |      1|word_perplexity|7.7711|  |7.7711|
24-11-25 16:06:23 | I |       |val_valid|      1|word_perplexity|9.0568|  |9.0568|
24-11-25 16:06:23 | I |       
24-11-25 16:06:23 | I | forward this layer
24-11-25 16:06:23 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/35.pt
24-11-25 16:06:23 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/35.pt
24-11-25 16:06:23 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 16:06:23 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 16:06:23 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 16:06:23 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 16:06:23 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 16:06:23 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 16:06:23 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 16:06:23 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 16:06:23 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 16:06:23 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 16:06:23 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 16:06:23 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 16:06:23 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 16:06:23 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 16:06:23 | I | [3] done with optimizer step
24-11-25 16:06:23 | I | epoch 001:     18 / 409600000 loss=0.00354449, loss_per_token=7.25911, loss_sum=237867, wps=153.4, ups=0, wpb=32768, bsz=64, num_updates=4, lr=1.2e-05, gnorm=347.556, clip=100, loss_scale=0.0078, train_wall=213, cuda_gb_allocated=12.3, cuda_gb_reserved=13.9, cuda_gb_free=11.4, wall=4113, lmquant_ppl_result_wikitext_in_train_no_quant=7.70749, lmquant_ppl_result_val_in_train_no_quant=8.97943, lmquant_ppl_result_wikitext_in_train_with_quant=7.77111, lmquant_ppl_result_val_in_train_with_quant=9.05676
24-11-25 16:06:23 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 16:06:23 | I | in layer model.layers.0
24-11-25 16:06:23 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 16:06:23 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 16:06:23 | I | - Evaluator: gptq
24-11-25 16:06:23 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 16:06:23 | I | - Batch_size: 8
24-11-25 16:06:23 | I |   + Max_seq_length: 2048
24-11-25 16:07:01 | I |     - Results:
24-11-25 16:07:01 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 16:07:01 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 16:07:01 | I |       |wikitext |      1|word_perplexity|7.7072|  |7.7072|
24-11-25 16:07:01 | I |       |val_valid|      1|word_perplexity|8.9792|  |8.9792|
24-11-25 16:07:01 | I |       
24-11-25 16:07:01 | I | quantizing weights for layer model.layers.0
24-11-25 16:07:01 | I | collecting info in model.layers.0
24-11-25 16:07:01 | I | collecting info in model.layers.0
24-11-25 16:07:01 | I | collecting info in model.layers.0
24-11-25 16:07:01 | I | collecting info in model.layers.0
24-11-25 16:07:02 | I | collecting calibration activations in model.layers.0
24-11-25 16:07:02 | I | collecting calibration activations in model.layers.0
24-11-25 16:07:02 | I | collecting calibration activations in model.layers.0
24-11-25 16:07:02 | I | collecting calibration activations in model.layers.0
24-11-25 16:07:02 | I | - Quantizing decoder layer model.layers.0
24-11-25 16:07:02 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 16:07:03 | I |       - range scale = [    1.0000]
24-11-25 16:07:03 | I |         sum  error  = [    0.0668]
24-11-25 16:07:03 | I |         best error  = [    0.0668]
24-11-25 16:07:03 | I |     + error = [0.0668]
24-11-25 16:07:04 | I |       - range scale = [    1.0000]
24-11-25 16:07:04 | I |         sum  error  = [    0.6798]
24-11-25 16:07:04 | I |         best error  = [    0.6798]
24-11-25 16:07:04 | I |     + error = [0.6798]
24-11-25 16:07:04 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 16:07:05 | I |       - range scale = [    1.0000]
24-11-25 16:07:05 | I |         sum  error  = [    0.0692]
24-11-25 16:07:05 | I |         best error  = [    0.0692]
24-11-25 16:07:05 | I |     + error = [0.0692]
24-11-25 16:07:05 | I |       - range scale = [    1.0000]
24-11-25 16:07:05 | I |         sum  error  = [    0.5311]
24-11-25 16:07:05 | I |         best error  = [    0.5311]
24-11-25 16:07:05 | I |     + error = [0.5311]
24-11-25 16:07:06 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 16:07:06 | I |       - range scale = [    1.0000]
24-11-25 16:07:06 | I |         sum  error  = [    0.2453]
24-11-25 16:07:06 | I |         best error  = [    0.2453]
24-11-25 16:07:06 | I |     + error = [0.2453]
24-11-25 16:07:07 | I |       - range scale = [    1.0000]
24-11-25 16:07:07 | I |         sum  error  = [    1.8394]
24-11-25 16:07:07 | I |         best error  = [    1.8394]
24-11-25 16:07:07 | I |     + error = [1.8394]
24-11-25 16:07:07 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 16:07:08 | I |       - range scale = [    1.0000]
24-11-25 16:07:08 | I |         sum  error  = [    0.0629]
24-11-25 16:07:08 | I |         best error  = [    0.0629]
24-11-25 16:07:08 | I |     + error = [0.0629]
24-11-25 16:07:09 | I |       - range scale = [    1.0000]
24-11-25 16:07:09 | I |         sum  error  = [    0.5993]
24-11-25 16:07:09 | I |         best error  = [    0.5993]
24-11-25 16:07:09 | I |     + error = [0.5993]
24-11-25 16:07:09 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 16:07:09 | I |       - range scale = [    1.0000]
24-11-25 16:07:09 | I |         sum  error  = [    1.0505]
24-11-25 16:07:09 | I |         best error  = [    1.0505]
24-11-25 16:07:09 | I |     + error = [1.0505]
24-11-25 16:07:10 | I |       - range scale = [    1.0000]
24-11-25 16:07:10 | I |         sum  error  = [   11.6166]
24-11-25 16:07:10 | I |         best error  = [   11.6166]
24-11-25 16:07:10 | I |     + error = [11.6166]
24-11-25 16:07:10 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 16:07:11 | I |       - range scale = [    1.0000]
24-11-25 16:07:11 | I |         sum  error  = [    1.2175]
24-11-25 16:07:11 | I |         best error  = [    1.2175]
24-11-25 16:07:11 | I |     + error = [1.2175]
24-11-25 16:07:12 | I |       - range scale = [    1.0000]
24-11-25 16:07:12 | I |         sum  error  = [   12.0193]
24-11-25 16:07:12 | I |         best error  = [   12.0193]
24-11-25 16:07:12 | I |     + error = [12.0193]
24-11-25 16:07:12 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 16:07:13 | I |       - range scale = [    1.0000]
24-11-25 16:07:13 | I |         sum  error  = [    4.1209]
24-11-25 16:07:13 | I |         best error  = [    4.1209]
24-11-25 16:07:13 | I |     + error = [4.1209]
24-11-25 16:07:13 | I |       - range scale = [    1.0000]
24-11-25 16:07:13 | I |         sum  error  = [   20.6083]
24-11-25 16:07:13 | I |         best error  = [   20.6083]
24-11-25 16:07:13 | I |     + error = [20.6083]
24-11-25 16:07:14 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 16:07:15 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 16:07:16 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 16:07:18 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 16:07:19 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 16:07:20 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 16:07:22 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 16:07:25 | I | quantizing activations for layer model.layers.0
24-11-25 16:07:25 | I | collecting info in model.layers.0
24-11-25 16:07:25 | I | collecting info in model.layers.0
24-11-25 16:07:25 | I | collecting info in model.layers.0
24-11-25 16:07:25 | I | collecting info in model.layers.0
24-11-25 16:07:26 | I | collecting calibration activations in model.layers.0
24-11-25 16:07:26 | I | collecting calibration activations in model.layers.0
24-11-25 16:07:26 | I | collecting calibration activations in model.layers.0
24-11-25 16:07:26 | I | collecting calibration activations in model.layers.0
24-11-25 16:07:28 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 16:07:28 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 16:07:28 | I | - Evaluator: gptq
24-11-25 16:07:28 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 16:07:28 | I | - Batch_size: 8
24-11-25 16:07:28 | I |   + Max_seq_length: 2048
24-11-25 16:08:09 | I |     - Results:
24-11-25 16:08:09 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 16:08:09 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 16:08:09 | I |       |wikitext |      1|word_perplexity|7.7619|  |7.7619|
24-11-25 16:08:09 | I |       |val_valid|      1|word_perplexity|9.0605|  |9.0605|
24-11-25 16:08:09 | I |       
24-11-25 16:08:09 | I | forward this layer
24-11-25 16:08:09 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/36.pt
24-11-25 16:08:09 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/36.pt
24-11-25 16:08:09 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 16:08:09 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 16:08:09 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 16:08:09 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 16:08:09 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 16:08:09 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 16:08:09 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 16:08:09 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 16:08:09 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 16:08:09 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 16:08:09 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 16:08:09 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 16:08:09 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 16:08:09 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 16:08:09 | I | in layer model.layers.0
24-11-25 16:08:09 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 16:08:09 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 16:08:09 | I | - Evaluator: gptq
24-11-25 16:08:09 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 16:08:09 | I | - Batch_size: 8
24-11-25 16:08:09 | I |   + Max_seq_length: 2048
24-11-25 16:08:47 | I |     - Results:
24-11-25 16:08:47 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 16:08:47 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 16:08:47 | I |       |wikitext |      1|word_perplexity|7.7072|  |7.7072|
24-11-25 16:08:47 | I |       |val_valid|      1|word_perplexity|8.9792|  |8.9792|
24-11-25 16:08:47 | I |       
24-11-25 16:08:47 | I | quantizing weights for layer model.layers.0
24-11-25 16:08:47 | I | collecting info in model.layers.0
24-11-25 16:08:47 | I | collecting info in model.layers.0
24-11-25 16:08:47 | I | collecting info in model.layers.0
24-11-25 16:08:47 | I | collecting info in model.layers.0
24-11-25 16:08:48 | I | collecting calibration activations in model.layers.0
24-11-25 16:08:48 | I | collecting calibration activations in model.layers.0
24-11-25 16:08:48 | I | collecting calibration activations in model.layers.0
24-11-25 16:08:48 | I | collecting calibration activations in model.layers.0
24-11-25 16:08:49 | I | - Quantizing decoder layer model.layers.0
24-11-25 16:08:49 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 16:08:49 | I |       - range scale = [    1.0000]
24-11-25 16:08:49 | I |         sum  error  = [    0.0669]
24-11-25 16:08:49 | I |         best error  = [    0.0669]
24-11-25 16:08:49 | I |     + error = [0.0669]
24-11-25 16:08:50 | I |       - range scale = [    1.0000]
24-11-25 16:08:50 | I |         sum  error  = [    0.6839]
24-11-25 16:08:50 | I |         best error  = [    0.6839]
24-11-25 16:08:50 | I |     + error = [0.6839]
24-11-25 16:08:50 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 16:08:51 | I |       - range scale = [    1.0000]
24-11-25 16:08:51 | I |         sum  error  = [    0.0688]
24-11-25 16:08:51 | I |         best error  = [    0.0688]
24-11-25 16:08:51 | I |     + error = [0.0688]
24-11-25 16:08:52 | I |       - range scale = [    1.0000]
24-11-25 16:08:52 | I |         sum  error  = [    0.5344]
24-11-25 16:08:52 | I |         best error  = [    0.5344]
24-11-25 16:08:52 | I |     + error = [0.5344]
24-11-25 16:08:52 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 16:08:52 | I |       - range scale = [    1.0000]
24-11-25 16:08:52 | I |         sum  error  = [    0.2445]
24-11-25 16:08:52 | I |         best error  = [    0.2445]
24-11-25 16:08:52 | I |     + error = [0.2445]
24-11-25 16:08:53 | I |       - range scale = [    1.0000]
24-11-25 16:08:53 | I |         sum  error  = [    1.8397]
24-11-25 16:08:53 | I |         best error  = [    1.8397]
24-11-25 16:08:53 | I |     + error = [1.8397]
24-11-25 16:08:53 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 16:08:54 | I |       - range scale = [    1.0000]
24-11-25 16:08:54 | I |         sum  error  = [    0.0605]
24-11-25 16:08:54 | I |         best error  = [    0.0605]
24-11-25 16:08:54 | I |     + error = [0.0605]
24-11-25 16:08:55 | I |       - range scale = [    1.0000]
24-11-25 16:08:55 | I |         sum  error  = [    0.5801]
24-11-25 16:08:55 | I |         best error  = [    0.5801]
24-11-25 16:08:55 | I |     + error = [0.5801]
24-11-25 16:08:55 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 16:08:55 | I |       - range scale = [    1.0000]
24-11-25 16:08:55 | I |         sum  error  = [    1.0449]
24-11-25 16:08:55 | I |         best error  = [    1.0449]
24-11-25 16:08:55 | I |     + error = [1.0449]
24-11-25 16:08:56 | I |       - range scale = [    1.0000]
24-11-25 16:08:56 | I |         sum  error  = [   11.5620]
24-11-25 16:08:56 | I |         best error  = [   11.5620]
24-11-25 16:08:56 | I |     + error = [11.5620]
24-11-25 16:08:56 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 16:08:57 | I |       - range scale = [    1.0000]
24-11-25 16:08:57 | I |         sum  error  = [    1.2115]
24-11-25 16:08:57 | I |         best error  = [    1.2115]
24-11-25 16:08:57 | I |     + error = [1.2115]
24-11-25 16:08:58 | I |       - range scale = [    1.0000]
24-11-25 16:08:58 | I |         sum  error  = [   11.9533]
24-11-25 16:08:58 | I |         best error  = [   11.9533]
24-11-25 16:08:58 | I |     + error = [11.9533]
24-11-25 16:08:58 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 16:08:59 | I |       - range scale = [    1.0000]
24-11-25 16:08:59 | I |         sum  error  = [    4.0794]
24-11-25 16:08:59 | I |         best error  = [    4.0794]
24-11-25 16:08:59 | I |     + error = [4.0794]
24-11-25 16:08:59 | I |       - range scale = [    1.0000]
24-11-25 16:08:59 | I |         sum  error  = [   20.5981]
24-11-25 16:08:59 | I |         best error  = [   20.5981]
24-11-25 16:08:59 | I |     + error = [20.5981]
24-11-25 16:09:00 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 16:09:01 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 16:09:02 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 16:09:04 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 16:09:05 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 16:09:06 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 16:09:08 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 16:09:11 | I | quantizing activations for layer model.layers.0
24-11-25 16:09:11 | I | collecting info in model.layers.0
24-11-25 16:09:11 | I | collecting info in model.layers.0
24-11-25 16:09:11 | I | collecting info in model.layers.0
24-11-25 16:09:11 | I | collecting info in model.layers.0
24-11-25 16:09:11 | I | collecting calibration activations in model.layers.0
24-11-25 16:09:12 | I | collecting calibration activations in model.layers.0
24-11-25 16:09:12 | I | collecting calibration activations in model.layers.0
24-11-25 16:09:12 | I | collecting calibration activations in model.layers.0
24-11-25 16:09:14 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 16:09:14 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 16:09:14 | I | - Evaluator: gptq
24-11-25 16:09:14 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 16:09:14 | I | - Batch_size: 8
24-11-25 16:09:14 | I |   + Max_seq_length: 2048
24-11-25 16:09:55 | I |     - Results:
24-11-25 16:09:55 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 16:09:55 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 16:09:55 | I |       |wikitext |      1|word_perplexity|7.7795|  |7.7795|
24-11-25 16:09:55 | I |       |val_valid|      1|word_perplexity|9.0548|  |9.0548|
24-11-25 16:09:55 | I |       
24-11-25 16:09:55 | I | forward this layer
24-11-25 16:09:55 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/37.pt
24-11-25 16:09:55 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/37.pt
24-11-25 16:09:55 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 16:09:55 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 16:09:55 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 16:09:55 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 16:09:55 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 16:09:55 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 16:09:55 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 16:09:55 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 16:09:55 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 16:09:55 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 16:09:55 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 16:09:55 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 16:09:55 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 16:09:55 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 16:09:55 | I | [4] done with optimizer step
24-11-25 16:09:55 | I | epoch 001:     19 / 409600000 loss=0.00327334, loss_per_token=6.70381, loss_sum=219670, wps=154.4, ups=0, wpb=32768, bsz=64, num_updates=5, lr=1.5e-05, gnorm=334.951, clip=100, loss_scale=0.0078, train_wall=212, cuda_gb_allocated=12.3, cuda_gb_reserved=13.9, cuda_gb_free=11.4, wall=4325, lmquant_ppl_result_wikitext_in_train_no_quant=7.70723, lmquant_ppl_result_val_in_train_no_quant=8.97917, lmquant_ppl_result_wikitext_in_train_with_quant=7.7795, lmquant_ppl_result_val_in_train_with_quant=9.05478
24-11-25 16:09:55 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 16:09:55 | I | in layer model.layers.0
24-11-25 16:09:55 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 16:09:55 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 16:09:55 | I | - Evaluator: gptq
24-11-25 16:09:55 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 16:09:55 | I | - Batch_size: 8
24-11-25 16:09:55 | I |   + Max_seq_length: 2048
24-11-25 16:10:34 | I |     - Results:
24-11-25 16:10:34 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 16:10:34 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 16:10:34 | I |       |wikitext |      1|word_perplexity|7.7072|  |7.7072|
24-11-25 16:10:34 | I |       |val_valid|      1|word_perplexity|8.9787|  |8.9787|
24-11-25 16:10:34 | I |       
24-11-25 16:10:34 | I | quantizing weights for layer model.layers.0
24-11-25 16:10:34 | I | collecting info in model.layers.0
24-11-25 16:10:34 | I | collecting info in model.layers.0
24-11-25 16:10:34 | I | collecting info in model.layers.0
24-11-25 16:10:34 | I | collecting info in model.layers.0
24-11-25 16:10:34 | I | collecting calibration activations in model.layers.0
24-11-25 16:10:34 | I | collecting calibration activations in model.layers.0
24-11-25 16:10:34 | I | collecting calibration activations in model.layers.0
24-11-25 16:10:35 | I | collecting calibration activations in model.layers.0
24-11-25 16:10:35 | I | - Quantizing decoder layer model.layers.0
24-11-25 16:10:35 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 16:10:36 | I |       - range scale = [    1.0000]
24-11-25 16:10:36 | I |         sum  error  = [    0.0627]
24-11-25 16:10:36 | I |         best error  = [    0.0627]
24-11-25 16:10:36 | I |     + error = [0.0627]
24-11-25 16:10:36 | I |       - range scale = [    1.0000]
24-11-25 16:10:36 | I |         sum  error  = [    0.6317]
24-11-25 16:10:36 | I |         best error  = [    0.6317]
24-11-25 16:10:36 | I |     + error = [0.6317]
24-11-25 16:10:36 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 16:10:37 | I |       - range scale = [    1.0000]
24-11-25 16:10:37 | I |         sum  error  = [    0.0707]
24-11-25 16:10:37 | I |         best error  = [    0.0707]
24-11-25 16:10:37 | I |     + error = [0.0707]
24-11-25 16:10:38 | I |       - range scale = [    1.0000]
24-11-25 16:10:38 | I |         sum  error  = [    0.5134]
24-11-25 16:10:38 | I |         best error  = [    0.5134]
24-11-25 16:10:38 | I |     + error = [0.5134]
24-11-25 16:10:38 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 16:10:39 | I |       - range scale = [    1.0000]
24-11-25 16:10:39 | I |         sum  error  = [    0.2507]
24-11-25 16:10:39 | I |         best error  = [    0.2507]
24-11-25 16:10:39 | I |     + error = [0.2507]
24-11-25 16:10:39 | I |       - range scale = [    1.0000]
24-11-25 16:10:39 | I |         sum  error  = [    1.8310]
24-11-25 16:10:39 | I |         best error  = [    1.8310]
24-11-25 16:10:39 | I |     + error = [1.8310]
24-11-25 16:10:40 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 16:10:40 | I |       - range scale = [    1.0000]
24-11-25 16:10:40 | I |         sum  error  = [    0.0614]
24-11-25 16:10:40 | I |         best error  = [    0.0614]
24-11-25 16:10:40 | I |     + error = [0.0614]
24-11-25 16:10:41 | I |       - range scale = [    1.0000]
24-11-25 16:10:41 | I |         sum  error  = [    0.5887]
24-11-25 16:10:41 | I |         best error  = [    0.5887]
24-11-25 16:10:41 | I |     + error = [0.5887]
24-11-25 16:10:41 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 16:10:42 | I |       - range scale = [    1.0000]
24-11-25 16:10:42 | I |         sum  error  = [    1.0362]
24-11-25 16:10:42 | I |         best error  = [    1.0362]
24-11-25 16:10:42 | I |     + error = [1.0362]
24-11-25 16:10:42 | I |       - range scale = [    1.0000]
24-11-25 16:10:42 | I |         sum  error  = [   11.4761]
24-11-25 16:10:42 | I |         best error  = [   11.4761]
24-11-25 16:10:42 | I |     + error = [11.4761]
24-11-25 16:10:43 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 16:10:43 | I |       - range scale = [    1.0000]
24-11-25 16:10:43 | I |         sum  error  = [    1.2006]
24-11-25 16:10:43 | I |         best error  = [    1.2006]
24-11-25 16:10:43 | I |     + error = [1.2006]
24-11-25 16:10:44 | I |       - range scale = [    1.0000]
24-11-25 16:10:44 | I |         sum  error  = [   11.8611]
24-11-25 16:10:44 | I |         best error  = [   11.8611]
24-11-25 16:10:44 | I |     + error = [11.8611]
24-11-25 16:10:44 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 16:10:45 | I |       - range scale = [    1.0000]
24-11-25 16:10:45 | I |         sum  error  = [    3.2222]
24-11-25 16:10:45 | I |         best error  = [    3.2222]
24-11-25 16:10:45 | I |     + error = [3.2222]
24-11-25 16:10:46 | I |       - range scale = [    1.0000]
24-11-25 16:10:46 | I |         sum  error  = [   16.7404]
24-11-25 16:10:46 | I |         best error  = [   16.7404]
24-11-25 16:10:46 | I |     + error = [16.7404]
24-11-25 16:10:46 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 16:10:47 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 16:10:49 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 16:10:50 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 16:10:51 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 16:10:53 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 16:10:54 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 16:10:58 | I | quantizing activations for layer model.layers.0
24-11-25 16:10:58 | I | collecting info in model.layers.0
24-11-25 16:10:58 | I | collecting info in model.layers.0
24-11-25 16:10:58 | I | collecting info in model.layers.0
24-11-25 16:10:58 | I | collecting info in model.layers.0
24-11-25 16:10:58 | I | collecting calibration activations in model.layers.0
24-11-25 16:10:58 | I | collecting calibration activations in model.layers.0
24-11-25 16:10:58 | I | collecting calibration activations in model.layers.0
24-11-25 16:10:58 | I | collecting calibration activations in model.layers.0
24-11-25 16:11:00 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 16:11:00 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 16:11:00 | I | - Evaluator: gptq
24-11-25 16:11:00 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 16:11:00 | I | - Batch_size: 8
24-11-25 16:11:00 | I |   + Max_seq_length: 2048
24-11-25 16:11:42 | I |     - Results:
24-11-25 16:11:42 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 16:11:42 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 16:11:42 | I |       |wikitext |      1|word_perplexity|7.7662|  |7.7662|
24-11-25 16:11:42 | I |       |val_valid|      1|word_perplexity|9.0498|  |9.0498|
24-11-25 16:11:42 | I |       
24-11-25 16:11:42 | I | forward this layer
24-11-25 16:11:42 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/38.pt
24-11-25 16:11:42 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/38.pt
24-11-25 16:11:42 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 16:11:42 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 16:11:42 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 16:11:42 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 16:11:42 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 16:11:42 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 16:11:42 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 16:11:42 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 16:11:42 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 16:11:42 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 16:11:42 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 16:11:42 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 16:11:42 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 16:11:42 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 16:11:42 | I | in layer model.layers.0
24-11-25 16:11:42 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 16:11:42 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 16:11:42 | I | - Evaluator: gptq
24-11-25 16:11:42 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 16:11:42 | I | - Batch_size: 8
24-11-25 16:11:42 | I |   + Max_seq_length: 2048
24-11-25 16:12:20 | I |     - Results:
24-11-25 16:12:20 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 16:12:20 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 16:12:20 | I |       |wikitext |      1|word_perplexity|7.7072|  |7.7072|
24-11-25 16:12:20 | I |       |val_valid|      1|word_perplexity|8.9787|  |8.9787|
24-11-25 16:12:20 | I |       
24-11-25 16:12:20 | I | quantizing weights for layer model.layers.0
24-11-25 16:12:20 | I | collecting info in model.layers.0
24-11-25 16:12:20 | I | collecting info in model.layers.0
24-11-25 16:12:20 | I | collecting info in model.layers.0
24-11-25 16:12:20 | I | collecting info in model.layers.0
24-11-25 16:12:21 | I | collecting calibration activations in model.layers.0
24-11-25 16:12:21 | I | collecting calibration activations in model.layers.0
24-11-25 16:12:21 | I | collecting calibration activations in model.layers.0
24-11-25 16:12:21 | I | collecting calibration activations in model.layers.0
24-11-25 16:12:21 | I | - Quantizing decoder layer model.layers.0
24-11-25 16:12:21 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 16:12:22 | I |       - range scale = [    1.0000]
24-11-25 16:12:22 | I |         sum  error  = [    0.0616]
24-11-25 16:12:22 | I |         best error  = [    0.0616]
24-11-25 16:12:22 | I |     + error = [0.0616]
24-11-25 16:12:23 | I |       - range scale = [    1.0000]
24-11-25 16:12:23 | I |         sum  error  = [    0.6114]
24-11-25 16:12:23 | I |         best error  = [    0.6114]
24-11-25 16:12:23 | I |     + error = [0.6114]
24-11-25 16:12:23 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 16:12:24 | I |       - range scale = [    1.0000]
24-11-25 16:12:24 | I |         sum  error  = [    0.0679]
24-11-25 16:12:24 | I |         best error  = [    0.0679]
24-11-25 16:12:24 | I |     + error = [0.0679]
24-11-25 16:12:24 | I |       - range scale = [    1.0000]
24-11-25 16:12:24 | I |         sum  error  = [    0.4964]
24-11-25 16:12:24 | I |         best error  = [    0.4964]
24-11-25 16:12:24 | I |     + error = [0.4964]
24-11-25 16:12:24 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 16:12:25 | I |       - range scale = [    1.0000]
24-11-25 16:12:25 | I |         sum  error  = [    0.2403]
24-11-25 16:12:25 | I |         best error  = [    0.2403]
24-11-25 16:12:25 | I |     + error = [0.2403]
24-11-25 16:12:26 | I |       - range scale = [    1.0000]
24-11-25 16:12:26 | I |         sum  error  = [    1.7630]
24-11-25 16:12:26 | I |         best error  = [    1.7630]
24-11-25 16:12:26 | I |     + error = [1.7630]
24-11-25 16:12:26 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 16:12:27 | I |       - range scale = [    1.0000]
24-11-25 16:12:27 | I |         sum  error  = [    0.0538]
24-11-25 16:12:27 | I |         best error  = [    0.0538]
24-11-25 16:12:27 | I |     + error = [0.0538]
24-11-25 16:12:27 | I |       - range scale = [    1.0000]
24-11-25 16:12:27 | I |         sum  error  = [    0.5219]
24-11-25 16:12:27 | I |         best error  = [    0.5219]
24-11-25 16:12:27 | I |     + error = [0.5219]
24-11-25 16:12:28 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 16:12:28 | I |       - range scale = [    1.0000]
24-11-25 16:12:28 | I |         sum  error  = [    1.0467]
24-11-25 16:12:28 | I |         best error  = [    1.0467]
24-11-25 16:12:28 | I |     + error = [1.0467]
24-11-25 16:12:29 | I |       - range scale = [    1.0000]
24-11-25 16:12:29 | I |         sum  error  = [   11.5957]
24-11-25 16:12:29 | I |         best error  = [   11.5957]
24-11-25 16:12:29 | I |     + error = [11.5957]
24-11-25 16:12:29 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 16:12:30 | I |       - range scale = [    1.0000]
24-11-25 16:12:30 | I |         sum  error  = [    1.2117]
24-11-25 16:12:30 | I |         best error  = [    1.2117]
24-11-25 16:12:30 | I |     + error = [1.2117]
24-11-25 16:12:31 | I |       - range scale = [    1.0000]
24-11-25 16:12:31 | I |         sum  error  = [   11.9554]
24-11-25 16:12:31 | I |         best error  = [   11.9554]
24-11-25 16:12:31 | I |     + error = [11.9554]
24-11-25 16:12:31 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 16:12:31 | I |       - range scale = [    1.0000]
24-11-25 16:12:31 | I |         sum  error  = [    2.7836]
24-11-25 16:12:31 | I |         best error  = [    2.7836]
24-11-25 16:12:31 | I |     + error = [2.7836]
24-11-25 16:12:32 | I |       - range scale = [    1.0000]
24-11-25 16:12:32 | I |         sum  error  = [   14.6479]
24-11-25 16:12:32 | I |         best error  = [   14.6479]
24-11-25 16:12:32 | I |     + error = [14.6479]
24-11-25 16:12:32 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 16:12:34 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 16:12:35 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 16:12:37 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 16:12:38 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 16:12:39 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 16:12:41 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 16:12:44 | I | quantizing activations for layer model.layers.0
24-11-25 16:12:44 | I | collecting info in model.layers.0
24-11-25 16:12:44 | I | collecting info in model.layers.0
24-11-25 16:12:44 | I | collecting info in model.layers.0
24-11-25 16:12:44 | I | collecting info in model.layers.0
24-11-25 16:12:44 | I | collecting calibration activations in model.layers.0
24-11-25 16:12:45 | I | collecting calibration activations in model.layers.0
24-11-25 16:12:45 | I | collecting calibration activations in model.layers.0
24-11-25 16:12:45 | I | collecting calibration activations in model.layers.0
24-11-25 16:12:47 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 16:12:47 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 16:12:47 | I | - Evaluator: gptq
24-11-25 16:12:47 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 16:12:47 | I | - Batch_size: 8
24-11-25 16:12:47 | I |   + Max_seq_length: 2048
24-11-25 16:13:28 | I |     - Results:
24-11-25 16:13:28 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 16:13:28 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 16:13:28 | I |       |wikitext |      1|word_perplexity|7.7799|  |7.7799|
24-11-25 16:13:28 | I |       |val_valid|      1|word_perplexity|9.0600|  |9.0600|
24-11-25 16:13:28 | I |       
24-11-25 16:13:28 | I | forward this layer
24-11-25 16:13:28 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/39.pt
24-11-25 16:13:28 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/39.pt
24-11-25 16:13:28 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 16:13:28 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 16:13:28 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 16:13:28 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 16:13:28 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 16:13:28 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 16:13:28 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 16:13:28 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 16:13:28 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 16:13:28 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 16:13:28 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 16:13:28 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 16:13:28 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 16:13:28 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 16:13:28 | I | [5] done with optimizer step
24-11-25 16:13:28 | I | epoch 001:     20 / 409600000 loss=0.0029036, loss_per_token=5.94656, loss_sum=194857, wps=153.7, ups=0, wpb=32768, bsz=64, num_updates=6, lr=1.8e-05, gnorm=208.474, clip=100, loss_scale=0.0078, train_wall=213, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=4539, lmquant_ppl_result_wikitext_in_train_no_quant=7.70717, lmquant_ppl_result_val_in_train_no_quant=8.97869, lmquant_ppl_result_wikitext_in_train_with_quant=7.77992, lmquant_ppl_result_val_in_train_with_quant=9.06003
24-11-25 16:13:29 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 16:13:29 | I | in layer model.layers.0
24-11-25 16:13:29 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 16:13:29 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 16:13:29 | I | - Evaluator: gptq
24-11-25 16:13:29 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 16:13:29 | I | - Batch_size: 8
24-11-25 16:13:29 | I |   + Max_seq_length: 2048
24-11-25 16:14:07 | I |     - Results:
24-11-25 16:14:07 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 16:14:07 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 16:14:07 | I |       |wikitext |      1|word_perplexity|7.7072|  |7.7072|
24-11-25 16:14:07 | I |       |val_valid|      1|word_perplexity|8.9783|  |8.9783|
24-11-25 16:14:07 | I |       
24-11-25 16:14:07 | I | quantizing weights for layer model.layers.0
24-11-25 16:14:07 | I | collecting info in model.layers.0
24-11-25 16:14:07 | I | collecting info in model.layers.0
24-11-25 16:14:07 | I | collecting info in model.layers.0
24-11-25 16:14:07 | I | collecting info in model.layers.0
24-11-25 16:14:07 | I | collecting calibration activations in model.layers.0
24-11-25 16:14:07 | I | collecting calibration activations in model.layers.0
24-11-25 16:14:08 | I | collecting calibration activations in model.layers.0
24-11-25 16:14:08 | I | collecting calibration activations in model.layers.0
24-11-25 16:14:08 | I | - Quantizing decoder layer model.layers.0
24-11-25 16:14:08 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 16:14:09 | I |       - range scale = [    1.0000]
24-11-25 16:14:09 | I |         sum  error  = [    0.0640]
24-11-25 16:14:09 | I |         best error  = [    0.0640]
24-11-25 16:14:09 | I |     + error = [0.0640]
24-11-25 16:14:09 | I |       - range scale = [    1.0000]
24-11-25 16:14:09 | I |         sum  error  = [    0.6167]
24-11-25 16:14:09 | I |         best error  = [    0.6167]
24-11-25 16:14:09 | I |     + error = [0.6167]
24-11-25 16:14:10 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 16:14:10 | I |       - range scale = [    1.0000]
24-11-25 16:14:10 | I |         sum  error  = [    0.0729]
24-11-25 16:14:10 | I |         best error  = [    0.0729]
24-11-25 16:14:10 | I |     + error = [0.0729]
24-11-25 16:14:11 | I |       - range scale = [    1.0000]
24-11-25 16:14:11 | I |         sum  error  = [    0.4974]
24-11-25 16:14:11 | I |         best error  = [    0.4974]
24-11-25 16:14:11 | I |     + error = [0.4974]
24-11-25 16:14:11 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 16:14:12 | I |       - range scale = [    1.0000]
24-11-25 16:14:12 | I |         sum  error  = [    0.2360]
24-11-25 16:14:12 | I |         best error  = [    0.2360]
24-11-25 16:14:12 | I |     + error = [0.2360]
24-11-25 16:14:12 | I |       - range scale = [    1.0000]
24-11-25 16:14:12 | I |         sum  error  = [    1.7666]
24-11-25 16:14:12 | I |         best error  = [    1.7666]
24-11-25 16:14:12 | I |     + error = [1.7666]
24-11-25 16:14:13 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 16:14:13 | I |       - range scale = [    1.0000]
24-11-25 16:14:13 | I |         sum  error  = [    0.0604]
24-11-25 16:14:13 | I |         best error  = [    0.0604]
24-11-25 16:14:13 | I |     + error = [0.0604]
24-11-25 16:14:14 | I |       - range scale = [    1.0000]
24-11-25 16:14:14 | I |         sum  error  = [    0.5897]
24-11-25 16:14:14 | I |         best error  = [    0.5897]
24-11-25 16:14:14 | I |     + error = [0.5897]
24-11-25 16:14:14 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 16:14:15 | I |       - range scale = [    1.0000]
24-11-25 16:14:15 | I |         sum  error  = [    1.1067]
24-11-25 16:14:15 | I |         best error  = [    1.1067]
24-11-25 16:14:15 | I |     + error = [1.1067]
24-11-25 16:14:16 | I |       - range scale = [    1.0000]
24-11-25 16:14:16 | I |         sum  error  = [   12.2591]
24-11-25 16:14:16 | I |         best error  = [   12.2591]
24-11-25 16:14:16 | I |     + error = [12.2591]
24-11-25 16:14:16 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 16:14:16 | I |       - range scale = [    1.0000]
24-11-25 16:14:16 | I |         sum  error  = [    1.2822]
24-11-25 16:14:16 | I |         best error  = [    1.2822]
24-11-25 16:14:16 | I |     + error = [1.2822]
24-11-25 16:14:17 | I |       - range scale = [    1.0000]
24-11-25 16:14:17 | I |         sum  error  = [   12.6856]
24-11-25 16:14:17 | I |         best error  = [   12.6856]
24-11-25 16:14:17 | I |     + error = [12.6856]
24-11-25 16:14:17 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 16:14:18 | I |       - range scale = [    1.0000]
24-11-25 16:14:18 | I |         sum  error  = [    3.4408]
24-11-25 16:14:18 | I |         best error  = [    3.4408]
24-11-25 16:14:18 | I |     + error = [3.4408]
24-11-25 16:14:19 | I |       - range scale = [    1.0000]
24-11-25 16:14:19 | I |         sum  error  = [   16.9000]
24-11-25 16:14:19 | I |         best error  = [   16.9000]
24-11-25 16:14:19 | I |     + error = [16.9000]
24-11-25 16:14:19 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 16:14:21 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 16:14:22 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 16:14:23 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 16:14:25 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 16:14:26 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 16:14:27 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 16:14:31 | I | quantizing activations for layer model.layers.0
24-11-25 16:14:31 | I | collecting info in model.layers.0
24-11-25 16:14:31 | I | collecting info in model.layers.0
24-11-25 16:14:31 | I | collecting info in model.layers.0
24-11-25 16:14:31 | I | collecting info in model.layers.0
24-11-25 16:14:31 | I | collecting calibration activations in model.layers.0
24-11-25 16:14:31 | I | collecting calibration activations in model.layers.0
24-11-25 16:14:31 | I | collecting calibration activations in model.layers.0
24-11-25 16:14:32 | I | collecting calibration activations in model.layers.0
24-11-25 16:14:33 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 16:14:33 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 16:14:33 | I | - Evaluator: gptq
24-11-25 16:14:33 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 16:14:33 | I | - Batch_size: 8
24-11-25 16:14:33 | I |   + Max_seq_length: 2048
24-11-25 16:15:15 | I |     - Results:
24-11-25 16:15:15 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 16:15:15 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 16:15:15 | I |       |wikitext |      1|word_perplexity|7.7674|  |7.7674|
24-11-25 16:15:15 | I |       |val_valid|      1|word_perplexity|9.0560|  |9.0560|
24-11-25 16:15:15 | I |       
24-11-25 16:15:15 | I | forward this layer
24-11-25 16:15:15 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/40.pt
24-11-25 16:15:15 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/40.pt
24-11-25 16:15:15 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 16:15:15 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 16:15:15 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 16:15:15 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 16:15:15 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 16:15:15 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 16:15:15 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 16:15:15 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 16:15:15 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 16:15:15 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 16:15:15 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 16:15:15 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 16:15:15 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 16:15:15 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 16:15:15 | I | in layer model.layers.0
24-11-25 16:15:15 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 16:15:15 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 16:15:15 | I | - Evaluator: gptq
24-11-25 16:15:15 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 16:15:15 | I | - Batch_size: 8
24-11-25 16:15:15 | I |   + Max_seq_length: 2048
24-11-25 16:15:53 | I |     - Results:
24-11-25 16:15:53 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 16:15:53 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 16:15:53 | I |       |wikitext |      1|word_perplexity|7.7072|  |7.7072|
24-11-25 16:15:53 | I |       |val_valid|      1|word_perplexity|8.9783|  |8.9783|
24-11-25 16:15:53 | I |       
24-11-25 16:15:53 | I | quantizing weights for layer model.layers.0
24-11-25 16:15:53 | I | collecting info in model.layers.0
24-11-25 16:15:53 | I | collecting info in model.layers.0
24-11-25 16:15:53 | I | collecting info in model.layers.0
24-11-25 16:15:53 | I | collecting info in model.layers.0
24-11-25 16:15:54 | I | collecting calibration activations in model.layers.0
24-11-25 16:15:54 | I | collecting calibration activations in model.layers.0
24-11-25 16:15:54 | I | collecting calibration activations in model.layers.0
24-11-25 16:15:54 | I | collecting calibration activations in model.layers.0
24-11-25 16:15:55 | I | - Quantizing decoder layer model.layers.0
24-11-25 16:15:55 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 16:15:55 | I |       - range scale = [    1.0000]
24-11-25 16:15:55 | I |         sum  error  = [    0.0636]
24-11-25 16:15:55 | I |         best error  = [    0.0636]
24-11-25 16:15:55 | I |     + error = [0.0636]
24-11-25 16:15:56 | I |       - range scale = [    1.0000]
24-11-25 16:15:56 | I |         sum  error  = [    0.5973]
24-11-25 16:15:56 | I |         best error  = [    0.5973]
24-11-25 16:15:56 | I |     + error = [0.5973]
24-11-25 16:15:56 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 16:15:57 | I |       - range scale = [    1.0000]
24-11-25 16:15:57 | I |         sum  error  = [    0.0700]
24-11-25 16:15:57 | I |         best error  = [    0.0700]
24-11-25 16:15:57 | I |     + error = [0.0700]
24-11-25 16:15:58 | I |       - range scale = [    1.0000]
24-11-25 16:15:58 | I |         sum  error  = [    0.4767]
24-11-25 16:15:58 | I |         best error  = [    0.4767]
24-11-25 16:15:58 | I |     + error = [0.4767]
24-11-25 16:15:58 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 16:15:58 | I |       - range scale = [    1.0000]
24-11-25 16:15:58 | I |         sum  error  = [    0.2383]
24-11-25 16:15:58 | I |         best error  = [    0.2383]
24-11-25 16:15:58 | I |     + error = [0.2383]
24-11-25 16:15:59 | I |       - range scale = [    1.0000]
24-11-25 16:15:59 | I |         sum  error  = [    1.7665]
24-11-25 16:15:59 | I |         best error  = [    1.7665]
24-11-25 16:15:59 | I |     + error = [1.7665]
24-11-25 16:15:59 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 16:16:00 | I |       - range scale = [    1.0000]
24-11-25 16:16:00 | I |         sum  error  = [    0.0585]
24-11-25 16:16:00 | I |         best error  = [    0.0585]
24-11-25 16:16:00 | I |     + error = [0.0585]
24-11-25 16:16:01 | I |       - range scale = [    1.0000]
24-11-25 16:16:01 | I |         sum  error  = [    0.5631]
24-11-25 16:16:01 | I |         best error  = [    0.5631]
24-11-25 16:16:01 | I |     + error = [0.5631]
24-11-25 16:16:01 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 16:16:02 | I |       - range scale = [    1.0000]
24-11-25 16:16:02 | I |         sum  error  = [    1.0499]
24-11-25 16:16:02 | I |         best error  = [    1.0499]
24-11-25 16:16:02 | I |     + error = [1.0499]
24-11-25 16:16:02 | I |       - range scale = [    1.0000]
24-11-25 16:16:02 | I |         sum  error  = [   11.6340]
24-11-25 16:16:02 | I |         best error  = [   11.6340]
24-11-25 16:16:02 | I |     + error = [11.6340]
24-11-25 16:16:03 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 16:16:03 | I |       - range scale = [    1.0000]
24-11-25 16:16:03 | I |         sum  error  = [    1.2152]
24-11-25 16:16:03 | I |         best error  = [    1.2152]
24-11-25 16:16:03 | I |     + error = [1.2152]
24-11-25 16:16:04 | I |       - range scale = [    1.0000]
24-11-25 16:16:04 | I |         sum  error  = [   12.0222]
24-11-25 16:16:04 | I |         best error  = [   12.0222]
24-11-25 16:16:04 | I |     + error = [12.0222]
24-11-25 16:16:04 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 16:16:05 | I |       - range scale = [    1.0000]
24-11-25 16:16:05 | I |         sum  error  = [    3.1663]
24-11-25 16:16:05 | I |         best error  = [    3.1663]
24-11-25 16:16:05 | I |     + error = [3.1663]
24-11-25 16:16:06 | I |       - range scale = [    1.0000]
24-11-25 16:16:06 | I |         sum  error  = [   16.0123]
24-11-25 16:16:06 | I |         best error  = [   16.0123]
24-11-25 16:16:06 | I |     + error = [16.0123]
24-11-25 16:16:06 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 16:16:07 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 16:16:09 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 16:16:10 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 16:16:12 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 16:16:13 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 16:16:14 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 16:16:18 | I | quantizing activations for layer model.layers.0
24-11-25 16:16:18 | I | collecting info in model.layers.0
24-11-25 16:16:18 | I | collecting info in model.layers.0
24-11-25 16:16:18 | I | collecting info in model.layers.0
24-11-25 16:16:18 | I | collecting info in model.layers.0
24-11-25 16:16:18 | I | collecting calibration activations in model.layers.0
24-11-25 16:16:18 | I | collecting calibration activations in model.layers.0
24-11-25 16:16:18 | I | collecting calibration activations in model.layers.0
24-11-25 16:16:18 | I | collecting calibration activations in model.layers.0
24-11-25 16:16:20 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 16:16:20 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 16:16:20 | I | - Evaluator: gptq
24-11-25 16:16:20 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 16:16:20 | I | - Batch_size: 8
24-11-25 16:16:20 | I |   + Max_seq_length: 2048
24-11-25 16:17:02 | I |     - Results:
24-11-25 16:17:02 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 16:17:02 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 16:17:02 | I |       |wikitext |      1|word_perplexity|7.7708|  |7.7708|
24-11-25 16:17:02 | I |       |val_valid|      1|word_perplexity|9.0591|  |9.0591|
24-11-25 16:17:02 | I |       
24-11-25 16:17:02 | I | forward this layer
24-11-25 16:17:02 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/41.pt
24-11-25 16:17:02 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/41.pt
24-11-25 16:17:02 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 16:17:02 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 16:17:02 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 16:17:02 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 16:17:02 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 16:17:02 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 16:17:02 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 16:17:02 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 16:17:02 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 16:17:02 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 16:17:02 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 16:17:02 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 16:17:02 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 16:17:02 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 16:17:02 | I | [6] done with optimizer step
24-11-25 16:17:02 | I | epoch 001:     21 / 409600000 loss=0.00265724, loss_per_token=5.44204, loss_sum=178325, wps=153.3, ups=0, wpb=32768, bsz=64, num_updates=7, lr=2.1e-05, gnorm=206.81, clip=100, loss_scale=0.0078, train_wall=214, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=4752, lmquant_ppl_result_wikitext_in_train_no_quant=7.70716, lmquant_ppl_result_val_in_train_no_quant=8.97833, lmquant_ppl_result_wikitext_in_train_with_quant=7.77084, lmquant_ppl_result_val_in_train_with_quant=9.05913
24-11-25 16:17:02 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 16:17:02 | I | in layer model.layers.0
24-11-25 16:17:02 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 16:17:02 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 16:17:02 | I | - Evaluator: gptq
24-11-25 16:17:02 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 16:17:02 | I | - Batch_size: 8
24-11-25 16:17:02 | I |   + Max_seq_length: 2048
24-11-25 16:17:41 | I |     - Results:
24-11-25 16:17:41 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 16:17:41 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 16:17:41 | I |       |wikitext |      1|word_perplexity|7.7074|  |7.7074|
24-11-25 16:17:41 | I |       |val_valid|      1|word_perplexity|8.9779|  |8.9779|
24-11-25 16:17:41 | I |       
24-11-25 16:17:41 | I | quantizing weights for layer model.layers.0
24-11-25 16:17:41 | I | collecting info in model.layers.0
24-11-25 16:17:41 | I | collecting info in model.layers.0
24-11-25 16:17:41 | I | collecting info in model.layers.0
24-11-25 16:17:41 | I | collecting info in model.layers.0
24-11-25 16:17:41 | I | collecting calibration activations in model.layers.0
24-11-25 16:17:41 | I | collecting calibration activations in model.layers.0
24-11-25 16:17:41 | I | collecting calibration activations in model.layers.0
24-11-25 16:17:42 | I | collecting calibration activations in model.layers.0
24-11-25 16:17:42 | I | - Quantizing decoder layer model.layers.0
24-11-25 16:17:42 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 16:17:43 | I |       - range scale = [    1.0000]
24-11-25 16:17:43 | I |         sum  error  = [    0.0622]
24-11-25 16:17:43 | I |         best error  = [    0.0622]
24-11-25 16:17:43 | I |     + error = [0.0622]
24-11-25 16:17:43 | I |       - range scale = [    1.0000]
24-11-25 16:17:43 | I |         sum  error  = [    0.6094]
24-11-25 16:17:43 | I |         best error  = [    0.6094]
24-11-25 16:17:43 | I |     + error = [0.6094]
24-11-25 16:17:44 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 16:17:44 | I |       - range scale = [    1.0000]
24-11-25 16:17:44 | I |         sum  error  = [    0.0722]
24-11-25 16:17:44 | I |         best error  = [    0.0722]
24-11-25 16:17:44 | I |     + error = [0.0722]
24-11-25 16:17:45 | I |       - range scale = [    1.0000]
24-11-25 16:17:45 | I |         sum  error  = [    0.4860]
24-11-25 16:17:45 | I |         best error  = [    0.4860]
24-11-25 16:17:45 | I |     + error = [0.4860]
24-11-25 16:17:45 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 16:17:46 | I |       - range scale = [    1.0000]
24-11-25 16:17:46 | I |         sum  error  = [    0.2408]
24-11-25 16:17:46 | I |         best error  = [    0.2408]
24-11-25 16:17:46 | I |     + error = [0.2408]
24-11-25 16:17:47 | I |       - range scale = [    1.0000]
24-11-25 16:17:47 | I |         sum  error  = [    1.7666]
24-11-25 16:17:47 | I |         best error  = [    1.7666]
24-11-25 16:17:47 | I |     + error = [1.7666]
24-11-25 16:17:47 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 16:17:47 | I |       - range scale = [    1.0000]
24-11-25 16:17:47 | I |         sum  error  = [    0.0595]
24-11-25 16:17:47 | I |         best error  = [    0.0595]
24-11-25 16:17:47 | I |     + error = [0.0595]
24-11-25 16:17:48 | I |       - range scale = [    1.0000]
24-11-25 16:17:48 | I |         sum  error  = [    0.5641]
24-11-25 16:17:48 | I |         best error  = [    0.5641]
24-11-25 16:17:48 | I |     + error = [0.5641]
24-11-25 16:17:48 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 16:17:49 | I |       - range scale = [    1.0000]
24-11-25 16:17:49 | I |         sum  error  = [    1.0451]
24-11-25 16:17:49 | I |         best error  = [    1.0451]
24-11-25 16:17:49 | I |     + error = [1.0451]
24-11-25 16:17:50 | I |       - range scale = [    1.0000]
24-11-25 16:17:50 | I |         sum  error  = [   11.5704]
24-11-25 16:17:50 | I |         best error  = [   11.5704]
24-11-25 16:17:50 | I |     + error = [11.5704]
24-11-25 16:17:50 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 16:17:51 | I |       - range scale = [    1.0000]
24-11-25 16:17:51 | I |         sum  error  = [    1.2088]
24-11-25 16:17:51 | I |         best error  = [    1.2088]
24-11-25 16:17:51 | I |     + error = [1.2088]
24-11-25 16:17:51 | I |       - range scale = [    1.0000]
24-11-25 16:17:51 | I |         sum  error  = [   11.9606]
24-11-25 16:17:51 | I |         best error  = [   11.9606]
24-11-25 16:17:51 | I |     + error = [11.9606]
24-11-25 16:17:52 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 16:17:52 | I |       - range scale = [    1.0000]
24-11-25 16:17:52 | I |         sum  error  = [    3.8988]
24-11-25 16:17:52 | I |         best error  = [    3.8988]
24-11-25 16:17:52 | I |     + error = [3.8988]
24-11-25 16:17:53 | I |       - range scale = [    1.0000]
24-11-25 16:17:53 | I |         sum  error  = [   19.3361]
24-11-25 16:17:53 | I |         best error  = [   19.3361]
24-11-25 16:17:53 | I |     + error = [19.3361]
24-11-25 16:17:53 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 16:17:55 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 16:17:56 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 16:17:57 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 16:17:59 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 16:18:00 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 16:18:02 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 16:18:05 | I | quantizing activations for layer model.layers.0
24-11-25 16:18:05 | I | collecting info in model.layers.0
24-11-25 16:18:05 | I | collecting info in model.layers.0
24-11-25 16:18:05 | I | collecting info in model.layers.0
24-11-25 16:18:05 | I | collecting info in model.layers.0
24-11-25 16:18:05 | I | collecting calibration activations in model.layers.0
24-11-25 16:18:06 | I | collecting calibration activations in model.layers.0
24-11-25 16:18:06 | I | collecting calibration activations in model.layers.0
24-11-25 16:18:06 | I | collecting calibration activations in model.layers.0
24-11-25 16:18:08 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 16:18:08 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 16:18:08 | I | - Evaluator: gptq
24-11-25 16:18:08 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 16:18:08 | I | - Batch_size: 8
24-11-25 16:18:08 | I |   + Max_seq_length: 2048
24-11-25 16:18:49 | I |     - Results:
24-11-25 16:18:49 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 16:18:49 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 16:18:49 | I |       |wikitext |      1|word_perplexity|7.7741|  |7.7741|
24-11-25 16:18:49 | I |       |val_valid|      1|word_perplexity|9.0650|  |9.0650|
24-11-25 16:18:49 | I |       
24-11-25 16:18:49 | I | forward this layer
24-11-25 16:18:49 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/42.pt
24-11-25 16:18:49 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/42.pt
24-11-25 16:18:49 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 16:18:49 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 16:18:49 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 16:18:49 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 16:18:49 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 16:18:49 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 16:18:49 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 16:18:49 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 16:18:49 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 16:18:49 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 16:18:49 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 16:18:49 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 16:18:49 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 16:18:49 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 16:18:49 | I | in layer model.layers.0
24-11-25 16:18:49 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 16:18:49 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 16:18:49 | I | - Evaluator: gptq
24-11-25 16:18:49 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 16:18:49 | I | - Batch_size: 8
24-11-25 16:18:49 | I |   + Max_seq_length: 2048
24-11-25 16:19:28 | I |     - Results:
24-11-25 16:19:28 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 16:19:28 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 16:19:28 | I |       |wikitext |      1|word_perplexity|7.7074|  |7.7074|
24-11-25 16:19:28 | I |       |val_valid|      1|word_perplexity|8.9779|  |8.9779|
24-11-25 16:19:28 | I |       
24-11-25 16:19:28 | I | quantizing weights for layer model.layers.0
24-11-25 16:19:28 | I | collecting info in model.layers.0
24-11-25 16:19:28 | I | collecting info in model.layers.0
24-11-25 16:19:28 | I | collecting info in model.layers.0
24-11-25 16:19:28 | I | collecting info in model.layers.0
24-11-25 16:19:28 | I | collecting calibration activations in model.layers.0
24-11-25 16:19:28 | I | collecting calibration activations in model.layers.0
24-11-25 16:19:28 | I | collecting calibration activations in model.layers.0
24-11-25 16:19:29 | I | collecting calibration activations in model.layers.0
24-11-25 16:19:29 | I | - Quantizing decoder layer model.layers.0
24-11-25 16:19:29 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 16:19:30 | I |       - range scale = [    1.0000]
24-11-25 16:19:30 | I |         sum  error  = [    0.0574]
24-11-25 16:19:30 | I |         best error  = [    0.0574]
24-11-25 16:19:30 | I |     + error = [0.0574]
24-11-25 16:19:30 | I |       - range scale = [    1.0000]
24-11-25 16:19:30 | I |         sum  error  = [    0.6038]
24-11-25 16:19:30 | I |         best error  = [    0.6038]
24-11-25 16:19:30 | I |     + error = [0.6038]
24-11-25 16:19:30 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 16:19:31 | I |       - range scale = [    1.0000]
24-11-25 16:19:31 | I |         sum  error  = [    0.0718]
24-11-25 16:19:31 | I |         best error  = [    0.0718]
24-11-25 16:19:31 | I |     + error = [0.0718]
24-11-25 16:19:32 | I |       - range scale = [    1.0000]
24-11-25 16:19:32 | I |         sum  error  = [    0.5052]
24-11-25 16:19:32 | I |         best error  = [    0.5052]
24-11-25 16:19:32 | I |     + error = [0.5052]
24-11-25 16:19:32 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 16:19:33 | I |       - range scale = [    1.0000]
24-11-25 16:19:33 | I |         sum  error  = [    0.2394]
24-11-25 16:19:33 | I |         best error  = [    0.2394]
24-11-25 16:19:33 | I |     + error = [0.2394]
24-11-25 16:19:33 | I |       - range scale = [    1.0000]
24-11-25 16:19:33 | I |         sum  error  = [    1.7729]
24-11-25 16:19:33 | I |         best error  = [    1.7729]
24-11-25 16:19:33 | I |     + error = [1.7729]
24-11-25 16:19:34 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 16:19:34 | I |       - range scale = [    1.0000]
24-11-25 16:19:34 | I |         sum  error  = [    0.0598]
24-11-25 16:19:34 | I |         best error  = [    0.0598]
24-11-25 16:19:34 | I |     + error = [0.0598]
24-11-25 16:19:35 | I |       - range scale = [    1.0000]
24-11-25 16:19:35 | I |         sum  error  = [    0.5854]
24-11-25 16:19:35 | I |         best error  = [    0.5854]
24-11-25 16:19:35 | I |     + error = [0.5854]
24-11-25 16:19:35 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 16:19:36 | I |       - range scale = [    1.0000]
24-11-25 16:19:36 | I |         sum  error  = [    1.0591]
24-11-25 16:19:36 | I |         best error  = [    1.0591]
24-11-25 16:19:36 | I |     + error = [1.0591]
24-11-25 16:19:37 | I |       - range scale = [    1.0000]
24-11-25 16:19:37 | I |         sum  error  = [   11.7233]
24-11-25 16:19:37 | I |         best error  = [   11.7233]
24-11-25 16:19:37 | I |     + error = [11.7233]
24-11-25 16:19:37 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 16:19:38 | I |       - range scale = [    1.0000]
24-11-25 16:19:38 | I |         sum  error  = [    1.2243]
24-11-25 16:19:38 | I |         best error  = [    1.2243]
24-11-25 16:19:38 | I |     + error = [1.2243]
24-11-25 16:19:38 | I |       - range scale = [    1.0000]
24-11-25 16:19:38 | I |         sum  error  = [   12.1030]
24-11-25 16:19:38 | I |         best error  = [   12.1030]
24-11-25 16:19:38 | I |     + error = [12.1030]
24-11-25 16:19:39 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 16:19:39 | I |       - range scale = [    1.0000]
24-11-25 16:19:39 | I |         sum  error  = [    2.6817]
24-11-25 16:19:39 | I |         best error  = [    2.6817]
24-11-25 16:19:39 | I |     + error = [2.6817]
24-11-25 16:19:40 | I |       - range scale = [    1.0000]
24-11-25 16:19:40 | I |         sum  error  = [   13.4752]
24-11-25 16:19:40 | I |         best error  = [   13.4752]
24-11-25 16:19:40 | I |     + error = [13.4752]
24-11-25 16:19:40 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 16:19:42 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 16:19:43 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 16:19:44 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 16:19:46 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 16:19:47 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 16:19:49 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 16:19:52 | I | quantizing activations for layer model.layers.0
24-11-25 16:19:52 | I | collecting info in model.layers.0
24-11-25 16:19:52 | I | collecting info in model.layers.0
24-11-25 16:19:52 | I | collecting info in model.layers.0
24-11-25 16:19:52 | I | collecting info in model.layers.0
24-11-25 16:19:52 | I | collecting calibration activations in model.layers.0
24-11-25 16:19:52 | I | collecting calibration activations in model.layers.0
24-11-25 16:19:53 | I | collecting calibration activations in model.layers.0
24-11-25 16:19:53 | I | collecting calibration activations in model.layers.0
24-11-25 16:19:55 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 16:19:55 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 16:19:55 | I | - Evaluator: gptq
24-11-25 16:19:55 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 16:19:55 | I | - Batch_size: 8
24-11-25 16:19:55 | I |   + Max_seq_length: 2048
24-11-25 16:20:36 | I |     - Results:
24-11-25 16:20:36 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 16:20:36 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 16:20:36 | I |       |wikitext |      1|word_perplexity|7.7674|  |7.7674|
24-11-25 16:20:36 | I |       |val_valid|      1|word_perplexity|9.0492|  |9.0492|
24-11-25 16:20:36 | I |       
24-11-25 16:20:36 | I | forward this layer
24-11-25 16:20:36 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/43.pt
24-11-25 16:20:36 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/43.pt
24-11-25 16:20:36 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 16:20:36 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 16:20:36 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 16:20:36 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 16:20:36 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 16:20:36 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 16:20:36 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 16:20:36 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 16:20:36 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 16:20:36 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 16:20:36 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 16:20:36 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 16:20:36 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 16:20:36 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 16:20:36 | I | [7] done with optimizer step
24-11-25 16:20:36 | I | epoch 001:     22 / 409600000 loss=0.00327179, loss_per_token=6.70063, loss_sum=219566, wps=152.9, ups=0, wpb=32768, bsz=64, num_updates=8, lr=2.4e-05, gnorm=366.648, clip=100, loss_scale=0.0078, train_wall=214, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=4967, lmquant_ppl_result_wikitext_in_train_no_quant=7.7074, lmquant_ppl_result_val_in_train_no_quant=8.9779, lmquant_ppl_result_wikitext_in_train_with_quant=7.76736, lmquant_ppl_result_val_in_train_with_quant=9.04922
24-11-25 16:20:37 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 16:20:37 | I | in layer model.layers.0
24-11-25 16:20:37 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 16:20:37 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 16:20:37 | I | - Evaluator: gptq
24-11-25 16:20:37 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 16:20:37 | I | - Batch_size: 8
24-11-25 16:20:37 | I |   + Max_seq_length: 2048
24-11-25 16:21:15 | I |     - Results:
24-11-25 16:21:15 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 16:21:15 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 16:21:15 | I |       |wikitext |      1|word_perplexity|7.7081|  |7.7081|
24-11-25 16:21:15 | I |       |val_valid|      1|word_perplexity|8.9777|  |8.9777|
24-11-25 16:21:15 | I |       
24-11-25 16:21:15 | I | quantizing weights for layer model.layers.0
24-11-25 16:21:15 | I | collecting info in model.layers.0
24-11-25 16:21:15 | I | collecting info in model.layers.0
24-11-25 16:21:15 | I | collecting info in model.layers.0
24-11-25 16:21:15 | I | collecting info in model.layers.0
24-11-25 16:21:16 | I | collecting calibration activations in model.layers.0
24-11-25 16:21:16 | I | collecting calibration activations in model.layers.0
24-11-25 16:21:16 | I | collecting calibration activations in model.layers.0
24-11-25 16:21:16 | I | collecting calibration activations in model.layers.0
24-11-25 16:21:16 | I | - Quantizing decoder layer model.layers.0
24-11-25 16:21:16 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 16:21:17 | I |       - range scale = [    1.0000]
24-11-25 16:21:17 | I |         sum  error  = [    0.0602]
24-11-25 16:21:17 | I |         best error  = [    0.0602]
24-11-25 16:21:17 | I |     + error = [0.0602]
24-11-25 16:21:18 | I |       - range scale = [    1.0000]
24-11-25 16:21:18 | I |         sum  error  = [    0.6013]
24-11-25 16:21:18 | I |         best error  = [    0.6013]
24-11-25 16:21:18 | I |     + error = [0.6013]
24-11-25 16:21:18 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 16:21:18 | I |       - range scale = [    1.0000]
24-11-25 16:21:18 | I |         sum  error  = [    0.0687]
24-11-25 16:21:18 | I |         best error  = [    0.0687]
24-11-25 16:21:18 | I |     + error = [0.0687]
24-11-25 16:21:19 | I |       - range scale = [    1.0000]
24-11-25 16:21:19 | I |         sum  error  = [    0.5021]
24-11-25 16:21:19 | I |         best error  = [    0.5021]
24-11-25 16:21:19 | I |     + error = [0.5021]
24-11-25 16:21:19 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 16:21:20 | I |       - range scale = [    1.0000]
24-11-25 16:21:20 | I |         sum  error  = [    0.2341]
24-11-25 16:21:20 | I |         best error  = [    0.2341]
24-11-25 16:21:20 | I |     + error = [0.2341]
24-11-25 16:21:21 | I |       - range scale = [    1.0000]
24-11-25 16:21:21 | I |         sum  error  = [    1.7494]
24-11-25 16:21:21 | I |         best error  = [    1.7494]
24-11-25 16:21:21 | I |     + error = [1.7494]
24-11-25 16:21:21 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 16:21:22 | I |       - range scale = [    1.0000]
24-11-25 16:21:22 | I |         sum  error  = [    0.0585]
24-11-25 16:21:22 | I |         best error  = [    0.0585]
24-11-25 16:21:22 | I |     + error = [0.0585]
24-11-25 16:21:22 | I |       - range scale = [    1.0000]
24-11-25 16:21:22 | I |         sum  error  = [    0.5646]
24-11-25 16:21:22 | I |         best error  = [    0.5646]
24-11-25 16:21:22 | I |     + error = [0.5646]
24-11-25 16:21:23 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 16:21:23 | I |       - range scale = [    1.0000]
24-11-25 16:21:23 | I |         sum  error  = [    1.0693]
24-11-25 16:21:23 | I |         best error  = [    1.0693]
24-11-25 16:21:23 | I |     + error = [1.0693]
24-11-25 16:21:24 | I |       - range scale = [    1.0000]
24-11-25 16:21:24 | I |         sum  error  = [   11.8448]
24-11-25 16:21:24 | I |         best error  = [   11.8448]
24-11-25 16:21:24 | I |     + error = [11.8448]
24-11-25 16:21:24 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 16:21:25 | I |       - range scale = [    1.0000]
24-11-25 16:21:25 | I |         sum  error  = [    1.2366]
24-11-25 16:21:25 | I |         best error  = [    1.2366]
24-11-25 16:21:25 | I |     + error = [1.2366]
24-11-25 16:21:26 | I |       - range scale = [    1.0000]
24-11-25 16:21:26 | I |         sum  error  = [   12.2383]
24-11-25 16:21:26 | I |         best error  = [   12.2383]
24-11-25 16:21:26 | I |     + error = [12.2383]
24-11-25 16:21:26 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 16:21:27 | I |       - range scale = [    1.0000]
24-11-25 16:21:27 | I |         sum  error  = [    3.6888]
24-11-25 16:21:27 | I |         best error  = [    3.6888]
24-11-25 16:21:27 | I |     + error = [3.6888]
24-11-25 16:21:27 | I |       - range scale = [    1.0000]
24-11-25 16:21:27 | I |         sum  error  = [   18.6920]
24-11-25 16:21:27 | I |         best error  = [   18.6920]
24-11-25 16:21:27 | I |     + error = [18.6920]
24-11-25 16:21:28 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 16:21:29 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 16:21:30 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 16:21:32 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 16:21:33 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 16:21:35 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 16:21:36 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 16:21:39 | I | quantizing activations for layer model.layers.0
24-11-25 16:21:39 | I | collecting info in model.layers.0
24-11-25 16:21:39 | I | collecting info in model.layers.0
24-11-25 16:21:39 | I | collecting info in model.layers.0
24-11-25 16:21:39 | I | collecting info in model.layers.0
24-11-25 16:21:40 | I | collecting calibration activations in model.layers.0
24-11-25 16:21:40 | I | collecting calibration activations in model.layers.0
24-11-25 16:21:40 | I | collecting calibration activations in model.layers.0
24-11-25 16:21:40 | I | collecting calibration activations in model.layers.0
24-11-25 16:21:42 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 16:21:42 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 16:21:42 | I | - Evaluator: gptq
24-11-25 16:21:42 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 16:21:42 | I | - Batch_size: 8
24-11-25 16:21:42 | I |   + Max_seq_length: 2048
24-11-25 16:22:23 | I |     - Results:
24-11-25 16:22:23 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 16:22:23 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 16:22:23 | I |       |wikitext |      1|word_perplexity|7.7671|  |7.7671|
24-11-25 16:22:23 | I |       |val_valid|      1|word_perplexity|9.0526|  |9.0526|
24-11-25 16:22:23 | I |       
24-11-25 16:22:23 | I | forward this layer
24-11-25 16:22:23 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/44.pt
24-11-25 16:22:23 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/44.pt
24-11-25 16:22:24 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 16:22:24 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 16:22:24 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 16:22:24 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 16:22:24 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 16:22:24 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 16:22:24 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 16:22:24 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 16:22:24 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 16:22:24 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 16:22:24 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 16:22:24 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 16:22:24 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 16:22:24 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 16:22:24 | I | in layer model.layers.0
24-11-25 16:22:24 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 16:22:24 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 16:22:24 | I | - Evaluator: gptq
24-11-25 16:22:24 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 16:22:24 | I | - Batch_size: 8
24-11-25 16:22:24 | I |   + Max_seq_length: 2048
24-11-25 16:23:02 | I |     - Results:
24-11-25 16:23:02 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 16:23:02 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 16:23:02 | I |       |wikitext |      1|word_perplexity|7.7081|  |7.7081|
24-11-25 16:23:02 | I |       |val_valid|      1|word_perplexity|8.9777|  |8.9777|
24-11-25 16:23:02 | I |       
24-11-25 16:23:02 | I | quantizing weights for layer model.layers.0
24-11-25 16:23:02 | I | collecting info in model.layers.0
24-11-25 16:23:02 | I | collecting info in model.layers.0
24-11-25 16:23:02 | I | collecting info in model.layers.0
24-11-25 16:23:02 | I | collecting info in model.layers.0
24-11-25 16:23:03 | I | collecting calibration activations in model.layers.0
24-11-25 16:23:03 | I | collecting calibration activations in model.layers.0
24-11-25 16:23:03 | I | collecting calibration activations in model.layers.0
24-11-25 16:23:03 | I | collecting calibration activations in model.layers.0
24-11-25 16:23:03 | I | - Quantizing decoder layer model.layers.0
24-11-25 16:23:03 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 16:23:04 | I |       - range scale = [    1.0000]
24-11-25 16:23:04 | I |         sum  error  = [    0.0641]
24-11-25 16:23:04 | I |         best error  = [    0.0641]
24-11-25 16:23:04 | I |     + error = [0.0641]
24-11-25 16:23:05 | I |       - range scale = [    1.0000]
24-11-25 16:23:05 | I |         sum  error  = [    0.6303]
24-11-25 16:23:05 | I |         best error  = [    0.6303]
24-11-25 16:23:05 | I |     + error = [0.6303]
24-11-25 16:23:05 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 16:23:06 | I |       - range scale = [    1.0000]
24-11-25 16:23:06 | I |         sum  error  = [    0.0743]
24-11-25 16:23:06 | I |         best error  = [    0.0743]
24-11-25 16:23:06 | I |     + error = [0.0743]
24-11-25 16:23:06 | I |       - range scale = [    1.0000]
24-11-25 16:23:06 | I |         sum  error  = [    0.5285]
24-11-25 16:23:06 | I |         best error  = [    0.5285]
24-11-25 16:23:06 | I |     + error = [0.5285]
24-11-25 16:23:07 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 16:23:07 | I |       - range scale = [    1.0000]
24-11-25 16:23:07 | I |         sum  error  = [    0.2376]
24-11-25 16:23:07 | I |         best error  = [    0.2376]
24-11-25 16:23:07 | I |     + error = [0.2376]
24-11-25 16:23:08 | I |       - range scale = [    1.0000]
24-11-25 16:23:08 | I |         sum  error  = [    1.7754]
24-11-25 16:23:08 | I |         best error  = [    1.7754]
24-11-25 16:23:08 | I |     + error = [1.7754]
24-11-25 16:23:08 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 16:23:09 | I |       - range scale = [    1.0000]
24-11-25 16:23:09 | I |         sum  error  = [    0.0627]
24-11-25 16:23:09 | I |         best error  = [    0.0627]
24-11-25 16:23:09 | I |     + error = [0.0627]
24-11-25 16:23:09 | I |       - range scale = [    1.0000]
24-11-25 16:23:09 | I |         sum  error  = [    0.6039]
24-11-25 16:23:09 | I |         best error  = [    0.6039]
24-11-25 16:23:09 | I |     + error = [0.6039]
24-11-25 16:23:10 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 16:23:10 | I |       - range scale = [    1.0000]
24-11-25 16:23:10 | I |         sum  error  = [    1.0968]
24-11-25 16:23:10 | I |         best error  = [    1.0968]
24-11-25 16:23:10 | I |     + error = [1.0968]
24-11-25 16:23:11 | I |       - range scale = [    1.0000]
24-11-25 16:23:11 | I |         sum  error  = [   12.1510]
24-11-25 16:23:11 | I |         best error  = [   12.1510]
24-11-25 16:23:11 | I |     + error = [12.1510]
24-11-25 16:23:11 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 16:23:12 | I |       - range scale = [    1.0000]
24-11-25 16:23:12 | I |         sum  error  = [    1.2675]
24-11-25 16:23:12 | I |         best error  = [    1.2675]
24-11-25 16:23:12 | I |     + error = [1.2675]
24-11-25 16:23:13 | I |       - range scale = [    1.0000]
24-11-25 16:23:13 | I |         sum  error  = [   12.5888]
24-11-25 16:23:13 | I |         best error  = [   12.5888]
24-11-25 16:23:13 | I |     + error = [12.5888]
24-11-25 16:23:13 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 16:23:14 | I |       - range scale = [    1.0000]
24-11-25 16:23:14 | I |         sum  error  = [    3.1640]
24-11-25 16:23:14 | I |         best error  = [    3.1640]
24-11-25 16:23:14 | I |     + error = [3.1640]
24-11-25 16:23:14 | I |       - range scale = [    1.0000]
24-11-25 16:23:14 | I |         sum  error  = [   15.9519]
24-11-25 16:23:14 | I |         best error  = [   15.9519]
24-11-25 16:23:14 | I |     + error = [15.9519]
24-11-25 16:23:15 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 16:23:16 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 16:23:18 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 16:23:20 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 16:23:21 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 16:23:23 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 16:23:25 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 16:23:29 | I | quantizing activations for layer model.layers.0
24-11-25 16:23:29 | I | collecting info in model.layers.0
24-11-25 16:23:29 | I | collecting info in model.layers.0
24-11-25 16:23:29 | I | collecting info in model.layers.0
24-11-25 16:23:29 | I | collecting info in model.layers.0
24-11-25 16:23:30 | I | collecting calibration activations in model.layers.0
24-11-25 16:23:30 | I | collecting calibration activations in model.layers.0
24-11-25 16:23:30 | I | collecting calibration activations in model.layers.0
24-11-25 16:23:30 | I | collecting calibration activations in model.layers.0
24-11-25 16:23:32 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 16:23:32 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 16:23:32 | I | - Evaluator: gptq
24-11-25 16:23:32 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 16:23:32 | I | - Batch_size: 8
24-11-25 16:23:32 | I |   + Max_seq_length: 2048
24-11-25 16:24:13 | I |     - Results:
24-11-25 16:24:14 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 16:24:14 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 16:24:14 | I |       |wikitext |      1|word_perplexity|7.7698|  |7.7698|
24-11-25 16:24:14 | I |       |val_valid|      1|word_perplexity|9.0594|  |9.0594|
24-11-25 16:24:14 | I |       
24-11-25 16:24:14 | I | forward this layer
24-11-25 16:24:14 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/45.pt
24-11-25 16:24:14 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/45.pt
24-11-25 16:24:14 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 16:24:14 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 16:24:14 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 16:24:14 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 16:24:14 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 16:24:14 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 16:24:14 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 16:24:14 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 16:24:14 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 16:24:14 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 16:24:14 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 16:24:14 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 16:24:14 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 16:24:14 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 16:24:14 | I | [8] done with optimizer step
24-11-25 16:24:14 | I | epoch 001:     23 / 409600000 loss=0.00196896, loss_per_token=4.03244, loss_sum=132135, wps=150.7, ups=0, wpb=32768, bsz=64, num_updates=9, lr=2.7e-05, gnorm=118.736, clip=100, loss_scale=0.0078, train_wall=217, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=5184, lmquant_ppl_result_wikitext_in_train_no_quant=7.70806, lmquant_ppl_result_val_in_train_no_quant=8.97774, lmquant_ppl_result_wikitext_in_train_with_quant=7.7698, lmquant_ppl_result_val_in_train_with_quant=9.0594
24-11-25 16:24:14 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 16:24:14 | I | in layer model.layers.0
24-11-25 16:24:14 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 16:24:14 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 16:24:14 | I | - Evaluator: gptq
24-11-25 16:24:14 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 16:24:14 | I | - Batch_size: 8
24-11-25 16:24:14 | I |   + Max_seq_length: 2048
24-11-25 16:24:52 | I |     - Results:
24-11-25 16:24:52 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 16:24:52 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 16:24:52 | I |       |wikitext |      1|word_perplexity|7.7093|  |7.7093|
24-11-25 16:24:52 | I |       |val_valid|      1|word_perplexity|8.9779|  |8.9779|
24-11-25 16:24:52 | I |       
24-11-25 16:24:52 | I | quantizing weights for layer model.layers.0
24-11-25 16:24:52 | I | collecting info in model.layers.0
24-11-25 16:24:52 | I | collecting info in model.layers.0
24-11-25 16:24:52 | I | collecting info in model.layers.0
24-11-25 16:24:52 | I | collecting info in model.layers.0
24-11-25 16:24:53 | I | collecting calibration activations in model.layers.0
24-11-25 16:24:53 | I | collecting calibration activations in model.layers.0
24-11-25 16:24:53 | I | collecting calibration activations in model.layers.0
24-11-25 16:24:53 | I | collecting calibration activations in model.layers.0
24-11-25 16:24:54 | I | - Quantizing decoder layer model.layers.0
24-11-25 16:24:54 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 16:24:54 | I |       - range scale = [    1.0000]
24-11-25 16:24:54 | I |         sum  error  = [    0.0653]
24-11-25 16:24:54 | I |         best error  = [    0.0653]
24-11-25 16:24:54 | I |     + error = [0.0653]
24-11-25 16:24:55 | I |       - range scale = [    1.0000]
24-11-25 16:24:55 | I |         sum  error  = [    0.5923]
24-11-25 16:24:55 | I |         best error  = [    0.5923]
24-11-25 16:24:55 | I |     + error = [0.5923]
24-11-25 16:24:55 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 16:24:56 | I |       - range scale = [    1.0000]
24-11-25 16:24:56 | I |         sum  error  = [    0.0689]
24-11-25 16:24:56 | I |         best error  = [    0.0689]
24-11-25 16:24:56 | I |     + error = [0.0689]
24-11-25 16:24:57 | I |       - range scale = [    1.0000]
24-11-25 16:24:57 | I |         sum  error  = [    0.4772]
24-11-25 16:24:57 | I |         best error  = [    0.4772]
24-11-25 16:24:57 | I |     + error = [0.4772]
24-11-25 16:24:57 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 16:24:57 | I |       - range scale = [    1.0000]
24-11-25 16:24:57 | I |         sum  error  = [    0.2412]
24-11-25 16:24:57 | I |         best error  = [    0.2412]
24-11-25 16:24:57 | I |     + error = [0.2412]
24-11-25 16:24:58 | I |       - range scale = [    1.0000]
24-11-25 16:24:58 | I |         sum  error  = [    1.7867]
24-11-25 16:24:58 | I |         best error  = [    1.7867]
24-11-25 16:24:58 | I |     + error = [1.7867]
24-11-25 16:24:58 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 16:24:59 | I |       - range scale = [    1.0000]
24-11-25 16:24:59 | I |         sum  error  = [    0.0618]
24-11-25 16:24:59 | I |         best error  = [    0.0618]
24-11-25 16:24:59 | I |     + error = [0.0618]
24-11-25 16:25:00 | I |       - range scale = [    1.0000]
24-11-25 16:25:00 | I |         sum  error  = [    0.5917]
24-11-25 16:25:00 | I |         best error  = [    0.5917]
24-11-25 16:25:00 | I |     + error = [0.5917]
24-11-25 16:25:00 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 16:25:01 | I |       - range scale = [    1.0000]
24-11-25 16:25:01 | I |         sum  error  = [    1.0335]
24-11-25 16:25:01 | I |         best error  = [    1.0335]
24-11-25 16:25:01 | I |     + error = [1.0335]
24-11-25 16:25:01 | I |       - range scale = [    1.0000]
24-11-25 16:25:01 | I |         sum  error  = [   11.4447]
24-11-25 16:25:01 | I |         best error  = [   11.4447]
24-11-25 16:25:01 | I |     + error = [11.4447]
24-11-25 16:25:02 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 16:25:02 | I |       - range scale = [    1.0000]
24-11-25 16:25:02 | I |         sum  error  = [    1.1922]
24-11-25 16:25:02 | I |         best error  = [    1.1922]
24-11-25 16:25:02 | I |     + error = [1.1922]
24-11-25 16:25:03 | I |       - range scale = [    1.0000]
24-11-25 16:25:03 | I |         sum  error  = [   11.8338]
24-11-25 16:25:03 | I |         best error  = [   11.8338]
24-11-25 16:25:03 | I |     + error = [11.8338]
24-11-25 16:25:03 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 16:25:04 | I |       - range scale = [    1.0000]
24-11-25 16:25:04 | I |         sum  error  = [    3.2053]
24-11-25 16:25:04 | I |         best error  = [    3.2053]
24-11-25 16:25:04 | I |     + error = [3.2053]
24-11-25 16:25:05 | I |       - range scale = [    1.0000]
24-11-25 16:25:05 | I |         sum  error  = [   16.3908]
24-11-25 16:25:05 | I |         best error  = [   16.3908]
24-11-25 16:25:05 | I |     + error = [16.3908]
24-11-25 16:25:05 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 16:25:06 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 16:25:08 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 16:25:09 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 16:25:10 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 16:25:12 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 16:25:13 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 16:25:16 | I | quantizing activations for layer model.layers.0
24-11-25 16:25:16 | I | collecting info in model.layers.0
24-11-25 16:25:16 | I | collecting info in model.layers.0
24-11-25 16:25:16 | I | collecting info in model.layers.0
24-11-25 16:25:16 | I | collecting info in model.layers.0
24-11-25 16:25:17 | I | collecting calibration activations in model.layers.0
24-11-25 16:25:17 | I | collecting calibration activations in model.layers.0
24-11-25 16:25:17 | I | collecting calibration activations in model.layers.0
24-11-25 16:25:17 | I | collecting calibration activations in model.layers.0
24-11-25 16:25:19 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 16:25:19 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 16:25:19 | I | - Evaluator: gptq
24-11-25 16:25:19 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 16:25:19 | I | - Batch_size: 8
24-11-25 16:25:19 | I |   + Max_seq_length: 2048
24-11-25 16:26:01 | I |     - Results:
24-11-25 16:26:01 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 16:26:01 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 16:26:01 | I |       |wikitext |      1|word_perplexity|7.8016|  |7.8016|
24-11-25 16:26:01 | I |       |val_valid|      1|word_perplexity|9.0533|  |9.0533|
24-11-25 16:26:01 | I |       
24-11-25 16:26:01 | I | forward this layer
24-11-25 16:26:01 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/46.pt
24-11-25 16:26:01 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/46.pt
24-11-25 16:26:01 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 16:26:01 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 16:26:01 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 16:26:01 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 16:26:01 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 16:26:01 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 16:26:01 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 16:26:01 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 16:26:01 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 16:26:01 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 16:26:01 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 16:26:01 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 16:26:01 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 16:26:01 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 16:26:01 | I | in layer model.layers.0
24-11-25 16:26:01 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 16:26:01 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 16:26:01 | I | - Evaluator: gptq
24-11-25 16:26:01 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 16:26:01 | I | - Batch_size: 8
24-11-25 16:26:01 | I |   + Max_seq_length: 2048
24-11-25 16:26:39 | I |     - Results:
24-11-25 16:26:39 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 16:26:39 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 16:26:39 | I |       |wikitext |      1|word_perplexity|7.7093|  |7.7093|
24-11-25 16:26:39 | I |       |val_valid|      1|word_perplexity|8.9779|  |8.9779|
24-11-25 16:26:39 | I |       
24-11-25 16:26:39 | I | quantizing weights for layer model.layers.0
24-11-25 16:26:39 | I | collecting info in model.layers.0
24-11-25 16:26:39 | I | collecting info in model.layers.0
24-11-25 16:26:39 | I | collecting info in model.layers.0
24-11-25 16:26:39 | I | collecting info in model.layers.0
24-11-25 16:26:40 | I | collecting calibration activations in model.layers.0
24-11-25 16:26:40 | I | collecting calibration activations in model.layers.0
24-11-25 16:26:40 | I | collecting calibration activations in model.layers.0
24-11-25 16:26:40 | I | collecting calibration activations in model.layers.0
24-11-25 16:26:40 | I | - Quantizing decoder layer model.layers.0
24-11-25 16:26:40 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 16:26:41 | I |       - range scale = [    1.0000]
24-11-25 16:26:41 | I |         sum  error  = [    0.0654]
24-11-25 16:26:41 | I |         best error  = [    0.0654]
24-11-25 16:26:41 | I |     + error = [0.0654]
24-11-25 16:26:42 | I |       - range scale = [    1.0000]
24-11-25 16:26:42 | I |         sum  error  = [    0.6032]
24-11-25 16:26:42 | I |         best error  = [    0.6032]
24-11-25 16:26:42 | I |     + error = [0.6032]
24-11-25 16:26:42 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 16:26:43 | I |       - range scale = [    1.0000]
24-11-25 16:26:43 | I |         sum  error  = [    0.0795]
24-11-25 16:26:43 | I |         best error  = [    0.0795]
24-11-25 16:26:43 | I |     + error = [0.0795]
24-11-25 16:26:43 | I |       - range scale = [    1.0000]
24-11-25 16:26:43 | I |         sum  error  = [    0.5385]
24-11-25 16:26:43 | I |         best error  = [    0.5385]
24-11-25 16:26:43 | I |     + error = [0.5385]
24-11-25 16:26:44 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 16:26:44 | I |       - range scale = [    1.0000]
24-11-25 16:26:44 | I |         sum  error  = [    0.2385]
24-11-25 16:26:44 | I |         best error  = [    0.2385]
24-11-25 16:26:44 | I |     + error = [0.2385]
24-11-25 16:26:45 | I |       - range scale = [    1.0000]
24-11-25 16:26:45 | I |         sum  error  = [    1.7737]
24-11-25 16:26:45 | I |         best error  = [    1.7737]
24-11-25 16:26:45 | I |     + error = [1.7737]
24-11-25 16:26:45 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 16:26:46 | I |       - range scale = [    1.0000]
24-11-25 16:26:46 | I |         sum  error  = [    0.0625]
24-11-25 16:26:46 | I |         best error  = [    0.0625]
24-11-25 16:26:46 | I |     + error = [0.0625]
24-11-25 16:26:46 | I |       - range scale = [    1.0000]
24-11-25 16:26:46 | I |         sum  error  = [    0.6033]
24-11-25 16:26:46 | I |         best error  = [    0.6033]
24-11-25 16:26:46 | I |     + error = [0.6033]
24-11-25 16:26:47 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 16:26:47 | I |       - range scale = [    1.0000]
24-11-25 16:26:47 | I |         sum  error  = [    1.0950]
24-11-25 16:26:47 | I |         best error  = [    1.0950]
24-11-25 16:26:47 | I |     + error = [1.0950]
24-11-25 16:26:48 | I |       - range scale = [    1.0000]
24-11-25 16:26:48 | I |         sum  error  = [   12.1273]
24-11-25 16:26:48 | I |         best error  = [   12.1273]
24-11-25 16:26:48 | I |     + error = [12.1273]
24-11-25 16:26:48 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 16:26:49 | I |       - range scale = [    1.0000]
24-11-25 16:26:49 | I |         sum  error  = [    1.2648]
24-11-25 16:26:49 | I |         best error  = [    1.2648]
24-11-25 16:26:49 | I |     + error = [1.2648]
24-11-25 16:26:50 | I |       - range scale = [    1.0000]
24-11-25 16:26:50 | I |         sum  error  = [   12.5541]
24-11-25 16:26:50 | I |         best error  = [   12.5541]
24-11-25 16:26:50 | I |     + error = [12.5541]
24-11-25 16:26:50 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 16:26:51 | I |       - range scale = [    1.0000]
24-11-25 16:26:51 | I |         sum  error  = [    3.1560]
24-11-25 16:26:51 | I |         best error  = [    3.1560]
24-11-25 16:26:51 | I |     + error = [3.1560]
24-11-25 16:26:51 | I |       - range scale = [    1.0000]
24-11-25 16:26:51 | I |         sum  error  = [   15.6781]
24-11-25 16:26:51 | I |         best error  = [   15.6781]
24-11-25 16:26:51 | I |     + error = [15.6781]
24-11-25 16:26:52 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 16:26:53 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 16:26:54 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 16:26:56 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 16:26:57 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 16:26:58 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 16:27:00 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 16:27:03 | I | quantizing activations for layer model.layers.0
24-11-25 16:27:03 | I | collecting info in model.layers.0
24-11-25 16:27:03 | I | collecting info in model.layers.0
24-11-25 16:27:03 | I | collecting info in model.layers.0
24-11-25 16:27:03 | I | collecting info in model.layers.0
24-11-25 16:27:04 | I | collecting calibration activations in model.layers.0
24-11-25 16:27:04 | I | collecting calibration activations in model.layers.0
24-11-25 16:27:04 | I | collecting calibration activations in model.layers.0
24-11-25 16:27:04 | I | collecting calibration activations in model.layers.0
24-11-25 16:27:06 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 16:27:06 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 16:27:06 | I | - Evaluator: gptq
24-11-25 16:27:06 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 16:27:06 | I | - Batch_size: 8
24-11-25 16:27:06 | I |   + Max_seq_length: 2048
24-11-25 16:27:47 | I |     - Results:
24-11-25 16:27:47 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 16:27:47 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 16:27:47 | I |       |wikitext |      1|word_perplexity|7.7684|  |7.7684|
24-11-25 16:27:47 | I |       |val_valid|      1|word_perplexity|9.0627|  |9.0627|
24-11-25 16:27:47 | I |       
24-11-25 16:27:47 | I | forward this layer
24-11-25 16:27:47 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/47.pt
24-11-25 16:27:47 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/47.pt
24-11-25 16:27:48 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 16:27:48 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 16:27:48 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 16:27:48 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 16:27:48 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 16:27:48 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 16:27:48 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 16:27:48 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 16:27:48 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 16:27:48 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 16:27:48 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 16:27:48 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 16:27:48 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 16:27:48 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 16:27:48 | I | [9] done with optimizer step
24-11-25 16:27:48 | I | epoch 001:     24 / 409600000 loss=0.00166475, loss_per_token=3.4094, loss_sum=111719, wps=153.3, ups=0, wpb=32768, bsz=64, num_updates=10, lr=3e-05, gnorm=158.44, clip=100, loss_scale=0.0078, train_wall=214, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=5398, lmquant_ppl_result_wikitext_in_train_no_quant=7.70928, lmquant_ppl_result_val_in_train_no_quant=8.97789, lmquant_ppl_result_wikitext_in_train_with_quant=7.76839, lmquant_ppl_result_val_in_train_with_quant=9.0627
24-11-25 16:27:48 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 16:27:48 | I | in layer model.layers.0
24-11-25 16:27:48 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 16:27:48 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 16:27:48 | I | - Evaluator: gptq
24-11-25 16:27:48 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 16:27:48 | I | - Batch_size: 8
24-11-25 16:27:48 | I |   + Max_seq_length: 2048
24-11-25 16:28:26 | I |     - Results:
24-11-25 16:28:26 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 16:28:26 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 16:28:26 | I |       |wikitext |      1|word_perplexity|7.7111|  |7.7111|
24-11-25 16:28:26 | I |       |val_valid|      1|word_perplexity|8.9784|  |8.9784|
24-11-25 16:28:26 | I |       
24-11-25 16:28:26 | I | quantizing weights for layer model.layers.0
24-11-25 16:28:26 | I | collecting info in model.layers.0
24-11-25 16:28:26 | I | collecting info in model.layers.0
24-11-25 16:28:26 | I | collecting info in model.layers.0
24-11-25 16:28:26 | I | collecting info in model.layers.0
24-11-25 16:28:27 | I | collecting calibration activations in model.layers.0
24-11-25 16:28:27 | I | collecting calibration activations in model.layers.0
24-11-25 16:28:27 | I | collecting calibration activations in model.layers.0
24-11-25 16:28:27 | I | collecting calibration activations in model.layers.0
24-11-25 16:28:27 | I | - Quantizing decoder layer model.layers.0
24-11-25 16:28:27 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 16:28:28 | I |       - range scale = [    1.0000]
24-11-25 16:28:28 | I |         sum  error  = [    0.0704]
24-11-25 16:28:28 | I |         best error  = [    0.0704]
24-11-25 16:28:28 | I |     + error = [0.0704]
24-11-25 16:28:29 | I |       - range scale = [    1.0000]
24-11-25 16:28:29 | I |         sum  error  = [    0.6220]
24-11-25 16:28:29 | I |         best error  = [    0.6220]
24-11-25 16:28:29 | I |     + error = [0.6220]
24-11-25 16:28:29 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 16:28:30 | I |       - range scale = [    1.0000]
24-11-25 16:28:30 | I |         sum  error  = [    0.0760]
24-11-25 16:28:30 | I |         best error  = [    0.0760]
24-11-25 16:28:30 | I |     + error = [0.0760]
24-11-25 16:28:30 | I |       - range scale = [    1.0000]
24-11-25 16:28:30 | I |         sum  error  = [    0.5404]
24-11-25 16:28:30 | I |         best error  = [    0.5404]
24-11-25 16:28:30 | I |     + error = [0.5404]
24-11-25 16:28:31 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 16:28:31 | I |       - range scale = [    1.0000]
24-11-25 16:28:31 | I |         sum  error  = [    0.2387]
24-11-25 16:28:31 | I |         best error  = [    0.2387]
24-11-25 16:28:31 | I |     + error = [0.2387]
24-11-25 16:28:32 | I |       - range scale = [    1.0000]
24-11-25 16:28:32 | I |         sum  error  = [    1.7790]
24-11-25 16:28:32 | I |         best error  = [    1.7790]
24-11-25 16:28:32 | I |     + error = [1.7790]
24-11-25 16:28:32 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 16:28:33 | I |       - range scale = [    1.0000]
24-11-25 16:28:33 | I |         sum  error  = [    0.0627]
24-11-25 16:28:33 | I |         best error  = [    0.0627]
24-11-25 16:28:33 | I |     + error = [0.0627]
24-11-25 16:28:33 | I |       - range scale = [    1.0000]
24-11-25 16:28:33 | I |         sum  error  = [    0.6082]
24-11-25 16:28:33 | I |         best error  = [    0.6082]
24-11-25 16:28:33 | I |     + error = [0.6082]
24-11-25 16:28:34 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 16:28:34 | I |       - range scale = [    1.0000]
24-11-25 16:28:34 | I |         sum  error  = [    1.1048]
24-11-25 16:28:34 | I |         best error  = [    1.1048]
24-11-25 16:28:34 | I |     + error = [1.1048]
24-11-25 16:28:35 | I |       - range scale = [    1.0000]
24-11-25 16:28:35 | I |         sum  error  = [   12.2581]
24-11-25 16:28:35 | I |         best error  = [   12.2581]
24-11-25 16:28:35 | I |     + error = [12.2581]
24-11-25 16:28:35 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 16:28:36 | I |       - range scale = [    1.0000]
24-11-25 16:28:36 | I |         sum  error  = [    1.2757]
24-11-25 16:28:36 | I |         best error  = [    1.2757]
24-11-25 16:28:36 | I |     + error = [1.2757]
24-11-25 16:28:37 | I |       - range scale = [    1.0000]
24-11-25 16:28:37 | I |         sum  error  = [   12.6827]
24-11-25 16:28:37 | I |         best error  = [   12.6827]
24-11-25 16:28:37 | I |     + error = [12.6827]
24-11-25 16:28:37 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 16:28:38 | I |       - range scale = [    1.0000]
24-11-25 16:28:38 | I |         sum  error  = [    3.5060]
24-11-25 16:28:38 | I |         best error  = [    3.5060]
24-11-25 16:28:38 | I |     + error = [3.5060]
24-11-25 16:28:38 | I |       - range scale = [    1.0000]
24-11-25 16:28:38 | I |         sum  error  = [   17.4115]
24-11-25 16:28:38 | I |         best error  = [   17.4115]
24-11-25 16:28:38 | I |     + error = [17.4115]
24-11-25 16:28:39 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 16:28:40 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 16:28:41 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 16:28:43 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 16:28:44 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 16:28:46 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 16:28:47 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 16:28:50 | I | quantizing activations for layer model.layers.0
24-11-25 16:28:50 | I | collecting info in model.layers.0
24-11-25 16:28:50 | I | collecting info in model.layers.0
24-11-25 16:28:50 | I | collecting info in model.layers.0
24-11-25 16:28:50 | I | collecting info in model.layers.0
24-11-25 16:28:51 | I | collecting calibration activations in model.layers.0
24-11-25 16:28:51 | I | collecting calibration activations in model.layers.0
24-11-25 16:28:51 | I | collecting calibration activations in model.layers.0
24-11-25 16:28:51 | I | collecting calibration activations in model.layers.0
24-11-25 16:28:53 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 16:28:53 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 16:28:53 | I | - Evaluator: gptq
24-11-25 16:28:53 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 16:28:53 | I | - Batch_size: 8
24-11-25 16:28:53 | I |   + Max_seq_length: 2048
24-11-25 16:29:34 | I |     - Results:
24-11-25 16:29:34 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 16:29:34 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 16:29:34 | I |       |wikitext |      1|word_perplexity|7.7716|  |7.7716|
24-11-25 16:29:34 | I |       |val_valid|      1|word_perplexity|9.0554|  |9.0554|
24-11-25 16:29:34 | I |       
24-11-25 16:29:34 | I | forward this layer
24-11-25 16:29:34 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/48.pt
24-11-25 16:29:34 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/48.pt
24-11-25 16:29:35 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 16:29:35 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 16:29:35 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 16:29:35 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 16:29:35 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 16:29:35 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 16:29:35 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 16:29:35 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 16:29:35 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 16:29:35 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 16:29:35 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 16:29:35 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 16:29:35 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 16:29:35 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 16:29:35 | I | in layer model.layers.0
24-11-25 16:29:35 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 16:29:35 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 16:29:35 | I | - Evaluator: gptq
24-11-25 16:29:35 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 16:29:35 | I | - Batch_size: 8
24-11-25 16:29:35 | I |   + Max_seq_length: 2048
24-11-25 16:30:13 | I |     - Results:
24-11-25 16:30:13 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 16:30:13 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 16:30:13 | I |       |wikitext |      1|word_perplexity|7.7111|  |7.7111|
24-11-25 16:30:13 | I |       |val_valid|      1|word_perplexity|8.9784|  |8.9784|
24-11-25 16:30:13 | I |       
24-11-25 16:30:13 | I | quantizing weights for layer model.layers.0
24-11-25 16:30:13 | I | collecting info in model.layers.0
24-11-25 16:30:13 | I | collecting info in model.layers.0
24-11-25 16:30:13 | I | collecting info in model.layers.0
24-11-25 16:30:13 | I | collecting info in model.layers.0
24-11-25 16:30:14 | I | collecting calibration activations in model.layers.0
24-11-25 16:30:14 | I | collecting calibration activations in model.layers.0
24-11-25 16:30:14 | I | collecting calibration activations in model.layers.0
24-11-25 16:30:14 | I | collecting calibration activations in model.layers.0
24-11-25 16:30:14 | I | - Quantizing decoder layer model.layers.0
24-11-25 16:30:14 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 16:30:15 | I |       - range scale = [    1.0000]
24-11-25 16:30:15 | I |         sum  error  = [    0.0711]
24-11-25 16:30:15 | I |         best error  = [    0.0711]
24-11-25 16:30:15 | I |     + error = [0.0711]
24-11-25 16:30:16 | I |       - range scale = [    1.0000]
24-11-25 16:30:16 | I |         sum  error  = [    0.6643]
24-11-25 16:30:16 | I |         best error  = [    0.6643]
24-11-25 16:30:16 | I |     + error = [0.6643]
24-11-25 16:30:16 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 16:30:16 | I |       - range scale = [    1.0000]
24-11-25 16:30:16 | I |         sum  error  = [    0.0720]
24-11-25 16:30:16 | I |         best error  = [    0.0720]
24-11-25 16:30:16 | I |     + error = [0.0720]
24-11-25 16:30:17 | I |       - range scale = [    1.0000]
24-11-25 16:30:17 | I |         sum  error  = [    0.5044]
24-11-25 16:30:17 | I |         best error  = [    0.5044]
24-11-25 16:30:17 | I |     + error = [0.5044]
24-11-25 16:30:17 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 16:30:18 | I |       - range scale = [    1.0000]
24-11-25 16:30:18 | I |         sum  error  = [    0.2449]
24-11-25 16:30:18 | I |         best error  = [    0.2449]
24-11-25 16:30:18 | I |     + error = [0.2449]
24-11-25 16:30:19 | I |       - range scale = [    1.0000]
24-11-25 16:30:19 | I |         sum  error  = [    1.7940]
24-11-25 16:30:19 | I |         best error  = [    1.7940]
24-11-25 16:30:19 | I |     + error = [1.7940]
24-11-25 16:30:19 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 16:30:20 | I |       - range scale = [    1.0000]
24-11-25 16:30:20 | I |         sum  error  = [    0.0655]
24-11-25 16:30:20 | I |         best error  = [    0.0655]
24-11-25 16:30:20 | I |     + error = [0.0655]
24-11-25 16:30:20 | I |       - range scale = [    1.0000]
24-11-25 16:30:20 | I |         sum  error  = [    0.6261]
24-11-25 16:30:20 | I |         best error  = [    0.6261]
24-11-25 16:30:20 | I |     + error = [0.6261]
24-11-25 16:30:21 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 16:30:21 | I |       - range scale = [    1.0000]
24-11-25 16:30:21 | I |         sum  error  = [    1.0750]
24-11-25 16:30:21 | I |         best error  = [    1.0750]
24-11-25 16:30:21 | I |     + error = [1.0750]
24-11-25 16:30:22 | I |       - range scale = [    1.0000]
24-11-25 16:30:22 | I |         sum  error  = [   11.9192]
24-11-25 16:30:22 | I |         best error  = [   11.9192]
24-11-25 16:30:22 | I |     + error = [11.9192]
24-11-25 16:30:22 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 16:30:23 | I |       - range scale = [    1.0000]
24-11-25 16:30:23 | I |         sum  error  = [    1.2418]
24-11-25 16:30:23 | I |         best error  = [    1.2418]
24-11-25 16:30:23 | I |     + error = [1.2418]
24-11-25 16:30:24 | I |       - range scale = [    1.0000]
24-11-25 16:30:24 | I |         sum  error  = [   12.3373]
24-11-25 16:30:24 | I |         best error  = [   12.3373]
24-11-25 16:30:24 | I |     + error = [12.3373]
24-11-25 16:30:24 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 16:30:25 | I |       - range scale = [    1.0000]
24-11-25 16:30:25 | I |         sum  error  = [    3.0252]
24-11-25 16:30:25 | I |         best error  = [    3.0252]
24-11-25 16:30:25 | I |     + error = [3.0252]
24-11-25 16:30:25 | I |       - range scale = [    1.0000]
24-11-25 16:30:25 | I |         sum  error  = [   14.9696]
24-11-25 16:30:25 | I |         best error  = [   14.9696]
24-11-25 16:30:25 | I |     + error = [14.9696]
24-11-25 16:30:26 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 16:30:27 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 16:30:28 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 16:30:30 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 16:30:31 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 16:30:32 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 16:30:34 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 16:30:37 | I | quantizing activations for layer model.layers.0
24-11-25 16:30:37 | I | collecting info in model.layers.0
24-11-25 16:30:37 | I | collecting info in model.layers.0
24-11-25 16:30:37 | I | collecting info in model.layers.0
24-11-25 16:30:37 | I | collecting info in model.layers.0
24-11-25 16:30:38 | I | collecting calibration activations in model.layers.0
24-11-25 16:30:38 | I | collecting calibration activations in model.layers.0
24-11-25 16:30:38 | I | collecting calibration activations in model.layers.0
24-11-25 16:30:38 | I | collecting calibration activations in model.layers.0
24-11-25 16:30:40 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 16:30:40 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 16:30:40 | I | - Evaluator: gptq
24-11-25 16:30:40 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 16:30:40 | I | - Batch_size: 8
24-11-25 16:30:40 | I |   + Max_seq_length: 2048
24-11-25 16:31:21 | I |     - Results:
24-11-25 16:31:21 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 16:31:21 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 16:31:21 | I |       |wikitext |      1|word_perplexity|7.7794|  |7.7794|
24-11-25 16:31:21 | I |       |val_valid|      1|word_perplexity|9.0570|  |9.0570|
24-11-25 16:31:21 | I |       
24-11-25 16:31:21 | I | forward this layer
24-11-25 16:31:21 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/49.pt
24-11-25 16:31:21 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/49.pt
24-11-25 16:31:22 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 16:31:22 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 16:31:22 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 16:31:22 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 16:31:22 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 16:31:22 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 16:31:22 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 16:31:22 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 16:31:22 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 16:31:22 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 16:31:22 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 16:31:22 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 16:31:22 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 16:31:22 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 16:31:22 | I | [10] done with optimizer step
24-11-25 16:31:22 | I | epoch 001:     25 / 409600000 loss=0.00111554, loss_per_token=2.28462, loss_sum=74862.5, wps=153.1, ups=0, wpb=32768, bsz=64, num_updates=11, lr=3.3e-05, gnorm=80.418, clip=100, loss_scale=0.0078, train_wall=214, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=5612, lmquant_ppl_result_wikitext_in_train_no_quant=7.71111, lmquant_ppl_result_val_in_train_no_quant=8.97836, lmquant_ppl_result_wikitext_in_train_with_quant=7.7794, lmquant_ppl_result_val_in_train_with_quant=9.05703
24-11-25 16:31:22 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 16:31:22 | I | in layer model.layers.0
24-11-25 16:31:22 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 16:31:22 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 16:31:22 | I | - Evaluator: gptq
24-11-25 16:31:22 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 16:31:22 | I | - Batch_size: 8
24-11-25 16:31:22 | I |   + Max_seq_length: 2048
24-11-25 16:32:00 | I |     - Results:
24-11-25 16:32:00 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 16:32:00 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 16:32:00 | I |       |wikitext |      1|word_perplexity|7.7133|  |7.7133|
24-11-25 16:32:00 | I |       |val_valid|      1|word_perplexity|8.9793|  |8.9793|
24-11-25 16:32:00 | I |       
24-11-25 16:32:00 | I | quantizing weights for layer model.layers.0
24-11-25 16:32:00 | I | collecting info in model.layers.0
24-11-25 16:32:00 | I | collecting info in model.layers.0
24-11-25 16:32:00 | I | collecting info in model.layers.0
24-11-25 16:32:00 | I | collecting info in model.layers.0
24-11-25 16:32:01 | I | collecting calibration activations in model.layers.0
24-11-25 16:32:01 | I | collecting calibration activations in model.layers.0
24-11-25 16:32:01 | I | collecting calibration activations in model.layers.0
24-11-25 16:32:01 | I | collecting calibration activations in model.layers.0
24-11-25 16:32:01 | I | - Quantizing decoder layer model.layers.0
24-11-25 16:32:01 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 16:32:02 | I |       - range scale = [    1.0000]
24-11-25 16:32:02 | I |         sum  error  = [    0.0739]
24-11-25 16:32:02 | I |         best error  = [    0.0739]
24-11-25 16:32:02 | I |     + error = [0.0739]
24-11-25 16:32:03 | I |       - range scale = [    1.0000]
24-11-25 16:32:03 | I |         sum  error  = [    0.6156]
24-11-25 16:32:03 | I |         best error  = [    0.6156]
24-11-25 16:32:03 | I |     + error = [0.6156]
24-11-25 16:32:03 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 16:32:04 | I |       - range scale = [    1.0000]
24-11-25 16:32:04 | I |         sum  error  = [    0.0614]
24-11-25 16:32:04 | I |         best error  = [    0.0614]
24-11-25 16:32:04 | I |     + error = [0.0614]
24-11-25 16:32:04 | I |       - range scale = [    1.0000]
24-11-25 16:32:04 | I |         sum  error  = [    0.5035]
24-11-25 16:32:04 | I |         best error  = [    0.5035]
24-11-25 16:32:04 | I |     + error = [0.5035]
24-11-25 16:32:05 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 16:32:05 | I |       - range scale = [    1.0000]
24-11-25 16:32:05 | I |         sum  error  = [    0.2294]
24-11-25 16:32:05 | I |         best error  = [    0.2294]
24-11-25 16:32:05 | I |     + error = [0.2294]
24-11-25 16:32:06 | I |       - range scale = [    1.0000]
24-11-25 16:32:06 | I |         sum  error  = [    1.7673]
24-11-25 16:32:06 | I |         best error  = [    1.7673]
24-11-25 16:32:06 | I |     + error = [1.7673]
24-11-25 16:32:06 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 16:32:07 | I |       - range scale = [    1.0000]
24-11-25 16:32:07 | I |         sum  error  = [    0.0724]
24-11-25 16:32:07 | I |         best error  = [    0.0724]
24-11-25 16:32:07 | I |     + error = [0.0724]
24-11-25 16:32:07 | I |       - range scale = [    1.0000]
24-11-25 16:32:07 | I |         sum  error  = [    0.7183]
24-11-25 16:32:07 | I |         best error  = [    0.7183]
24-11-25 16:32:07 | I |     + error = [0.7183]
24-11-25 16:32:08 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 16:32:08 | I |       - range scale = [    1.0000]
24-11-25 16:32:08 | I |         sum  error  = [    1.1373]
24-11-25 16:32:08 | I |         best error  = [    1.1373]
24-11-25 16:32:08 | I |     + error = [1.1373]
24-11-25 16:32:09 | I |       - range scale = [    1.0000]
24-11-25 16:32:09 | I |         sum  error  = [   12.6155]
24-11-25 16:32:09 | I |         best error  = [   12.6155]
24-11-25 16:32:09 | I |     + error = [12.6155]
24-11-25 16:32:09 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 16:32:10 | I |       - range scale = [    1.0000]
24-11-25 16:32:10 | I |         sum  error  = [    1.3129]
24-11-25 16:32:10 | I |         best error  = [    1.3129]
24-11-25 16:32:10 | I |     + error = [1.3129]
24-11-25 16:32:11 | I |       - range scale = [    1.0000]
24-11-25 16:32:11 | I |         sum  error  = [   13.0460]
24-11-25 16:32:11 | I |         best error  = [   13.0460]
24-11-25 16:32:11 | I |     + error = [13.0460]
24-11-25 16:32:11 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 16:32:12 | I |       - range scale = [    1.0000]
24-11-25 16:32:12 | I |         sum  error  = [    2.0729]
24-11-25 16:32:12 | I |         best error  = [    2.0729]
24-11-25 16:32:12 | I |     + error = [2.0729]
24-11-25 16:32:12 | I |       - range scale = [    1.0000]
24-11-25 16:32:12 | I |         sum  error  = [    9.5878]
24-11-25 16:32:12 | I |         best error  = [    9.5878]
24-11-25 16:32:12 | I |     + error = [9.5878]
24-11-25 16:32:13 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 16:32:14 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 16:32:15 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 16:32:17 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 16:32:18 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 16:32:19 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 16:32:21 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 16:32:24 | I | quantizing activations for layer model.layers.0
24-11-25 16:32:24 | I | collecting info in model.layers.0
24-11-25 16:32:24 | I | collecting info in model.layers.0
24-11-25 16:32:24 | I | collecting info in model.layers.0
24-11-25 16:32:24 | I | collecting info in model.layers.0
24-11-25 16:32:25 | I | collecting calibration activations in model.layers.0
24-11-25 16:32:25 | I | collecting calibration activations in model.layers.0
24-11-25 16:32:25 | I | collecting calibration activations in model.layers.0
24-11-25 16:32:25 | I | collecting calibration activations in model.layers.0
24-11-25 16:32:27 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 16:32:27 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 16:32:27 | I | - Evaluator: gptq
24-11-25 16:32:27 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 16:32:27 | I | - Batch_size: 8
24-11-25 16:32:27 | I |   + Max_seq_length: 2048
24-11-25 16:33:08 | I |     - Results:
24-11-25 16:33:08 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 16:33:08 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 16:33:08 | I |       |wikitext |      1|word_perplexity|7.7648|  |7.7648|
24-11-25 16:33:08 | I |       |val_valid|      1|word_perplexity|9.0557|  |9.0557|
24-11-25 16:33:08 | I |       
24-11-25 16:33:08 | I | forward this layer
24-11-25 16:33:08 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/50.pt
24-11-25 16:33:08 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/50.pt
24-11-25 16:33:09 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 16:33:09 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 16:33:09 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 16:33:09 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 16:33:09 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 16:33:09 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 16:33:09 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 16:33:09 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 16:33:09 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 16:33:09 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 16:33:09 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 16:33:09 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 16:33:09 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 16:33:09 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 16:33:09 | I | in layer model.layers.0
24-11-25 16:33:09 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 16:33:09 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 16:33:09 | I | - Evaluator: gptq
24-11-25 16:33:09 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 16:33:09 | I | - Batch_size: 8
24-11-25 16:33:09 | I |   + Max_seq_length: 2048
24-11-25 16:33:47 | I |     - Results:
24-11-25 16:33:47 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 16:33:47 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 16:33:47 | I |       |wikitext |      1|word_perplexity|7.7133|  |7.7133|
24-11-25 16:33:47 | I |       |val_valid|      1|word_perplexity|8.9793|  |8.9793|
24-11-25 16:33:47 | I |       
24-11-25 16:33:47 | I | quantizing weights for layer model.layers.0
24-11-25 16:33:47 | I | collecting info in model.layers.0
24-11-25 16:33:47 | I | collecting info in model.layers.0
24-11-25 16:33:47 | I | collecting info in model.layers.0
24-11-25 16:33:47 | I | collecting info in model.layers.0
24-11-25 16:33:47 | I | collecting calibration activations in model.layers.0
24-11-25 16:33:47 | I | collecting calibration activations in model.layers.0
24-11-25 16:33:48 | I | collecting calibration activations in model.layers.0
24-11-25 16:33:48 | I | collecting calibration activations in model.layers.0
24-11-25 16:33:48 | I | - Quantizing decoder layer model.layers.0
24-11-25 16:33:48 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 16:33:49 | I |       - range scale = [    1.0000]
24-11-25 16:33:49 | I |         sum  error  = [    0.0712]
24-11-25 16:33:49 | I |         best error  = [    0.0712]
24-11-25 16:33:49 | I |     + error = [0.0712]
24-11-25 16:33:49 | I |       - range scale = [    1.0000]
24-11-25 16:33:49 | I |         sum  error  = [    0.6352]
24-11-25 16:33:49 | I |         best error  = [    0.6352]
24-11-25 16:33:49 | I |     + error = [0.6352]
24-11-25 16:33:50 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 16:33:50 | I |       - range scale = [    1.0000]
24-11-25 16:33:50 | I |         sum  error  = [    0.0775]
24-11-25 16:33:50 | I |         best error  = [    0.0775]
24-11-25 16:33:50 | I |     + error = [0.0775]
24-11-25 16:33:51 | I |       - range scale = [    1.0000]
24-11-25 16:33:51 | I |         sum  error  = [    0.5694]
24-11-25 16:33:51 | I |         best error  = [    0.5694]
24-11-25 16:33:51 | I |     + error = [0.5694]
24-11-25 16:33:51 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 16:33:52 | I |       - range scale = [    1.0000]
24-11-25 16:33:52 | I |         sum  error  = [    0.2335]
24-11-25 16:33:52 | I |         best error  = [    0.2335]
24-11-25 16:33:52 | I |     + error = [0.2335]
24-11-25 16:33:53 | I |       - range scale = [    1.0000]
24-11-25 16:33:53 | I |         sum  error  = [    1.8140]
24-11-25 16:33:53 | I |         best error  = [    1.8140]
24-11-25 16:33:53 | I |     + error = [1.8140]
24-11-25 16:33:53 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 16:33:53 | I |       - range scale = [    1.0000]
24-11-25 16:33:53 | I |         sum  error  = [    0.0688]
24-11-25 16:33:53 | I |         best error  = [    0.0688]
24-11-25 16:33:53 | I |     + error = [0.0688]
24-11-25 16:33:54 | I |       - range scale = [    1.0000]
24-11-25 16:33:54 | I |         sum  error  = [    0.6774]
24-11-25 16:33:54 | I |         best error  = [    0.6774]
24-11-25 16:33:54 | I |     + error = [0.6774]
24-11-25 16:33:54 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 16:33:55 | I |       - range scale = [    1.0000]
24-11-25 16:33:55 | I |         sum  error  = [    1.1355]
24-11-25 16:33:55 | I |         best error  = [    1.1355]
24-11-25 16:33:55 | I |     + error = [1.1355]
24-11-25 16:33:56 | I |       - range scale = [    1.0000]
24-11-25 16:33:56 | I |         sum  error  = [   12.6003]
24-11-25 16:33:56 | I |         best error  = [   12.6003]
24-11-25 16:33:56 | I |     + error = [12.6003]
24-11-25 16:33:56 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 16:33:57 | I |       - range scale = [    1.0000]
24-11-25 16:33:57 | I |         sum  error  = [    1.3154]
24-11-25 16:33:57 | I |         best error  = [    1.3154]
24-11-25 16:33:57 | I |     + error = [1.3154]
24-11-25 16:33:57 | I |       - range scale = [    1.0000]
24-11-25 16:33:57 | I |         sum  error  = [   13.0420]
24-11-25 16:33:57 | I |         best error  = [   13.0420]
24-11-25 16:33:57 | I |     + error = [13.0420]
24-11-25 16:33:58 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 16:33:58 | I |       - range scale = [    1.0000]
24-11-25 16:33:58 | I |         sum  error  = [    2.1702]
24-11-25 16:33:58 | I |         best error  = [    2.1702]
24-11-25 16:33:58 | I |     + error = [2.1702]
24-11-25 16:33:59 | I |       - range scale = [    1.0000]
24-11-25 16:33:59 | I |         sum  error  = [   10.5313]
24-11-25 16:33:59 | I |         best error  = [   10.5313]
24-11-25 16:33:59 | I |     + error = [10.5313]
24-11-25 16:33:59 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 16:34:01 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 16:34:02 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 16:34:04 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 16:34:05 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 16:34:06 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 16:34:08 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 16:34:11 | I | quantizing activations for layer model.layers.0
24-11-25 16:34:11 | I | collecting info in model.layers.0
24-11-25 16:34:11 | I | collecting info in model.layers.0
24-11-25 16:34:11 | I | collecting info in model.layers.0
24-11-25 16:34:11 | I | collecting info in model.layers.0
24-11-25 16:34:12 | I | collecting calibration activations in model.layers.0
24-11-25 16:34:12 | I | collecting calibration activations in model.layers.0
24-11-25 16:34:12 | I | collecting calibration activations in model.layers.0
24-11-25 16:34:12 | I | collecting calibration activations in model.layers.0
24-11-25 16:34:14 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 16:34:14 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 16:34:14 | I | - Evaluator: gptq
24-11-25 16:34:14 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 16:34:14 | I | - Batch_size: 8
24-11-25 16:34:14 | I |   + Max_seq_length: 2048
24-11-25 16:34:55 | I |     - Results:
24-11-25 16:34:55 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 16:34:55 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 16:34:55 | I |       |wikitext |      1|word_perplexity|7.7756|  |7.7756|
24-11-25 16:34:55 | I |       |val_valid|      1|word_perplexity|9.0644|  |9.0644|
24-11-25 16:34:55 | I |       
24-11-25 16:34:55 | I | forward this layer
24-11-25 16:34:55 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/51.pt
24-11-25 16:34:55 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/51.pt
24-11-25 16:34:55 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 16:34:55 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 16:34:55 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 16:34:55 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 16:34:55 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 16:34:55 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 16:34:55 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 16:34:55 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 16:34:55 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 16:34:55 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 16:34:55 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 16:34:55 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 16:34:55 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 16:34:55 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 16:34:55 | I | [11] done with optimizer step
24-11-25 16:34:56 | I | epoch 001:     26 / 409600000 loss=0.000363423, loss_per_token=0.74429, loss_sum=24388.9, wps=153.2, ups=0, wpb=32768, bsz=64, num_updates=12, lr=3.6e-05, gnorm=79.1, clip=100, loss_scale=0.0078, train_wall=214, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=5826, lmquant_ppl_result_wikitext_in_train_no_quant=7.71334, lmquant_ppl_result_val_in_train_no_quant=8.97928, lmquant_ppl_result_wikitext_in_train_with_quant=7.77561, lmquant_ppl_result_val_in_train_with_quant=9.06439
24-11-25 16:34:56 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 16:34:56 | I | in layer model.layers.0
24-11-25 16:34:56 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 16:34:56 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 16:34:56 | I | - Evaluator: gptq
24-11-25 16:34:56 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 16:34:56 | I | - Batch_size: 8
24-11-25 16:34:56 | I |   + Max_seq_length: 2048
24-11-25 16:35:34 | I |     - Results:
24-11-25 16:35:34 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 16:35:34 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 16:35:34 | I |       |wikitext |      1|word_perplexity|7.7156|  |7.7156|
24-11-25 16:35:34 | I |       |val_valid|      1|word_perplexity|8.9806|  |8.9806|
24-11-25 16:35:34 | I |       
24-11-25 16:35:34 | I | quantizing weights for layer model.layers.0
24-11-25 16:35:34 | I | collecting info in model.layers.0
24-11-25 16:35:34 | I | collecting info in model.layers.0
24-11-25 16:35:34 | I | collecting info in model.layers.0
24-11-25 16:35:34 | I | collecting info in model.layers.0
24-11-25 16:35:35 | I | collecting calibration activations in model.layers.0
24-11-25 16:35:35 | I | collecting calibration activations in model.layers.0
24-11-25 16:35:35 | I | collecting calibration activations in model.layers.0
24-11-25 16:35:35 | I | collecting calibration activations in model.layers.0
24-11-25 16:35:35 | I | - Quantizing decoder layer model.layers.0
24-11-25 16:35:35 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 16:35:36 | I |       - range scale = [    1.0000]
24-11-25 16:35:36 | I |         sum  error  = [    0.0641]
24-11-25 16:35:36 | I |         best error  = [    0.0641]
24-11-25 16:35:36 | I |     + error = [0.0641]
24-11-25 16:35:37 | I |       - range scale = [    1.0000]
24-11-25 16:35:37 | I |         sum  error  = [    0.6119]
24-11-25 16:35:37 | I |         best error  = [    0.6119]
24-11-25 16:35:37 | I |     + error = [0.6119]
24-11-25 16:35:37 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 16:35:37 | I |       - range scale = [    1.0000]
24-11-25 16:35:37 | I |         sum  error  = [    0.0651]
24-11-25 16:35:37 | I |         best error  = [    0.0651]
24-11-25 16:35:37 | I |     + error = [0.0651]
24-11-25 16:35:38 | I |       - range scale = [    1.0000]
24-11-25 16:35:38 | I |         sum  error  = [    0.5232]
24-11-25 16:35:38 | I |         best error  = [    0.5232]
24-11-25 16:35:38 | I |     + error = [0.5232]
24-11-25 16:35:38 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 16:35:39 | I |       - range scale = [    1.0000]
24-11-25 16:35:39 | I |         sum  error  = [    0.2369]
24-11-25 16:35:39 | I |         best error  = [    0.2369]
24-11-25 16:35:39 | I |     + error = [0.2369]
24-11-25 16:35:40 | I |       - range scale = [    1.0000]
24-11-25 16:35:40 | I |         sum  error  = [    1.8241]
24-11-25 16:35:40 | I |         best error  = [    1.8241]
24-11-25 16:35:40 | I |     + error = [1.8241]
24-11-25 16:35:40 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 16:35:41 | I |       - range scale = [    1.0000]
24-11-25 16:35:41 | I |         sum  error  = [    0.0649]
24-11-25 16:35:41 | I |         best error  = [    0.0649]
24-11-25 16:35:41 | I |     + error = [0.0649]
24-11-25 16:35:41 | I |       - range scale = [    1.0000]
24-11-25 16:35:41 | I |         sum  error  = [    0.6384]
24-11-25 16:35:41 | I |         best error  = [    0.6384]
24-11-25 16:35:41 | I |     + error = [0.6384]
24-11-25 16:35:42 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 16:35:42 | I |       - range scale = [    1.0000]
24-11-25 16:35:42 | I |         sum  error  = [    1.1531]
24-11-25 16:35:42 | I |         best error  = [    1.1531]
24-11-25 16:35:42 | I |     + error = [1.1531]
24-11-25 16:35:43 | I |       - range scale = [    1.0000]
24-11-25 16:35:43 | I |         sum  error  = [   12.7831]
24-11-25 16:35:43 | I |         best error  = [   12.7831]
24-11-25 16:35:43 | I |     + error = [12.7831]
24-11-25 16:35:43 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 16:35:44 | I |       - range scale = [    1.0000]
24-11-25 16:35:44 | I |         sum  error  = [    1.3313]
24-11-25 16:35:44 | I |         best error  = [    1.3313]
24-11-25 16:35:44 | I |     + error = [1.3313]
24-11-25 16:35:45 | I |       - range scale = [    1.0000]
24-11-25 16:35:45 | I |         sum  error  = [   13.2474]
24-11-25 16:35:45 | I |         best error  = [   13.2474]
24-11-25 16:35:45 | I |     + error = [13.2474]
24-11-25 16:35:45 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 16:35:45 | I |       - range scale = [    1.0000]
24-11-25 16:35:45 | I |         sum  error  = [    2.8007]
24-11-25 16:35:45 | I |         best error  = [    2.8007]
24-11-25 16:35:45 | I |     + error = [2.8007]
24-11-25 16:35:46 | I |       - range scale = [    1.0000]
24-11-25 16:35:46 | I |         sum  error  = [   13.9319]
24-11-25 16:35:46 | I |         best error  = [   13.9319]
24-11-25 16:35:46 | I |     + error = [13.9319]
24-11-25 16:35:46 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 16:35:48 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 16:35:49 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 16:35:51 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 16:35:52 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 16:35:54 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 16:35:55 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 16:35:58 | I | quantizing activations for layer model.layers.0
24-11-25 16:35:58 | I | collecting info in model.layers.0
24-11-25 16:35:58 | I | collecting info in model.layers.0
24-11-25 16:35:58 | I | collecting info in model.layers.0
24-11-25 16:35:58 | I | collecting info in model.layers.0
24-11-25 16:35:59 | I | collecting calibration activations in model.layers.0
24-11-25 16:35:59 | I | collecting calibration activations in model.layers.0
24-11-25 16:35:59 | I | collecting calibration activations in model.layers.0
24-11-25 16:35:59 | I | collecting calibration activations in model.layers.0
24-11-25 16:36:01 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 16:36:01 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 16:36:01 | I | - Evaluator: gptq
24-11-25 16:36:01 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 16:36:01 | I | - Batch_size: 8
24-11-25 16:36:01 | I |   + Max_seq_length: 2048
24-11-25 16:36:42 | I |     - Results:
24-11-25 16:36:42 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 16:36:42 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 16:36:42 | I |       |wikitext |      1|word_perplexity|7.7592|  |7.7592|
24-11-25 16:36:42 | I |       |val_valid|      1|word_perplexity|9.0487|  |9.0487|
24-11-25 16:36:42 | I |       
24-11-25 16:36:42 | I | forward this layer
24-11-25 16:36:42 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/52.pt
24-11-25 16:36:42 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/52.pt
24-11-25 16:36:43 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 16:36:43 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 16:36:43 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 16:36:43 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 16:36:43 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 16:36:43 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 16:36:43 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 16:36:43 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 16:36:43 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 16:36:43 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 16:36:43 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 16:36:43 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 16:36:43 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 16:36:43 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 16:36:43 | I | in layer model.layers.0
24-11-25 16:36:43 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 16:36:43 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 16:36:43 | I | - Evaluator: gptq
24-11-25 16:36:43 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 16:36:43 | I | - Batch_size: 8
24-11-25 16:36:43 | I |   + Max_seq_length: 2048
24-11-25 16:37:21 | I |     - Results:
24-11-25 16:37:21 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 16:37:21 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 16:37:21 | I |       |wikitext |      1|word_perplexity|7.7156|  |7.7156|
24-11-25 16:37:21 | I |       |val_valid|      1|word_perplexity|8.9806|  |8.9806|
24-11-25 16:37:21 | I |       
24-11-25 16:37:21 | I | quantizing weights for layer model.layers.0
24-11-25 16:37:21 | I | collecting info in model.layers.0
24-11-25 16:37:21 | I | collecting info in model.layers.0
24-11-25 16:37:21 | I | collecting info in model.layers.0
24-11-25 16:37:21 | I | collecting info in model.layers.0
24-11-25 16:37:21 | I | collecting calibration activations in model.layers.0
24-11-25 16:37:22 | I | collecting calibration activations in model.layers.0
24-11-25 16:37:22 | I | collecting calibration activations in model.layers.0
24-11-25 16:37:22 | I | collecting calibration activations in model.layers.0
24-11-25 16:37:22 | I | - Quantizing decoder layer model.layers.0
24-11-25 16:37:22 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 16:37:23 | I |       - range scale = [    1.0000]
24-11-25 16:37:23 | I |         sum  error  = [    0.0652]
24-11-25 16:37:23 | I |         best error  = [    0.0652]
24-11-25 16:37:23 | I |     + error = [0.0652]
24-11-25 16:37:23 | I |       - range scale = [    1.0000]
24-11-25 16:37:23 | I |         sum  error  = [    0.6135]
24-11-25 16:37:23 | I |         best error  = [    0.6135]
24-11-25 16:37:23 | I |     + error = [0.6135]
24-11-25 16:37:24 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 16:37:24 | I |       - range scale = [    1.0000]
24-11-25 16:37:24 | I |         sum  error  = [    0.0647]
24-11-25 16:37:24 | I |         best error  = [    0.0647]
24-11-25 16:37:24 | I |     + error = [0.0647]
24-11-25 16:37:25 | I |       - range scale = [    1.0000]
24-11-25 16:37:25 | I |         sum  error  = [    0.5217]
24-11-25 16:37:25 | I |         best error  = [    0.5217]
24-11-25 16:37:25 | I |     + error = [0.5217]
24-11-25 16:37:25 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 16:37:26 | I |       - range scale = [    1.0000]
24-11-25 16:37:26 | I |         sum  error  = [    0.2386]
24-11-25 16:37:26 | I |         best error  = [    0.2386]
24-11-25 16:37:26 | I |     + error = [0.2386]
24-11-25 16:37:27 | I |       - range scale = [    1.0000]
24-11-25 16:37:27 | I |         sum  error  = [    1.8196]
24-11-25 16:37:27 | I |         best error  = [    1.8196]
24-11-25 16:37:27 | I |     + error = [1.8196]
24-11-25 16:37:27 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 16:37:27 | I |       - range scale = [    1.0000]
24-11-25 16:37:27 | I |         sum  error  = [    0.0605]
24-11-25 16:37:27 | I |         best error  = [    0.0605]
24-11-25 16:37:27 | I |     + error = [0.0605]
24-11-25 16:37:28 | I |       - range scale = [    1.0000]
24-11-25 16:37:28 | I |         sum  error  = [    0.5903]
24-11-25 16:37:28 | I |         best error  = [    0.5903]
24-11-25 16:37:28 | I |     + error = [0.5903]
24-11-25 16:37:28 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 16:37:29 | I |       - range scale = [    1.0000]
24-11-25 16:37:29 | I |         sum  error  = [    1.0756]
24-11-25 16:37:29 | I |         best error  = [    1.0756]
24-11-25 16:37:29 | I |     + error = [1.0756]
24-11-25 16:37:30 | I |       - range scale = [    1.0000]
24-11-25 16:37:30 | I |         sum  error  = [   11.9335]
24-11-25 16:37:30 | I |         best error  = [   11.9335]
24-11-25 16:37:30 | I |     + error = [11.9335]
24-11-25 16:37:30 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 16:37:31 | I |       - range scale = [    1.0000]
24-11-25 16:37:31 | I |         sum  error  = [    1.2439]
24-11-25 16:37:31 | I |         best error  = [    1.2439]
24-11-25 16:37:31 | I |     + error = [1.2439]
24-11-25 16:37:31 | I |       - range scale = [    1.0000]
24-11-25 16:37:31 | I |         sum  error  = [   12.3327]
24-11-25 16:37:31 | I |         best error  = [   12.3327]
24-11-25 16:37:31 | I |     + error = [12.3327]
24-11-25 16:37:32 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 16:37:32 | I |       - range scale = [    1.0000]
24-11-25 16:37:32 | I |         sum  error  = [    2.5634]
24-11-25 16:37:32 | I |         best error  = [    2.5634]
24-11-25 16:37:32 | I |     + error = [2.5634]
24-11-25 16:37:33 | I |       - range scale = [    1.0000]
24-11-25 16:37:33 | I |         sum  error  = [   13.5880]
24-11-25 16:37:33 | I |         best error  = [   13.5880]
24-11-25 16:37:33 | I |     + error = [13.5880]
24-11-25 16:37:33 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 16:37:35 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 16:37:36 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 16:37:37 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 16:37:39 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 16:37:40 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 16:37:42 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 16:37:45 | I | quantizing activations for layer model.layers.0
24-11-25 16:37:45 | I | collecting info in model.layers.0
24-11-25 16:37:45 | I | collecting info in model.layers.0
24-11-25 16:37:45 | I | collecting info in model.layers.0
24-11-25 16:37:45 | I | collecting info in model.layers.0
24-11-25 16:37:45 | I | collecting calibration activations in model.layers.0
24-11-25 16:37:46 | I | collecting calibration activations in model.layers.0
24-11-25 16:37:46 | I | collecting calibration activations in model.layers.0
24-11-25 16:37:46 | I | collecting calibration activations in model.layers.0
24-11-25 16:37:48 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 16:37:48 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 16:37:48 | I | - Evaluator: gptq
24-11-25 16:37:48 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 16:37:48 | I | - Batch_size: 8
24-11-25 16:37:48 | I |   + Max_seq_length: 2048
24-11-25 16:38:29 | I |     - Results:
24-11-25 16:38:29 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 16:38:29 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 16:38:29 | I |       |wikitext |      1|word_perplexity|7.7711|  |7.7711|
24-11-25 16:38:29 | I |       |val_valid|      1|word_perplexity|9.0503|  |9.0503|
24-11-25 16:38:29 | I |       
24-11-25 16:38:29 | I | forward this layer
24-11-25 16:38:29 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/53.pt
24-11-25 16:38:29 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/53.pt
24-11-25 16:38:30 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 16:38:30 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 16:38:30 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 16:38:30 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 16:38:30 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 16:38:30 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 16:38:30 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 16:38:30 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 16:38:30 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 16:38:30 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 16:38:30 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 16:38:30 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 16:38:30 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 16:38:30 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 16:38:30 | I | [12] done with optimizer step
24-11-25 16:38:30 | I | epoch 001:     27 / 409600000 loss=0.00150643, loss_per_token=3.08518, loss_sum=101095, wps=153, ups=0, wpb=32768, bsz=64, num_updates=13, lr=3.9e-05, gnorm=116.854, clip=100, loss_scale=0.0078, train_wall=214, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=6040, lmquant_ppl_result_wikitext_in_train_no_quant=7.71564, lmquant_ppl_result_val_in_train_no_quant=8.98057, lmquant_ppl_result_wikitext_in_train_with_quant=7.77113, lmquant_ppl_result_val_in_train_with_quant=9.05027
24-11-25 16:38:30 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 16:38:30 | I | in layer model.layers.0
24-11-25 16:38:30 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 16:38:30 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 16:38:30 | I | - Evaluator: gptq
24-11-25 16:38:30 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 16:38:30 | I | - Batch_size: 8
24-11-25 16:38:30 | I |   + Max_seq_length: 2048
24-11-25 16:39:08 | I |     - Results:
24-11-25 16:39:08 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 16:39:08 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 16:39:08 | I |       |wikitext |      1|word_perplexity|7.7190|  |7.7190|
24-11-25 16:39:08 | I |       |val_valid|      1|word_perplexity|8.9821|  |8.9821|
24-11-25 16:39:08 | I |       
24-11-25 16:39:08 | I | quantizing weights for layer model.layers.0
24-11-25 16:39:08 | I | collecting info in model.layers.0
24-11-25 16:39:08 | I | collecting info in model.layers.0
24-11-25 16:39:08 | I | collecting info in model.layers.0
24-11-25 16:39:08 | I | collecting info in model.layers.0
24-11-25 16:39:09 | I | collecting calibration activations in model.layers.0
24-11-25 16:39:09 | I | collecting calibration activations in model.layers.0
24-11-25 16:39:09 | I | collecting calibration activations in model.layers.0
24-11-25 16:39:09 | I | collecting calibration activations in model.layers.0
24-11-25 16:39:09 | I | - Quantizing decoder layer model.layers.0
24-11-25 16:39:09 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 16:39:10 | I |       - range scale = [    1.0000]
24-11-25 16:39:10 | I |         sum  error  = [    0.0609]
24-11-25 16:39:10 | I |         best error  = [    0.0609]
24-11-25 16:39:10 | I |     + error = [0.0609]
24-11-25 16:39:11 | I |       - range scale = [    1.0000]
24-11-25 16:39:11 | I |         sum  error  = [    0.5962]
24-11-25 16:39:11 | I |         best error  = [    0.5962]
24-11-25 16:39:11 | I |     + error = [0.5962]
24-11-25 16:39:11 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 16:39:12 | I |       - range scale = [    1.0000]
24-11-25 16:39:12 | I |         sum  error  = [    0.0598]
24-11-25 16:39:12 | I |         best error  = [    0.0598]
24-11-25 16:39:12 | I |     + error = [0.0598]
24-11-25 16:39:12 | I |       - range scale = [    1.0000]
24-11-25 16:39:12 | I |         sum  error  = [    0.4885]
24-11-25 16:39:12 | I |         best error  = [    0.4885]
24-11-25 16:39:12 | I |     + error = [0.4885]
24-11-25 16:39:13 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 16:39:13 | I |       - range scale = [    1.0000]
24-11-25 16:39:13 | I |         sum  error  = [    0.2305]
24-11-25 16:39:13 | I |         best error  = [    0.2305]
24-11-25 16:39:13 | I |     + error = [0.2305]
24-11-25 16:39:14 | I |       - range scale = [    1.0000]
24-11-25 16:39:14 | I |         sum  error  = [    1.7572]
24-11-25 16:39:14 | I |         best error  = [    1.7572]
24-11-25 16:39:14 | I |     + error = [1.7572]
24-11-25 16:39:14 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 16:39:15 | I |       - range scale = [    1.0000]
24-11-25 16:39:15 | I |         sum  error  = [    0.0562]
24-11-25 16:39:15 | I |         best error  = [    0.0562]
24-11-25 16:39:15 | I |     + error = [0.0562]
24-11-25 16:39:15 | I |       - range scale = [    1.0000]
24-11-25 16:39:15 | I |         sum  error  = [    0.5449]
24-11-25 16:39:15 | I |         best error  = [    0.5449]
24-11-25 16:39:15 | I |     + error = [0.5449]
24-11-25 16:39:16 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 16:39:16 | I |       - range scale = [    1.0000]
24-11-25 16:39:16 | I |         sum  error  = [    1.0802]
24-11-25 16:39:16 | I |         best error  = [    1.0802]
24-11-25 16:39:16 | I |     + error = [1.0802]
24-11-25 16:39:17 | I |       - range scale = [    1.0000]
24-11-25 16:39:17 | I |         sum  error  = [   11.9716]
24-11-25 16:39:17 | I |         best error  = [   11.9716]
24-11-25 16:39:17 | I |     + error = [11.9716]
24-11-25 16:39:17 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 16:39:18 | I |       - range scale = [    1.0000]
24-11-25 16:39:18 | I |         sum  error  = [    1.2496]
24-11-25 16:39:18 | I |         best error  = [    1.2496]
24-11-25 16:39:18 | I |     + error = [1.2496]
24-11-25 16:39:19 | I |       - range scale = [    1.0000]
24-11-25 16:39:19 | I |         sum  error  = [   12.3720]
24-11-25 16:39:19 | I |         best error  = [   12.3720]
24-11-25 16:39:19 | I |     + error = [12.3720]
24-11-25 16:39:19 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 16:39:20 | I |       - range scale = [    1.0000]
24-11-25 16:39:20 | I |         sum  error  = [    3.1011]
24-11-25 16:39:20 | I |         best error  = [    3.1011]
24-11-25 16:39:20 | I |     + error = [3.1011]
24-11-25 16:39:20 | I |       - range scale = [    1.0000]
24-11-25 16:39:20 | I |         sum  error  = [   16.7274]
24-11-25 16:39:20 | I |         best error  = [   16.7274]
24-11-25 16:39:20 | I |     + error = [16.7274]
24-11-25 16:39:21 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 16:39:22 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 16:39:23 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 16:39:25 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 16:39:26 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 16:39:28 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 16:39:29 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 16:39:32 | I | quantizing activations for layer model.layers.0
24-11-25 16:39:32 | I | collecting info in model.layers.0
24-11-25 16:39:32 | I | collecting info in model.layers.0
24-11-25 16:39:32 | I | collecting info in model.layers.0
24-11-25 16:39:32 | I | collecting info in model.layers.0
24-11-25 16:39:33 | I | collecting calibration activations in model.layers.0
24-11-25 16:39:33 | I | collecting calibration activations in model.layers.0
24-11-25 16:39:33 | I | collecting calibration activations in model.layers.0
24-11-25 16:39:33 | I | collecting calibration activations in model.layers.0
24-11-25 16:39:35 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 16:39:35 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 16:39:35 | I | - Evaluator: gptq
24-11-25 16:39:35 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 16:39:35 | I | - Batch_size: 8
24-11-25 16:39:35 | I |   + Max_seq_length: 2048
24-11-25 16:40:16 | I |     - Results:
24-11-25 16:40:16 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 16:40:16 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 16:40:16 | I |       |wikitext |      1|word_perplexity|7.7642|  |7.7642|
24-11-25 16:40:16 | I |       |val_valid|      1|word_perplexity|9.0464|  |9.0464|
24-11-25 16:40:16 | I |       
24-11-25 16:40:16 | I | forward this layer
24-11-25 16:40:16 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/54.pt
24-11-25 16:40:16 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/54.pt
24-11-25 16:40:17 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 16:40:17 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 16:40:17 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 16:40:17 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 16:40:17 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 16:40:17 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 16:40:17 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 16:40:17 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 16:40:17 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 16:40:17 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 16:40:17 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 16:40:17 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 16:40:17 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 16:40:17 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 16:40:17 | I | in layer model.layers.0
24-11-25 16:40:17 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 16:40:17 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 16:40:17 | I | - Evaluator: gptq
24-11-25 16:40:17 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 16:40:17 | I | - Batch_size: 8
24-11-25 16:40:17 | I |   + Max_seq_length: 2048
24-11-25 16:40:55 | I |     - Results:
24-11-25 16:40:55 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 16:40:55 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 16:40:55 | I |       |wikitext |      1|word_perplexity|7.7190|  |7.7190|
24-11-25 16:40:55 | I |       |val_valid|      1|word_perplexity|8.9821|  |8.9821|
24-11-25 16:40:55 | I |       
24-11-25 16:40:55 | I | quantizing weights for layer model.layers.0
24-11-25 16:40:55 | I | collecting info in model.layers.0
24-11-25 16:40:55 | I | collecting info in model.layers.0
24-11-25 16:40:55 | I | collecting info in model.layers.0
24-11-25 16:40:55 | I | collecting info in model.layers.0
24-11-25 16:40:55 | I | collecting calibration activations in model.layers.0
24-11-25 16:40:56 | I | collecting calibration activations in model.layers.0
24-11-25 16:40:56 | I | collecting calibration activations in model.layers.0
24-11-25 16:40:56 | I | collecting calibration activations in model.layers.0
24-11-25 16:40:56 | I | - Quantizing decoder layer model.layers.0
24-11-25 16:40:56 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 16:40:57 | I |       - range scale = [    1.0000]
24-11-25 16:40:57 | I |         sum  error  = [    0.0646]
24-11-25 16:40:57 | I |         best error  = [    0.0646]
24-11-25 16:40:57 | I |     + error = [0.0646]
24-11-25 16:40:58 | I |       - range scale = [    1.0000]
24-11-25 16:40:58 | I |         sum  error  = [    0.6286]
24-11-25 16:40:58 | I |         best error  = [    0.6286]
24-11-25 16:40:58 | I |     + error = [0.6286]
24-11-25 16:40:58 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 16:40:58 | I |       - range scale = [    1.0000]
24-11-25 16:40:58 | I |         sum  error  = [    0.0663]
24-11-25 16:40:58 | I |         best error  = [    0.0663]
24-11-25 16:40:58 | I |     + error = [0.0663]
24-11-25 16:40:59 | I |       - range scale = [    1.0000]
24-11-25 16:40:59 | I |         sum  error  = [    0.5338]
24-11-25 16:40:59 | I |         best error  = [    0.5338]
24-11-25 16:40:59 | I |     + error = [0.5338]
24-11-25 16:40:59 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 16:41:00 | I |       - range scale = [    1.0000]
24-11-25 16:41:00 | I |         sum  error  = [    0.2391]
24-11-25 16:41:00 | I |         best error  = [    0.2391]
24-11-25 16:41:00 | I |     + error = [0.2391]
24-11-25 16:41:01 | I |       - range scale = [    1.0000]
24-11-25 16:41:01 | I |         sum  error  = [    1.7845]
24-11-25 16:41:01 | I |         best error  = [    1.7845]
24-11-25 16:41:01 | I |     + error = [1.7845]
24-11-25 16:41:01 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 16:41:02 | I |       - range scale = [    1.0000]
24-11-25 16:41:02 | I |         sum  error  = [    0.0626]
24-11-25 16:41:02 | I |         best error  = [    0.0626]
24-11-25 16:41:02 | I |     + error = [0.0626]
24-11-25 16:41:02 | I |       - range scale = [    1.0000]
24-11-25 16:41:02 | I |         sum  error  = [    0.6130]
24-11-25 16:41:02 | I |         best error  = [    0.6130]
24-11-25 16:41:02 | I |     + error = [0.6130]
24-11-25 16:41:03 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 16:41:03 | I |       - range scale = [    1.0000]
24-11-25 16:41:03 | I |         sum  error  = [    1.0505]
24-11-25 16:41:03 | I |         best error  = [    1.0505]
24-11-25 16:41:03 | I |     + error = [1.0505]
24-11-25 16:41:04 | I |       - range scale = [    1.0000]
24-11-25 16:41:04 | I |         sum  error  = [   11.6405]
24-11-25 16:41:04 | I |         best error  = [   11.6405]
24-11-25 16:41:04 | I |     + error = [11.6405]
24-11-25 16:41:04 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 16:41:05 | I |       - range scale = [    1.0000]
24-11-25 16:41:05 | I |         sum  error  = [    1.2136]
24-11-25 16:41:05 | I |         best error  = [    1.2136]
24-11-25 16:41:05 | I |     + error = [1.2136]
24-11-25 16:41:06 | I |       - range scale = [    1.0000]
24-11-25 16:41:06 | I |         sum  error  = [   12.0147]
24-11-25 16:41:06 | I |         best error  = [   12.0147]
24-11-25 16:41:06 | I |     + error = [12.0147]
24-11-25 16:41:06 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 16:41:07 | I |       - range scale = [    1.0000]
24-11-25 16:41:07 | I |         sum  error  = [    2.3973]
24-11-25 16:41:07 | I |         best error  = [    2.3973]
24-11-25 16:41:07 | I |     + error = [2.3973]
24-11-25 16:41:07 | I |       - range scale = [    1.0000]
24-11-25 16:41:07 | I |         sum  error  = [   12.5157]
24-11-25 16:41:07 | I |         best error  = [   12.5157]
24-11-25 16:41:07 | I |     + error = [12.5157]
24-11-25 16:41:08 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 16:41:09 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 16:41:10 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 16:41:12 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 16:41:13 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 16:41:14 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 16:41:16 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 16:41:20 | I | quantizing activations for layer model.layers.0
24-11-25 16:41:20 | I | collecting info in model.layers.0
24-11-25 16:41:20 | I | collecting info in model.layers.0
24-11-25 16:41:20 | I | collecting info in model.layers.0
24-11-25 16:41:20 | I | collecting info in model.layers.0
24-11-25 16:41:20 | I | collecting calibration activations in model.layers.0
24-11-25 16:41:21 | I | collecting calibration activations in model.layers.0
24-11-25 16:41:21 | I | collecting calibration activations in model.layers.0
24-11-25 16:41:21 | I | collecting calibration activations in model.layers.0
24-11-25 16:41:23 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 16:41:23 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 16:41:23 | I | - Evaluator: gptq
24-11-25 16:41:23 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 16:41:23 | I | - Batch_size: 8
24-11-25 16:41:23 | I |   + Max_seq_length: 2048
24-11-25 16:42:05 | I |     - Results:
24-11-25 16:42:05 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 16:42:05 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 16:42:05 | I |       |wikitext |      1|word_perplexity|7.7700|  |7.7700|
24-11-25 16:42:05 | I |       |val_valid|      1|word_perplexity|9.0447|  |9.0447|
24-11-25 16:42:05 | I |       
24-11-25 16:42:05 | I | forward this layer
24-11-25 16:42:05 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/55.pt
24-11-25 16:42:05 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/55.pt
24-11-25 16:42:05 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 16:42:05 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 16:42:05 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 16:42:05 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 16:42:05 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 16:42:05 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 16:42:05 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 16:42:05 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 16:42:05 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 16:42:05 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 16:42:05 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 16:42:05 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 16:42:05 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 16:42:05 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 16:42:05 | I | [13] done with optimizer step
24-11-25 16:42:05 | I | epoch 001:     28 / 409600000 loss=0.000843682, loss_per_token=1.72786, loss_sum=56618.6, wps=152.2, ups=0, wpb=32768, bsz=64, num_updates=14, lr=4.2e-05, gnorm=77.166, clip=100, loss_scale=0.0078, train_wall=215, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=6255, lmquant_ppl_result_wikitext_in_train_no_quant=7.71903, lmquant_ppl_result_val_in_train_no_quant=8.98214, lmquant_ppl_result_wikitext_in_train_with_quant=7.77003, lmquant_ppl_result_val_in_train_with_quant=9.04465
24-11-25 16:42:05 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 16:42:05 | I | in layer model.layers.0
24-11-25 16:42:05 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 16:42:05 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 16:42:05 | I | - Evaluator: gptq
24-11-25 16:42:05 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 16:42:05 | I | - Batch_size: 8
24-11-25 16:42:05 | I |   + Max_seq_length: 2048
24-11-25 16:42:43 | I |     - Results:
24-11-25 16:42:43 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 16:42:43 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 16:42:43 | I |       |wikitext |      1|word_perplexity|7.7223|  |7.7223|
24-11-25 16:42:43 | I |       |val_valid|      1|word_perplexity|8.9839|  |8.9839|
24-11-25 16:42:43 | I |       
24-11-25 16:42:43 | I | quantizing weights for layer model.layers.0
24-11-25 16:42:43 | I | collecting info in model.layers.0
24-11-25 16:42:43 | I | collecting info in model.layers.0
24-11-25 16:42:43 | I | collecting info in model.layers.0
24-11-25 16:42:43 | I | collecting info in model.layers.0
24-11-25 16:42:44 | I | collecting calibration activations in model.layers.0
24-11-25 16:42:44 | I | collecting calibration activations in model.layers.0
24-11-25 16:42:44 | I | collecting calibration activations in model.layers.0
24-11-25 16:42:44 | I | collecting calibration activations in model.layers.0
24-11-25 16:42:45 | I | - Quantizing decoder layer model.layers.0
24-11-25 16:42:45 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 16:42:45 | I |       - range scale = [    1.0000]
24-11-25 16:42:45 | I |         sum  error  = [    0.0655]
24-11-25 16:42:45 | I |         best error  = [    0.0655]
24-11-25 16:42:45 | I |     + error = [0.0655]
24-11-25 16:42:46 | I |       - range scale = [    1.0000]
24-11-25 16:42:46 | I |         sum  error  = [    0.6162]
24-11-25 16:42:46 | I |         best error  = [    0.6162]
24-11-25 16:42:46 | I |     + error = [0.6162]
24-11-25 16:42:46 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 16:42:47 | I |       - range scale = [    1.0000]
24-11-25 16:42:47 | I |         sum  error  = [    0.0690]
24-11-25 16:42:47 | I |         best error  = [    0.0690]
24-11-25 16:42:47 | I |     + error = [0.0690]
24-11-25 16:42:48 | I |       - range scale = [    1.0000]
24-11-25 16:42:48 | I |         sum  error  = [    0.5264]
24-11-25 16:42:48 | I |         best error  = [    0.5264]
24-11-25 16:42:48 | I |     + error = [0.5264]
24-11-25 16:42:48 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 16:42:48 | I |       - range scale = [    1.0000]
24-11-25 16:42:48 | I |         sum  error  = [    0.2341]
24-11-25 16:42:48 | I |         best error  = [    0.2341]
24-11-25 16:42:48 | I |     + error = [0.2341]
24-11-25 16:42:49 | I |       - range scale = [    1.0000]
24-11-25 16:42:49 | I |         sum  error  = [    1.7899]
24-11-25 16:42:49 | I |         best error  = [    1.7899]
24-11-25 16:42:49 | I |     + error = [1.7899]
24-11-25 16:42:49 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 16:42:50 | I |       - range scale = [    1.0000]
24-11-25 16:42:50 | I |         sum  error  = [    0.0636]
24-11-25 16:42:50 | I |         best error  = [    0.0636]
24-11-25 16:42:50 | I |     + error = [0.0636]
24-11-25 16:42:51 | I |       - range scale = [    1.0000]
24-11-25 16:42:51 | I |         sum  error  = [    0.6213]
24-11-25 16:42:51 | I |         best error  = [    0.6213]
24-11-25 16:42:51 | I |     + error = [0.6213]
24-11-25 16:42:51 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 16:42:52 | I |       - range scale = [    1.0000]
24-11-25 16:42:52 | I |         sum  error  = [    1.1071]
24-11-25 16:42:52 | I |         best error  = [    1.1071]
24-11-25 16:42:52 | I |     + error = [1.1071]
24-11-25 16:42:52 | I |       - range scale = [    1.0000]
24-11-25 16:42:52 | I |         sum  error  = [   12.2843]
24-11-25 16:42:52 | I |         best error  = [   12.2843]
24-11-25 16:42:52 | I |     + error = [12.2843]
24-11-25 16:42:52 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 16:42:53 | I |       - range scale = [    1.0000]
24-11-25 16:42:53 | I |         sum  error  = [    1.2831]
24-11-25 16:42:53 | I |         best error  = [    1.2831]
24-11-25 16:42:53 | I |     + error = [1.2831]
24-11-25 16:42:54 | I |       - range scale = [    1.0000]
24-11-25 16:42:54 | I |         sum  error  = [   12.7108]
24-11-25 16:42:54 | I |         best error  = [   12.7108]
24-11-25 16:42:54 | I |     + error = [12.7108]
24-11-25 16:42:54 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 16:42:55 | I |       - range scale = [    1.0000]
24-11-25 16:42:55 | I |         sum  error  = [    2.2485]
24-11-25 16:42:55 | I |         best error  = [    2.2485]
24-11-25 16:42:55 | I |     + error = [2.2485]
24-11-25 16:42:55 | I |       - range scale = [    1.0000]
24-11-25 16:42:55 | I |         sum  error  = [   11.9103]
24-11-25 16:42:55 | I |         best error  = [   11.9103]
24-11-25 16:42:55 | I |     + error = [11.9103]
24-11-25 16:42:56 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 16:42:57 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 16:42:59 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 16:43:01 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 16:43:02 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 16:43:04 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 16:43:06 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 16:43:09 | I | quantizing activations for layer model.layers.0
24-11-25 16:43:09 | I | collecting info in model.layers.0
24-11-25 16:43:09 | I | collecting info in model.layers.0
24-11-25 16:43:09 | I | collecting info in model.layers.0
24-11-25 16:43:09 | I | collecting info in model.layers.0
24-11-25 16:43:10 | I | collecting calibration activations in model.layers.0
24-11-25 16:43:10 | I | collecting calibration activations in model.layers.0
24-11-25 16:43:10 | I | collecting calibration activations in model.layers.0
24-11-25 16:43:10 | I | collecting calibration activations in model.layers.0
24-11-25 16:43:12 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 16:43:12 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 16:43:12 | I | - Evaluator: gptq
24-11-25 16:43:12 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 16:43:12 | I | - Batch_size: 8
24-11-25 16:43:12 | I |   + Max_seq_length: 2048
24-11-25 16:43:53 | I |     - Results:
24-11-25 16:43:53 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 16:43:53 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 16:43:53 | I |       |wikitext |      1|word_perplexity|7.7728|  |7.7728|
24-11-25 16:43:53 | I |       |val_valid|      1|word_perplexity|9.0465|  |9.0465|
24-11-25 16:43:53 | I |       
24-11-25 16:43:53 | I | forward this layer
24-11-25 16:43:53 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/56.pt
24-11-25 16:43:53 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/56.pt
24-11-25 16:43:54 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 16:43:54 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 16:43:54 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 16:43:54 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 16:43:54 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 16:43:54 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 16:43:54 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 16:43:54 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 16:43:54 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 16:43:54 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 16:43:54 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 16:43:54 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 16:43:54 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 16:43:54 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 16:43:54 | I | in layer model.layers.0
24-11-25 16:43:54 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 16:43:54 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 16:43:54 | I | - Evaluator: gptq
24-11-25 16:43:54 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 16:43:54 | I | - Batch_size: 8
24-11-25 16:43:54 | I |   + Max_seq_length: 2048
24-11-25 16:44:32 | I |     - Results:
24-11-25 16:44:32 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 16:44:32 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 16:44:32 | I |       |wikitext |      1|word_perplexity|7.7223|  |7.7223|
24-11-25 16:44:32 | I |       |val_valid|      1|word_perplexity|8.9839|  |8.9839|
24-11-25 16:44:32 | I |       
24-11-25 16:44:32 | I | quantizing weights for layer model.layers.0
24-11-25 16:44:32 | I | collecting info in model.layers.0
24-11-25 16:44:32 | I | collecting info in model.layers.0
24-11-25 16:44:32 | I | collecting info in model.layers.0
24-11-25 16:44:32 | I | collecting info in model.layers.0
24-11-25 16:44:32 | I | collecting calibration activations in model.layers.0
24-11-25 16:44:33 | I | collecting calibration activations in model.layers.0
24-11-25 16:44:33 | I | collecting calibration activations in model.layers.0
24-11-25 16:44:33 | I | collecting calibration activations in model.layers.0
24-11-25 16:44:33 | I | - Quantizing decoder layer model.layers.0
24-11-25 16:44:33 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 16:44:34 | I |       - range scale = [    1.0000]
24-11-25 16:44:34 | I |         sum  error  = [    0.0643]
24-11-25 16:44:34 | I |         best error  = [    0.0643]
24-11-25 16:44:34 | I |     + error = [0.0643]
24-11-25 16:44:34 | I |       - range scale = [    1.0000]
24-11-25 16:44:34 | I |         sum  error  = [    0.6328]
24-11-25 16:44:34 | I |         best error  = [    0.6328]
24-11-25 16:44:34 | I |     + error = [0.6328]
24-11-25 16:44:35 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 16:44:35 | I |       - range scale = [    1.0000]
24-11-25 16:44:35 | I |         sum  error  = [    0.0740]
24-11-25 16:44:35 | I |         best error  = [    0.0740]
24-11-25 16:44:35 | I |     + error = [0.0740]
24-11-25 16:44:36 | I |       - range scale = [    1.0000]
24-11-25 16:44:36 | I |         sum  error  = [    0.5427]
24-11-25 16:44:36 | I |         best error  = [    0.5427]
24-11-25 16:44:36 | I |     + error = [0.5427]
24-11-25 16:44:36 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 16:44:37 | I |       - range scale = [    1.0000]
24-11-25 16:44:37 | I |         sum  error  = [    0.2324]
24-11-25 16:44:37 | I |         best error  = [    0.2324]
24-11-25 16:44:37 | I |     + error = [0.2324]
24-11-25 16:44:38 | I |       - range scale = [    1.0000]
24-11-25 16:44:38 | I |         sum  error  = [    1.7725]
24-11-25 16:44:38 | I |         best error  = [    1.7725]
24-11-25 16:44:38 | I |     + error = [1.7725]
24-11-25 16:44:38 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 16:44:38 | I |       - range scale = [    1.0000]
24-11-25 16:44:38 | I |         sum  error  = [    0.0592]
24-11-25 16:44:38 | I |         best error  = [    0.0592]
24-11-25 16:44:38 | I |     + error = [0.0592]
24-11-25 16:44:39 | I |       - range scale = [    1.0000]
24-11-25 16:44:39 | I |         sum  error  = [    0.5704]
24-11-25 16:44:39 | I |         best error  = [    0.5704]
24-11-25 16:44:39 | I |     + error = [0.5704]
24-11-25 16:44:39 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 16:44:40 | I |       - range scale = [    1.0000]
24-11-25 16:44:40 | I |         sum  error  = [    1.0848]
24-11-25 16:44:40 | I |         best error  = [    1.0848]
24-11-25 16:44:40 | I |     + error = [1.0848]
24-11-25 16:44:41 | I |       - range scale = [    1.0000]
24-11-25 16:44:41 | I |         sum  error  = [   12.0361]
24-11-25 16:44:41 | I |         best error  = [   12.0361]
24-11-25 16:44:41 | I |     + error = [12.0361]
24-11-25 16:44:41 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 16:44:42 | I |       - range scale = [    1.0000]
24-11-25 16:44:42 | I |         sum  error  = [    1.2560]
24-11-25 16:44:42 | I |         best error  = [    1.2560]
24-11-25 16:44:42 | I |     + error = [1.2560]
24-11-25 16:44:42 | I |       - range scale = [    1.0000]
24-11-25 16:44:42 | I |         sum  error  = [   12.4456]
24-11-25 16:44:42 | I |         best error  = [   12.4456]
24-11-25 16:44:42 | I |     + error = [12.4456]
24-11-25 16:44:43 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 16:44:43 | I |       - range scale = [    1.0000]
24-11-25 16:44:43 | I |         sum  error  = [    3.0619]
24-11-25 16:44:43 | I |         best error  = [    3.0619]
24-11-25 16:44:43 | I |     + error = [3.0619]
24-11-25 16:44:44 | I |       - range scale = [    1.0000]
24-11-25 16:44:44 | I |         sum  error  = [   15.8402]
24-11-25 16:44:44 | I |         best error  = [   15.8402]
24-11-25 16:44:44 | I |     + error = [15.8402]
24-11-25 16:44:44 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 16:44:46 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 16:44:47 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 16:44:48 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 16:44:50 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 16:44:51 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 16:44:53 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 16:44:56 | I | quantizing activations for layer model.layers.0
24-11-25 16:44:56 | I | collecting info in model.layers.0
24-11-25 16:44:56 | I | collecting info in model.layers.0
24-11-25 16:44:56 | I | collecting info in model.layers.0
24-11-25 16:44:56 | I | collecting info in model.layers.0
24-11-25 16:44:56 | I | collecting calibration activations in model.layers.0
24-11-25 16:44:56 | I | collecting calibration activations in model.layers.0
24-11-25 16:44:57 | I | collecting calibration activations in model.layers.0
24-11-25 16:44:57 | I | collecting calibration activations in model.layers.0
24-11-25 16:44:59 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 16:44:59 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 16:44:59 | I | - Evaluator: gptq
24-11-25 16:44:59 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 16:44:59 | I | - Batch_size: 8
24-11-25 16:44:59 | I |   + Max_seq_length: 2048
24-11-25 16:45:40 | I |     - Results:
24-11-25 16:45:40 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 16:45:40 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 16:45:40 | I |       |wikitext |      1|word_perplexity|7.7825|  |7.7825|
24-11-25 16:45:40 | I |       |val_valid|      1|word_perplexity|9.0529|  |9.0529|
24-11-25 16:45:40 | I |       
24-11-25 16:45:40 | I | forward this layer
24-11-25 16:45:40 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/57.pt
24-11-25 16:45:40 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/57.pt
24-11-25 16:45:40 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 16:45:40 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 16:45:40 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 16:45:40 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 16:45:40 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 16:45:40 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 16:45:40 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 16:45:40 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 16:45:40 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 16:45:40 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 16:45:40 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 16:45:40 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 16:45:40 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 16:45:40 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 16:45:40 | I | [14] done with optimizer step
24-11-25 16:45:40 | I | epoch 001:     29 / 409600000 loss=0.000853575, loss_per_token=1.74812, loss_sum=57282.4, wps=152.2, ups=0, wpb=32768, bsz=64, num_updates=15, lr=4.5e-05, gnorm=74.731, clip=100, loss_scale=0.0078, train_wall=215, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=6471, lmquant_ppl_result_wikitext_in_train_no_quant=7.72226, lmquant_ppl_result_val_in_train_no_quant=8.98392, lmquant_ppl_result_wikitext_in_train_with_quant=7.78246, lmquant_ppl_result_val_in_train_with_quant=9.05292
24-11-25 16:45:41 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 16:45:41 | I | in layer model.layers.0
24-11-25 16:45:41 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 16:45:41 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 16:45:41 | I | - Evaluator: gptq
24-11-25 16:45:41 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 16:45:41 | I | - Batch_size: 8
24-11-25 16:45:41 | I |   + Max_seq_length: 2048
24-11-25 16:46:19 | I |     - Results:
24-11-25 16:46:19 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 16:46:19 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 16:46:19 | I |       |wikitext |      1|word_perplexity|7.7260|  |7.7260|
24-11-25 16:46:19 | I |       |val_valid|      1|word_perplexity|8.9857|  |8.9857|
24-11-25 16:46:19 | I |       
24-11-25 16:46:19 | I | quantizing weights for layer model.layers.0
24-11-25 16:46:19 | I | collecting info in model.layers.0
24-11-25 16:46:19 | I | collecting info in model.layers.0
24-11-25 16:46:19 | I | collecting info in model.layers.0
24-11-25 16:46:19 | I | collecting info in model.layers.0
24-11-25 16:46:19 | I | collecting calibration activations in model.layers.0
24-11-25 16:46:19 | I | collecting calibration activations in model.layers.0
24-11-25 16:46:20 | I | collecting calibration activations in model.layers.0
24-11-25 16:46:20 | I | collecting calibration activations in model.layers.0
24-11-25 16:46:20 | I | - Quantizing decoder layer model.layers.0
24-11-25 16:46:20 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 16:46:21 | I |       - range scale = [    1.0000]
24-11-25 16:46:21 | I |         sum  error  = [    0.0612]
24-11-25 16:46:21 | I |         best error  = [    0.0612]
24-11-25 16:46:21 | I |     + error = [0.0612]
24-11-25 16:46:21 | I |       - range scale = [    1.0000]
24-11-25 16:46:21 | I |         sum  error  = [    0.6166]
24-11-25 16:46:21 | I |         best error  = [    0.6166]
24-11-25 16:46:21 | I |     + error = [0.6166]
24-11-25 16:46:22 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 16:46:22 | I |       - range scale = [    1.0000]
24-11-25 16:46:22 | I |         sum  error  = [    0.0636]
24-11-25 16:46:22 | I |         best error  = [    0.0636]
24-11-25 16:46:22 | I |     + error = [0.0636]
24-11-25 16:46:23 | I |       - range scale = [    1.0000]
24-11-25 16:46:23 | I |         sum  error  = [    0.5311]
24-11-25 16:46:23 | I |         best error  = [    0.5311]
24-11-25 16:46:23 | I |     + error = [0.5311]
24-11-25 16:46:23 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 16:46:24 | I |       - range scale = [    1.0000]
24-11-25 16:46:24 | I |         sum  error  = [    0.2374]
24-11-25 16:46:24 | I |         best error  = [    0.2374]
24-11-25 16:46:24 | I |     + error = [0.2374]
24-11-25 16:46:24 | I |       - range scale = [    1.0000]
24-11-25 16:46:24 | I |         sum  error  = [    1.7880]
24-11-25 16:46:25 | I |         best error  = [    1.7880]
24-11-25 16:46:25 | I |     + error = [1.7880]
24-11-25 16:46:25 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 16:46:25 | I |       - range scale = [    1.0000]
24-11-25 16:46:25 | I |         sum  error  = [    0.0625]
24-11-25 16:46:25 | I |         best error  = [    0.0625]
24-11-25 16:46:25 | I |     + error = [0.0625]
24-11-25 16:46:26 | I |       - range scale = [    1.0000]
24-11-25 16:46:26 | I |         sum  error  = [    0.6132]
24-11-25 16:46:26 | I |         best error  = [    0.6132]
24-11-25 16:46:26 | I |     + error = [0.6132]
24-11-25 16:46:26 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 16:46:27 | I |       - range scale = [    1.0000]
24-11-25 16:46:27 | I |         sum  error  = [    1.0621]
24-11-25 16:46:27 | I |         best error  = [    1.0621]
24-11-25 16:46:27 | I |     + error = [1.0621]
24-11-25 16:46:28 | I |       - range scale = [    1.0000]
24-11-25 16:46:28 | I |         sum  error  = [   11.7765]
24-11-25 16:46:28 | I |         best error  = [   11.7765]
24-11-25 16:46:28 | I |     + error = [11.7765]
24-11-25 16:46:28 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 16:46:29 | I |       - range scale = [    1.0000]
24-11-25 16:46:29 | I |         sum  error  = [    1.2301]
24-11-25 16:46:29 | I |         best error  = [    1.2301]
24-11-25 16:46:29 | I |     + error = [1.2301]
24-11-25 16:46:29 | I |       - range scale = [    1.0000]
24-11-25 16:46:29 | I |         sum  error  = [   12.1869]
24-11-25 16:46:29 | I |         best error  = [   12.1869]
24-11-25 16:46:29 | I |     + error = [12.1869]
24-11-25 16:46:30 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 16:46:30 | I |       - range scale = [    1.0000]
24-11-25 16:46:30 | I |         sum  error  = [    2.7086]
24-11-25 16:46:30 | I |         best error  = [    2.7086]
24-11-25 16:46:30 | I |     + error = [2.7086]
24-11-25 16:46:31 | I |       - range scale = [    1.0000]
24-11-25 16:46:31 | I |         sum  error  = [   13.6994]
24-11-25 16:46:31 | I |         best error  = [   13.6994]
24-11-25 16:46:31 | I |     + error = [13.6994]
24-11-25 16:46:31 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 16:46:33 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 16:46:34 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 16:46:35 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 16:46:37 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 16:46:38 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 16:46:39 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 16:46:43 | I | quantizing activations for layer model.layers.0
24-11-25 16:46:43 | I | collecting info in model.layers.0
24-11-25 16:46:43 | I | collecting info in model.layers.0
24-11-25 16:46:43 | I | collecting info in model.layers.0
24-11-25 16:46:43 | I | collecting info in model.layers.0
24-11-25 16:46:43 | I | collecting calibration activations in model.layers.0
24-11-25 16:46:43 | I | collecting calibration activations in model.layers.0
24-11-25 16:46:43 | I | collecting calibration activations in model.layers.0
24-11-25 16:46:44 | I | collecting calibration activations in model.layers.0
24-11-25 16:46:45 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 16:46:45 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 16:46:45 | I | - Evaluator: gptq
24-11-25 16:46:45 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 16:46:45 | I | - Batch_size: 8
24-11-25 16:46:45 | I |   + Max_seq_length: 2048
24-11-25 16:47:27 | I |     - Results:
24-11-25 16:47:27 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 16:47:27 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 16:47:27 | I |       |wikitext |      1|word_perplexity|7.7671|  |7.7671|
24-11-25 16:47:27 | I |       |val_valid|      1|word_perplexity|9.0415|  |9.0415|
24-11-25 16:47:27 | I |       
24-11-25 16:47:27 | I | forward this layer
24-11-25 16:47:27 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/58.pt
24-11-25 16:47:27 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/58.pt
24-11-25 16:47:27 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 16:47:27 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 16:47:27 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 16:47:27 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 16:47:27 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 16:47:27 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 16:47:27 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 16:47:27 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 16:47:27 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 16:47:27 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 16:47:27 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 16:47:27 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 16:47:27 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 16:47:27 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 16:47:27 | I | in layer model.layers.0
24-11-25 16:47:27 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 16:47:27 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 16:47:27 | I | - Evaluator: gptq
24-11-25 16:47:27 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 16:47:27 | I | - Batch_size: 8
24-11-25 16:47:27 | I |   + Max_seq_length: 2048
24-11-25 16:48:06 | I |     - Results:
24-11-25 16:48:06 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 16:48:06 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 16:48:06 | I |       |wikitext |      1|word_perplexity|7.7260|  |7.7260|
24-11-25 16:48:06 | I |       |val_valid|      1|word_perplexity|8.9857|  |8.9857|
24-11-25 16:48:06 | I |       
24-11-25 16:48:06 | I | quantizing weights for layer model.layers.0
24-11-25 16:48:06 | I | collecting info in model.layers.0
24-11-25 16:48:06 | I | collecting info in model.layers.0
24-11-25 16:48:06 | I | collecting info in model.layers.0
24-11-25 16:48:06 | I | collecting info in model.layers.0
24-11-25 16:48:06 | I | collecting calibration activations in model.layers.0
24-11-25 16:48:06 | I | collecting calibration activations in model.layers.0
24-11-25 16:48:06 | I | collecting calibration activations in model.layers.0
24-11-25 16:48:07 | I | collecting calibration activations in model.layers.0
24-11-25 16:48:07 | I | - Quantizing decoder layer model.layers.0
24-11-25 16:48:07 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 16:48:08 | I |       - range scale = [    1.0000]
24-11-25 16:48:08 | I |         sum  error  = [    0.0580]
24-11-25 16:48:08 | I |         best error  = [    0.0580]
24-11-25 16:48:08 | I |     + error = [0.0580]
24-11-25 16:48:08 | I |       - range scale = [    1.0000]
24-11-25 16:48:08 | I |         sum  error  = [    0.6093]
24-11-25 16:48:08 | I |         best error  = [    0.6093]
24-11-25 16:48:08 | I |     + error = [0.6093]
24-11-25 16:48:08 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 16:48:09 | I |       - range scale = [    1.0000]
24-11-25 16:48:09 | I |         sum  error  = [    0.0604]
24-11-25 16:48:09 | I |         best error  = [    0.0604]
24-11-25 16:48:09 | I |     + error = [0.0604]
24-11-25 16:48:10 | I |       - range scale = [    1.0000]
24-11-25 16:48:10 | I |         sum  error  = [    0.5002]
24-11-25 16:48:10 | I |         best error  = [    0.5002]
24-11-25 16:48:10 | I |     + error = [0.5002]
24-11-25 16:48:10 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 16:48:11 | I |       - range scale = [    1.0000]
24-11-25 16:48:11 | I |         sum  error  = [    0.2305]
24-11-25 16:48:11 | I |         best error  = [    0.2305]
24-11-25 16:48:11 | I |     + error = [0.2305]
24-11-25 16:48:11 | I |       - range scale = [    1.0000]
24-11-25 16:48:11 | I |         sum  error  = [    1.7588]
24-11-25 16:48:11 | I |         best error  = [    1.7588]
24-11-25 16:48:11 | I |     + error = [1.7588]
24-11-25 16:48:12 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 16:48:12 | I |       - range scale = [    1.0000]
24-11-25 16:48:12 | I |         sum  error  = [    0.0562]
24-11-25 16:48:12 | I |         best error  = [    0.0562]
24-11-25 16:48:12 | I |     + error = [0.0562]
24-11-25 16:48:13 | I |       - range scale = [    1.0000]
24-11-25 16:48:13 | I |         sum  error  = [    0.5472]
24-11-25 16:48:13 | I |         best error  = [    0.5472]
24-11-25 16:48:13 | I |     + error = [0.5472]
24-11-25 16:48:13 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 16:48:14 | I |       - range scale = [    1.0000]
24-11-25 16:48:14 | I |         sum  error  = [    1.0460]
24-11-25 16:48:14 | I |         best error  = [    1.0460]
24-11-25 16:48:14 | I |     + error = [1.0460]
24-11-25 16:48:15 | I |       - range scale = [    1.0000]
24-11-25 16:48:15 | I |         sum  error  = [   11.6013]
24-11-25 16:48:15 | I |         best error  = [   11.6013]
24-11-25 16:48:15 | I |     + error = [11.6013]
24-11-25 16:48:15 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 16:48:15 | I |       - range scale = [    1.0000]
24-11-25 16:48:15 | I |         sum  error  = [    1.2128]
24-11-25 16:48:15 | I |         best error  = [    1.2128]
24-11-25 16:48:15 | I |     + error = [1.2128]
24-11-25 16:48:16 | I |       - range scale = [    1.0000]
24-11-25 16:48:16 | I |         sum  error  = [   11.9938]
24-11-25 16:48:16 | I |         best error  = [   11.9938]
24-11-25 16:48:16 | I |     + error = [11.9938]
24-11-25 16:48:16 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 16:48:17 | I |       - range scale = [    1.0000]
24-11-25 16:48:17 | I |         sum  error  = [    3.4269]
24-11-25 16:48:17 | I |         best error  = [    3.4269]
24-11-25 16:48:17 | I |     + error = [3.4269]
24-11-25 16:48:18 | I |       - range scale = [    1.0000]
24-11-25 16:48:18 | I |         sum  error  = [   17.7023]
24-11-25 16:48:18 | I |         best error  = [   17.7023]
24-11-25 16:48:18 | I |     + error = [17.7023]
24-11-25 16:48:18 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 16:48:19 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 16:48:21 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 16:48:22 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 16:48:24 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 16:48:25 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 16:48:26 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 16:48:30 | I | quantizing activations for layer model.layers.0
24-11-25 16:48:30 | I | collecting info in model.layers.0
24-11-25 16:48:30 | I | collecting info in model.layers.0
24-11-25 16:48:30 | I | collecting info in model.layers.0
24-11-25 16:48:30 | I | collecting info in model.layers.0
24-11-25 16:48:30 | I | collecting calibration activations in model.layers.0
24-11-25 16:48:30 | I | collecting calibration activations in model.layers.0
24-11-25 16:48:30 | I | collecting calibration activations in model.layers.0
24-11-25 16:48:31 | I | collecting calibration activations in model.layers.0
24-11-25 16:48:32 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 16:48:32 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 16:48:32 | I | - Evaluator: gptq
24-11-25 16:48:32 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 16:48:32 | I | - Batch_size: 8
24-11-25 16:48:32 | I |   + Max_seq_length: 2048
24-11-25 16:49:14 | I |     - Results:
24-11-25 16:49:14 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 16:49:14 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 16:49:14 | I |       |wikitext |      1|word_perplexity|7.7754|  |7.7754|
24-11-25 16:49:14 | I |       |val_valid|      1|word_perplexity|9.0446|  |9.0446|
24-11-25 16:49:14 | I |       
24-11-25 16:49:14 | I | forward this layer
24-11-25 16:49:14 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/59.pt
24-11-25 16:49:14 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/59.pt
24-11-25 16:49:14 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 16:49:14 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 16:49:14 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 16:49:14 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 16:49:14 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 16:49:14 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 16:49:14 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 16:49:14 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 16:49:14 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 16:49:14 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 16:49:14 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 16:49:14 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 16:49:14 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 16:49:14 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 16:49:14 | I | [15] done with optimizer step
24-11-25 16:49:14 | I | epoch 001:     30 / 409600000 loss=0.000724056, loss_per_token=1.48287, loss_sum=48590.6, wps=153.2, ups=0, wpb=32768, bsz=64, num_updates=16, lr=4.8e-05, gnorm=63.922, clip=100, loss_scale=0.0078, train_wall=214, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=6685, lmquant_ppl_result_wikitext_in_train_no_quant=7.72604, lmquant_ppl_result_val_in_train_no_quant=8.98574, lmquant_ppl_result_wikitext_in_train_with_quant=7.77545, lmquant_ppl_result_val_in_train_with_quant=9.04463
24-11-25 16:49:14 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 16:49:14 | I | in layer model.layers.0
24-11-25 16:49:14 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 16:49:14 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 16:49:14 | I | - Evaluator: gptq
24-11-25 16:49:14 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 16:49:14 | I | - Batch_size: 8
24-11-25 16:49:14 | I |   + Max_seq_length: 2048
24-11-25 16:49:53 | I |     - Results:
24-11-25 16:49:53 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 16:49:53 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 16:49:53 | I |       |wikitext |      1|word_perplexity|7.7301|  |7.7301|
24-11-25 16:49:53 | I |       |val_valid|      1|word_perplexity|8.9872|  |8.9872|
24-11-25 16:49:53 | I |       
24-11-25 16:49:53 | I | quantizing weights for layer model.layers.0
24-11-25 16:49:53 | I | collecting info in model.layers.0
24-11-25 16:49:53 | I | collecting info in model.layers.0
24-11-25 16:49:53 | I | collecting info in model.layers.0
24-11-25 16:49:53 | I | collecting info in model.layers.0
24-11-25 16:49:53 | I | collecting calibration activations in model.layers.0
24-11-25 16:49:53 | I | collecting calibration activations in model.layers.0
24-11-25 16:49:54 | I | collecting calibration activations in model.layers.0
24-11-25 16:49:54 | I | collecting calibration activations in model.layers.0
24-11-25 16:49:54 | I | - Quantizing decoder layer model.layers.0
24-11-25 16:49:54 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 16:49:55 | I |       - range scale = [    1.0000]
24-11-25 16:49:55 | I |         sum  error  = [    0.0614]
24-11-25 16:49:55 | I |         best error  = [    0.0614]
24-11-25 16:49:55 | I |     + error = [0.0614]
24-11-25 16:49:55 | I |       - range scale = [    1.0000]
24-11-25 16:49:55 | I |         sum  error  = [    0.6563]
24-11-25 16:49:55 | I |         best error  = [    0.6563]
24-11-25 16:49:55 | I |     + error = [0.6563]
24-11-25 16:49:56 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 16:49:56 | I |       - range scale = [    1.0000]
24-11-25 16:49:56 | I |         sum  error  = [    0.0584]
24-11-25 16:49:56 | I |         best error  = [    0.0584]
24-11-25 16:49:56 | I |     + error = [0.0584]
24-11-25 16:49:57 | I |       - range scale = [    1.0000]
24-11-25 16:49:57 | I |         sum  error  = [    0.5075]
24-11-25 16:49:57 | I |         best error  = [    0.5075]
24-11-25 16:49:57 | I |     + error = [0.5075]
24-11-25 16:49:57 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 16:49:58 | I |       - range scale = [    1.0000]
24-11-25 16:49:58 | I |         sum  error  = [    0.2369]
24-11-25 16:49:58 | I |         best error  = [    0.2369]
24-11-25 16:49:58 | I |     + error = [0.2369]
24-11-25 16:49:58 | I |       - range scale = [    1.0000]
24-11-25 16:49:58 | I |         sum  error  = [    1.7575]
24-11-25 16:49:58 | I |         best error  = [    1.7575]
24-11-25 16:49:58 | I |     + error = [1.7575]
24-11-25 16:49:59 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 16:49:59 | I |       - range scale = [    1.0000]
24-11-25 16:49:59 | I |         sum  error  = [    0.0596]
24-11-25 16:49:59 | I |         best error  = [    0.0596]
24-11-25 16:49:59 | I |     + error = [0.0596]
24-11-25 16:50:00 | I |       - range scale = [    1.0000]
24-11-25 16:50:00 | I |         sum  error  = [    0.5767]
24-11-25 16:50:00 | I |         best error  = [    0.5767]
24-11-25 16:50:00 | I |     + error = [0.5767]
24-11-25 16:50:00 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 16:50:01 | I |       - range scale = [    1.0000]
24-11-25 16:50:01 | I |         sum  error  = [    1.0332]
24-11-25 16:50:01 | I |         best error  = [    1.0332]
24-11-25 16:50:01 | I |     + error = [1.0332]
24-11-25 16:50:02 | I |       - range scale = [    1.0000]
24-11-25 16:50:02 | I |         sum  error  = [   11.4571]
24-11-25 16:50:02 | I |         best error  = [   11.4571]
24-11-25 16:50:02 | I |     + error = [11.4571]
24-11-25 16:50:02 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 16:50:03 | I |       - range scale = [    1.0000]
24-11-25 16:50:03 | I |         sum  error  = [    1.1985]
24-11-25 16:50:03 | I |         best error  = [    1.1985]
24-11-25 16:50:03 | I |     + error = [1.1985]
24-11-25 16:50:03 | I |       - range scale = [    1.0000]
24-11-25 16:50:03 | I |         sum  error  = [   11.8543]
24-11-25 16:50:03 | I |         best error  = [   11.8543]
24-11-25 16:50:03 | I |     + error = [11.8543]
24-11-25 16:50:04 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 16:50:04 | I |       - range scale = [    1.0000]
24-11-25 16:50:04 | I |         sum  error  = [    3.4359]
24-11-25 16:50:04 | I |         best error  = [    3.4359]
24-11-25 16:50:04 | I |     + error = [3.4359]
24-11-25 16:50:05 | I |       - range scale = [    1.0000]
24-11-25 16:50:05 | I |         sum  error  = [   18.1051]
24-11-25 16:50:05 | I |         best error  = [   18.1051]
24-11-25 16:50:05 | I |     + error = [18.1051]
24-11-25 16:50:05 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 16:50:07 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 16:50:08 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 16:50:09 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 16:50:11 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 16:50:12 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 16:50:14 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 16:50:17 | I | quantizing activations for layer model.layers.0
24-11-25 16:50:17 | I | collecting info in model.layers.0
24-11-25 16:50:17 | I | collecting info in model.layers.0
24-11-25 16:50:17 | I | collecting info in model.layers.0
24-11-25 16:50:17 | I | collecting info in model.layers.0
24-11-25 16:50:17 | I | collecting calibration activations in model.layers.0
24-11-25 16:50:18 | I | collecting calibration activations in model.layers.0
24-11-25 16:50:18 | I | collecting calibration activations in model.layers.0
24-11-25 16:50:18 | I | collecting calibration activations in model.layers.0
24-11-25 16:50:20 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 16:50:20 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 16:50:20 | I | - Evaluator: gptq
24-11-25 16:50:20 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 16:50:20 | I | - Batch_size: 8
24-11-25 16:50:20 | I |   + Max_seq_length: 2048
24-11-25 16:51:01 | I |     - Results:
24-11-25 16:51:01 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 16:51:01 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 16:51:01 | I |       |wikitext |      1|word_perplexity|7.7722|  |7.7722|
24-11-25 16:51:01 | I |       |val_valid|      1|word_perplexity|9.0454|  |9.0454|
24-11-25 16:51:01 | I |       
24-11-25 16:51:01 | I | forward this layer
24-11-25 16:51:01 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/60.pt
24-11-25 16:51:01 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/60.pt
24-11-25 16:51:01 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 16:51:01 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 16:51:01 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 16:51:01 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 16:51:01 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 16:51:01 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 16:51:01 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 16:51:01 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 16:51:01 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 16:51:01 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 16:51:01 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 16:51:01 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 16:51:01 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 16:51:01 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 16:51:01 | I | in layer model.layers.0
24-11-25 16:51:01 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 16:51:01 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 16:51:01 | I | - Evaluator: gptq
24-11-25 16:51:01 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 16:51:01 | I | - Batch_size: 8
24-11-25 16:51:01 | I |   + Max_seq_length: 2048
24-11-25 16:51:40 | I |     - Results:
24-11-25 16:51:40 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 16:51:40 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 16:51:40 | I |       |wikitext |      1|word_perplexity|7.7301|  |7.7301|
24-11-25 16:51:40 | I |       |val_valid|      1|word_perplexity|8.9872|  |8.9872|
24-11-25 16:51:40 | I |       
24-11-25 16:51:40 | I | quantizing weights for layer model.layers.0
24-11-25 16:51:40 | I | collecting info in model.layers.0
24-11-25 16:51:40 | I | collecting info in model.layers.0
24-11-25 16:51:40 | I | collecting info in model.layers.0
24-11-25 16:51:40 | I | collecting info in model.layers.0
24-11-25 16:51:40 | I | collecting calibration activations in model.layers.0
24-11-25 16:51:40 | I | collecting calibration activations in model.layers.0
24-11-25 16:51:41 | I | collecting calibration activations in model.layers.0
24-11-25 16:51:41 | I | collecting calibration activations in model.layers.0
24-11-25 16:51:41 | I | - Quantizing decoder layer model.layers.0
24-11-25 16:51:41 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 16:51:42 | I |       - range scale = [    1.0000]
24-11-25 16:51:42 | I |         sum  error  = [    0.0629]
24-11-25 16:51:42 | I |         best error  = [    0.0629]
24-11-25 16:51:42 | I |     + error = [0.0629]
24-11-25 16:51:42 | I |       - range scale = [    1.0000]
24-11-25 16:51:42 | I |         sum  error  = [    0.6328]
24-11-25 16:51:42 | I |         best error  = [    0.6328]
24-11-25 16:51:42 | I |     + error = [0.6328]
24-11-25 16:51:43 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 16:51:43 | I |       - range scale = [    1.0000]
24-11-25 16:51:43 | I |         sum  error  = [    0.0618]
24-11-25 16:51:43 | I |         best error  = [    0.0618]
24-11-25 16:51:43 | I |     + error = [0.0618]
24-11-25 16:51:44 | I |       - range scale = [    1.0000]
24-11-25 16:51:44 | I |         sum  error  = [    0.5282]
24-11-25 16:51:44 | I |         best error  = [    0.5282]
24-11-25 16:51:44 | I |     + error = [0.5282]
24-11-25 16:51:44 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 16:51:45 | I |       - range scale = [    1.0000]
24-11-25 16:51:45 | I |         sum  error  = [    0.2393]
24-11-25 16:51:45 | I |         best error  = [    0.2393]
24-11-25 16:51:45 | I |     + error = [0.2393]
24-11-25 16:51:45 | I |       - range scale = [    1.0000]
24-11-25 16:51:45 | I |         sum  error  = [    1.8028]
24-11-25 16:51:45 | I |         best error  = [    1.8028]
24-11-25 16:51:45 | I |     + error = [1.8028]
24-11-25 16:51:46 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 16:51:46 | I |       - range scale = [    1.0000]
24-11-25 16:51:46 | I |         sum  error  = [    0.0643]
24-11-25 16:51:46 | I |         best error  = [    0.0643]
24-11-25 16:51:46 | I |     + error = [0.0643]
24-11-25 16:51:47 | I |       - range scale = [    1.0000]
24-11-25 16:51:47 | I |         sum  error  = [    0.6239]
24-11-25 16:51:47 | I |         best error  = [    0.6239]
24-11-25 16:51:47 | I |     + error = [0.6239]
24-11-25 16:51:47 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 16:51:48 | I |       - range scale = [    1.0000]
24-11-25 16:51:48 | I |         sum  error  = [    1.0804]
24-11-25 16:51:48 | I |         best error  = [    1.0804]
24-11-25 16:51:48 | I |     + error = [1.0804]
24-11-25 16:51:49 | I |       - range scale = [    1.0000]
24-11-25 16:51:49 | I |         sum  error  = [   11.9721]
24-11-25 16:51:49 | I |         best error  = [   11.9721]
24-11-25 16:51:49 | I |     + error = [11.9721]
24-11-25 16:51:49 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 16:51:50 | I |       - range scale = [    1.0000]
24-11-25 16:51:50 | I |         sum  error  = [    1.2510]
24-11-25 16:51:50 | I |         best error  = [    1.2510]
24-11-25 16:51:50 | I |     + error = [1.2510]
24-11-25 16:51:50 | I |       - range scale = [    1.0000]
24-11-25 16:51:50 | I |         sum  error  = [   12.3918]
24-11-25 16:51:50 | I |         best error  = [   12.3918]
24-11-25 16:51:50 | I |     + error = [12.3918]
24-11-25 16:51:51 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 16:51:51 | I |       - range scale = [    1.0000]
24-11-25 16:51:51 | I |         sum  error  = [    3.0515]
24-11-25 16:51:51 | I |         best error  = [    3.0515]
24-11-25 16:51:51 | I |     + error = [3.0515]
24-11-25 16:51:52 | I |       - range scale = [    1.0000]
24-11-25 16:51:52 | I |         sum  error  = [   15.8426]
24-11-25 16:51:52 | I |         best error  = [   15.8426]
24-11-25 16:51:52 | I |     + error = [15.8426]
24-11-25 16:51:52 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 16:51:54 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 16:51:55 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 16:51:56 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 16:51:58 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 16:51:59 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 16:52:01 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 16:52:04 | I | quantizing activations for layer model.layers.0
24-11-25 16:52:04 | I | collecting info in model.layers.0
24-11-25 16:52:04 | I | collecting info in model.layers.0
24-11-25 16:52:04 | I | collecting info in model.layers.0
24-11-25 16:52:04 | I | collecting info in model.layers.0
24-11-25 16:52:04 | I | collecting calibration activations in model.layers.0
24-11-25 16:52:05 | I | collecting calibration activations in model.layers.0
24-11-25 16:52:05 | I | collecting calibration activations in model.layers.0
24-11-25 16:52:05 | I | collecting calibration activations in model.layers.0
24-11-25 16:52:07 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 16:52:07 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 16:52:07 | I | - Evaluator: gptq
24-11-25 16:52:07 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 16:52:07 | I | - Batch_size: 8
24-11-25 16:52:07 | I |   + Max_seq_length: 2048
24-11-25 16:52:48 | I |     - Results:
24-11-25 16:52:48 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 16:52:48 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 16:52:48 | I |       |wikitext |      1|word_perplexity|7.7767|  |7.7767|
24-11-25 16:52:48 | I |       |val_valid|      1|word_perplexity|9.0490|  |9.0490|
24-11-25 16:52:48 | I |       
24-11-25 16:52:48 | I | forward this layer
24-11-25 16:52:48 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/61.pt
24-11-25 16:52:48 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/61.pt
24-11-25 16:52:48 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 16:52:48 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 16:52:48 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 16:52:48 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 16:52:48 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 16:52:48 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 16:52:48 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 16:52:48 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 16:52:48 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 16:52:48 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 16:52:48 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 16:52:48 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 16:52:48 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 16:52:48 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 16:52:48 | I | [16] done with optimizer step
24-11-25 16:52:48 | I | epoch 001:     31 / 409600000 loss=0.000748238, loss_per_token=1.53239, loss_sum=50213.4, wps=153, ups=0, wpb=32768, bsz=64, num_updates=17, lr=5.1e-05, gnorm=62.709, clip=100, loss_scale=0.0078, train_wall=214, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=6899, lmquant_ppl_result_wikitext_in_train_no_quant=7.73006, lmquant_ppl_result_val_in_train_no_quant=8.98725, lmquant_ppl_result_wikitext_in_train_with_quant=7.77674, lmquant_ppl_result_val_in_train_with_quant=9.04903
24-11-25 16:52:49 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 16:52:49 | I | in layer model.layers.0
24-11-25 16:52:49 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 16:52:49 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 16:52:49 | I | - Evaluator: gptq
24-11-25 16:52:49 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 16:52:49 | I | - Batch_size: 8
24-11-25 16:52:49 | I |   + Max_seq_length: 2048
24-11-25 16:53:27 | I |     - Results:
24-11-25 16:53:27 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 16:53:27 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 16:53:27 | I |       |wikitext |      1|word_perplexity|7.7339|  |7.7339|
24-11-25 16:53:27 | I |       |val_valid|      1|word_perplexity|8.9894|  |8.9894|
24-11-25 16:53:27 | I |       
24-11-25 16:53:27 | I | quantizing weights for layer model.layers.0
24-11-25 16:53:27 | I | collecting info in model.layers.0
24-11-25 16:53:27 | I | collecting info in model.layers.0
24-11-25 16:53:27 | I | collecting info in model.layers.0
24-11-25 16:53:27 | I | collecting info in model.layers.0
24-11-25 16:53:27 | I | collecting calibration activations in model.layers.0
24-11-25 16:53:27 | I | collecting calibration activations in model.layers.0
24-11-25 16:53:28 | I | collecting calibration activations in model.layers.0
24-11-25 16:53:28 | I | collecting calibration activations in model.layers.0
24-11-25 16:53:28 | I | - Quantizing decoder layer model.layers.0
24-11-25 16:53:28 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 16:53:29 | I |       - range scale = [    1.0000]
24-11-25 16:53:29 | I |         sum  error  = [    0.0625]
24-11-25 16:53:29 | I |         best error  = [    0.0625]
24-11-25 16:53:29 | I |     + error = [0.0625]
24-11-25 16:53:29 | I |       - range scale = [    1.0000]
24-11-25 16:53:29 | I |         sum  error  = [    0.6147]
24-11-25 16:53:29 | I |         best error  = [    0.6147]
24-11-25 16:53:29 | I |     + error = [0.6147]
24-11-25 16:53:30 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 16:53:30 | I |       - range scale = [    1.0000]
24-11-25 16:53:30 | I |         sum  error  = [    0.0630]
24-11-25 16:53:30 | I |         best error  = [    0.0630]
24-11-25 16:53:30 | I |     + error = [0.0630]
24-11-25 16:53:31 | I |       - range scale = [    1.0000]
24-11-25 16:53:31 | I |         sum  error  = [    0.5393]
24-11-25 16:53:31 | I |         best error  = [    0.5393]
24-11-25 16:53:31 | I |     + error = [0.5393]
24-11-25 16:53:31 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 16:53:32 | I |       - range scale = [    1.0000]
24-11-25 16:53:32 | I |         sum  error  = [    0.2326]
24-11-25 16:53:32 | I |         best error  = [    0.2326]
24-11-25 16:53:32 | I |     + error = [0.2326]
24-11-25 16:53:33 | I |       - range scale = [    1.0000]
24-11-25 16:53:33 | I |         sum  error  = [    1.7760]
24-11-25 16:53:33 | I |         best error  = [    1.7760]
24-11-25 16:53:33 | I |     + error = [1.7760]
24-11-25 16:53:33 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 16:53:33 | I |       - range scale = [    1.0000]
24-11-25 16:53:33 | I |         sum  error  = [    0.0632]
24-11-25 16:53:33 | I |         best error  = [    0.0632]
24-11-25 16:53:33 | I |     + error = [0.0632]
24-11-25 16:53:34 | I |       - range scale = [    1.0000]
24-11-25 16:53:34 | I |         sum  error  = [    0.6197]
24-11-25 16:53:34 | I |         best error  = [    0.6197]
24-11-25 16:53:34 | I |     + error = [0.6197]
24-11-25 16:53:34 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 16:53:35 | I |       - range scale = [    1.0000]
24-11-25 16:53:35 | I |         sum  error  = [    1.1559]
24-11-25 16:53:35 | I |         best error  = [    1.1559]
24-11-25 16:53:35 | I |     + error = [1.1559]
24-11-25 16:53:36 | I |       - range scale = [    1.0000]
24-11-25 16:53:36 | I |         sum  error  = [   12.8070]
24-11-25 16:53:36 | I |         best error  = [   12.8070]
24-11-25 16:53:36 | I |     + error = [12.8070]
24-11-25 16:53:36 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 16:53:37 | I |       - range scale = [    1.0000]
24-11-25 16:53:37 | I |         sum  error  = [    1.3371]
24-11-25 16:53:37 | I |         best error  = [    1.3371]
24-11-25 16:53:37 | I |     + error = [1.3371]
24-11-25 16:53:37 | I |       - range scale = [    1.0000]
24-11-25 16:53:37 | I |         sum  error  = [   13.2891]
24-11-25 16:53:37 | I |         best error  = [   13.2891]
24-11-25 16:53:37 | I |     + error = [13.2891]
24-11-25 16:53:38 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 16:53:38 | I |       - range scale = [    1.0000]
24-11-25 16:53:38 | I |         sum  error  = [    2.4559]
24-11-25 16:53:38 | I |         best error  = [    2.4559]
24-11-25 16:53:38 | I |     + error = [2.4559]
24-11-25 16:53:39 | I |       - range scale = [    1.0000]
24-11-25 16:53:39 | I |         sum  error  = [   13.2330]
24-11-25 16:53:39 | I |         best error  = [   13.2330]
24-11-25 16:53:39 | I |     + error = [13.2330]
24-11-25 16:53:39 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 16:53:41 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 16:53:42 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 16:53:44 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 16:53:45 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 16:53:46 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 16:53:48 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 16:53:51 | I | quantizing activations for layer model.layers.0
24-11-25 16:53:51 | I | collecting info in model.layers.0
24-11-25 16:53:51 | I | collecting info in model.layers.0
24-11-25 16:53:51 | I | collecting info in model.layers.0
24-11-25 16:53:51 | I | collecting info in model.layers.0
24-11-25 16:53:52 | I | collecting calibration activations in model.layers.0
24-11-25 16:53:52 | I | collecting calibration activations in model.layers.0
24-11-25 16:53:52 | I | collecting calibration activations in model.layers.0
24-11-25 16:53:52 | I | collecting calibration activations in model.layers.0
24-11-25 16:53:54 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 16:53:54 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 16:53:54 | I | - Evaluator: gptq
24-11-25 16:53:54 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 16:53:54 | I | - Batch_size: 8
24-11-25 16:53:54 | I |   + Max_seq_length: 2048
24-11-25 16:54:35 | I |     - Results:
24-11-25 16:54:35 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 16:54:35 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 16:54:35 | I |       |wikitext |      1|word_perplexity|7.7720|  |7.7720|
24-11-25 16:54:35 | I |       |val_valid|      1|word_perplexity|9.0473|  |9.0473|
24-11-25 16:54:35 | I |       
24-11-25 16:54:35 | I | forward this layer
24-11-25 16:54:35 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/62.pt
24-11-25 16:54:35 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/62.pt
24-11-25 16:54:35 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 16:54:35 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 16:54:35 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 16:54:35 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 16:54:35 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 16:54:35 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 16:54:35 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 16:54:35 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 16:54:35 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 16:54:35 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 16:54:35 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 16:54:35 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 16:54:35 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 16:54:35 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 16:54:35 | I | in layer model.layers.0
24-11-25 16:54:35 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 16:54:35 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 16:54:35 | I | - Evaluator: gptq
24-11-25 16:54:35 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 16:54:35 | I | - Batch_size: 8
24-11-25 16:54:35 | I |   + Max_seq_length: 2048
24-11-25 16:55:13 | I |     - Results:
24-11-25 16:55:13 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 16:55:13 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 16:55:13 | I |       |wikitext |      1|word_perplexity|7.7339|  |7.7339|
24-11-25 16:55:13 | I |       |val_valid|      1|word_perplexity|8.9894|  |8.9894|
24-11-25 16:55:13 | I |       
24-11-25 16:55:13 | I | quantizing weights for layer model.layers.0
24-11-25 16:55:13 | I | collecting info in model.layers.0
24-11-25 16:55:13 | I | collecting info in model.layers.0
24-11-25 16:55:13 | I | collecting info in model.layers.0
24-11-25 16:55:13 | I | collecting info in model.layers.0
24-11-25 16:55:14 | I | collecting calibration activations in model.layers.0
24-11-25 16:55:14 | I | collecting calibration activations in model.layers.0
24-11-25 16:55:14 | I | collecting calibration activations in model.layers.0
24-11-25 16:55:14 | I | collecting calibration activations in model.layers.0
24-11-25 16:55:15 | I | - Quantizing decoder layer model.layers.0
24-11-25 16:55:15 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 16:55:15 | I |       - range scale = [    1.0000]
24-11-25 16:55:15 | I |         sum  error  = [    0.0646]
24-11-25 16:55:15 | I |         best error  = [    0.0646]
24-11-25 16:55:15 | I |     + error = [0.0646]
24-11-25 16:55:16 | I |       - range scale = [    1.0000]
24-11-25 16:55:16 | I |         sum  error  = [    0.6209]
24-11-25 16:55:16 | I |         best error  = [    0.6209]
24-11-25 16:55:16 | I |     + error = [0.6209]
24-11-25 16:55:16 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 16:55:17 | I |       - range scale = [    1.0000]
24-11-25 16:55:17 | I |         sum  error  = [    0.0632]
24-11-25 16:55:17 | I |         best error  = [    0.0632]
24-11-25 16:55:17 | I |     + error = [0.0632]
24-11-25 16:55:18 | I |       - range scale = [    1.0000]
24-11-25 16:55:18 | I |         sum  error  = [    0.5373]
24-11-25 16:55:18 | I |         best error  = [    0.5373]
24-11-25 16:55:18 | I |     + error = [0.5373]
24-11-25 16:55:18 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 16:55:19 | I |       - range scale = [    1.0000]
24-11-25 16:55:19 | I |         sum  error  = [    0.2414]
24-11-25 16:55:19 | I |         best error  = [    0.2414]
24-11-25 16:55:19 | I |     + error = [0.2414]
24-11-25 16:55:19 | I |       - range scale = [    1.0000]
24-11-25 16:55:19 | I |         sum  error  = [    1.8053]
24-11-25 16:55:19 | I |         best error  = [    1.8053]
24-11-25 16:55:19 | I |     + error = [1.8053]
24-11-25 16:55:19 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 16:55:20 | I |       - range scale = [    1.0000]
24-11-25 16:55:20 | I |         sum  error  = [    0.0656]
24-11-25 16:55:20 | I |         best error  = [    0.0656]
24-11-25 16:55:20 | I |     + error = [0.0656]
24-11-25 16:55:21 | I |       - range scale = [    1.0000]
24-11-25 16:55:21 | I |         sum  error  = [    0.6403]
24-11-25 16:55:21 | I |         best error  = [    0.6403]
24-11-25 16:55:21 | I |     + error = [0.6403]
24-11-25 16:55:21 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 16:55:22 | I |       - range scale = [    1.0000]
24-11-25 16:55:22 | I |         sum  error  = [    1.1083]
24-11-25 16:55:22 | I |         best error  = [    1.1083]
24-11-25 16:55:22 | I |     + error = [1.1083]
24-11-25 16:55:22 | I |       - range scale = [    1.0000]
24-11-25 16:55:22 | I |         sum  error  = [   12.2657]
24-11-25 16:55:22 | I |         best error  = [   12.2657]
24-11-25 16:55:22 | I |     + error = [12.2657]
24-11-25 16:55:23 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 16:55:23 | I |       - range scale = [    1.0000]
24-11-25 16:55:23 | I |         sum  error  = [    1.2809]
24-11-25 16:55:23 | I |         best error  = [    1.2809]
24-11-25 16:55:23 | I |     + error = [1.2809]
24-11-25 16:55:24 | I |       - range scale = [    1.0000]
24-11-25 16:55:24 | I |         sum  error  = [   12.7123]
24-11-25 16:55:24 | I |         best error  = [   12.7123]
24-11-25 16:55:24 | I |     + error = [12.7123]
24-11-25 16:55:24 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 16:55:25 | I |       - range scale = [    1.0000]
24-11-25 16:55:25 | I |         sum  error  = [    2.7319]
24-11-25 16:55:25 | I |         best error  = [    2.7319]
24-11-25 16:55:25 | I |     + error = [2.7319]
24-11-25 16:55:26 | I |       - range scale = [    1.0000]
24-11-25 16:55:26 | I |         sum  error  = [   13.8791]
24-11-25 16:55:26 | I |         best error  = [   13.8791]
24-11-25 16:55:26 | I |     + error = [13.8791]
24-11-25 16:55:26 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 16:55:27 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 16:55:29 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 16:55:30 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 16:55:32 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 16:55:33 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 16:55:34 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 16:55:38 | I | quantizing activations for layer model.layers.0
24-11-25 16:55:38 | I | collecting info in model.layers.0
24-11-25 16:55:38 | I | collecting info in model.layers.0
24-11-25 16:55:38 | I | collecting info in model.layers.0
24-11-25 16:55:38 | I | collecting info in model.layers.0
24-11-25 16:55:38 | I | collecting calibration activations in model.layers.0
24-11-25 16:55:38 | I | collecting calibration activations in model.layers.0
24-11-25 16:55:38 | I | collecting calibration activations in model.layers.0
24-11-25 16:55:39 | I | collecting calibration activations in model.layers.0
24-11-25 16:55:40 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 16:55:40 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 16:55:40 | I | - Evaluator: gptq
24-11-25 16:55:40 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 16:55:40 | I | - Batch_size: 8
24-11-25 16:55:40 | I |   + Max_seq_length: 2048
24-11-25 16:56:22 | I |     - Results:
24-11-25 16:56:22 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 16:56:22 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 16:56:22 | I |       |wikitext |      1|word_perplexity|7.7883|  |7.7883|
24-11-25 16:56:22 | I |       |val_valid|      1|word_perplexity|9.0480|  |9.0480|
24-11-25 16:56:22 | I |       
24-11-25 16:56:22 | I | forward this layer
24-11-25 16:56:22 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/63.pt
24-11-25 16:56:22 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/63.pt
24-11-25 16:56:22 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 16:56:22 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 16:56:22 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 16:56:22 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 16:56:22 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 16:56:22 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 16:56:22 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 16:56:22 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 16:56:22 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 16:56:22 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 16:56:22 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 16:56:22 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 16:56:22 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 16:56:22 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 16:56:22 | I | [17] done with optimizer step
24-11-25 16:56:22 | I | epoch 001:     32 / 409600000 loss=0.000203276, loss_per_token=0.416309, loss_sum=13641.6, wps=153.4, ups=0, wpb=32768, bsz=64, num_updates=18, lr=5.4e-05, gnorm=49.915, clip=100, loss_scale=0.0078, train_wall=213, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=7112, lmquant_ppl_result_wikitext_in_train_no_quant=7.73395, lmquant_ppl_result_val_in_train_no_quant=8.98936, lmquant_ppl_result_wikitext_in_train_with_quant=7.78827, lmquant_ppl_result_val_in_train_with_quant=9.04796
24-11-25 16:56:22 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 16:56:22 | I | in layer model.layers.0
24-11-25 16:56:22 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 16:56:22 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 16:56:22 | I | - Evaluator: gptq
24-11-25 16:56:22 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 16:56:22 | I | - Batch_size: 8
24-11-25 16:56:22 | I |   + Max_seq_length: 2048
24-11-25 16:57:01 | I |     - Results:
24-11-25 16:57:01 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 16:57:01 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 16:57:01 | I |       |wikitext |      1|word_perplexity|7.7371|  |7.7371|
24-11-25 16:57:01 | I |       |val_valid|      1|word_perplexity|8.9916|  |8.9916|
24-11-25 16:57:01 | I |       
24-11-25 16:57:01 | I | quantizing weights for layer model.layers.0
24-11-25 16:57:01 | I | collecting info in model.layers.0
24-11-25 16:57:01 | I | collecting info in model.layers.0
24-11-25 16:57:01 | I | collecting info in model.layers.0
24-11-25 16:57:01 | I | collecting info in model.layers.0
24-11-25 16:57:01 | I | collecting calibration activations in model.layers.0
24-11-25 16:57:01 | I | collecting calibration activations in model.layers.0
24-11-25 16:57:01 | I | collecting calibration activations in model.layers.0
24-11-25 16:57:01 | I | collecting calibration activations in model.layers.0
24-11-25 16:57:02 | I | - Quantizing decoder layer model.layers.0
24-11-25 16:57:02 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 16:57:02 | I |       - range scale = [    1.0000]
24-11-25 16:57:02 | I |         sum  error  = [    0.0647]
24-11-25 16:57:02 | I |         best error  = [    0.0647]
24-11-25 16:57:02 | I |     + error = [0.0647]
24-11-25 16:57:03 | I |       - range scale = [    1.0000]
24-11-25 16:57:03 | I |         sum  error  = [    0.6385]
24-11-25 16:57:03 | I |         best error  = [    0.6385]
24-11-25 16:57:03 | I |     + error = [0.6385]
24-11-25 16:57:03 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 16:57:04 | I |       - range scale = [    1.0000]
24-11-25 16:57:04 | I |         sum  error  = [    0.0649]
24-11-25 16:57:04 | I |         best error  = [    0.0649]
24-11-25 16:57:04 | I |     + error = [0.0649]
24-11-25 16:57:05 | I |       - range scale = [    1.0000]
24-11-25 16:57:05 | I |         sum  error  = [    0.5407]
24-11-25 16:57:05 | I |         best error  = [    0.5407]
24-11-25 16:57:05 | I |     + error = [0.5407]
24-11-25 16:57:05 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 16:57:06 | I |       - range scale = [    1.0000]
24-11-25 16:57:06 | I |         sum  error  = [    0.2422]
24-11-25 16:57:06 | I |         best error  = [    0.2422]
24-11-25 16:57:06 | I |     + error = [0.2422]
24-11-25 16:57:06 | I |       - range scale = [    1.0000]
24-11-25 16:57:06 | I |         sum  error  = [    1.8170]
24-11-25 16:57:06 | I |         best error  = [    1.8170]
24-11-25 16:57:06 | I |     + error = [1.8170]
24-11-25 16:57:07 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 16:57:07 | I |       - range scale = [    1.0000]
24-11-25 16:57:07 | I |         sum  error  = [    0.0625]
24-11-25 16:57:07 | I |         best error  = [    0.0625]
24-11-25 16:57:07 | I |     + error = [0.0625]
24-11-25 16:57:08 | I |       - range scale = [    1.0000]
24-11-25 16:57:08 | I |         sum  error  = [    0.6054]
24-11-25 16:57:08 | I |         best error  = [    0.6054]
24-11-25 16:57:08 | I |     + error = [0.6054]
24-11-25 16:57:08 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 16:57:09 | I |       - range scale = [    1.0000]
24-11-25 16:57:09 | I |         sum  error  = [    1.0607]
24-11-25 16:57:09 | I |         best error  = [    1.0607]
24-11-25 16:57:09 | I |     + error = [1.0607]
24-11-25 16:57:10 | I |       - range scale = [    1.0000]
24-11-25 16:57:10 | I |         sum  error  = [   11.7537]
24-11-25 16:57:10 | I |         best error  = [   11.7537]
24-11-25 16:57:10 | I |     + error = [11.7537]
24-11-25 16:57:10 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 16:57:11 | I |       - range scale = [    1.0000]
24-11-25 16:57:11 | I |         sum  error  = [    1.2277]
24-11-25 16:57:11 | I |         best error  = [    1.2277]
24-11-25 16:57:11 | I |     + error = [1.2277]
24-11-25 16:57:11 | I |       - range scale = [    1.0000]
24-11-25 16:57:11 | I |         sum  error  = [   12.1544]
24-11-25 16:57:11 | I |         best error  = [   12.1544]
24-11-25 16:57:11 | I |     + error = [12.1544]
24-11-25 16:57:12 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 16:57:12 | I |       - range scale = [    1.0000]
24-11-25 16:57:12 | I |         sum  error  = [    2.9047]
24-11-25 16:57:12 | I |         best error  = [    2.9047]
24-11-25 16:57:12 | I |     + error = [2.9047]
24-11-25 16:57:13 | I |       - range scale = [    1.0000]
24-11-25 16:57:13 | I |         sum  error  = [   15.4567]
24-11-25 16:57:13 | I |         best error  = [   15.4567]
24-11-25 16:57:13 | I |     + error = [15.4567]
24-11-25 16:57:13 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 16:57:15 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 16:57:16 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 16:57:17 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 16:57:19 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 16:57:20 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 16:57:22 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 16:57:25 | I | quantizing activations for layer model.layers.0
24-11-25 16:57:25 | I | collecting info in model.layers.0
24-11-25 16:57:25 | I | collecting info in model.layers.0
24-11-25 16:57:25 | I | collecting info in model.layers.0
24-11-25 16:57:25 | I | collecting info in model.layers.0
24-11-25 16:57:25 | I | collecting calibration activations in model.layers.0
24-11-25 16:57:25 | I | collecting calibration activations in model.layers.0
24-11-25 16:57:26 | I | collecting calibration activations in model.layers.0
24-11-25 16:57:26 | I | collecting calibration activations in model.layers.0
24-11-25 16:57:28 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 16:57:28 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 16:57:28 | I | - Evaluator: gptq
24-11-25 16:57:28 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 16:57:28 | I | - Batch_size: 8
24-11-25 16:57:28 | I |   + Max_seq_length: 2048
24-11-25 16:58:09 | I |     - Results:
24-11-25 16:58:09 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 16:58:09 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 16:58:09 | I |       |wikitext |      1|word_perplexity|7.7797|  |7.7797|
24-11-25 16:58:09 | I |       |val_valid|      1|word_perplexity|9.0502|  |9.0502|
24-11-25 16:58:09 | I |       
24-11-25 16:58:09 | I | forward this layer
24-11-25 16:58:09 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/64.pt
24-11-25 16:58:09 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/64.pt
24-11-25 16:58:09 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 16:58:09 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 16:58:09 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 16:58:09 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 16:58:09 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 16:58:09 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 16:58:09 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 16:58:09 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 16:58:09 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 16:58:09 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 16:58:09 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 16:58:09 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 16:58:09 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 16:58:09 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 16:58:09 | I | in layer model.layers.0
24-11-25 16:58:09 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 16:58:09 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 16:58:09 | I | - Evaluator: gptq
24-11-25 16:58:09 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 16:58:09 | I | - Batch_size: 8
24-11-25 16:58:09 | I |   + Max_seq_length: 2048
24-11-25 16:58:47 | I |     - Results:
24-11-25 16:58:48 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 16:58:48 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 16:58:48 | I |       |wikitext |      1|word_perplexity|7.7371|  |7.7371|
24-11-25 16:58:48 | I |       |val_valid|      1|word_perplexity|8.9916|  |8.9916|
24-11-25 16:58:48 | I |       
24-11-25 16:58:48 | I | quantizing weights for layer model.layers.0
24-11-25 16:58:48 | I | collecting info in model.layers.0
24-11-25 16:58:48 | I | collecting info in model.layers.0
24-11-25 16:58:48 | I | collecting info in model.layers.0
24-11-25 16:58:48 | I | collecting info in model.layers.0
24-11-25 16:58:48 | I | collecting calibration activations in model.layers.0
24-11-25 16:58:48 | I | collecting calibration activations in model.layers.0
24-11-25 16:58:48 | I | collecting calibration activations in model.layers.0
24-11-25 16:58:48 | I | collecting calibration activations in model.layers.0
24-11-25 16:58:49 | I | - Quantizing decoder layer model.layers.0
24-11-25 16:58:49 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 16:58:49 | I |       - range scale = [    1.0000]
24-11-25 16:58:49 | I |         sum  error  = [    0.0619]
24-11-25 16:58:49 | I |         best error  = [    0.0619]
24-11-25 16:58:49 | I |     + error = [0.0619]
24-11-25 16:58:50 | I |       - range scale = [    1.0000]
24-11-25 16:58:50 | I |         sum  error  = [    0.6205]
24-11-25 16:58:50 | I |         best error  = [    0.6205]
24-11-25 16:58:50 | I |     + error = [0.6205]
24-11-25 16:58:50 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 16:58:51 | I |       - range scale = [    1.0000]
24-11-25 16:58:51 | I |         sum  error  = [    0.0613]
24-11-25 16:58:51 | I |         best error  = [    0.0613]
24-11-25 16:58:51 | I |     + error = [0.0613]
24-11-25 16:58:52 | I |       - range scale = [    1.0000]
24-11-25 16:58:52 | I |         sum  error  = [    0.5123]
24-11-25 16:58:52 | I |         best error  = [    0.5123]
24-11-25 16:58:52 | I |     + error = [0.5123]
24-11-25 16:58:52 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 16:58:53 | I |       - range scale = [    1.0000]
24-11-25 16:58:53 | I |         sum  error  = [    0.2384]
24-11-25 16:58:53 | I |         best error  = [    0.2384]
24-11-25 16:58:53 | I |     + error = [0.2384]
24-11-25 16:58:53 | I |       - range scale = [    1.0000]
24-11-25 16:58:53 | I |         sum  error  = [    1.7964]
24-11-25 16:58:53 | I |         best error  = [    1.7964]
24-11-25 16:58:53 | I |     + error = [1.7964]
24-11-25 16:58:53 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 16:58:54 | I |       - range scale = [    1.0000]
24-11-25 16:58:54 | I |         sum  error  = [    0.0593]
24-11-25 16:58:54 | I |         best error  = [    0.0593]
24-11-25 16:58:54 | I |     + error = [0.0593]
24-11-25 16:58:55 | I |       - range scale = [    1.0000]
24-11-25 16:58:55 | I |         sum  error  = [    0.5712]
24-11-25 16:58:55 | I |         best error  = [    0.5712]
24-11-25 16:58:55 | I |     + error = [0.5712]
24-11-25 16:58:55 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 16:58:56 | I |       - range scale = [    1.0000]
24-11-25 16:58:56 | I |         sum  error  = [    1.0664]
24-11-25 16:58:56 | I |         best error  = [    1.0664]
24-11-25 16:58:56 | I |     + error = [1.0664]
24-11-25 16:58:56 | I |       - range scale = [    1.0000]
24-11-25 16:58:56 | I |         sum  error  = [   11.8296]
24-11-25 16:58:56 | I |         best error  = [   11.8296]
24-11-25 16:58:56 | I |     + error = [11.8296]
24-11-25 16:58:57 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 16:58:57 | I |       - range scale = [    1.0000]
24-11-25 16:58:57 | I |         sum  error  = [    1.2353]
24-11-25 16:58:57 | I |         best error  = [    1.2353]
24-11-25 16:58:57 | I |     + error = [1.2353]
24-11-25 16:58:58 | I |       - range scale = [    1.0000]
24-11-25 16:58:58 | I |         sum  error  = [   12.2153]
24-11-25 16:58:58 | I |         best error  = [   12.2153]
24-11-25 16:58:58 | I |     + error = [12.2153]
24-11-25 16:58:58 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 16:58:59 | I |       - range scale = [    1.0000]
24-11-25 16:58:59 | I |         sum  error  = [    3.3927]
24-11-25 16:58:59 | I |         best error  = [    3.3927]
24-11-25 16:58:59 | I |     + error = [3.3927]
24-11-25 16:59:00 | I |       - range scale = [    1.0000]
24-11-25 16:59:00 | I |         sum  error  = [   18.0211]
24-11-25 16:59:00 | I |         best error  = [   18.0211]
24-11-25 16:59:00 | I |     + error = [18.0211]
24-11-25 16:59:00 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 16:59:01 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 16:59:03 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 16:59:04 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 16:59:06 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 16:59:07 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 16:59:08 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 16:59:12 | I | quantizing activations for layer model.layers.0
24-11-25 16:59:12 | I | collecting info in model.layers.0
24-11-25 16:59:12 | I | collecting info in model.layers.0
24-11-25 16:59:12 | I | collecting info in model.layers.0
24-11-25 16:59:12 | I | collecting info in model.layers.0
24-11-25 16:59:12 | I | collecting calibration activations in model.layers.0
24-11-25 16:59:12 | I | collecting calibration activations in model.layers.0
24-11-25 16:59:13 | I | collecting calibration activations in model.layers.0
24-11-25 16:59:13 | I | collecting calibration activations in model.layers.0
24-11-25 16:59:14 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 16:59:15 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 16:59:15 | I | - Evaluator: gptq
24-11-25 16:59:15 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 16:59:15 | I | - Batch_size: 8
24-11-25 16:59:15 | I |   + Max_seq_length: 2048
24-11-25 16:59:57 | I |     - Results:
24-11-25 16:59:57 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 16:59:57 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 16:59:57 | I |       |wikitext |      1|word_perplexity|7.7831|  |7.7831|
24-11-25 16:59:57 | I |       |val_valid|      1|word_perplexity|9.0501|  |9.0501|
24-11-25 16:59:57 | I |       
24-11-25 16:59:57 | I | forward this layer
24-11-25 16:59:57 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/65.pt
24-11-25 16:59:57 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/65.pt
24-11-25 16:59:57 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 16:59:57 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 16:59:57 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 16:59:57 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 16:59:57 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 16:59:57 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 16:59:57 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 16:59:57 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 16:59:57 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 16:59:57 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 16:59:57 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 16:59:57 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 16:59:57 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 16:59:57 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 16:59:57 | I | [18] done with optimizer step
24-11-25 16:59:57 | I | epoch 001:     33 / 409600000 loss=0.000361311, loss_per_token=0.739965, loss_sum=24247.2, wps=152.6, ups=0, wpb=32768, bsz=64, num_updates=19, lr=5.7e-05, gnorm=45.928, clip=100, loss_scale=0.0078, train_wall=215, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=7327, lmquant_ppl_result_wikitext_in_train_no_quant=7.73706, lmquant_ppl_result_val_in_train_no_quant=8.99158, lmquant_ppl_result_wikitext_in_train_with_quant=7.78315, lmquant_ppl_result_val_in_train_with_quant=9.0501
24-11-25 16:59:57 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 16:59:57 | I | in layer model.layers.0
24-11-25 16:59:57 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 16:59:57 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 16:59:57 | I | - Evaluator: gptq
24-11-25 16:59:57 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 16:59:57 | I | - Batch_size: 8
24-11-25 16:59:57 | I |   + Max_seq_length: 2048
24-11-25 17:00:35 | I |     - Results:
24-11-25 17:00:35 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 17:00:35 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 17:00:35 | I |       |wikitext |      1|word_perplexity|7.7407|  |7.7407|
24-11-25 17:00:35 | I |       |val_valid|      1|word_perplexity|8.9944|  |8.9944|
24-11-25 17:00:35 | I |       
24-11-25 17:00:35 | I | quantizing weights for layer model.layers.0
24-11-25 17:00:35 | I | collecting info in model.layers.0
24-11-25 17:00:35 | I | collecting info in model.layers.0
24-11-25 17:00:35 | I | collecting info in model.layers.0
24-11-25 17:00:35 | I | collecting info in model.layers.0
24-11-25 17:00:36 | I | collecting calibration activations in model.layers.0
24-11-25 17:00:36 | I | collecting calibration activations in model.layers.0
24-11-25 17:00:36 | I | collecting calibration activations in model.layers.0
24-11-25 17:00:36 | I | collecting calibration activations in model.layers.0
24-11-25 17:00:36 | I | - Quantizing decoder layer model.layers.0
24-11-25 17:00:36 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 17:00:37 | I |       - range scale = [    1.0000]
24-11-25 17:00:37 | I |         sum  error  = [    0.0619]
24-11-25 17:00:37 | I |         best error  = [    0.0619]
24-11-25 17:00:37 | I |     + error = [0.0619]
24-11-25 17:00:38 | I |       - range scale = [    1.0000]
24-11-25 17:00:38 | I |         sum  error  = [    0.6080]
24-11-25 17:00:38 | I |         best error  = [    0.6080]
24-11-25 17:00:38 | I |     + error = [0.6080]
24-11-25 17:00:38 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 17:00:39 | I |       - range scale = [    1.0000]
24-11-25 17:00:39 | I |         sum  error  = [    0.0662]
24-11-25 17:00:39 | I |         best error  = [    0.0662]
24-11-25 17:00:39 | I |     + error = [0.0662]
24-11-25 17:00:39 | I |       - range scale = [    1.0000]
24-11-25 17:00:39 | I |         sum  error  = [    0.5120]
24-11-25 17:00:39 | I |         best error  = [    0.5120]
24-11-25 17:00:39 | I |     + error = [0.5120]
24-11-25 17:00:40 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 17:00:40 | I |       - range scale = [    1.0000]
24-11-25 17:00:40 | I |         sum  error  = [    0.2361]
24-11-25 17:00:40 | I |         best error  = [    0.2361]
24-11-25 17:00:40 | I |     + error = [0.2361]
24-11-25 17:00:41 | I |       - range scale = [    1.0000]
24-11-25 17:00:41 | I |         sum  error  = [    1.7510]
24-11-25 17:00:41 | I |         best error  = [    1.7510]
24-11-25 17:00:41 | I |     + error = [1.7510]
24-11-25 17:00:41 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 17:00:42 | I |       - range scale = [    1.0000]
24-11-25 17:00:42 | I |         sum  error  = [    0.0557]
24-11-25 17:00:42 | I |         best error  = [    0.0557]
24-11-25 17:00:42 | I |     + error = [0.0557]
24-11-25 17:00:43 | I |       - range scale = [    1.0000]
24-11-25 17:00:43 | I |         sum  error  = [    0.5392]
24-11-25 17:00:43 | I |         best error  = [    0.5392]
24-11-25 17:00:43 | I |     + error = [0.5392]
24-11-25 17:00:43 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 17:00:43 | I |       - range scale = [    1.0000]
24-11-25 17:00:43 | I |         sum  error  = [    1.0605]
24-11-25 17:00:43 | I |         best error  = [    1.0605]
24-11-25 17:00:43 | I |     + error = [1.0605]
24-11-25 17:00:44 | I |       - range scale = [    1.0000]
24-11-25 17:00:44 | I |         sum  error  = [   11.7433]
24-11-25 17:00:44 | I |         best error  = [   11.7433]
24-11-25 17:00:44 | I |     + error = [11.7433]
24-11-25 17:00:44 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 17:00:45 | I |       - range scale = [    1.0000]
24-11-25 17:00:45 | I |         sum  error  = [    1.2289]
24-11-25 17:00:45 | I |         best error  = [    1.2289]
24-11-25 17:00:45 | I |     + error = [1.2289]
24-11-25 17:00:46 | I |       - range scale = [    1.0000]
24-11-25 17:00:46 | I |         sum  error  = [   12.1336]
24-11-25 17:00:46 | I |         best error  = [   12.1336]
24-11-25 17:00:46 | I |     + error = [12.1336]
24-11-25 17:00:46 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 17:00:47 | I |       - range scale = [    1.0000]
24-11-25 17:00:47 | I |         sum  error  = [    3.0487]
24-11-25 17:00:47 | I |         best error  = [    3.0487]
24-11-25 17:00:47 | I |     + error = [3.0487]
24-11-25 17:00:47 | I |       - range scale = [    1.0000]
24-11-25 17:00:47 | I |         sum  error  = [   16.7031]
24-11-25 17:00:47 | I |         best error  = [   16.7031]
24-11-25 17:00:47 | I |     + error = [16.7031]
24-11-25 17:00:48 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 17:00:49 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 17:00:51 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 17:00:53 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 17:00:54 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 17:00:56 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 17:00:58 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 17:01:02 | I | quantizing activations for layer model.layers.0
24-11-25 17:01:02 | I | collecting info in model.layers.0
24-11-25 17:01:02 | I | collecting info in model.layers.0
24-11-25 17:01:02 | I | collecting info in model.layers.0
24-11-25 17:01:02 | I | collecting info in model.layers.0
24-11-25 17:01:02 | I | collecting calibration activations in model.layers.0
24-11-25 17:01:03 | I | collecting calibration activations in model.layers.0
24-11-25 17:01:03 | I | collecting calibration activations in model.layers.0
24-11-25 17:01:03 | I | collecting calibration activations in model.layers.0
24-11-25 17:01:05 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 17:01:05 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 17:01:05 | I | - Evaluator: gptq
24-11-25 17:01:05 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 17:01:05 | I | - Batch_size: 8
24-11-25 17:01:05 | I |   + Max_seq_length: 2048
24-11-25 17:01:47 | I |     - Results:
24-11-25 17:01:47 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 17:01:47 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 17:01:47 | I |       |wikitext |      1|word_perplexity|7.7717|  |7.7717|
24-11-25 17:01:47 | I |       |val_valid|      1|word_perplexity|9.0460|  |9.0460|
24-11-25 17:01:47 | I |       
24-11-25 17:01:47 | I | forward this layer
24-11-25 17:01:47 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/66.pt
24-11-25 17:01:47 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/66.pt
24-11-25 17:01:47 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 17:01:47 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 17:01:47 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 17:01:47 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 17:01:47 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 17:01:47 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 17:01:47 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 17:01:47 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 17:01:47 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 17:01:47 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 17:01:47 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 17:01:47 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 17:01:47 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 17:01:47 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 17:01:47 | I | in layer model.layers.0
24-11-25 17:01:47 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 17:01:47 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 17:01:47 | I | - Evaluator: gptq
24-11-25 17:01:47 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 17:01:47 | I | - Batch_size: 8
24-11-25 17:01:47 | I |   + Max_seq_length: 2048
24-11-25 17:02:25 | I |     - Results:
24-11-25 17:02:25 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 17:02:25 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 17:02:25 | I |       |wikitext |      1|word_perplexity|7.7407|  |7.7407|
24-11-25 17:02:25 | I |       |val_valid|      1|word_perplexity|8.9944|  |8.9944|
24-11-25 17:02:25 | I |       
24-11-25 17:02:25 | I | quantizing weights for layer model.layers.0
24-11-25 17:02:25 | I | collecting info in model.layers.0
24-11-25 17:02:25 | I | collecting info in model.layers.0
24-11-25 17:02:25 | I | collecting info in model.layers.0
24-11-25 17:02:25 | I | collecting info in model.layers.0
24-11-25 17:02:26 | I | collecting calibration activations in model.layers.0
24-11-25 17:02:26 | I | collecting calibration activations in model.layers.0
24-11-25 17:02:26 | I | collecting calibration activations in model.layers.0
24-11-25 17:02:26 | I | collecting calibration activations in model.layers.0
24-11-25 17:02:26 | I | - Quantizing decoder layer model.layers.0
24-11-25 17:02:26 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 17:02:27 | I |       - range scale = [    1.0000]
24-11-25 17:02:27 | I |         sum  error  = [    0.0625]
24-11-25 17:02:27 | I |         best error  = [    0.0625]
24-11-25 17:02:27 | I |     + error = [0.0625]
24-11-25 17:02:28 | I |       - range scale = [    1.0000]
24-11-25 17:02:28 | I |         sum  error  = [    0.6066]
24-11-25 17:02:28 | I |         best error  = [    0.6066]
24-11-25 17:02:28 | I |     + error = [0.6066]
24-11-25 17:02:28 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 17:02:29 | I |       - range scale = [    1.0000]
24-11-25 17:02:29 | I |         sum  error  = [    0.0667]
24-11-25 17:02:29 | I |         best error  = [    0.0667]
24-11-25 17:02:29 | I |     + error = [0.0667]
24-11-25 17:02:29 | I |       - range scale = [    1.0000]
24-11-25 17:02:29 | I |         sum  error  = [    0.5174]
24-11-25 17:02:29 | I |         best error  = [    0.5174]
24-11-25 17:02:29 | I |     + error = [0.5174]
24-11-25 17:02:30 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 17:02:30 | I |       - range scale = [    1.0000]
24-11-25 17:02:30 | I |         sum  error  = [    0.2386]
24-11-25 17:02:30 | I |         best error  = [    0.2386]
24-11-25 17:02:30 | I |     + error = [0.2386]
24-11-25 17:02:31 | I |       - range scale = [    1.0000]
24-11-25 17:02:31 | I |         sum  error  = [    1.7985]
24-11-25 17:02:31 | I |         best error  = [    1.7985]
24-11-25 17:02:31 | I |     + error = [1.7985]
24-11-25 17:02:31 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 17:02:32 | I |       - range scale = [    1.0000]
24-11-25 17:02:32 | I |         sum  error  = [    0.0622]
24-11-25 17:02:32 | I |         best error  = [    0.0622]
24-11-25 17:02:32 | I |     + error = [0.0622]
24-11-25 17:02:32 | I |       - range scale = [    1.0000]
24-11-25 17:02:32 | I |         sum  error  = [    0.6002]
24-11-25 17:02:32 | I |         best error  = [    0.6002]
24-11-25 17:02:32 | I |     + error = [0.6002]
24-11-25 17:02:33 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 17:02:33 | I |       - range scale = [    1.0000]
24-11-25 17:02:33 | I |         sum  error  = [    1.0979]
24-11-25 17:02:33 | I |         best error  = [    1.0979]
24-11-25 17:02:33 | I |     + error = [1.0979]
24-11-25 17:02:34 | I |       - range scale = [    1.0000]
24-11-25 17:02:34 | I |         sum  error  = [   12.1535]
24-11-25 17:02:34 | I |         best error  = [   12.1535]
24-11-25 17:02:34 | I |     + error = [12.1535]
24-11-25 17:02:34 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 17:02:35 | I |       - range scale = [    1.0000]
24-11-25 17:02:35 | I |         sum  error  = [    1.2705]
24-11-25 17:02:35 | I |         best error  = [    1.2705]
24-11-25 17:02:35 | I |     + error = [1.2705]
24-11-25 17:02:36 | I |       - range scale = [    1.0000]
24-11-25 17:02:36 | I |         sum  error  = [   12.5550]
24-11-25 17:02:36 | I |         best error  = [   12.5550]
24-11-25 17:02:36 | I |     + error = [12.5550]
24-11-25 17:02:36 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 17:02:37 | I |       - range scale = [    1.0000]
24-11-25 17:02:37 | I |         sum  error  = [    2.8119]
24-11-25 17:02:37 | I |         best error  = [    2.8119]
24-11-25 17:02:37 | I |     + error = [2.8119]
24-11-25 17:02:37 | I |       - range scale = [    1.0000]
24-11-25 17:02:37 | I |         sum  error  = [   14.9108]
24-11-25 17:02:37 | I |         best error  = [   14.9108]
24-11-25 17:02:37 | I |     + error = [14.9108]
24-11-25 17:02:38 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 17:02:40 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 17:02:41 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 17:02:43 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 17:02:45 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 17:02:46 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 17:02:48 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 17:02:52 | I | quantizing activations for layer model.layers.0
24-11-25 17:02:52 | I | collecting info in model.layers.0
24-11-25 17:02:52 | I | collecting info in model.layers.0
24-11-25 17:02:52 | I | collecting info in model.layers.0
24-11-25 17:02:52 | I | collecting info in model.layers.0
24-11-25 17:02:53 | I | collecting calibration activations in model.layers.0
24-11-25 17:02:53 | I | collecting calibration activations in model.layers.0
24-11-25 17:02:53 | I | collecting calibration activations in model.layers.0
24-11-25 17:02:53 | I | collecting calibration activations in model.layers.0
24-11-25 17:02:55 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 17:02:55 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 17:02:55 | I | - Evaluator: gptq
24-11-25 17:02:55 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 17:02:55 | I | - Batch_size: 8
24-11-25 17:02:55 | I |   + Max_seq_length: 2048
24-11-25 17:03:37 | I |     - Results:
24-11-25 17:03:37 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 17:03:37 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 17:03:37 | I |       |wikitext |      1|word_perplexity|7.7805|  |7.7805|
24-11-25 17:03:37 | I |       |val_valid|      1|word_perplexity|9.0562|  |9.0562|
24-11-25 17:03:37 | I |       
24-11-25 17:03:37 | I | forward this layer
24-11-25 17:03:37 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/67.pt
24-11-25 17:03:37 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/67.pt
24-11-25 17:03:37 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 17:03:37 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 17:03:37 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 17:03:37 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 17:03:37 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 17:03:37 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 17:03:37 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 17:03:37 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 17:03:37 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 17:03:37 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 17:03:37 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 17:03:37 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 17:03:37 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 17:03:37 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 17:03:37 | I | [19] done with optimizer step
24-11-25 17:03:37 | I | epoch 001:     34 / 409600000 loss=0.00026379, loss_per_token=0.540242, loss_sum=17702.7, wps=148.7, ups=0, wpb=32768, bsz=64, num_updates=20, lr=6e-05, gnorm=43.191, clip=100, loss_scale=0.0078, train_wall=220, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=7548, lmquant_ppl_result_wikitext_in_train_no_quant=7.7407, lmquant_ppl_result_val_in_train_no_quant=8.99435, lmquant_ppl_result_wikitext_in_train_with_quant=7.78045, lmquant_ppl_result_val_in_train_with_quant=9.05619
24-11-25 17:03:38 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 17:03:38 | I | in layer model.layers.0
24-11-25 17:03:38 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 17:03:38 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 17:03:38 | I | - Evaluator: gptq
24-11-25 17:03:38 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 17:03:38 | I | - Batch_size: 8
24-11-25 17:03:38 | I |   + Max_seq_length: 2048
24-11-25 17:04:16 | I |     - Results:
24-11-25 17:04:16 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 17:04:16 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 17:04:16 | I |       |wikitext |      1|word_perplexity|7.7486|  |7.7486|
24-11-25 17:04:16 | I |       |val_valid|      1|word_perplexity|8.9980|  |8.9980|
24-11-25 17:04:16 | I |       
24-11-25 17:04:16 | I | quantizing weights for layer model.layers.0
24-11-25 17:04:16 | I | collecting info in model.layers.0
24-11-25 17:04:16 | I | collecting info in model.layers.0
24-11-25 17:04:16 | I | collecting info in model.layers.0
24-11-25 17:04:16 | I | collecting info in model.layers.0
24-11-25 17:04:16 | I | collecting calibration activations in model.layers.0
24-11-25 17:04:16 | I | collecting calibration activations in model.layers.0
24-11-25 17:04:16 | I | collecting calibration activations in model.layers.0
24-11-25 17:04:17 | I | collecting calibration activations in model.layers.0
24-11-25 17:04:17 | I | - Quantizing decoder layer model.layers.0
24-11-25 17:04:17 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 17:04:18 | I |       - range scale = [    1.0000]
24-11-25 17:04:18 | I |         sum  error  = [    0.0639]
24-11-25 17:04:18 | I |         best error  = [    0.0639]
24-11-25 17:04:18 | I |     + error = [0.0639]
24-11-25 17:04:18 | I |       - range scale = [    1.0000]
24-11-25 17:04:18 | I |         sum  error  = [    0.6177]
24-11-25 17:04:18 | I |         best error  = [    0.6177]
24-11-25 17:04:18 | I |     + error = [0.6177]
24-11-25 17:04:18 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 17:04:19 | I |       - range scale = [    1.0000]
24-11-25 17:04:19 | I |         sum  error  = [    0.0695]
24-11-25 17:04:19 | I |         best error  = [    0.0695]
24-11-25 17:04:19 | I |     + error = [0.0695]
24-11-25 17:04:20 | I |       - range scale = [    1.0000]
24-11-25 17:04:20 | I |         sum  error  = [    0.5238]
24-11-25 17:04:20 | I |         best error  = [    0.5238]
24-11-25 17:04:20 | I |     + error = [0.5238]
24-11-25 17:04:20 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 17:04:21 | I |       - range scale = [    1.0000]
24-11-25 17:04:21 | I |         sum  error  = [    0.2429]
24-11-25 17:04:21 | I |         best error  = [    0.2429]
24-11-25 17:04:21 | I |     + error = [0.2429]
24-11-25 17:04:21 | I |       - range scale = [    1.0000]
24-11-25 17:04:21 | I |         sum  error  = [    1.8162]
24-11-25 17:04:21 | I |         best error  = [    1.8162]
24-11-25 17:04:21 | I |     + error = [1.8162]
24-11-25 17:04:22 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 17:04:22 | I |       - range scale = [    1.0000]
24-11-25 17:04:22 | I |         sum  error  = [    0.0631]
24-11-25 17:04:22 | I |         best error  = [    0.0631]
24-11-25 17:04:22 | I |     + error = [0.0631]
24-11-25 17:04:23 | I |       - range scale = [    1.0000]
24-11-25 17:04:23 | I |         sum  error  = [    0.6080]
24-11-25 17:04:23 | I |         best error  = [    0.6080]
24-11-25 17:04:23 | I |     + error = [0.6080]
24-11-25 17:04:23 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 17:04:24 | I |       - range scale = [    1.0000]
24-11-25 17:04:24 | I |         sum  error  = [    1.0696]
24-11-25 17:04:24 | I |         best error  = [    1.0696]
24-11-25 17:04:24 | I |     + error = [1.0696]
24-11-25 17:04:25 | I |       - range scale = [    1.0000]
24-11-25 17:04:25 | I |         sum  error  = [   11.8504]
24-11-25 17:04:25 | I |         best error  = [   11.8504]
24-11-25 17:04:25 | I |     + error = [11.8504]
24-11-25 17:04:25 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 17:04:25 | I |       - range scale = [    1.0000]
24-11-25 17:04:25 | I |         sum  error  = [    1.2373]
24-11-25 17:04:25 | I |         best error  = [    1.2373]
24-11-25 17:04:25 | I |     + error = [1.2373]
24-11-25 17:04:26 | I |       - range scale = [    1.0000]
24-11-25 17:04:26 | I |         sum  error  = [   12.2389]
24-11-25 17:04:26 | I |         best error  = [   12.2389]
24-11-25 17:04:26 | I |     + error = [12.2389]
24-11-25 17:04:26 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 17:04:27 | I |       - range scale = [    1.0000]
24-11-25 17:04:27 | I |         sum  error  = [    3.3381]
24-11-25 17:04:27 | I |         best error  = [    3.3381]
24-11-25 17:04:27 | I |     + error = [3.3381]
24-11-25 17:04:28 | I |       - range scale = [    1.0000]
24-11-25 17:04:28 | I |         sum  error  = [   17.5210]
24-11-25 17:04:28 | I |         best error  = [   17.5210]
24-11-25 17:04:28 | I |     + error = [17.5210]
24-11-25 17:04:28 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 17:04:30 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 17:04:31 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 17:04:33 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 17:04:35 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 17:04:37 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 17:04:38 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 17:04:42 | I | quantizing activations for layer model.layers.0
24-11-25 17:04:42 | I | collecting info in model.layers.0
24-11-25 17:04:42 | I | collecting info in model.layers.0
24-11-25 17:04:42 | I | collecting info in model.layers.0
24-11-25 17:04:42 | I | collecting info in model.layers.0
24-11-25 17:04:43 | I | collecting calibration activations in model.layers.0
24-11-25 17:04:43 | I | collecting calibration activations in model.layers.0
24-11-25 17:04:43 | I | collecting calibration activations in model.layers.0
24-11-25 17:04:43 | I | collecting calibration activations in model.layers.0
24-11-25 17:04:45 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 17:04:45 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 17:04:45 | I | - Evaluator: gptq
24-11-25 17:04:45 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 17:04:45 | I | - Batch_size: 8
24-11-25 17:04:45 | I |   + Max_seq_length: 2048
24-11-25 17:05:27 | I |     - Results:
24-11-25 17:05:27 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 17:05:27 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 17:05:27 | I |       |wikitext |      1|word_perplexity|7.7907|  |7.7907|
24-11-25 17:05:27 | I |       |val_valid|      1|word_perplexity|9.0515|  |9.0515|
24-11-25 17:05:27 | I |       
24-11-25 17:05:27 | I | forward this layer
24-11-25 17:05:27 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/68.pt
24-11-25 17:05:27 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/68.pt
24-11-25 17:05:27 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 17:05:27 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 17:05:27 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 17:05:27 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 17:05:27 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 17:05:27 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 17:05:27 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 17:05:27 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 17:05:27 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 17:05:27 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 17:05:27 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 17:05:27 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 17:05:27 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 17:05:27 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 17:05:27 | I | in layer model.layers.0
24-11-25 17:05:27 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 17:05:28 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 17:05:28 | I | - Evaluator: gptq
24-11-25 17:05:28 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 17:05:28 | I | - Batch_size: 8
24-11-25 17:05:28 | I |   + Max_seq_length: 2048
24-11-25 17:06:06 | I |     - Results:
24-11-25 17:06:06 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 17:06:06 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 17:06:06 | I |       |wikitext |      1|word_perplexity|7.7486|  |7.7486|
24-11-25 17:06:06 | I |       |val_valid|      1|word_perplexity|8.9980|  |8.9980|
24-11-25 17:06:06 | I |       
24-11-25 17:06:06 | I | quantizing weights for layer model.layers.0
24-11-25 17:06:06 | I | collecting info in model.layers.0
24-11-25 17:06:06 | I | collecting info in model.layers.0
24-11-25 17:06:06 | I | collecting info in model.layers.0
24-11-25 17:06:06 | I | collecting info in model.layers.0
24-11-25 17:06:06 | I | collecting calibration activations in model.layers.0
24-11-25 17:06:06 | I | collecting calibration activations in model.layers.0
24-11-25 17:06:06 | I | collecting calibration activations in model.layers.0
24-11-25 17:06:07 | I | collecting calibration activations in model.layers.0
24-11-25 17:06:07 | I | - Quantizing decoder layer model.layers.0
24-11-25 17:06:07 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 17:06:08 | I |       - range scale = [    1.0000]
24-11-25 17:06:08 | I |         sum  error  = [    0.0648]
24-11-25 17:06:08 | I |         best error  = [    0.0648]
24-11-25 17:06:08 | I |     + error = [0.0648]
24-11-25 17:06:08 | I |       - range scale = [    1.0000]
24-11-25 17:06:08 | I |         sum  error  = [    0.6347]
24-11-25 17:06:08 | I |         best error  = [    0.6347]
24-11-25 17:06:08 | I |     + error = [0.6347]
24-11-25 17:06:08 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 17:06:09 | I |       - range scale = [    1.0000]
24-11-25 17:06:09 | I |         sum  error  = [    0.0686]
24-11-25 17:06:09 | I |         best error  = [    0.0686]
24-11-25 17:06:09 | I |     + error = [0.0686]
24-11-25 17:06:10 | I |       - range scale = [    1.0000]
24-11-25 17:06:10 | I |         sum  error  = [    0.5119]
24-11-25 17:06:10 | I |         best error  = [    0.5119]
24-11-25 17:06:10 | I |     + error = [0.5119]
24-11-25 17:06:10 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 17:06:11 | I |       - range scale = [    1.0000]
24-11-25 17:06:11 | I |         sum  error  = [    0.2451]
24-11-25 17:06:11 | I |         best error  = [    0.2451]
24-11-25 17:06:11 | I |     + error = [0.2451]
24-11-25 17:06:11 | I |       - range scale = [    1.0000]
24-11-25 17:06:11 | I |         sum  error  = [    1.8243]
24-11-25 17:06:11 | I |         best error  = [    1.8243]
24-11-25 17:06:11 | I |     + error = [1.8243]
24-11-25 17:06:12 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 17:06:12 | I |       - range scale = [    1.0000]
24-11-25 17:06:12 | I |         sum  error  = [    0.0639]
24-11-25 17:06:12 | I |         best error  = [    0.0639]
24-11-25 17:06:12 | I |     + error = [0.0639]
24-11-25 17:06:13 | I |       - range scale = [    1.0000]
24-11-25 17:06:13 | I |         sum  error  = [    0.6144]
24-11-25 17:06:13 | I |         best error  = [    0.6144]
24-11-25 17:06:13 | I |     + error = [0.6144]
24-11-25 17:06:13 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 17:06:14 | I |       - range scale = [    1.0000]
24-11-25 17:06:14 | I |         sum  error  = [    1.0871]
24-11-25 17:06:14 | I |         best error  = [    1.0871]
24-11-25 17:06:14 | I |     + error = [1.0871]
24-11-25 17:06:15 | I |       - range scale = [    1.0000]
24-11-25 17:06:15 | I |         sum  error  = [   12.0372]
24-11-25 17:06:15 | I |         best error  = [   12.0372]
24-11-25 17:06:15 | I |     + error = [12.0372]
24-11-25 17:06:15 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 17:06:15 | I |       - range scale = [    1.0000]
24-11-25 17:06:15 | I |         sum  error  = [    1.2567]
24-11-25 17:06:15 | I |         best error  = [    1.2567]
24-11-25 17:06:15 | I |     + error = [1.2567]
24-11-25 17:06:16 | I |       - range scale = [    1.0000]
24-11-25 17:06:16 | I |         sum  error  = [   12.4623]
24-11-25 17:06:16 | I |         best error  = [   12.4623]
24-11-25 17:06:16 | I |     + error = [12.4623]
24-11-25 17:06:16 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 17:06:17 | I |       - range scale = [    1.0000]
24-11-25 17:06:17 | I |         sum  error  = [    3.5204]
24-11-25 17:06:17 | I |         best error  = [    3.5204]
24-11-25 17:06:17 | I |     + error = [3.5204]
24-11-25 17:06:18 | I |       - range scale = [    1.0000]
24-11-25 17:06:18 | I |         sum  error  = [   18.4184]
24-11-25 17:06:18 | I |         best error  = [   18.4184]
24-11-25 17:06:18 | I |     + error = [18.4184]
24-11-25 17:06:18 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 17:06:20 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 17:06:21 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 17:06:23 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 17:06:25 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 17:06:26 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 17:06:28 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 17:06:32 | I | quantizing activations for layer model.layers.0
24-11-25 17:06:32 | I | collecting info in model.layers.0
24-11-25 17:06:32 | I | collecting info in model.layers.0
24-11-25 17:06:32 | I | collecting info in model.layers.0
24-11-25 17:06:32 | I | collecting info in model.layers.0
24-11-25 17:06:33 | I | collecting calibration activations in model.layers.0
24-11-25 17:06:33 | I | collecting calibration activations in model.layers.0
24-11-25 17:06:33 | I | collecting calibration activations in model.layers.0
24-11-25 17:06:33 | I | collecting calibration activations in model.layers.0
24-11-25 17:06:35 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 17:06:35 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 17:06:35 | I | - Evaluator: gptq
24-11-25 17:06:35 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 17:06:35 | I | - Batch_size: 8
24-11-25 17:06:35 | I |   + Max_seq_length: 2048
24-11-25 17:07:17 | I |     - Results:
24-11-25 17:07:17 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 17:07:17 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 17:07:17 | I |       |wikitext |      1|word_perplexity|7.7824|  |7.7824|
24-11-25 17:07:17 | I |       |val_valid|      1|word_perplexity|9.0458|  |9.0458|
24-11-25 17:07:17 | I |       
24-11-25 17:07:17 | I | forward this layer
24-11-25 17:07:17 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/69.pt
24-11-25 17:07:17 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/69.pt
24-11-25 17:07:17 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 17:07:17 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 17:07:17 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 17:07:17 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 17:07:17 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 17:07:17 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 17:07:17 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 17:07:17 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 17:07:17 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 17:07:17 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 17:07:17 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 17:07:17 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 17:07:17 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 17:07:17 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 17:07:17 | I | [20] done with optimizer step
24-11-25 17:07:17 | I | epoch 001:     35 / 409600000 loss=0.000146626, loss_per_token=0.300289, loss_sum=9839.87, wps=148.9, ups=0, wpb=32768, bsz=64, num_updates=21, lr=6.3e-05, gnorm=25.986, clip=100, loss_scale=0.0078, train_wall=220, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=7768, lmquant_ppl_result_wikitext_in_train_no_quant=7.74857, lmquant_ppl_result_val_in_train_no_quant=8.99797, lmquant_ppl_result_wikitext_in_train_with_quant=7.78237, lmquant_ppl_result_val_in_train_with_quant=9.04579
24-11-25 17:07:18 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 17:07:18 | I | in layer model.layers.0
24-11-25 17:07:18 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 17:07:18 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 17:07:18 | I | - Evaluator: gptq
24-11-25 17:07:18 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 17:07:18 | I | - Batch_size: 8
24-11-25 17:07:18 | I |   + Max_seq_length: 2048
24-11-25 17:07:56 | I |     - Results:
24-11-25 17:07:56 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 17:07:56 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 17:07:56 | I |       |wikitext |      1|word_perplexity|7.7596|  |7.7596|
24-11-25 17:07:56 | I |       |val_valid|      1|word_perplexity|9.0027|  |9.0027|
24-11-25 17:07:56 | I |       
24-11-25 17:07:56 | I | quantizing weights for layer model.layers.0
24-11-25 17:07:56 | I | collecting info in model.layers.0
24-11-25 17:07:56 | I | collecting info in model.layers.0
24-11-25 17:07:56 | I | collecting info in model.layers.0
24-11-25 17:07:56 | I | collecting info in model.layers.0
24-11-25 17:07:56 | I | collecting calibration activations in model.layers.0
24-11-25 17:07:57 | I | collecting calibration activations in model.layers.0
24-11-25 17:07:57 | I | collecting calibration activations in model.layers.0
24-11-25 17:07:57 | I | collecting calibration activations in model.layers.0
24-11-25 17:07:57 | I | - Quantizing decoder layer model.layers.0
24-11-25 17:07:57 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 17:07:58 | I |       - range scale = [    1.0000]
24-11-25 17:07:58 | I |         sum  error  = [    0.0566]
24-11-25 17:07:58 | I |         best error  = [    0.0566]
24-11-25 17:07:58 | I |     + error = [0.0566]
24-11-25 17:07:58 | I |       - range scale = [    1.0000]
24-11-25 17:07:58 | I |         sum  error  = [    0.5983]
24-11-25 17:07:58 | I |         best error  = [    0.5983]
24-11-25 17:07:58 | I |     + error = [0.5983]
24-11-25 17:07:59 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 17:07:59 | I |       - range scale = [    1.0000]
24-11-25 17:07:59 | I |         sum  error  = [    0.0678]
24-11-25 17:07:59 | I |         best error  = [    0.0678]
24-11-25 17:07:59 | I |     + error = [0.0678]
24-11-25 17:08:00 | I |       - range scale = [    1.0000]
24-11-25 17:08:00 | I |         sum  error  = [    0.5579]
24-11-25 17:08:00 | I |         best error  = [    0.5579]
24-11-25 17:08:00 | I |     + error = [0.5579]
24-11-25 17:08:00 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 17:08:01 | I |       - range scale = [    1.0000]
24-11-25 17:08:01 | I |         sum  error  = [    0.2376]
24-11-25 17:08:01 | I |         best error  = [    0.2376]
24-11-25 17:08:01 | I |     + error = [0.2376]
24-11-25 17:08:02 | I |       - range scale = [    1.0000]
24-11-25 17:08:02 | I |         sum  error  = [    1.7915]
24-11-25 17:08:02 | I |         best error  = [    1.7915]
24-11-25 17:08:02 | I |     + error = [1.7915]
24-11-25 17:08:02 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 17:08:02 | I |       - range scale = [    1.0000]
24-11-25 17:08:02 | I |         sum  error  = [    0.0614]
24-11-25 17:08:02 | I |         best error  = [    0.0614]
24-11-25 17:08:02 | I |     + error = [0.0614]
24-11-25 17:08:03 | I |       - range scale = [    1.0000]
24-11-25 17:08:03 | I |         sum  error  = [    0.5929]
24-11-25 17:08:03 | I |         best error  = [    0.5929]
24-11-25 17:08:03 | I |     + error = [0.5929]
24-11-25 17:08:03 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 17:08:04 | I |       - range scale = [    1.0000]
24-11-25 17:08:04 | I |         sum  error  = [    1.0601]
24-11-25 17:08:04 | I |         best error  = [    1.0601]
24-11-25 17:08:04 | I |     + error = [1.0601]
24-11-25 17:08:05 | I |       - range scale = [    1.0000]
24-11-25 17:08:05 | I |         sum  error  = [   11.7432]
24-11-25 17:08:05 | I |         best error  = [   11.7432]
24-11-25 17:08:05 | I |     + error = [11.7432]
24-11-25 17:08:05 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 17:08:06 | I |       - range scale = [    1.0000]
24-11-25 17:08:06 | I |         sum  error  = [    1.2275]
24-11-25 17:08:06 | I |         best error  = [    1.2275]
24-11-25 17:08:06 | I |     + error = [1.2275]
24-11-25 17:08:06 | I |       - range scale = [    1.0000]
24-11-25 17:08:06 | I |         sum  error  = [   12.1226]
24-11-25 17:08:06 | I |         best error  = [   12.1226]
24-11-25 17:08:06 | I |     + error = [12.1226]
24-11-25 17:08:07 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 17:08:07 | I |       - range scale = [    1.0000]
24-11-25 17:08:07 | I |         sum  error  = [    3.2969]
24-11-25 17:08:07 | I |         best error  = [    3.2969]
24-11-25 17:08:07 | I |     + error = [3.2969]
24-11-25 17:08:08 | I |       - range scale = [    1.0000]
24-11-25 17:08:08 | I |         sum  error  = [   17.6361]
24-11-25 17:08:08 | I |         best error  = [   17.6361]
24-11-25 17:08:08 | I |     + error = [17.6361]
24-11-25 17:08:08 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 17:08:10 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 17:08:12 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 17:08:13 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 17:08:15 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 17:08:17 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 17:08:18 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 17:08:22 | I | quantizing activations for layer model.layers.0
24-11-25 17:08:22 | I | collecting info in model.layers.0
24-11-25 17:08:22 | I | collecting info in model.layers.0
24-11-25 17:08:22 | I | collecting info in model.layers.0
24-11-25 17:08:22 | I | collecting info in model.layers.0
24-11-25 17:08:23 | I | collecting calibration activations in model.layers.0
24-11-25 17:08:23 | I | collecting calibration activations in model.layers.0
24-11-25 17:08:23 | I | collecting calibration activations in model.layers.0
24-11-25 17:08:23 | I | collecting calibration activations in model.layers.0
24-11-25 17:08:25 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 17:08:25 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 17:08:25 | I | - Evaluator: gptq
24-11-25 17:08:25 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 17:08:25 | I | - Batch_size: 8
24-11-25 17:08:25 | I |   + Max_seq_length: 2048
24-11-25 17:09:07 | I |     - Results:
24-11-25 17:09:07 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 17:09:07 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 17:09:07 | I |       |wikitext |      1|word_perplexity|7.7640|  |7.7640|
24-11-25 17:09:07 | I |       |val_valid|      1|word_perplexity|9.0417|  |9.0417|
24-11-25 17:09:07 | I |       
24-11-25 17:09:07 | I | forward this layer
24-11-25 17:09:07 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/70.pt
24-11-25 17:09:07 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/70.pt
24-11-25 17:09:07 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 17:09:07 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 17:09:07 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 17:09:07 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 17:09:07 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 17:09:07 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 17:09:07 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 17:09:07 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 17:09:07 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 17:09:07 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 17:09:07 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 17:09:07 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 17:09:07 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 17:09:07 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 17:09:07 | I | in layer model.layers.0
24-11-25 17:09:07 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 17:09:07 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 17:09:07 | I | - Evaluator: gptq
24-11-25 17:09:07 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 17:09:07 | I | - Batch_size: 8
24-11-25 17:09:07 | I |   + Max_seq_length: 2048
24-11-25 17:09:46 | I |     - Results:
24-11-25 17:09:46 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 17:09:46 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 17:09:46 | I |       |wikitext |      1|word_perplexity|7.7596|  |7.7596|
24-11-25 17:09:46 | I |       |val_valid|      1|word_perplexity|9.0027|  |9.0027|
24-11-25 17:09:46 | I |       
24-11-25 17:09:46 | I | quantizing weights for layer model.layers.0
24-11-25 17:09:46 | I | collecting info in model.layers.0
24-11-25 17:09:46 | I | collecting info in model.layers.0
24-11-25 17:09:46 | I | collecting info in model.layers.0
24-11-25 17:09:46 | I | collecting info in model.layers.0
24-11-25 17:09:46 | I | collecting calibration activations in model.layers.0
24-11-25 17:09:46 | I | collecting calibration activations in model.layers.0
24-11-25 17:09:46 | I | collecting calibration activations in model.layers.0
24-11-25 17:09:47 | I | collecting calibration activations in model.layers.0
24-11-25 17:09:47 | I | - Quantizing decoder layer model.layers.0
24-11-25 17:09:47 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 17:09:48 | I |       - range scale = [    1.0000]
24-11-25 17:09:48 | I |         sum  error  = [    0.0565]
24-11-25 17:09:48 | I |         best error  = [    0.0565]
24-11-25 17:09:48 | I |     + error = [0.0565]
24-11-25 17:09:48 | I |       - range scale = [    1.0000]
24-11-25 17:09:48 | I |         sum  error  = [    0.5995]
24-11-25 17:09:48 | I |         best error  = [    0.5995]
24-11-25 17:09:48 | I |     + error = [0.5995]
24-11-25 17:09:49 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 17:09:49 | I |       - range scale = [    1.0000]
24-11-25 17:09:49 | I |         sum  error  = [    0.0686]
24-11-25 17:09:49 | I |         best error  = [    0.0686]
24-11-25 17:09:49 | I |     + error = [0.0686]
24-11-25 17:09:50 | I |       - range scale = [    1.0000]
24-11-25 17:09:50 | I |         sum  error  = [    0.5503]
24-11-25 17:09:50 | I |         best error  = [    0.5503]
24-11-25 17:09:50 | I |     + error = [0.5503]
24-11-25 17:09:50 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 17:09:51 | I |       - range scale = [    1.0000]
24-11-25 17:09:51 | I |         sum  error  = [    0.2354]
24-11-25 17:09:51 | I |         best error  = [    0.2354]
24-11-25 17:09:51 | I |     + error = [0.2354]
24-11-25 17:09:51 | I |       - range scale = [    1.0000]
24-11-25 17:09:51 | I |         sum  error  = [    1.7924]
24-11-25 17:09:51 | I |         best error  = [    1.7924]
24-11-25 17:09:51 | I |     + error = [1.7924]
24-11-25 17:09:52 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 17:09:52 | I |       - range scale = [    1.0000]
24-11-25 17:09:52 | I |         sum  error  = [    0.0613]
24-11-25 17:09:52 | I |         best error  = [    0.0613]
24-11-25 17:09:52 | I |     + error = [0.0613]
24-11-25 17:09:53 | I |       - range scale = [    1.0000]
24-11-25 17:09:53 | I |         sum  error  = [    0.5932]
24-11-25 17:09:53 | I |         best error  = [    0.5932]
24-11-25 17:09:53 | I |     + error = [0.5932]
24-11-25 17:09:53 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 17:09:54 | I |       - range scale = [    1.0000]
24-11-25 17:09:54 | I |         sum  error  = [    1.0647]
24-11-25 17:09:54 | I |         best error  = [    1.0647]
24-11-25 17:09:54 | I |     + error = [1.0647]
24-11-25 17:09:55 | I |       - range scale = [    1.0000]
24-11-25 17:09:55 | I |         sum  error  = [   11.7974]
24-11-25 17:09:55 | I |         best error  = [   11.7974]
24-11-25 17:09:55 | I |     + error = [11.7974]
24-11-25 17:09:55 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 17:09:56 | I |       - range scale = [    1.0000]
24-11-25 17:09:56 | I |         sum  error  = [    1.2337]
24-11-25 17:09:56 | I |         best error  = [    1.2337]
24-11-25 17:09:56 | I |     + error = [1.2337]
24-11-25 17:09:56 | I |       - range scale = [    1.0000]
24-11-25 17:09:56 | I |         sum  error  = [   12.1837]
24-11-25 17:09:56 | I |         best error  = [   12.1837]
24-11-25 17:09:56 | I |     + error = [12.1837]
24-11-25 17:09:57 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 17:09:57 | I |       - range scale = [    1.0000]
24-11-25 17:09:57 | I |         sum  error  = [    3.2976]
24-11-25 17:09:57 | I |         best error  = [    3.2976]
24-11-25 17:09:57 | I |     + error = [3.2976]
24-11-25 17:09:58 | I |       - range scale = [    1.0000]
24-11-25 17:09:58 | I |         sum  error  = [   17.6685]
24-11-25 17:09:58 | I |         best error  = [   17.6685]
24-11-25 17:09:58 | I |     + error = [17.6685]
24-11-25 17:09:58 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 17:10:00 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 17:10:01 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 17:10:02 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 17:10:04 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 17:10:05 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 17:10:07 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 17:10:10 | I | quantizing activations for layer model.layers.0
24-11-25 17:10:10 | I | collecting info in model.layers.0
24-11-25 17:10:10 | I | collecting info in model.layers.0
24-11-25 17:10:10 | I | collecting info in model.layers.0
24-11-25 17:10:10 | I | collecting info in model.layers.0
24-11-25 17:10:10 | I | collecting calibration activations in model.layers.0
24-11-25 17:10:10 | I | collecting calibration activations in model.layers.0
24-11-25 17:10:11 | I | collecting calibration activations in model.layers.0
24-11-25 17:10:11 | I | collecting calibration activations in model.layers.0
24-11-25 17:10:13 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 17:10:13 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 17:10:13 | I | - Evaluator: gptq
24-11-25 17:10:13 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 17:10:13 | I | - Batch_size: 8
24-11-25 17:10:13 | I |   + Max_seq_length: 2048
24-11-25 17:10:54 | I |     - Results:
24-11-25 17:10:54 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 17:10:54 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 17:10:54 | I |       |wikitext |      1|word_perplexity|7.7725|  |7.7725|
24-11-25 17:10:54 | I |       |val_valid|      1|word_perplexity|9.0446|  |9.0446|
24-11-25 17:10:54 | I |       
24-11-25 17:10:54 | I | forward this layer
24-11-25 17:10:54 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/71.pt
24-11-25 17:10:54 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/71.pt
24-11-25 17:10:54 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 17:10:54 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 17:10:54 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 17:10:54 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 17:10:54 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 17:10:54 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 17:10:54 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 17:10:54 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 17:10:54 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 17:10:54 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 17:10:54 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 17:10:54 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 17:10:54 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 17:10:54 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 17:10:54 | I | [21] done with optimizer step
24-11-25 17:10:54 | I | epoch 001:     36 / 409600000 loss=0.000138841, loss_per_token=0.284347, loss_sum=9317.5, wps=151, ups=0, wpb=32768, bsz=64, num_updates=22, lr=6.6e-05, gnorm=23.116, clip=100, loss_scale=0.0078, train_wall=217, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=7985, lmquant_ppl_result_wikitext_in_train_no_quant=7.75962, lmquant_ppl_result_val_in_train_no_quant=9.00266, lmquant_ppl_result_wikitext_in_train_with_quant=7.77252, lmquant_ppl_result_val_in_train_with_quant=9.04459
24-11-25 17:10:55 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 17:10:55 | I | in layer model.layers.0
24-11-25 17:10:55 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 17:10:55 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 17:10:55 | I | - Evaluator: gptq
24-11-25 17:10:55 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 17:10:55 | I | - Batch_size: 8
24-11-25 17:10:55 | I |   + Max_seq_length: 2048
24-11-25 17:11:33 | I |     - Results:
24-11-25 17:11:33 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 17:11:33 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 17:11:33 | I |       |wikitext |      1|word_perplexity|7.7782|  |7.7782|
24-11-25 17:11:33 | I |       |val_valid|      1|word_perplexity|9.0099|  |9.0099|
24-11-25 17:11:33 | I |       
24-11-25 17:11:33 | I | quantizing weights for layer model.layers.0
24-11-25 17:11:33 | I | collecting info in model.layers.0
24-11-25 17:11:33 | I | collecting info in model.layers.0
24-11-25 17:11:33 | I | collecting info in model.layers.0
24-11-25 17:11:33 | I | collecting info in model.layers.0
24-11-25 17:11:33 | I | collecting calibration activations in model.layers.0
24-11-25 17:11:34 | I | collecting calibration activations in model.layers.0
24-11-25 17:11:34 | I | collecting calibration activations in model.layers.0
24-11-25 17:11:34 | I | collecting calibration activations in model.layers.0
24-11-25 17:11:34 | I | - Quantizing decoder layer model.layers.0
24-11-25 17:11:34 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 17:11:35 | I |       - range scale = [    1.0000]
24-11-25 17:11:35 | I |         sum  error  = [    0.0634]
24-11-25 17:11:35 | I |         best error  = [    0.0634]
24-11-25 17:11:35 | I |     + error = [0.0634]
24-11-25 17:11:35 | I |       - range scale = [    1.0000]
24-11-25 17:11:35 | I |         sum  error  = [    0.6466]
24-11-25 17:11:35 | I |         best error  = [    0.6466]
24-11-25 17:11:35 | I |     + error = [0.6466]
24-11-25 17:11:36 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 17:11:36 | I |       - range scale = [    1.0000]
24-11-25 17:11:36 | I |         sum  error  = [    0.0700]
24-11-25 17:11:36 | I |         best error  = [    0.0700]
24-11-25 17:11:36 | I |     + error = [0.0700]
24-11-25 17:11:37 | I |       - range scale = [    1.0000]
24-11-25 17:11:37 | I |         sum  error  = [    0.5808]
24-11-25 17:11:37 | I |         best error  = [    0.5808]
24-11-25 17:11:37 | I |     + error = [0.5808]
24-11-25 17:11:37 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 17:11:38 | I |       - range scale = [    1.0000]
24-11-25 17:11:38 | I |         sum  error  = [    0.2366]
24-11-25 17:11:38 | I |         best error  = [    0.2366]
24-11-25 17:11:38 | I |     + error = [0.2366]
24-11-25 17:11:39 | I |       - range scale = [    1.0000]
24-11-25 17:11:39 | I |         sum  error  = [    1.7861]
24-11-25 17:11:39 | I |         best error  = [    1.7861]
24-11-25 17:11:39 | I |     + error = [1.7861]
24-11-25 17:11:39 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 17:11:40 | I |       - range scale = [    1.0000]
24-11-25 17:11:40 | I |         sum  error  = [    0.0608]
24-11-25 17:11:40 | I |         best error  = [    0.0608]
24-11-25 17:11:40 | I |     + error = [0.0608]
24-11-25 17:11:40 | I |       - range scale = [    1.0000]
24-11-25 17:11:40 | I |         sum  error  = [    0.5793]
24-11-25 17:11:40 | I |         best error  = [    0.5793]
24-11-25 17:11:40 | I |     + error = [0.5793]
24-11-25 17:11:40 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 17:11:41 | I |       - range scale = [    1.0000]
24-11-25 17:11:41 | I |         sum  error  = [    1.0594]
24-11-25 17:11:41 | I |         best error  = [    1.0594]
24-11-25 17:11:41 | I |     + error = [1.0594]
24-11-25 17:11:42 | I |       - range scale = [    1.0000]
24-11-25 17:11:42 | I |         sum  error  = [   11.7270]
24-11-25 17:11:42 | I |         best error  = [   11.7270]
24-11-25 17:11:42 | I |     + error = [11.7270]
24-11-25 17:11:42 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 17:11:43 | I |       - range scale = [    1.0000]
24-11-25 17:11:43 | I |         sum  error  = [    1.2261]
24-11-25 17:11:43 | I |         best error  = [    1.2261]
24-11-25 17:11:43 | I |     + error = [1.2261]
24-11-25 17:11:44 | I |       - range scale = [    1.0000]
24-11-25 17:11:44 | I |         sum  error  = [   12.0997]
24-11-25 17:11:44 | I |         best error  = [   12.0997]
24-11-25 17:11:44 | I |     + error = [12.0997]
24-11-25 17:11:44 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 17:11:44 | I |       - range scale = [    1.0000]
24-11-25 17:11:44 | I |         sum  error  = [    3.0253]
24-11-25 17:11:44 | I |         best error  = [    3.0253]
24-11-25 17:11:44 | I |     + error = [3.0253]
24-11-25 17:11:45 | I |       - range scale = [    1.0000]
24-11-25 17:11:45 | I |         sum  error  = [   16.4318]
24-11-25 17:11:45 | I |         best error  = [   16.4318]
24-11-25 17:11:45 | I |     + error = [16.4318]
24-11-25 17:11:45 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 17:11:47 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 17:11:48 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 17:11:50 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 17:11:51 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 17:11:52 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 17:11:54 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 17:11:57 | I | quantizing activations for layer model.layers.0
24-11-25 17:11:57 | I | collecting info in model.layers.0
24-11-25 17:11:57 | I | collecting info in model.layers.0
24-11-25 17:11:57 | I | collecting info in model.layers.0
24-11-25 17:11:57 | I | collecting info in model.layers.0
24-11-25 17:11:58 | I | collecting calibration activations in model.layers.0
24-11-25 17:11:58 | I | collecting calibration activations in model.layers.0
24-11-25 17:11:58 | I | collecting calibration activations in model.layers.0
24-11-25 17:11:58 | I | collecting calibration activations in model.layers.0
24-11-25 17:12:00 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 17:12:00 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 17:12:00 | I | - Evaluator: gptq
24-11-25 17:12:00 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 17:12:00 | I | - Batch_size: 8
24-11-25 17:12:00 | I |   + Max_seq_length: 2048
24-11-25 17:12:41 | I |     - Results:
24-11-25 17:12:41 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 17:12:41 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 17:12:41 | I |       |wikitext |      1|word_perplexity|7.7714|  |7.7714|
24-11-25 17:12:41 | I |       |val_valid|      1|word_perplexity|9.0462|  |9.0462|
24-11-25 17:12:41 | I |       
24-11-25 17:12:41 | I | forward this layer
24-11-25 17:12:41 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/72.pt
24-11-25 17:12:41 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/72.pt
24-11-25 17:12:42 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 17:12:42 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 17:12:42 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 17:12:42 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 17:12:42 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 17:12:42 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 17:12:42 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 17:12:42 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 17:12:42 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 17:12:42 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 17:12:42 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 17:12:42 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 17:12:42 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 17:12:42 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 17:12:42 | I | in layer model.layers.0
24-11-25 17:12:42 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 17:12:42 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 17:12:42 | I | - Evaluator: gptq
24-11-25 17:12:42 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 17:12:42 | I | - Batch_size: 8
24-11-25 17:12:42 | I |   + Max_seq_length: 2048
24-11-25 17:13:20 | I |     - Results:
24-11-25 17:13:20 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 17:13:20 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 17:13:20 | I |       |wikitext |      1|word_perplexity|7.7782|  |7.7782|
24-11-25 17:13:20 | I |       |val_valid|      1|word_perplexity|9.0099|  |9.0099|
24-11-25 17:13:20 | I |       
24-11-25 17:13:20 | I | quantizing weights for layer model.layers.0
24-11-25 17:13:20 | I | collecting info in model.layers.0
24-11-25 17:13:20 | I | collecting info in model.layers.0
24-11-25 17:13:20 | I | collecting info in model.layers.0
24-11-25 17:13:20 | I | collecting info in model.layers.0
24-11-25 17:13:20 | I | collecting calibration activations in model.layers.0
24-11-25 17:13:21 | I | collecting calibration activations in model.layers.0
24-11-25 17:13:21 | I | collecting calibration activations in model.layers.0
24-11-25 17:13:21 | I | collecting calibration activations in model.layers.0
24-11-25 17:13:21 | I | - Quantizing decoder layer model.layers.0
24-11-25 17:13:21 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 17:13:22 | I |       - range scale = [    1.0000]
24-11-25 17:13:22 | I |         sum  error  = [    0.0559]
24-11-25 17:13:22 | I |         best error  = [    0.0559]
24-11-25 17:13:22 | I |     + error = [0.0559]
24-11-25 17:13:23 | I |       - range scale = [    1.0000]
24-11-25 17:13:23 | I |         sum  error  = [    0.6018]
24-11-25 17:13:23 | I |         best error  = [    0.6018]
24-11-25 17:13:23 | I |     + error = [0.6018]
24-11-25 17:13:23 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 17:13:23 | I |       - range scale = [    1.0000]
24-11-25 17:13:23 | I |         sum  error  = [    0.0638]
24-11-25 17:13:23 | I |         best error  = [    0.0638]
24-11-25 17:13:23 | I |     + error = [0.0638]
24-11-25 17:13:24 | I |       - range scale = [    1.0000]
24-11-25 17:13:24 | I |         sum  error  = [    0.5382]
24-11-25 17:13:24 | I |         best error  = [    0.5382]
24-11-25 17:13:24 | I |     + error = [0.5382]
24-11-25 17:13:24 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 17:13:25 | I |       - range scale = [    1.0000]
24-11-25 17:13:25 | I |         sum  error  = [    0.2351]
24-11-25 17:13:25 | I |         best error  = [    0.2351]
24-11-25 17:13:25 | I |     + error = [0.2351]
24-11-25 17:13:26 | I |       - range scale = [    1.0000]
24-11-25 17:13:26 | I |         sum  error  = [    1.7941]
24-11-25 17:13:26 | I |         best error  = [    1.7941]
24-11-25 17:13:26 | I |     + error = [1.7941]
24-11-25 17:13:26 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 17:13:27 | I |       - range scale = [    1.0000]
24-11-25 17:13:27 | I |         sum  error  = [    0.0601]
24-11-25 17:13:27 | I |         best error  = [    0.0601]
24-11-25 17:13:27 | I |     + error = [0.0601]
24-11-25 17:13:27 | I |       - range scale = [    1.0000]
24-11-25 17:13:27 | I |         sum  error  = [    0.5802]
24-11-25 17:13:27 | I |         best error  = [    0.5802]
24-11-25 17:13:27 | I |     + error = [0.5802]
24-11-25 17:13:27 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 17:13:28 | I |       - range scale = [    1.0000]
24-11-25 17:13:28 | I |         sum  error  = [    1.0775]
24-11-25 17:13:28 | I |         best error  = [    1.0775]
24-11-25 17:13:28 | I |     + error = [1.0775]
24-11-25 17:13:29 | I |       - range scale = [    1.0000]
24-11-25 17:13:29 | I |         sum  error  = [   11.9265]
24-11-25 17:13:29 | I |         best error  = [   11.9265]
24-11-25 17:13:29 | I |     + error = [11.9265]
24-11-25 17:13:29 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 17:13:30 | I |       - range scale = [    1.0000]
24-11-25 17:13:30 | I |         sum  error  = [    1.2472]
24-11-25 17:13:30 | I |         best error  = [    1.2472]
24-11-25 17:13:30 | I |     + error = [1.2472]
24-11-25 17:13:31 | I |       - range scale = [    1.0000]
24-11-25 17:13:31 | I |         sum  error  = [   12.3244]
24-11-25 17:13:31 | I |         best error  = [   12.3244]
24-11-25 17:13:31 | I |     + error = [12.3244]
24-11-25 17:13:31 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 17:13:31 | I |       - range scale = [    1.0000]
24-11-25 17:13:31 | I |         sum  error  = [    2.7046]
24-11-25 17:13:31 | I |         best error  = [    2.7046]
24-11-25 17:13:31 | I |     + error = [2.7046]
24-11-25 17:13:32 | I |       - range scale = [    1.0000]
24-11-25 17:13:32 | I |         sum  error  = [   14.8229]
24-11-25 17:13:32 | I |         best error  = [   14.8229]
24-11-25 17:13:32 | I |     + error = [14.8229]
24-11-25 17:13:32 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 17:13:34 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 17:13:35 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 17:13:37 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 17:13:38 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 17:13:39 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 17:13:41 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 17:13:44 | I | quantizing activations for layer model.layers.0
24-11-25 17:13:44 | I | collecting info in model.layers.0
24-11-25 17:13:44 | I | collecting info in model.layers.0
24-11-25 17:13:44 | I | collecting info in model.layers.0
24-11-25 17:13:44 | I | collecting info in model.layers.0
24-11-25 17:13:45 | I | collecting calibration activations in model.layers.0
24-11-25 17:13:45 | I | collecting calibration activations in model.layers.0
24-11-25 17:13:45 | I | collecting calibration activations in model.layers.0
24-11-25 17:13:45 | I | collecting calibration activations in model.layers.0
24-11-25 17:13:47 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 17:13:47 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 17:13:47 | I | - Evaluator: gptq
24-11-25 17:13:47 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 17:13:47 | I | - Batch_size: 8
24-11-25 17:13:47 | I |   + Max_seq_length: 2048
24-11-25 17:14:28 | I |     - Results:
24-11-25 17:14:28 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 17:14:28 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 17:14:28 | I |       |wikitext |      1|word_perplexity|7.7835|  |7.7835|
24-11-25 17:14:28 | I |       |val_valid|      1|word_perplexity|9.0505|  |9.0505|
24-11-25 17:14:28 | I |       
24-11-25 17:14:28 | I | forward this layer
24-11-25 17:14:28 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/73.pt
24-11-25 17:14:28 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/73.pt
24-11-25 17:14:28 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 17:14:28 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 17:14:28 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 17:14:28 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 17:14:28 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 17:14:28 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 17:14:28 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 17:14:28 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 17:14:28 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 17:14:28 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 17:14:28 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 17:14:28 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 17:14:28 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 17:14:28 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 17:14:28 | I | [22] done with optimizer step
24-11-25 17:14:28 | I | epoch 001:     37 / 409600000 loss=0.000134097, loss_per_token=0.274631, loss_sum=8999.11, wps=153.1, ups=0, wpb=32768, bsz=64, num_updates=23, lr=6.9e-05, gnorm=24.315, clip=100, loss_scale=0.0078, train_wall=214, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=8199, lmquant_ppl_result_wikitext_in_train_no_quant=7.77824, lmquant_ppl_result_val_in_train_no_quant=9.00988, lmquant_ppl_result_wikitext_in_train_with_quant=7.78353, lmquant_ppl_result_val_in_train_with_quant=9.05054
24-11-25 17:14:29 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 17:14:29 | I | in layer model.layers.0
24-11-25 17:14:29 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 17:14:29 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 17:14:29 | I | - Evaluator: gptq
24-11-25 17:14:29 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 17:14:29 | I | - Batch_size: 8
24-11-25 17:14:29 | I |   + Max_seq_length: 2048
24-11-25 17:15:07 | I |     - Results:
24-11-25 17:15:07 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 17:15:07 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 17:15:07 | I |       |wikitext |      1|word_perplexity|7.8066|  |7.8066|
24-11-25 17:15:07 | I |       |val_valid|      1|word_perplexity|9.0210|  |9.0210|
24-11-25 17:15:07 | I |       
24-11-25 17:15:07 | I | quantizing weights for layer model.layers.0
24-11-25 17:15:07 | I | collecting info in model.layers.0
24-11-25 17:15:07 | I | collecting info in model.layers.0
24-11-25 17:15:07 | I | collecting info in model.layers.0
24-11-25 17:15:07 | I | collecting info in model.layers.0
24-11-25 17:15:08 | I | collecting calibration activations in model.layers.0
24-11-25 17:15:08 | I | collecting calibration activations in model.layers.0
24-11-25 17:15:08 | I | collecting calibration activations in model.layers.0
24-11-25 17:15:08 | I | collecting calibration activations in model.layers.0
24-11-25 17:15:08 | I | - Quantizing decoder layer model.layers.0
24-11-25 17:15:08 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 17:15:09 | I |       - range scale = [    1.0000]
24-11-25 17:15:09 | I |         sum  error  = [    0.0669]
24-11-25 17:15:09 | I |         best error  = [    0.0669]
24-11-25 17:15:09 | I |     + error = [0.0669]
24-11-25 17:15:10 | I |       - range scale = [    1.0000]
24-11-25 17:15:10 | I |         sum  error  = [    0.6593]
24-11-25 17:15:10 | I |         best error  = [    0.6593]
24-11-25 17:15:10 | I |     + error = [0.6593]
24-11-25 17:15:10 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 17:15:10 | I |       - range scale = [    1.0000]
24-11-25 17:15:10 | I |         sum  error  = [    0.0717]
24-11-25 17:15:10 | I |         best error  = [    0.0717]
24-11-25 17:15:10 | I |     + error = [0.0717]
24-11-25 17:15:11 | I |       - range scale = [    1.0000]
24-11-25 17:15:11 | I |         sum  error  = [    0.6014]
24-11-25 17:15:11 | I |         best error  = [    0.6014]
24-11-25 17:15:11 | I |     + error = [0.6014]
24-11-25 17:15:11 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 17:15:12 | I |       - range scale = [    1.0000]
24-11-25 17:15:12 | I |         sum  error  = [    0.2354]
24-11-25 17:15:12 | I |         best error  = [    0.2354]
24-11-25 17:15:12 | I |     + error = [0.2354]
24-11-25 17:15:13 | I |       - range scale = [    1.0000]
24-11-25 17:15:13 | I |         sum  error  = [    1.8245]
24-11-25 17:15:13 | I |         best error  = [    1.8245]
24-11-25 17:15:13 | I |     + error = [1.8245]
24-11-25 17:15:13 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 17:15:14 | I |       - range scale = [    1.0000]
24-11-25 17:15:14 | I |         sum  error  = [    0.0683]
24-11-25 17:15:14 | I |         best error  = [    0.0683]
24-11-25 17:15:14 | I |     + error = [0.0683]
24-11-25 17:15:14 | I |       - range scale = [    1.0000]
24-11-25 17:15:14 | I |         sum  error  = [    0.6531]
24-11-25 17:15:14 | I |         best error  = [    0.6531]
24-11-25 17:15:14 | I |     + error = [0.6531]
24-11-25 17:15:15 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 17:15:15 | I |       - range scale = [    1.0000]
24-11-25 17:15:15 | I |         sum  error  = [    1.1090]
24-11-25 17:15:15 | I |         best error  = [    1.1090]
24-11-25 17:15:15 | I |     + error = [1.1090]
24-11-25 17:15:16 | I |       - range scale = [    1.0000]
24-11-25 17:15:16 | I |         sum  error  = [   12.2714]
24-11-25 17:15:16 | I |         best error  = [   12.2714]
24-11-25 17:15:16 | I |     + error = [12.2714]
24-11-25 17:15:16 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 17:15:17 | I |       - range scale = [    1.0000]
24-11-25 17:15:17 | I |         sum  error  = [    1.2799]
24-11-25 17:15:17 | I |         best error  = [    1.2799]
24-11-25 17:15:17 | I |     + error = [1.2799]
24-11-25 17:15:18 | I |       - range scale = [    1.0000]
24-11-25 17:15:18 | I |         sum  error  = [   12.6860]
24-11-25 17:15:18 | I |         best error  = [   12.6860]
24-11-25 17:15:18 | I |     + error = [12.6860]
24-11-25 17:15:18 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 17:15:18 | I |       - range scale = [    1.0000]
24-11-25 17:15:18 | I |         sum  error  = [    3.3778]
24-11-25 17:15:18 | I |         best error  = [    3.3778]
24-11-25 17:15:19 | I |     + error = [3.3778]
24-11-25 17:15:19 | I |       - range scale = [    1.0000]
24-11-25 17:15:19 | I |         sum  error  = [   18.2683]
24-11-25 17:15:19 | I |         best error  = [   18.2683]
24-11-25 17:15:19 | I |     + error = [18.2683]
24-11-25 17:15:19 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 17:15:21 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 17:15:22 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 17:15:24 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 17:15:25 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 17:15:26 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 17:15:28 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 17:15:31 | I | quantizing activations for layer model.layers.0
24-11-25 17:15:31 | I | collecting info in model.layers.0
24-11-25 17:15:31 | I | collecting info in model.layers.0
24-11-25 17:15:31 | I | collecting info in model.layers.0
24-11-25 17:15:31 | I | collecting info in model.layers.0
24-11-25 17:15:32 | I | collecting calibration activations in model.layers.0
24-11-25 17:15:32 | I | collecting calibration activations in model.layers.0
24-11-25 17:15:32 | I | collecting calibration activations in model.layers.0
24-11-25 17:15:32 | I | collecting calibration activations in model.layers.0
24-11-25 17:15:34 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 17:15:34 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 17:15:34 | I | - Evaluator: gptq
24-11-25 17:15:34 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 17:15:34 | I | - Batch_size: 8
24-11-25 17:15:34 | I |   + Max_seq_length: 2048
24-11-25 17:16:15 | I |     - Results:
24-11-25 17:16:15 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 17:16:15 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 17:16:15 | I |       |wikitext |      1|word_perplexity|7.7803|  |7.7803|
24-11-25 17:16:15 | I |       |val_valid|      1|word_perplexity|9.0528|  |9.0528|
24-11-25 17:16:15 | I |       
24-11-25 17:16:15 | I | forward this layer
24-11-25 17:16:15 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/74.pt
24-11-25 17:16:15 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/74.pt
24-11-25 17:16:15 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 17:16:15 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 17:16:15 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 17:16:15 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 17:16:15 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 17:16:15 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 17:16:15 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 17:16:15 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 17:16:15 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 17:16:15 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 17:16:15 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 17:16:15 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 17:16:15 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 17:16:15 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 17:16:16 | I | in layer model.layers.0
24-11-25 17:16:16 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 17:16:16 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 17:16:16 | I | - Evaluator: gptq
24-11-25 17:16:16 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 17:16:16 | I | - Batch_size: 8
24-11-25 17:16:16 | I |   + Max_seq_length: 2048
24-11-25 17:16:54 | I |     - Results:
24-11-25 17:16:54 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 17:16:54 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 17:16:54 | I |       |wikitext |      1|word_perplexity|7.8066|  |7.8066|
24-11-25 17:16:54 | I |       |val_valid|      1|word_perplexity|9.0210|  |9.0210|
24-11-25 17:16:54 | I |       
24-11-25 17:16:54 | I | quantizing weights for layer model.layers.0
24-11-25 17:16:54 | I | collecting info in model.layers.0
24-11-25 17:16:54 | I | collecting info in model.layers.0
24-11-25 17:16:54 | I | collecting info in model.layers.0
24-11-25 17:16:54 | I | collecting info in model.layers.0
24-11-25 17:16:54 | I | collecting calibration activations in model.layers.0
24-11-25 17:16:54 | I | collecting calibration activations in model.layers.0
24-11-25 17:16:55 | I | collecting calibration activations in model.layers.0
24-11-25 17:16:55 | I | collecting calibration activations in model.layers.0
24-11-25 17:16:55 | I | - Quantizing decoder layer model.layers.0
24-11-25 17:16:55 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 17:16:56 | I |       - range scale = [    1.0000]
24-11-25 17:16:56 | I |         sum  error  = [    0.0627]
24-11-25 17:16:56 | I |         best error  = [    0.0627]
24-11-25 17:16:56 | I |     + error = [0.0627]
24-11-25 17:16:56 | I |       - range scale = [    1.0000]
24-11-25 17:16:56 | I |         sum  error  = [    0.6213]
24-11-25 17:16:56 | I |         best error  = [    0.6213]
24-11-25 17:16:56 | I |     + error = [0.6213]
24-11-25 17:16:57 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 17:16:57 | I |       - range scale = [    1.0000]
24-11-25 17:16:57 | I |         sum  error  = [    0.0710]
24-11-25 17:16:57 | I |         best error  = [    0.0710]
24-11-25 17:16:57 | I |     + error = [0.0710]
24-11-25 17:16:58 | I |       - range scale = [    1.0000]
24-11-25 17:16:58 | I |         sum  error  = [    0.5799]
24-11-25 17:16:58 | I |         best error  = [    0.5799]
24-11-25 17:16:58 | I |     + error = [0.5799]
24-11-25 17:16:58 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 17:16:59 | I |       - range scale = [    1.0000]
24-11-25 17:16:59 | I |         sum  error  = [    0.2386]
24-11-25 17:16:59 | I |         best error  = [    0.2386]
24-11-25 17:16:59 | I |     + error = [0.2386]
24-11-25 17:16:59 | I |       - range scale = [    1.0000]
24-11-25 17:16:59 | I |         sum  error  = [    1.8263]
24-11-25 17:16:59 | I |         best error  = [    1.8263]
24-11-25 17:16:59 | I |     + error = [1.8263]
24-11-25 17:17:00 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 17:17:00 | I |       - range scale = [    1.0000]
24-11-25 17:17:00 | I |         sum  error  = [    0.0703]
24-11-25 17:17:00 | I |         best error  = [    0.0703]
24-11-25 17:17:00 | I |     + error = [0.0703]
24-11-25 17:17:01 | I |       - range scale = [    1.0000]
24-11-25 17:17:01 | I |         sum  error  = [    0.6753]
24-11-25 17:17:01 | I |         best error  = [    0.6753]
24-11-25 17:17:01 | I |     + error = [0.6753]
24-11-25 17:17:01 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 17:17:02 | I |       - range scale = [    1.0000]
24-11-25 17:17:02 | I |         sum  error  = [    1.1109]
24-11-25 17:17:02 | I |         best error  = [    1.1109]
24-11-25 17:17:02 | I |     + error = [1.1109]
24-11-25 17:17:03 | I |       - range scale = [    1.0000]
24-11-25 17:17:03 | I |         sum  error  = [   12.2933]
24-11-25 17:17:03 | I |         best error  = [   12.2933]
24-11-25 17:17:03 | I |     + error = [12.2933]
24-11-25 17:17:03 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 17:17:04 | I |       - range scale = [    1.0000]
24-11-25 17:17:04 | I |         sum  error  = [    1.2835]
24-11-25 17:17:04 | I |         best error  = [    1.2835]
24-11-25 17:17:04 | I |     + error = [1.2835]
24-11-25 17:17:04 | I |       - range scale = [    1.0000]
24-11-25 17:17:04 | I |         sum  error  = [   12.7171]
24-11-25 17:17:04 | I |         best error  = [   12.7171]
24-11-25 17:17:04 | I |     + error = [12.7171]
24-11-25 17:17:05 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 17:17:05 | I |       - range scale = [    1.0000]
24-11-25 17:17:05 | I |         sum  error  = [    2.8621]
24-11-25 17:17:05 | I |         best error  = [    2.8621]
24-11-25 17:17:05 | I |     + error = [2.8621]
24-11-25 17:17:06 | I |       - range scale = [    1.0000]
24-11-25 17:17:06 | I |         sum  error  = [   15.2767]
24-11-25 17:17:06 | I |         best error  = [   15.2767]
24-11-25 17:17:06 | I |     + error = [15.2767]
24-11-25 17:17:06 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 17:17:08 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 17:17:09 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 17:17:10 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 17:17:12 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 17:17:13 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 17:17:15 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 17:17:18 | I | quantizing activations for layer model.layers.0
24-11-25 17:17:18 | I | collecting info in model.layers.0
24-11-25 17:17:18 | I | collecting info in model.layers.0
24-11-25 17:17:18 | I | collecting info in model.layers.0
24-11-25 17:17:18 | I | collecting info in model.layers.0
24-11-25 17:17:18 | I | collecting calibration activations in model.layers.0
24-11-25 17:17:18 | I | collecting calibration activations in model.layers.0
24-11-25 17:17:19 | I | collecting calibration activations in model.layers.0
24-11-25 17:17:19 | I | collecting calibration activations in model.layers.0
24-11-25 17:17:21 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 17:17:21 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 17:17:21 | I | - Evaluator: gptq
24-11-25 17:17:21 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 17:17:21 | I | - Batch_size: 8
24-11-25 17:17:21 | I |   + Max_seq_length: 2048
24-11-25 17:18:02 | I |     - Results:
24-11-25 17:18:02 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 17:18:02 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 17:18:02 | I |       |wikitext |      1|word_perplexity|7.7898|  |7.7898|
24-11-25 17:18:02 | I |       |val_valid|      1|word_perplexity|9.0584|  |9.0584|
24-11-25 17:18:02 | I |       
24-11-25 17:18:02 | I | forward this layer
24-11-25 17:18:02 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/75.pt
24-11-25 17:18:02 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/75.pt
24-11-25 17:18:02 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 17:18:02 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 17:18:02 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 17:18:02 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 17:18:02 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 17:18:02 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 17:18:02 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 17:18:02 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 17:18:02 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 17:18:02 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 17:18:02 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 17:18:02 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 17:18:02 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 17:18:02 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 17:18:02 | I | [23] done with optimizer step
24-11-25 17:18:02 | I | epoch 001:     38 / 409600000 loss=0.000138628, loss_per_token=0.283911, loss_sum=9303.2, wps=153.2, ups=0, wpb=32768, bsz=64, num_updates=24, lr=7.2e-05, gnorm=35.473, clip=100, loss_scale=0.0078, train_wall=214, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=8413, lmquant_ppl_result_wikitext_in_train_no_quant=7.80658, lmquant_ppl_result_val_in_train_no_quant=9.02105, lmquant_ppl_result_wikitext_in_train_with_quant=7.7898, lmquant_ppl_result_val_in_train_with_quant=9.05841
24-11-25 17:18:03 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 17:18:03 | I | in layer model.layers.0
24-11-25 17:18:03 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 17:18:03 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 17:18:03 | I | - Evaluator: gptq
24-11-25 17:18:03 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 17:18:03 | I | - Batch_size: 8
24-11-25 17:18:03 | I |   + Max_seq_length: 2048
24-11-25 17:18:41 | I |     - Results:
24-11-25 17:18:41 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 17:18:41 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 17:18:41 | I |       |wikitext |      1|word_perplexity|7.8383|  |7.8383|
24-11-25 17:18:41 | I |       |val_valid|      1|word_perplexity|9.0359|  |9.0359|
24-11-25 17:18:41 | I |       
24-11-25 17:18:41 | I | quantizing weights for layer model.layers.0
24-11-25 17:18:41 | I | collecting info in model.layers.0
24-11-25 17:18:41 | I | collecting info in model.layers.0
24-11-25 17:18:41 | I | collecting info in model.layers.0
24-11-25 17:18:41 | I | collecting info in model.layers.0
24-11-25 17:18:41 | I | collecting calibration activations in model.layers.0
24-11-25 17:18:42 | I | collecting calibration activations in model.layers.0
24-11-25 17:18:42 | I | collecting calibration activations in model.layers.0
24-11-25 17:18:42 | I | collecting calibration activations in model.layers.0
24-11-25 17:18:42 | I | - Quantizing decoder layer model.layers.0
24-11-25 17:18:42 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 17:18:43 | I |       - range scale = [    1.0000]
24-11-25 17:18:43 | I |         sum  error  = [    0.0678]
24-11-25 17:18:43 | I |         best error  = [    0.0678]
24-11-25 17:18:43 | I |     + error = [0.0678]
24-11-25 17:18:43 | I |       - range scale = [    1.0000]
24-11-25 17:18:43 | I |         sum  error  = [    0.6659]
24-11-25 17:18:43 | I |         best error  = [    0.6659]
24-11-25 17:18:43 | I |     + error = [0.6659]
24-11-25 17:18:44 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 17:18:44 | I |       - range scale = [    1.0000]
24-11-25 17:18:44 | I |         sum  error  = [    0.0756]
24-11-25 17:18:44 | I |         best error  = [    0.0756]
24-11-25 17:18:44 | I |     + error = [0.0756]
24-11-25 17:18:45 | I |       - range scale = [    1.0000]
24-11-25 17:18:45 | I |         sum  error  = [    0.5825]
24-11-25 17:18:45 | I |         best error  = [    0.5825]
24-11-25 17:18:45 | I |     + error = [0.5825]
24-11-25 17:18:45 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 17:18:46 | I |       - range scale = [    1.0000]
24-11-25 17:18:46 | I |         sum  error  = [    0.2468]
24-11-25 17:18:46 | I |         best error  = [    0.2468]
24-11-25 17:18:46 | I |     + error = [0.2468]
24-11-25 17:18:47 | I |       - range scale = [    1.0000]
24-11-25 17:18:47 | I |         sum  error  = [    1.8365]
24-11-25 17:18:47 | I |         best error  = [    1.8365]
24-11-25 17:18:47 | I |     + error = [1.8365]
24-11-25 17:18:47 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 17:18:47 | I |       - range scale = [    1.0000]
24-11-25 17:18:47 | I |         sum  error  = [    0.0627]
24-11-25 17:18:47 | I |         best error  = [    0.0627]
24-11-25 17:18:47 | I |     + error = [0.0627]
24-11-25 17:18:48 | I |       - range scale = [    1.0000]
24-11-25 17:18:48 | I |         sum  error  = [    0.6028]
24-11-25 17:18:48 | I |         best error  = [    0.6028]
24-11-25 17:18:48 | I |     + error = [0.6028]
24-11-25 17:18:48 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 17:18:49 | I |       - range scale = [    1.0000]
24-11-25 17:18:49 | I |         sum  error  = [    1.0605]
24-11-25 17:18:49 | I |         best error  = [    1.0605]
24-11-25 17:18:49 | I |     + error = [1.0605]
24-11-25 17:18:50 | I |       - range scale = [    1.0000]
24-11-25 17:18:50 | I |         sum  error  = [   11.7411]
24-11-25 17:18:50 | I |         best error  = [   11.7411]
24-11-25 17:18:50 | I |     + error = [11.7411]
24-11-25 17:18:50 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 17:18:51 | I |       - range scale = [    1.0000]
24-11-25 17:18:51 | I |         sum  error  = [    1.2274]
24-11-25 17:18:51 | I |         best error  = [    1.2274]
24-11-25 17:18:51 | I |     + error = [1.2274]
24-11-25 17:18:52 | I |       - range scale = [    1.0000]
24-11-25 17:18:52 | I |         sum  error  = [   12.1198]
24-11-25 17:18:52 | I |         best error  = [   12.1198]
24-11-25 17:18:52 | I |     + error = [12.1198]
24-11-25 17:18:52 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 17:18:52 | I |       - range scale = [    1.0000]
24-11-25 17:18:52 | I |         sum  error  = [    3.0195]
24-11-25 17:18:52 | I |         best error  = [    3.0195]
24-11-25 17:18:52 | I |     + error = [3.0195]
24-11-25 17:18:53 | I |       - range scale = [    1.0000]
24-11-25 17:18:53 | I |         sum  error  = [   16.3542]
24-11-25 17:18:53 | I |         best error  = [   16.3542]
24-11-25 17:18:53 | I |     + error = [16.3542]
24-11-25 17:18:53 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 17:18:55 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 17:18:56 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 17:18:58 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 17:18:59 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 17:19:00 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 17:19:02 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 17:19:05 | I | quantizing activations for layer model.layers.0
24-11-25 17:19:05 | I | collecting info in model.layers.0
24-11-25 17:19:05 | I | collecting info in model.layers.0
24-11-25 17:19:05 | I | collecting info in model.layers.0
24-11-25 17:19:05 | I | collecting info in model.layers.0
24-11-25 17:19:06 | I | collecting calibration activations in model.layers.0
24-11-25 17:19:06 | I | collecting calibration activations in model.layers.0
24-11-25 17:19:06 | I | collecting calibration activations in model.layers.0
24-11-25 17:19:06 | I | collecting calibration activations in model.layers.0
24-11-25 17:19:08 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 17:19:08 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 17:19:08 | I | - Evaluator: gptq
24-11-25 17:19:08 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 17:19:08 | I | - Batch_size: 8
24-11-25 17:19:08 | I |   + Max_seq_length: 2048
24-11-25 17:19:49 | I |     - Results:
24-11-25 17:19:49 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 17:19:49 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 17:19:49 | I |       |wikitext |      1|word_perplexity|7.8220|  |7.8220|
24-11-25 17:19:49 | I |       |val_valid|      1|word_perplexity|9.0658|  |9.0658|
24-11-25 17:19:49 | I |       
24-11-25 17:19:49 | I | forward this layer
24-11-25 17:19:49 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/76.pt
24-11-25 17:19:49 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/76.pt
24-11-25 17:19:49 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 17:19:49 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 17:19:49 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 17:19:49 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 17:19:49 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 17:19:49 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 17:19:49 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 17:19:49 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 17:19:49 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 17:19:49 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 17:19:49 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 17:19:49 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 17:19:49 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 17:19:49 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 17:19:50 | I | in layer model.layers.0
24-11-25 17:19:50 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 17:19:50 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 17:19:50 | I | - Evaluator: gptq
24-11-25 17:19:50 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 17:19:50 | I | - Batch_size: 8
24-11-25 17:19:50 | I |   + Max_seq_length: 2048
24-11-25 17:20:28 | I |     - Results:
24-11-25 17:20:28 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 17:20:28 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 17:20:28 | I |       |wikitext |      1|word_perplexity|7.8383|  |7.8383|
24-11-25 17:20:28 | I |       |val_valid|      1|word_perplexity|9.0359|  |9.0359|
24-11-25 17:20:28 | I |       
24-11-25 17:20:28 | I | quantizing weights for layer model.layers.0
24-11-25 17:20:28 | I | collecting info in model.layers.0
24-11-25 17:20:28 | I | collecting info in model.layers.0
24-11-25 17:20:28 | I | collecting info in model.layers.0
24-11-25 17:20:28 | I | collecting info in model.layers.0
24-11-25 17:20:28 | I | collecting calibration activations in model.layers.0
24-11-25 17:20:28 | I | collecting calibration activations in model.layers.0
24-11-25 17:20:29 | I | collecting calibration activations in model.layers.0
24-11-25 17:20:29 | I | collecting calibration activations in model.layers.0
24-11-25 17:20:29 | I | - Quantizing decoder layer model.layers.0
24-11-25 17:20:29 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 17:20:30 | I |       - range scale = [    1.0000]
24-11-25 17:20:30 | I |         sum  error  = [    0.0700]
24-11-25 17:20:30 | I |         best error  = [    0.0700]
24-11-25 17:20:30 | I |     + error = [0.0700]
24-11-25 17:20:31 | I |       - range scale = [    1.0000]
24-11-25 17:20:31 | I |         sum  error  = [    0.6087]
24-11-25 17:20:31 | I |         best error  = [    0.6087]
24-11-25 17:20:31 | I |     + error = [0.6087]
24-11-25 17:20:31 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 17:20:32 | I |       - range scale = [    1.0000]
24-11-25 17:20:32 | I |         sum  error  = [    0.0770]
24-11-25 17:20:32 | I |         best error  = [    0.0770]
24-11-25 17:20:32 | I |     + error = [0.0770]
24-11-25 17:20:32 | I |       - range scale = [    1.0000]
24-11-25 17:20:32 | I |         sum  error  = [    0.5992]
24-11-25 17:20:32 | I |         best error  = [    0.5992]
24-11-25 17:20:32 | I |     + error = [0.5992]
24-11-25 17:20:32 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 17:20:33 | I |       - range scale = [    1.0000]
24-11-25 17:20:33 | I |         sum  error  = [    0.2372]
24-11-25 17:20:33 | I |         best error  = [    0.2372]
24-11-25 17:20:33 | I |     + error = [0.2372]
24-11-25 17:20:34 | I |       - range scale = [    1.0000]
24-11-25 17:20:34 | I |         sum  error  = [    1.7739]
24-11-25 17:20:34 | I |         best error  = [    1.7739]
24-11-25 17:20:34 | I |     + error = [1.7739]
24-11-25 17:20:34 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 17:20:35 | I |       - range scale = [    1.0000]
24-11-25 17:20:35 | I |         sum  error  = [    0.0744]
24-11-25 17:20:35 | I |         best error  = [    0.0744]
24-11-25 17:20:35 | I |     + error = [0.0744]
24-11-25 17:20:35 | I |       - range scale = [    1.0000]
24-11-25 17:20:35 | I |         sum  error  = [    0.7166]
24-11-25 17:20:35 | I |         best error  = [    0.7166]
24-11-25 17:20:35 | I |     + error = [0.7166]
24-11-25 17:20:35 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 17:20:36 | I |       - range scale = [    1.0000]
24-11-25 17:20:36 | I |         sum  error  = [    1.1055]
24-11-25 17:20:36 | I |         best error  = [    1.1055]
24-11-25 17:20:36 | I |     + error = [1.1055]
24-11-25 17:20:37 | I |       - range scale = [    1.0000]
24-11-25 17:20:37 | I |         sum  error  = [   12.2285]
24-11-25 17:20:37 | I |         best error  = [   12.2285]
24-11-25 17:20:37 | I |     + error = [12.2285]
24-11-25 17:20:37 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 17:20:38 | I |       - range scale = [    1.0000]
24-11-25 17:20:38 | I |         sum  error  = [    1.2739]
24-11-25 17:20:38 | I |         best error  = [    1.2739]
24-11-25 17:20:38 | I |     + error = [1.2739]
24-11-25 17:20:39 | I |       - range scale = [    1.0000]
24-11-25 17:20:39 | I |         sum  error  = [   12.6151]
24-11-25 17:20:39 | I |         best error  = [   12.6151]
24-11-25 17:20:39 | I |     + error = [12.6151]
24-11-25 17:20:39 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 17:20:39 | I |       - range scale = [    1.0000]
24-11-25 17:20:39 | I |         sum  error  = [    2.3631]
24-11-25 17:20:39 | I |         best error  = [    2.3631]
24-11-25 17:20:39 | I |     + error = [2.3631]
24-11-25 17:20:40 | I |       - range scale = [    1.0000]
24-11-25 17:20:40 | I |         sum  error  = [   12.5634]
24-11-25 17:20:40 | I |         best error  = [   12.5634]
24-11-25 17:20:40 | I |     + error = [12.5634]
24-11-25 17:20:40 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 17:20:42 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 17:20:44 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 17:20:45 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 17:20:47 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 17:20:48 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 17:20:49 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 17:20:53 | I | quantizing activations for layer model.layers.0
24-11-25 17:20:53 | I | collecting info in model.layers.0
24-11-25 17:20:53 | I | collecting info in model.layers.0
24-11-25 17:20:53 | I | collecting info in model.layers.0
24-11-25 17:20:53 | I | collecting info in model.layers.0
24-11-25 17:20:53 | I | collecting calibration activations in model.layers.0
24-11-25 17:20:53 | I | collecting calibration activations in model.layers.0
24-11-25 17:20:53 | I | collecting calibration activations in model.layers.0
24-11-25 17:20:53 | I | collecting calibration activations in model.layers.0
24-11-25 17:20:55 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 17:20:55 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 17:20:55 | I | - Evaluator: gptq
24-11-25 17:20:55 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 17:20:55 | I | - Batch_size: 8
24-11-25 17:20:55 | I |   + Max_seq_length: 2048
24-11-25 17:21:37 | I |     - Results:
24-11-25 17:21:37 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 17:21:37 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 17:21:37 | I |       |wikitext |      1|word_perplexity|7.8150|  |7.8150|
24-11-25 17:21:37 | I |       |val_valid|      1|word_perplexity|9.0534|  |9.0534|
24-11-25 17:21:37 | I |       
24-11-25 17:21:37 | I | forward this layer
24-11-25 17:21:37 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/77.pt
24-11-25 17:21:37 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/77.pt
24-11-25 17:21:37 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 17:21:37 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 17:21:37 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 17:21:37 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 17:21:37 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 17:21:37 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 17:21:37 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 17:21:37 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 17:21:37 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 17:21:37 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 17:21:37 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 17:21:37 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 17:21:37 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 17:21:37 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 17:21:37 | I | [24] done with optimizer step
24-11-25 17:21:37 | I | epoch 001:     39 / 409600000 loss=0.000170893, loss_per_token=0.349989, loss_sum=11468.4, wps=152.6, ups=0, wpb=32768, bsz=64, num_updates=25, lr=7.5e-05, gnorm=50.696, clip=100, loss_scale=0.0078, train_wall=215, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=8627, lmquant_ppl_result_wikitext_in_train_no_quant=7.83827, lmquant_ppl_result_val_in_train_no_quant=9.03593, lmquant_ppl_result_wikitext_in_train_with_quant=7.815, lmquant_ppl_result_val_in_train_with_quant=9.05336
24-11-25 17:21:37 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 17:21:37 | I | in layer model.layers.0
24-11-25 17:21:37 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 17:21:37 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 17:21:37 | I | - Evaluator: gptq
24-11-25 17:21:37 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 17:21:37 | I | - Batch_size: 8
24-11-25 17:21:37 | I |   + Max_seq_length: 2048
24-11-25 17:22:16 | I |     - Results:
24-11-25 17:22:16 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 17:22:16 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 17:22:16 | I |       |wikitext |      1|word_perplexity|7.8691|  |7.8691|
24-11-25 17:22:16 | I |       |val_valid|      1|word_perplexity|9.0551|  |9.0551|
24-11-25 17:22:16 | I |       
24-11-25 17:22:16 | I | quantizing weights for layer model.layers.0
24-11-25 17:22:16 | I | collecting info in model.layers.0
24-11-25 17:22:16 | I | collecting info in model.layers.0
24-11-25 17:22:16 | I | collecting info in model.layers.0
24-11-25 17:22:16 | I | collecting info in model.layers.0
24-11-25 17:22:16 | I | collecting calibration activations in model.layers.0
24-11-25 17:22:16 | I | collecting calibration activations in model.layers.0
24-11-25 17:22:16 | I | collecting calibration activations in model.layers.0
24-11-25 17:22:17 | I | collecting calibration activations in model.layers.0
24-11-25 17:22:17 | I | - Quantizing decoder layer model.layers.0
24-11-25 17:22:17 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 17:22:18 | I |       - range scale = [    1.0000]
24-11-25 17:22:18 | I |         sum  error  = [    0.0653]
24-11-25 17:22:18 | I |         best error  = [    0.0653]
24-11-25 17:22:18 | I |     + error = [0.0653]
24-11-25 17:22:18 | I |       - range scale = [    1.0000]
24-11-25 17:22:18 | I |         sum  error  = [    0.6162]
24-11-25 17:22:18 | I |         best error  = [    0.6162]
24-11-25 17:22:18 | I |     + error = [0.6162]
24-11-25 17:22:18 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 17:22:19 | I |       - range scale = [    1.0000]
24-11-25 17:22:19 | I |         sum  error  = [    0.0816]
24-11-25 17:22:19 | I |         best error  = [    0.0816]
24-11-25 17:22:19 | I |     + error = [0.0816]
24-11-25 17:22:20 | I |       - range scale = [    1.0000]
24-11-25 17:22:20 | I |         sum  error  = [    0.5801]
24-11-25 17:22:20 | I |         best error  = [    0.5801]
24-11-25 17:22:20 | I |     + error = [0.5801]
24-11-25 17:22:20 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 17:22:21 | I |       - range scale = [    1.0000]
24-11-25 17:22:21 | I |         sum  error  = [    0.2461]
24-11-25 17:22:21 | I |         best error  = [    0.2461]
24-11-25 17:22:21 | I |     + error = [0.2461]
24-11-25 17:22:21 | I |       - range scale = [    1.0000]
24-11-25 17:22:21 | I |         sum  error  = [    1.8205]
24-11-25 17:22:21 | I |         best error  = [    1.8205]
24-11-25 17:22:21 | I |     + error = [1.8205]
24-11-25 17:22:22 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 17:22:22 | I |       - range scale = [    1.0000]
24-11-25 17:22:22 | I |         sum  error  = [    0.0839]
24-11-25 17:22:22 | I |         best error  = [    0.0839]
24-11-25 17:22:22 | I |     + error = [0.0839]
24-11-25 17:22:23 | I |       - range scale = [    1.0000]
24-11-25 17:22:23 | I |         sum  error  = [    0.7960]
24-11-25 17:22:23 | I |         best error  = [    0.7960]
24-11-25 17:22:23 | I |     + error = [0.7960]
24-11-25 17:22:23 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 17:22:24 | I |       - range scale = [    1.0000]
24-11-25 17:22:24 | I |         sum  error  = [    1.1065]
24-11-25 17:22:24 | I |         best error  = [    1.1065]
24-11-25 17:22:24 | I |     + error = [1.1065]
24-11-25 17:22:25 | I |       - range scale = [    1.0000]
24-11-25 17:22:25 | I |         sum  error  = [   12.2919]
24-11-25 17:22:25 | I |         best error  = [   12.2919]
24-11-25 17:22:25 | I |     + error = [12.2919]
24-11-25 17:22:25 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 17:22:25 | I |       - range scale = [    1.0000]
24-11-25 17:22:25 | I |         sum  error  = [    1.2861]
24-11-25 17:22:25 | I |         best error  = [    1.2861]
24-11-25 17:22:25 | I |     + error = [1.2861]
24-11-25 17:22:26 | I |       - range scale = [    1.0000]
24-11-25 17:22:26 | I |         sum  error  = [   12.7049]
24-11-25 17:22:26 | I |         best error  = [   12.7049]
24-11-25 17:22:26 | I |     + error = [12.7049]
24-11-25 17:22:26 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 17:22:27 | I |       - range scale = [    1.0000]
24-11-25 17:22:27 | I |         sum  error  = [    1.8550]
24-11-25 17:22:27 | I |         best error  = [    1.8550]
24-11-25 17:22:27 | I |     + error = [1.8550]
24-11-25 17:22:28 | I |       - range scale = [    1.0000]
24-11-25 17:22:28 | I |         sum  error  = [    9.8955]
24-11-25 17:22:28 | I |         best error  = [    9.8955]
24-11-25 17:22:28 | I |     + error = [9.8955]
24-11-25 17:22:28 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 17:22:30 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 17:22:31 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 17:22:32 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 17:22:34 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 17:22:35 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 17:22:36 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 17:22:41 | I | quantizing activations for layer model.layers.0
24-11-25 17:22:41 | I | collecting info in model.layers.0
24-11-25 17:22:41 | I | collecting info in model.layers.0
24-11-25 17:22:41 | I | collecting info in model.layers.0
24-11-25 17:22:41 | I | collecting info in model.layers.0
24-11-25 17:22:41 | I | collecting calibration activations in model.layers.0
24-11-25 17:22:41 | I | collecting calibration activations in model.layers.0
24-11-25 17:22:41 | I | collecting calibration activations in model.layers.0
24-11-25 17:22:41 | I | collecting calibration activations in model.layers.0
24-11-25 17:22:43 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 17:22:43 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 17:22:43 | I | - Evaluator: gptq
24-11-25 17:22:43 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 17:22:43 | I | - Batch_size: 8
24-11-25 17:22:43 | I |   + Max_seq_length: 2048
24-11-25 17:23:25 | I |     - Results:
24-11-25 17:23:26 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 17:23:26 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 17:23:26 | I |       |wikitext |      1|word_perplexity|7.8264|  |7.8264|
24-11-25 17:23:26 | I |       |val_valid|      1|word_perplexity|9.0682|  |9.0682|
24-11-25 17:23:26 | I |       
24-11-25 17:23:26 | I | forward this layer
24-11-25 17:23:26 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/78.pt
24-11-25 17:23:26 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/78.pt
24-11-25 17:23:26 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 17:23:26 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 17:23:26 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 17:23:26 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 17:23:26 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 17:23:26 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 17:23:26 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 17:23:26 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 17:23:26 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 17:23:26 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 17:23:26 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 17:23:26 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 17:23:26 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 17:23:26 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 17:23:26 | I | in layer model.layers.0
24-11-25 17:23:26 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 17:23:26 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 17:23:26 | I | - Evaluator: gptq
24-11-25 17:23:26 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 17:23:26 | I | - Batch_size: 8
24-11-25 17:23:26 | I |   + Max_seq_length: 2048
24-11-25 17:24:04 | I |     - Results:
24-11-25 17:24:04 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 17:24:04 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 17:24:04 | I |       |wikitext |      1|word_perplexity|7.8691|  |7.8691|
24-11-25 17:24:04 | I |       |val_valid|      1|word_perplexity|9.0551|  |9.0551|
24-11-25 17:24:04 | I |       
24-11-25 17:24:04 | I | quantizing weights for layer model.layers.0
24-11-25 17:24:04 | I | collecting info in model.layers.0
24-11-25 17:24:04 | I | collecting info in model.layers.0
24-11-25 17:24:04 | I | collecting info in model.layers.0
24-11-25 17:24:04 | I | collecting info in model.layers.0
24-11-25 17:24:05 | I | collecting calibration activations in model.layers.0
24-11-25 17:24:05 | I | collecting calibration activations in model.layers.0
24-11-25 17:24:05 | I | collecting calibration activations in model.layers.0
24-11-25 17:24:05 | I | collecting calibration activations in model.layers.0
24-11-25 17:24:05 | I | - Quantizing decoder layer model.layers.0
24-11-25 17:24:05 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 17:24:06 | I |       - range scale = [    1.0000]
24-11-25 17:24:06 | I |         sum  error  = [    0.0638]
24-11-25 17:24:06 | I |         best error  = [    0.0638]
24-11-25 17:24:06 | I |     + error = [0.0638]
24-11-25 17:24:07 | I |       - range scale = [    1.0000]
24-11-25 17:24:07 | I |         sum  error  = [    0.6266]
24-11-25 17:24:07 | I |         best error  = [    0.6266]
24-11-25 17:24:07 | I |     + error = [0.6266]
24-11-25 17:24:07 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 17:24:07 | I |       - range scale = [    1.0000]
24-11-25 17:24:07 | I |         sum  error  = [    0.0830]
24-11-25 17:24:08 | I |         best error  = [    0.0830]
24-11-25 17:24:08 | I |     + error = [0.0830]
24-11-25 17:24:08 | I |       - range scale = [    1.0000]
24-11-25 17:24:08 | I |         sum  error  = [    0.5768]
24-11-25 17:24:08 | I |         best error  = [    0.5768]
24-11-25 17:24:08 | I |     + error = [0.5768]
24-11-25 17:24:08 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 17:24:09 | I |       - range scale = [    1.0000]
24-11-25 17:24:09 | I |         sum  error  = [    0.2387]
24-11-25 17:24:09 | I |         best error  = [    0.2387]
24-11-25 17:24:09 | I |     + error = [0.2387]
24-11-25 17:24:10 | I |       - range scale = [    1.0000]
24-11-25 17:24:10 | I |         sum  error  = [    1.8105]
24-11-25 17:24:10 | I |         best error  = [    1.8105]
24-11-25 17:24:10 | I |     + error = [1.8105]
24-11-25 17:24:10 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 17:24:11 | I |       - range scale = [    1.0000]
24-11-25 17:24:11 | I |         sum  error  = [    0.0660]
24-11-25 17:24:11 | I |         best error  = [    0.0660]
24-11-25 17:24:11 | I |     + error = [0.0660]
24-11-25 17:24:11 | I |       - range scale = [    1.0000]
24-11-25 17:24:11 | I |         sum  error  = [    0.6407]
24-11-25 17:24:11 | I |         best error  = [    0.6407]
24-11-25 17:24:11 | I |     + error = [0.6407]
24-11-25 17:24:12 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 17:24:12 | I |       - range scale = [    1.0000]
24-11-25 17:24:12 | I |         sum  error  = [    1.1527]
24-11-25 17:24:12 | I |         best error  = [    1.1527]
24-11-25 17:24:12 | I |     + error = [1.1527]
24-11-25 17:24:13 | I |       - range scale = [    1.0000]
24-11-25 17:24:13 | I |         sum  error  = [   12.7924]
24-11-25 17:24:13 | I |         best error  = [   12.7924]
24-11-25 17:24:13 | I |     + error = [12.7924]
24-11-25 17:24:13 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 17:24:14 | I |       - range scale = [    1.0000]
24-11-25 17:24:14 | I |         sum  error  = [    1.3350]
24-11-25 17:24:14 | I |         best error  = [    1.3350]
24-11-25 17:24:14 | I |     + error = [1.3350]
24-11-25 17:24:15 | I |       - range scale = [    1.0000]
24-11-25 17:24:15 | I |         sum  error  = [   13.2545]
24-11-25 17:24:15 | I |         best error  = [   13.2545]
24-11-25 17:24:15 | I |     + error = [13.2545]
24-11-25 17:24:15 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 17:24:16 | I |       - range scale = [    1.0000]
24-11-25 17:24:16 | I |         sum  error  = [    3.5668]
24-11-25 17:24:16 | I |         best error  = [    3.5668]
24-11-25 17:24:16 | I |     + error = [3.5668]
24-11-25 17:24:16 | I |       - range scale = [    1.0000]
24-11-25 17:24:16 | I |         sum  error  = [   19.2044]
24-11-25 17:24:16 | I |         best error  = [   19.2044]
24-11-25 17:24:16 | I |     + error = [19.2044]
24-11-25 17:24:17 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 17:24:18 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 17:24:19 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 17:24:21 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 17:24:22 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 17:24:23 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 17:24:25 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 17:24:28 | I | quantizing activations for layer model.layers.0
24-11-25 17:24:28 | I | collecting info in model.layers.0
24-11-25 17:24:28 | I | collecting info in model.layers.0
24-11-25 17:24:28 | I | collecting info in model.layers.0
24-11-25 17:24:28 | I | collecting info in model.layers.0
24-11-25 17:24:29 | I | collecting calibration activations in model.layers.0
24-11-25 17:24:29 | I | collecting calibration activations in model.layers.0
24-11-25 17:24:29 | I | collecting calibration activations in model.layers.0
24-11-25 17:24:29 | I | collecting calibration activations in model.layers.0
24-11-25 17:24:31 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 17:24:31 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 17:24:31 | I | - Evaluator: gptq
24-11-25 17:24:31 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 17:24:31 | I | - Batch_size: 8
24-11-25 17:24:31 | I |   + Max_seq_length: 2048
24-11-25 17:25:12 | I |     - Results:
24-11-25 17:25:12 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 17:25:12 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 17:25:12 | I |       |wikitext |      1|word_perplexity|7.8273|  |7.8273|
24-11-25 17:25:12 | I |       |val_valid|      1|word_perplexity|9.0639|  |9.0639|
24-11-25 17:25:12 | I |       
24-11-25 17:25:12 | I | forward this layer
24-11-25 17:25:12 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/79.pt
24-11-25 17:25:12 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/79.pt
24-11-25 17:25:13 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 17:25:13 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 17:25:13 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 17:25:13 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 17:25:13 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 17:25:13 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 17:25:13 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 17:25:13 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 17:25:13 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 17:25:13 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 17:25:13 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 17:25:13 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 17:25:13 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 17:25:13 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 17:25:13 | I | [25] done with optimizer step
24-11-25 17:25:13 | I | epoch 001:     40 / 409600000 loss=0.000127681, loss_per_token=0.261491, loss_sum=8568.53, wps=152.1, ups=0, wpb=32768, bsz=64, num_updates=26, lr=7.8e-05, gnorm=17.201, clip=100, loss_scale=0.0078, train_wall=215, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=8843, lmquant_ppl_result_wikitext_in_train_no_quant=7.86907, lmquant_ppl_result_val_in_train_no_quant=9.05506, lmquant_ppl_result_wikitext_in_train_with_quant=7.82727, lmquant_ppl_result_val_in_train_with_quant=9.06392
24-11-25 17:25:13 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 17:25:13 | I | in layer model.layers.0
24-11-25 17:25:13 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 17:25:13 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 17:25:13 | I | - Evaluator: gptq
24-11-25 17:25:13 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 17:25:13 | I | - Batch_size: 8
24-11-25 17:25:13 | I |   + Max_seq_length: 2048
24-11-25 17:25:51 | I |     - Results:
24-11-25 17:25:51 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 17:25:51 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 17:25:51 | I |       |wikitext |      1|word_perplexity|7.8978|  |7.8978|
24-11-25 17:25:51 | I |       |val_valid|      1|word_perplexity|9.0754|  |9.0754|
24-11-25 17:25:51 | I |       
24-11-25 17:25:51 | I | quantizing weights for layer model.layers.0
24-11-25 17:25:51 | I | collecting info in model.layers.0
24-11-25 17:25:51 | I | collecting info in model.layers.0
24-11-25 17:25:51 | I | collecting info in model.layers.0
24-11-25 17:25:51 | I | collecting info in model.layers.0
24-11-25 17:25:52 | I | collecting calibration activations in model.layers.0
24-11-25 17:25:52 | I | collecting calibration activations in model.layers.0
24-11-25 17:25:52 | I | collecting calibration activations in model.layers.0
24-11-25 17:25:52 | I | collecting calibration activations in model.layers.0
24-11-25 17:25:52 | I | - Quantizing decoder layer model.layers.0
24-11-25 17:25:52 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 17:25:53 | I |       - range scale = [    1.0000]
24-11-25 17:25:53 | I |         sum  error  = [    0.0590]
24-11-25 17:25:53 | I |         best error  = [    0.0590]
24-11-25 17:25:53 | I |     + error = [0.0590]
24-11-25 17:25:54 | I |       - range scale = [    1.0000]
24-11-25 17:25:54 | I |         sum  error  = [    0.6324]
24-11-25 17:25:54 | I |         best error  = [    0.6324]
24-11-25 17:25:54 | I |     + error = [0.6324]
24-11-25 17:25:54 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 17:25:55 | I |       - range scale = [    1.0000]
24-11-25 17:25:55 | I |         sum  error  = [    0.0761]
24-11-25 17:25:55 | I |         best error  = [    0.0761]
24-11-25 17:25:55 | I |     + error = [0.0761]
24-11-25 17:25:55 | I |       - range scale = [    1.0000]
24-11-25 17:25:55 | I |         sum  error  = [    0.5419]
24-11-25 17:25:55 | I |         best error  = [    0.5419]
24-11-25 17:25:55 | I |     + error = [0.5419]
24-11-25 17:25:56 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 17:25:56 | I |       - range scale = [    1.0000]
24-11-25 17:25:56 | I |         sum  error  = [    0.2367]
24-11-25 17:25:56 | I |         best error  = [    0.2367]
24-11-25 17:25:56 | I |     + error = [0.2367]
24-11-25 17:25:57 | I |       - range scale = [    1.0000]
24-11-25 17:25:57 | I |         sum  error  = [    1.7925]
24-11-25 17:25:57 | I |         best error  = [    1.7925]
24-11-25 17:25:57 | I |     + error = [1.7925]
24-11-25 17:25:57 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 17:25:58 | I |       - range scale = [    1.0000]
24-11-25 17:25:58 | I |         sum  error  = [    0.0584]
24-11-25 17:25:58 | I |         best error  = [    0.0584]
24-11-25 17:25:58 | I |     + error = [0.0584]
24-11-25 17:25:59 | I |       - range scale = [    1.0000]
24-11-25 17:25:59 | I |         sum  error  = [    0.5598]
24-11-25 17:25:59 | I |         best error  = [    0.5598]
24-11-25 17:25:59 | I |     + error = [0.5598]
24-11-25 17:25:59 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 17:25:59 | I |       - range scale = [    1.0000]
24-11-25 17:25:59 | I |         sum  error  = [    1.0536]
24-11-25 17:25:59 | I |         best error  = [    1.0536]
24-11-25 17:25:59 | I |     + error = [1.0536]
24-11-25 17:26:00 | I |       - range scale = [    1.0000]
24-11-25 17:26:00 | I |         sum  error  = [   11.6849]
24-11-25 17:26:00 | I |         best error  = [   11.6849]
24-11-25 17:26:00 | I |     + error = [11.6849]
24-11-25 17:26:00 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 17:26:01 | I |       - range scale = [    1.0000]
24-11-25 17:26:01 | I |         sum  error  = [    1.2201]
24-11-25 17:26:01 | I |         best error  = [    1.2201]
24-11-25 17:26:01 | I |     + error = [1.2201]
24-11-25 17:26:02 | I |       - range scale = [    1.0000]
24-11-25 17:26:02 | I |         sum  error  = [   12.0623]
24-11-25 17:26:02 | I |         best error  = [   12.0623]
24-11-25 17:26:02 | I |     + error = [12.0623]
24-11-25 17:26:02 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 17:26:03 | I |       - range scale = [    1.0000]
24-11-25 17:26:03 | I |         sum  error  = [    3.5889]
24-11-25 17:26:03 | I |         best error  = [    3.5889]
24-11-25 17:26:03 | I |     + error = [3.5889]
24-11-25 17:26:03 | I |       - range scale = [    1.0000]
24-11-25 17:26:03 | I |         sum  error  = [   19.5277]
24-11-25 17:26:03 | I |         best error  = [   19.5277]
24-11-25 17:26:03 | I |     + error = [19.5277]
24-11-25 17:26:04 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 17:26:05 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 17:26:06 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 17:26:08 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 17:26:09 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 17:26:11 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 17:26:12 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 17:26:15 | I | quantizing activations for layer model.layers.0
24-11-25 17:26:15 | I | collecting info in model.layers.0
24-11-25 17:26:15 | I | collecting info in model.layers.0
24-11-25 17:26:15 | I | collecting info in model.layers.0
24-11-25 17:26:15 | I | collecting info in model.layers.0
24-11-25 17:26:16 | I | collecting calibration activations in model.layers.0
24-11-25 17:26:16 | I | collecting calibration activations in model.layers.0
24-11-25 17:26:16 | I | collecting calibration activations in model.layers.0
24-11-25 17:26:16 | I | collecting calibration activations in model.layers.0
24-11-25 17:26:18 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 17:26:18 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 17:26:18 | I | - Evaluator: gptq
24-11-25 17:26:18 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 17:26:18 | I | - Batch_size: 8
24-11-25 17:26:18 | I |   + Max_seq_length: 2048
24-11-25 17:26:59 | I |     - Results:
24-11-25 17:27:00 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 17:27:00 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 17:27:00 | I |       |wikitext |      1|word_perplexity|7.8922|  |7.8922|
24-11-25 17:27:00 | I |       |val_valid|      1|word_perplexity|9.1002|  |9.1002|
24-11-25 17:27:00 | I |       
24-11-25 17:27:00 | I | forward this layer
24-11-25 17:27:00 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/80.pt
24-11-25 17:27:00 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/80.pt
24-11-25 17:27:00 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 17:27:00 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 17:27:00 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 17:27:00 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 17:27:00 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 17:27:00 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 17:27:00 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 17:27:00 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 17:27:00 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 17:27:00 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 17:27:00 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 17:27:00 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 17:27:00 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 17:27:00 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 17:27:00 | I | in layer model.layers.0
24-11-25 17:27:00 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 17:27:00 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 17:27:00 | I | - Evaluator: gptq
24-11-25 17:27:00 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 17:27:00 | I | - Batch_size: 8
24-11-25 17:27:00 | I |   + Max_seq_length: 2048
24-11-25 17:27:38 | I |     - Results:
24-11-25 17:27:38 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 17:27:38 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 17:27:38 | I |       |wikitext |      1|word_perplexity|7.8978|  |7.8978|
24-11-25 17:27:38 | I |       |val_valid|      1|word_perplexity|9.0754|  |9.0754|
24-11-25 17:27:38 | I |       
24-11-25 17:27:38 | I | quantizing weights for layer model.layers.0
24-11-25 17:27:38 | I | collecting info in model.layers.0
24-11-25 17:27:38 | I | collecting info in model.layers.0
24-11-25 17:27:38 | I | collecting info in model.layers.0
24-11-25 17:27:38 | I | collecting info in model.layers.0
24-11-25 17:27:39 | I | collecting calibration activations in model.layers.0
24-11-25 17:27:39 | I | collecting calibration activations in model.layers.0
24-11-25 17:27:39 | I | collecting calibration activations in model.layers.0
24-11-25 17:27:39 | I | collecting calibration activations in model.layers.0
24-11-25 17:27:39 | I | - Quantizing decoder layer model.layers.0
24-11-25 17:27:39 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 17:27:40 | I |       - range scale = [    1.0000]
24-11-25 17:27:40 | I |         sum  error  = [    0.0581]
24-11-25 17:27:40 | I |         best error  = [    0.0581]
24-11-25 17:27:40 | I |     + error = [0.0581]
24-11-25 17:27:41 | I |       - range scale = [    1.0000]
24-11-25 17:27:41 | I |         sum  error  = [    0.6331]
24-11-25 17:27:41 | I |         best error  = [    0.6331]
24-11-25 17:27:41 | I |     + error = [0.6331]
24-11-25 17:27:41 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 17:27:42 | I |       - range scale = [    1.0000]
24-11-25 17:27:42 | I |         sum  error  = [    0.0797]
24-11-25 17:27:42 | I |         best error  = [    0.0797]
24-11-25 17:27:42 | I |     + error = [0.0797]
24-11-25 17:27:42 | I |       - range scale = [    1.0000]
24-11-25 17:27:42 | I |         sum  error  = [    0.6052]
24-11-25 17:27:42 | I |         best error  = [    0.6052]
24-11-25 17:27:42 | I |     + error = [0.6052]
24-11-25 17:27:43 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 17:27:43 | I |       - range scale = [    1.0000]
24-11-25 17:27:43 | I |         sum  error  = [    0.2362]
24-11-25 17:27:43 | I |         best error  = [    0.2362]
24-11-25 17:27:43 | I |     + error = [0.2362]
24-11-25 17:27:44 | I |       - range scale = [    1.0000]
24-11-25 17:27:44 | I |         sum  error  = [    1.8019]
24-11-25 17:27:44 | I |         best error  = [    1.8019]
24-11-25 17:27:44 | I |     + error = [1.8019]
24-11-25 17:27:44 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 17:27:45 | I |       - range scale = [    1.0000]
24-11-25 17:27:45 | I |         sum  error  = [    0.0676]
24-11-25 17:27:45 | I |         best error  = [    0.0676]
24-11-25 17:27:45 | I |     + error = [0.0676]
24-11-25 17:27:45 | I |       - range scale = [    1.0000]
24-11-25 17:27:45 | I |         sum  error  = [    0.6521]
24-11-25 17:27:45 | I |         best error  = [    0.6521]
24-11-25 17:27:45 | I |     + error = [0.6521]
24-11-25 17:27:46 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 17:27:46 | I |       - range scale = [    1.0000]
24-11-25 17:27:46 | I |         sum  error  = [    1.1967]
24-11-25 17:27:46 | I |         best error  = [    1.1967]
24-11-25 17:27:46 | I |     + error = [1.1967]
24-11-25 17:27:47 | I |       - range scale = [    1.0000]
24-11-25 17:27:47 | I |         sum  error  = [   13.2568]
24-11-25 17:27:47 | I |         best error  = [   13.2568]
24-11-25 17:27:47 | I |     + error = [13.2568]
24-11-25 17:27:47 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 17:27:48 | I |       - range scale = [    1.0000]
24-11-25 17:27:48 | I |         sum  error  = [    1.3821]
24-11-25 17:27:48 | I |         best error  = [    1.3821]
24-11-25 17:27:48 | I |     + error = [1.3821]
24-11-25 17:27:49 | I |       - range scale = [    1.0000]
24-11-25 17:27:49 | I |         sum  error  = [   13.7535]
24-11-25 17:27:49 | I |         best error  = [   13.7535]
24-11-25 17:27:49 | I |     + error = [13.7535]
24-11-25 17:27:49 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 17:27:50 | I |       - range scale = [    1.0000]
24-11-25 17:27:50 | I |         sum  error  = [    2.4296]
24-11-25 17:27:50 | I |         best error  = [    2.4296]
24-11-25 17:27:50 | I |     + error = [2.4296]
24-11-25 17:27:51 | I |       - range scale = [    1.0000]
24-11-25 17:27:51 | I |         sum  error  = [   13.0000]
24-11-25 17:27:51 | I |         best error  = [   13.0000]
24-11-25 17:27:51 | I |     + error = [13.0000]
24-11-25 17:27:51 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 17:27:53 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 17:27:54 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 17:27:56 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 17:27:58 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 17:27:59 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 17:28:01 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 17:28:05 | I | quantizing activations for layer model.layers.0
24-11-25 17:28:05 | I | collecting info in model.layers.0
24-11-25 17:28:05 | I | collecting info in model.layers.0
24-11-25 17:28:05 | I | collecting info in model.layers.0
24-11-25 17:28:05 | I | collecting info in model.layers.0
24-11-25 17:28:06 | I | collecting calibration activations in model.layers.0
24-11-25 17:28:06 | I | collecting calibration activations in model.layers.0
24-11-25 17:28:06 | I | collecting calibration activations in model.layers.0
24-11-25 17:28:06 | I | collecting calibration activations in model.layers.0
24-11-25 17:28:08 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 17:28:08 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 17:28:08 | I | - Evaluator: gptq
24-11-25 17:28:08 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 17:28:08 | I | - Batch_size: 8
24-11-25 17:28:08 | I |   + Max_seq_length: 2048
24-11-25 17:28:50 | I |     - Results:
24-11-25 17:28:50 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 17:28:50 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 17:28:50 | I |       |wikitext |      1|word_perplexity|7.8653|  |7.8653|
24-11-25 17:28:50 | I |       |val_valid|      1|word_perplexity|9.1070|  |9.1070|
24-11-25 17:28:50 | I |       
24-11-25 17:28:50 | I | forward this layer
24-11-25 17:28:50 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/81.pt
24-11-25 17:28:50 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/81.pt
24-11-25 17:28:50 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 17:28:50 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 17:28:50 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 17:28:50 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 17:28:50 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 17:28:50 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 17:28:50 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 17:28:50 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 17:28:50 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 17:28:50 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 17:28:50 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 17:28:50 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 17:28:50 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 17:28:50 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 17:28:50 | I | [26] done with optimizer step
24-11-25 17:28:50 | I | epoch 001:     41 / 409600000 loss=0.00011795, loss_per_token=0.241562, loss_sum=7915.5, wps=150.6, ups=0, wpb=32768, bsz=64, num_updates=27, lr=8.1e-05, gnorm=16.342, clip=100, loss_scale=0.0078, train_wall=217, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=9060, lmquant_ppl_result_wikitext_in_train_no_quant=7.89779, lmquant_ppl_result_val_in_train_no_quant=9.07539, lmquant_ppl_result_wikitext_in_train_with_quant=7.86535, lmquant_ppl_result_val_in_train_with_quant=9.10701
24-11-25 17:28:50 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 17:28:50 | I | in layer model.layers.0
24-11-25 17:28:50 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 17:28:50 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 17:28:50 | I | - Evaluator: gptq
24-11-25 17:28:50 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 17:28:50 | I | - Batch_size: 8
24-11-25 17:28:50 | I |   + Max_seq_length: 2048
24-11-25 17:29:29 | I |     - Results:
24-11-25 17:29:29 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 17:29:29 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 17:29:29 | I |       |wikitext |      1|word_perplexity|7.9239|  |7.9239|
24-11-25 17:29:29 | I |       |val_valid|      1|word_perplexity|9.0961|  |9.0961|
24-11-25 17:29:29 | I |       
24-11-25 17:29:29 | I | quantizing weights for layer model.layers.0
24-11-25 17:29:29 | I | collecting info in model.layers.0
24-11-25 17:29:29 | I | collecting info in model.layers.0
24-11-25 17:29:29 | I | collecting info in model.layers.0
24-11-25 17:29:29 | I | collecting info in model.layers.0
24-11-25 17:29:29 | I | collecting calibration activations in model.layers.0
24-11-25 17:29:29 | I | collecting calibration activations in model.layers.0
24-11-25 17:29:29 | I | collecting calibration activations in model.layers.0
24-11-25 17:29:30 | I | collecting calibration activations in model.layers.0
24-11-25 17:29:30 | I | - Quantizing decoder layer model.layers.0
24-11-25 17:29:30 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 17:29:31 | I |       - range scale = [    1.0000]
24-11-25 17:29:31 | I |         sum  error  = [    0.0633]
24-11-25 17:29:31 | I |         best error  = [    0.0633]
24-11-25 17:29:31 | I |     + error = [0.0633]
24-11-25 17:29:31 | I |       - range scale = [    1.0000]
24-11-25 17:29:31 | I |         sum  error  = [    0.6352]
24-11-25 17:29:31 | I |         best error  = [    0.6352]
24-11-25 17:29:31 | I |     + error = [0.6352]
24-11-25 17:29:31 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 17:29:32 | I |       - range scale = [    1.0000]
24-11-25 17:29:32 | I |         sum  error  = [    0.0766]
24-11-25 17:29:32 | I |         best error  = [    0.0766]
24-11-25 17:29:32 | I |     + error = [0.0766]
24-11-25 17:29:33 | I |       - range scale = [    1.0000]
24-11-25 17:29:33 | I |         sum  error  = [    0.5763]
24-11-25 17:29:33 | I |         best error  = [    0.5763]
24-11-25 17:29:33 | I |     + error = [0.5763]
24-11-25 17:29:33 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 17:29:34 | I |       - range scale = [    1.0000]
24-11-25 17:29:34 | I |         sum  error  = [    0.2356]
24-11-25 17:29:34 | I |         best error  = [    0.2356]
24-11-25 17:29:34 | I |     + error = [0.2356]
24-11-25 17:29:34 | I |       - range scale = [    1.0000]
24-11-25 17:29:34 | I |         sum  error  = [    1.8152]
24-11-25 17:29:34 | I |         best error  = [    1.8152]
24-11-25 17:29:34 | I |     + error = [1.8152]
24-11-25 17:29:35 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 17:29:35 | I |       - range scale = [    1.0000]
24-11-25 17:29:35 | I |         sum  error  = [    0.0702]
24-11-25 17:29:35 | I |         best error  = [    0.0702]
24-11-25 17:29:35 | I |     + error = [0.0702]
24-11-25 17:29:36 | I |       - range scale = [    1.0000]
24-11-25 17:29:36 | I |         sum  error  = [    0.6701]
24-11-25 17:29:36 | I |         best error  = [    0.6701]
24-11-25 17:29:36 | I |     + error = [0.6701]
24-11-25 17:29:36 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 17:29:37 | I |       - range scale = [    1.0000]
24-11-25 17:29:37 | I |         sum  error  = [    1.1377]
24-11-25 17:29:37 | I |         best error  = [    1.1377]
24-11-25 17:29:37 | I |     + error = [1.1377]
24-11-25 17:29:38 | I |       - range scale = [    1.0000]
24-11-25 17:29:38 | I |         sum  error  = [   12.6197]
24-11-25 17:29:38 | I |         best error  = [   12.6197]
24-11-25 17:29:38 | I |     + error = [12.6197]
24-11-25 17:29:38 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 17:29:39 | I |       - range scale = [    1.0000]
24-11-25 17:29:39 | I |         sum  error  = [    1.3181]
24-11-25 17:29:39 | I |         best error  = [    1.3181]
24-11-25 17:29:39 | I |     + error = [1.3181]
24-11-25 17:29:39 | I |       - range scale = [    1.0000]
24-11-25 17:29:39 | I |         sum  error  = [   13.0575]
24-11-25 17:29:39 | I |         best error  = [   13.0575]
24-11-25 17:29:39 | I |     + error = [13.0575]
24-11-25 17:29:39 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 17:29:40 | I |       - range scale = [    1.0000]
24-11-25 17:29:40 | I |         sum  error  = [    3.2390]
24-11-25 17:29:40 | I |         best error  = [    3.2390]
24-11-25 17:29:40 | I |     + error = [3.2390]
24-11-25 17:29:41 | I |       - range scale = [    1.0000]
24-11-25 17:29:41 | I |         sum  error  = [   17.2785]
24-11-25 17:29:41 | I |         best error  = [   17.2785]
24-11-25 17:29:41 | I |     + error = [17.2785]
24-11-25 17:29:41 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 17:29:43 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 17:29:44 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 17:29:45 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 17:29:47 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 17:29:48 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 17:29:50 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 17:29:53 | I | quantizing activations for layer model.layers.0
24-11-25 17:29:53 | I | collecting info in model.layers.0
24-11-25 17:29:53 | I | collecting info in model.layers.0
24-11-25 17:29:53 | I | collecting info in model.layers.0
24-11-25 17:29:53 | I | collecting info in model.layers.0
24-11-25 17:29:53 | I | collecting calibration activations in model.layers.0
24-11-25 17:29:53 | I | collecting calibration activations in model.layers.0
24-11-25 17:29:54 | I | collecting calibration activations in model.layers.0
24-11-25 17:29:54 | I | collecting calibration activations in model.layers.0
24-11-25 17:29:56 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 17:29:56 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 17:29:56 | I | - Evaluator: gptq
24-11-25 17:29:56 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 17:29:56 | I | - Batch_size: 8
24-11-25 17:29:56 | I |   + Max_seq_length: 2048
24-11-25 17:30:37 | I |     - Results:
24-11-25 17:30:37 | I |       |  Task   |Version|    Metric     |Value|   |Stderr|
24-11-25 17:30:37 | I |       |---------|------:|---------------|----:|---|-----:|
24-11-25 17:30:37 | I |       |wikitext |      1|word_perplexity|7.908|  | 7.908|
24-11-25 17:30:37 | I |       |val_valid|      1|word_perplexity|9.131|  | 9.131|
24-11-25 17:30:37 | I |       
24-11-25 17:30:37 | I | forward this layer
24-11-25 17:30:37 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/82.pt
24-11-25 17:30:37 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/82.pt
24-11-25 17:30:37 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 17:30:37 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 17:30:37 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 17:30:37 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 17:30:37 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 17:30:37 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 17:30:37 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 17:30:37 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 17:30:37 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 17:30:37 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 17:30:37 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 17:30:37 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 17:30:37 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 17:30:37 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 17:30:37 | I | in layer model.layers.0
24-11-25 17:30:37 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 17:30:37 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 17:30:37 | I | - Evaluator: gptq
24-11-25 17:30:37 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 17:30:37 | I | - Batch_size: 8
24-11-25 17:30:37 | I |   + Max_seq_length: 2048
24-11-25 17:31:15 | I |     - Results:
24-11-25 17:31:15 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 17:31:15 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 17:31:15 | I |       |wikitext |      1|word_perplexity|7.9239|  |7.9239|
24-11-25 17:31:15 | I |       |val_valid|      1|word_perplexity|9.0961|  |9.0961|
24-11-25 17:31:15 | I |       
24-11-25 17:31:15 | I | quantizing weights for layer model.layers.0
24-11-25 17:31:15 | I | collecting info in model.layers.0
24-11-25 17:31:16 | I | collecting info in model.layers.0
24-11-25 17:31:16 | I | collecting info in model.layers.0
24-11-25 17:31:16 | I | collecting info in model.layers.0
24-11-25 17:31:16 | I | collecting calibration activations in model.layers.0
24-11-25 17:31:16 | I | collecting calibration activations in model.layers.0
24-11-25 17:31:16 | I | collecting calibration activations in model.layers.0
24-11-25 17:31:16 | I | collecting calibration activations in model.layers.0
24-11-25 17:31:17 | I | - Quantizing decoder layer model.layers.0
24-11-25 17:31:17 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 17:31:17 | I |       - range scale = [    1.0000]
24-11-25 17:31:17 | I |         sum  error  = [    0.0677]
24-11-25 17:31:17 | I |         best error  = [    0.0677]
24-11-25 17:31:17 | I |     + error = [0.0677]
24-11-25 17:31:18 | I |       - range scale = [    1.0000]
24-11-25 17:31:18 | I |         sum  error  = [    0.6557]
24-11-25 17:31:18 | I |         best error  = [    0.6557]
24-11-25 17:31:18 | I |     + error = [0.6557]
24-11-25 17:31:18 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 17:31:19 | I |       - range scale = [    1.0000]
24-11-25 17:31:19 | I |         sum  error  = [    0.0828]
24-11-25 17:31:19 | I |         best error  = [    0.0828]
24-11-25 17:31:19 | I |     + error = [0.0828]
24-11-25 17:31:20 | I |       - range scale = [    1.0000]
24-11-25 17:31:20 | I |         sum  error  = [    0.5789]
24-11-25 17:31:20 | I |         best error  = [    0.5789]
24-11-25 17:31:20 | I |     + error = [0.5789]
24-11-25 17:31:20 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 17:31:21 | I |       - range scale = [    1.0000]
24-11-25 17:31:21 | I |         sum  error  = [    0.2374]
24-11-25 17:31:21 | I |         best error  = [    0.2374]
24-11-25 17:31:21 | I |     + error = [0.2374]
24-11-25 17:31:21 | I |       - range scale = [    1.0000]
24-11-25 17:31:21 | I |         sum  error  = [    1.8129]
24-11-25 17:31:21 | I |         best error  = [    1.8129]
24-11-25 17:31:21 | I |     + error = [1.8129]
24-11-25 17:31:22 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 17:31:22 | I |       - range scale = [    1.0000]
24-11-25 17:31:22 | I |         sum  error  = [    0.0634]
24-11-25 17:31:22 | I |         best error  = [    0.0634]
24-11-25 17:31:22 | I |     + error = [0.0634]
24-11-25 17:31:23 | I |       - range scale = [    1.0000]
24-11-25 17:31:23 | I |         sum  error  = [    0.6008]
24-11-25 17:31:23 | I |         best error  = [    0.6008]
24-11-25 17:31:23 | I |     + error = [0.6008]
24-11-25 17:31:23 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 17:31:24 | I |       - range scale = [    1.0000]
24-11-25 17:31:24 | I |         sum  error  = [    1.0771]
24-11-25 17:31:24 | I |         best error  = [    1.0771]
24-11-25 17:31:24 | I |     + error = [1.0771]
24-11-25 17:31:25 | I |       - range scale = [    1.0000]
24-11-25 17:31:25 | I |         sum  error  = [   11.9421]
24-11-25 17:31:25 | I |         best error  = [   11.9421]
24-11-25 17:31:25 | I |     + error = [11.9421]
24-11-25 17:31:25 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 17:31:26 | I |       - range scale = [    1.0000]
24-11-25 17:31:26 | I |         sum  error  = [    1.2479]
24-11-25 17:31:26 | I |         best error  = [    1.2479]
24-11-25 17:31:26 | I |     + error = [1.2479]
24-11-25 17:31:26 | I |       - range scale = [    1.0000]
24-11-25 17:31:26 | I |         sum  error  = [   12.3442]
24-11-25 17:31:26 | I |         best error  = [   12.3442]
24-11-25 17:31:26 | I |     + error = [12.3442]
24-11-25 17:31:26 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 17:31:27 | I |       - range scale = [    1.0000]
24-11-25 17:31:27 | I |         sum  error  = [    4.0289]
24-11-25 17:31:27 | I |         best error  = [    4.0289]
24-11-25 17:31:27 | I |     + error = [4.0289]
24-11-25 17:31:28 | I |       - range scale = [    1.0000]
24-11-25 17:31:28 | I |         sum  error  = [   21.5517]
24-11-25 17:31:28 | I |         best error  = [   21.5517]
24-11-25 17:31:28 | I |     + error = [21.5517]
24-11-25 17:31:28 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 17:31:30 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 17:31:31 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 17:31:32 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 17:31:34 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 17:31:35 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 17:31:36 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 17:31:40 | I | quantizing activations for layer model.layers.0
24-11-25 17:31:40 | I | collecting info in model.layers.0
24-11-25 17:31:40 | I | collecting info in model.layers.0
24-11-25 17:31:40 | I | collecting info in model.layers.0
24-11-25 17:31:40 | I | collecting info in model.layers.0
24-11-25 17:31:40 | I | collecting calibration activations in model.layers.0
24-11-25 17:31:40 | I | collecting calibration activations in model.layers.0
24-11-25 17:31:40 | I | collecting calibration activations in model.layers.0
24-11-25 17:31:40 | I | collecting calibration activations in model.layers.0
24-11-25 17:31:42 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 17:31:42 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 17:31:42 | I | - Evaluator: gptq
24-11-25 17:31:42 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 17:31:42 | I | - Batch_size: 8
24-11-25 17:31:42 | I |   + Max_seq_length: 2048
24-11-25 17:32:24 | I |     - Results:
24-11-25 17:32:24 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 17:32:24 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 17:32:24 | I |       |wikitext |      1|word_perplexity|7.9001|  |7.9001|
24-11-25 17:32:24 | I |       |val_valid|      1|word_perplexity|9.1097|  |9.1097|
24-11-25 17:32:24 | I |       
24-11-25 17:32:24 | I | forward this layer
24-11-25 17:32:24 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/83.pt
24-11-25 17:32:24 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/83.pt
24-11-25 17:32:24 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 17:32:24 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 17:32:24 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 17:32:24 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 17:32:24 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 17:32:24 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 17:32:24 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 17:32:24 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 17:32:24 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 17:32:24 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 17:32:24 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 17:32:24 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 17:32:24 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 17:32:24 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 17:32:24 | I | [27] done with optimizer step
24-11-25 17:32:24 | I | epoch 001:     42 / 409600000 loss=0.000289441, loss_per_token=0.592776, loss_sum=19424.1, wps=153.3, ups=0, wpb=32768, bsz=64, num_updates=28, lr=8.4e-05, gnorm=54.919, clip=100, loss_scale=0.0078, train_wall=214, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=9274, lmquant_ppl_result_wikitext_in_train_no_quant=7.92385, lmquant_ppl_result_val_in_train_no_quant=9.09607, lmquant_ppl_result_wikitext_in_train_with_quant=7.90006, lmquant_ppl_result_val_in_train_with_quant=9.10972
24-11-25 17:32:24 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 17:32:24 | I | in layer model.layers.0
24-11-25 17:32:24 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 17:32:24 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 17:32:24 | I | - Evaluator: gptq
24-11-25 17:32:24 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 17:32:24 | I | - Batch_size: 8
24-11-25 17:32:24 | I |   + Max_seq_length: 2048
24-11-25 17:33:02 | I |     - Results:
24-11-25 17:33:02 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 17:33:02 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 17:33:02 | I |       |wikitext |      1|word_perplexity|7.9395|  |7.9395|
24-11-25 17:33:02 | I |       |val_valid|      1|word_perplexity|9.1092|  |9.1092|
24-11-25 17:33:02 | I |       
24-11-25 17:33:02 | I | quantizing weights for layer model.layers.0
24-11-25 17:33:02 | I | collecting info in model.layers.0
24-11-25 17:33:02 | I | collecting info in model.layers.0
24-11-25 17:33:02 | I | collecting info in model.layers.0
24-11-25 17:33:02 | I | collecting info in model.layers.0
24-11-25 17:33:03 | I | collecting calibration activations in model.layers.0
24-11-25 17:33:03 | I | collecting calibration activations in model.layers.0
24-11-25 17:33:03 | I | collecting calibration activations in model.layers.0
24-11-25 17:33:03 | I | collecting calibration activations in model.layers.0
24-11-25 17:33:04 | I | - Quantizing decoder layer model.layers.0
24-11-25 17:33:04 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 17:33:04 | I |       - range scale = [    1.0000]
24-11-25 17:33:04 | I |         sum  error  = [    0.0596]
24-11-25 17:33:04 | I |         best error  = [    0.0596]
24-11-25 17:33:04 | I |     + error = [0.0596]
24-11-25 17:33:05 | I |       - range scale = [    1.0000]
24-11-25 17:33:05 | I |         sum  error  = [    0.6533]
24-11-25 17:33:05 | I |         best error  = [    0.6533]
24-11-25 17:33:05 | I |     + error = [0.6533]
24-11-25 17:33:05 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 17:33:06 | I |       - range scale = [    1.0000]
24-11-25 17:33:06 | I |         sum  error  = [    0.0780]
24-11-25 17:33:06 | I |         best error  = [    0.0780]
24-11-25 17:33:06 | I |     + error = [0.0780]
24-11-25 17:33:07 | I |       - range scale = [    1.0000]
24-11-25 17:33:07 | I |         sum  error  = [    0.5641]
24-11-25 17:33:07 | I |         best error  = [    0.5641]
24-11-25 17:33:07 | I |     + error = [0.5641]
24-11-25 17:33:07 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 17:33:08 | I |       - range scale = [    1.0000]
24-11-25 17:33:08 | I |         sum  error  = [    0.2318]
24-11-25 17:33:08 | I |         best error  = [    0.2318]
24-11-25 17:33:08 | I |     + error = [0.2318]
24-11-25 17:33:08 | I |       - range scale = [    1.0000]
24-11-25 17:33:08 | I |         sum  error  = [    1.7942]
24-11-25 17:33:08 | I |         best error  = [    1.7942]
24-11-25 17:33:08 | I |     + error = [1.7942]
24-11-25 17:33:08 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 17:33:09 | I |       - range scale = [    1.0000]
24-11-25 17:33:09 | I |         sum  error  = [    0.0639]
24-11-25 17:33:09 | I |         best error  = [    0.0639]
24-11-25 17:33:09 | I |     + error = [0.0639]
24-11-25 17:33:10 | I |       - range scale = [    1.0000]
24-11-25 17:33:10 | I |         sum  error  = [    0.6161]
24-11-25 17:33:10 | I |         best error  = [    0.6161]
24-11-25 17:33:10 | I |     + error = [0.6161]
24-11-25 17:33:10 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 17:33:11 | I |       - range scale = [    1.0000]
24-11-25 17:33:11 | I |         sum  error  = [    1.1056]
24-11-25 17:33:11 | I |         best error  = [    1.1056]
24-11-25 17:33:11 | I |     + error = [1.1056]
24-11-25 17:33:11 | I |       - range scale = [    1.0000]
24-11-25 17:33:11 | I |         sum  error  = [   12.2711]
24-11-25 17:33:11 | I |         best error  = [   12.2711]
24-11-25 17:33:11 | I |     + error = [12.2711]
24-11-25 17:33:12 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 17:33:12 | I |       - range scale = [    1.0000]
24-11-25 17:33:12 | I |         sum  error  = [    1.2803]
24-11-25 17:33:12 | I |         best error  = [    1.2803]
24-11-25 17:33:12 | I |     + error = [1.2803]
24-11-25 17:33:13 | I |       - range scale = [    1.0000]
24-11-25 17:33:13 | I |         sum  error  = [   12.6883]
24-11-25 17:33:13 | I |         best error  = [   12.6883]
24-11-25 17:33:13 | I |     + error = [12.6883]
24-11-25 17:33:13 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 17:33:14 | I |       - range scale = [    1.0000]
24-11-25 17:33:14 | I |         sum  error  = [    3.1128]
24-11-25 17:33:14 | I |         best error  = [    3.1128]
24-11-25 17:33:14 | I |     + error = [3.1128]
24-11-25 17:33:15 | I |       - range scale = [    1.0000]
24-11-25 17:33:15 | I |         sum  error  = [   16.7916]
24-11-25 17:33:15 | I |         best error  = [   16.7916]
24-11-25 17:33:15 | I |     + error = [16.7916]
24-11-25 17:33:15 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 17:33:16 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 17:33:18 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 17:33:19 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 17:33:21 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 17:33:22 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 17:33:23 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 17:33:27 | I | quantizing activations for layer model.layers.0
24-11-25 17:33:27 | I | collecting info in model.layers.0
24-11-25 17:33:27 | I | collecting info in model.layers.0
24-11-25 17:33:27 | I | collecting info in model.layers.0
24-11-25 17:33:27 | I | collecting info in model.layers.0
24-11-25 17:33:27 | I | collecting calibration activations in model.layers.0
24-11-25 17:33:27 | I | collecting calibration activations in model.layers.0
24-11-25 17:33:27 | I | collecting calibration activations in model.layers.0
24-11-25 17:33:27 | I | collecting calibration activations in model.layers.0
24-11-25 17:33:29 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 17:33:29 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 17:33:29 | I | - Evaluator: gptq
24-11-25 17:33:29 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 17:33:29 | I | - Batch_size: 8
24-11-25 17:33:29 | I |   + Max_seq_length: 2048
24-11-25 17:34:11 | I |     - Results:
24-11-25 17:34:11 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 17:34:11 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 17:34:11 | I |       |wikitext |      1|word_perplexity|7.9048|  |7.9048|
24-11-25 17:34:11 | I |       |val_valid|      1|word_perplexity|9.1168|  |9.1168|
24-11-25 17:34:11 | I |       
24-11-25 17:34:11 | I | forward this layer
24-11-25 17:34:11 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/84.pt
24-11-25 17:34:11 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/84.pt
24-11-25 17:34:11 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 17:34:11 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 17:34:11 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 17:34:11 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 17:34:11 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 17:34:11 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 17:34:11 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 17:34:11 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 17:34:11 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 17:34:11 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 17:34:11 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 17:34:11 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 17:34:11 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 17:34:11 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 17:34:11 | I | in layer model.layers.0
24-11-25 17:34:11 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 17:34:11 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 17:34:11 | I | - Evaluator: gptq
24-11-25 17:34:11 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 17:34:11 | I | - Batch_size: 8
24-11-25 17:34:11 | I |   + Max_seq_length: 2048
24-11-25 17:34:49 | I |     - Results:
24-11-25 17:34:49 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 17:34:49 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 17:34:49 | I |       |wikitext |      1|word_perplexity|7.9395|  |7.9395|
24-11-25 17:34:49 | I |       |val_valid|      1|word_perplexity|9.1092|  |9.1092|
24-11-25 17:34:49 | I |       
24-11-25 17:34:49 | I | quantizing weights for layer model.layers.0
24-11-25 17:34:49 | I | collecting info in model.layers.0
24-11-25 17:34:49 | I | collecting info in model.layers.0
24-11-25 17:34:49 | I | collecting info in model.layers.0
24-11-25 17:34:49 | I | collecting info in model.layers.0
24-11-25 17:34:50 | I | collecting calibration activations in model.layers.0
24-11-25 17:34:50 | I | collecting calibration activations in model.layers.0
24-11-25 17:34:50 | I | collecting calibration activations in model.layers.0
24-11-25 17:34:50 | I | collecting calibration activations in model.layers.0
24-11-25 17:34:50 | I | - Quantizing decoder layer model.layers.0
24-11-25 17:34:50 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 17:34:51 | I |       - range scale = [    1.0000]
24-11-25 17:34:51 | I |         sum  error  = [    0.0630]
24-11-25 17:34:51 | I |         best error  = [    0.0630]
24-11-25 17:34:51 | I |     + error = [0.0630]
24-11-25 17:34:52 | I |       - range scale = [    1.0000]
24-11-25 17:34:52 | I |         sum  error  = [    0.6708]
24-11-25 17:34:52 | I |         best error  = [    0.6708]
24-11-25 17:34:52 | I |     + error = [0.6708]
24-11-25 17:34:52 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 17:34:53 | I |       - range scale = [    1.0000]
24-11-25 17:34:53 | I |         sum  error  = [    0.0836]
24-11-25 17:34:53 | I |         best error  = [    0.0836]
24-11-25 17:34:53 | I |     + error = [0.0836]
24-11-25 17:34:53 | I |       - range scale = [    1.0000]
24-11-25 17:34:53 | I |         sum  error  = [    0.5889]
24-11-25 17:34:53 | I |         best error  = [    0.5889]
24-11-25 17:34:53 | I |     + error = [0.5889]
24-11-25 17:34:54 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 17:34:54 | I |       - range scale = [    1.0000]
24-11-25 17:34:54 | I |         sum  error  = [    0.2326]
24-11-25 17:34:54 | I |         best error  = [    0.2326]
24-11-25 17:34:54 | I |     + error = [0.2326]
24-11-25 17:34:55 | I |       - range scale = [    1.0000]
24-11-25 17:34:55 | I |         sum  error  = [    1.8080]
24-11-25 17:34:55 | I |         best error  = [    1.8080]
24-11-25 17:34:55 | I |     + error = [1.8080]
24-11-25 17:34:55 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 17:34:56 | I |       - range scale = [    1.0000]
24-11-25 17:34:56 | I |         sum  error  = [    0.0643]
24-11-25 17:34:56 | I |         best error  = [    0.0643]
24-11-25 17:34:56 | I |     + error = [0.0643]
24-11-25 17:34:56 | I |       - range scale = [    1.0000]
24-11-25 17:34:56 | I |         sum  error  = [    0.6224]
24-11-25 17:34:56 | I |         best error  = [    0.6224]
24-11-25 17:34:56 | I |     + error = [0.6224]
24-11-25 17:34:57 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 17:34:57 | I |       - range scale = [    1.0000]
24-11-25 17:34:57 | I |         sum  error  = [    1.0724]
24-11-25 17:34:57 | I |         best error  = [    1.0724]
24-11-25 17:34:57 | I |     + error = [1.0724]
24-11-25 17:34:58 | I |       - range scale = [    1.0000]
24-11-25 17:34:58 | I |         sum  error  = [   11.8926]
24-11-25 17:34:58 | I |         best error  = [   11.8926]
24-11-25 17:34:58 | I |     + error = [11.8926]
24-11-25 17:34:58 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 17:34:59 | I |       - range scale = [    1.0000]
24-11-25 17:34:59 | I |         sum  error  = [    1.2426]
24-11-25 17:34:59 | I |         best error  = [    1.2426]
24-11-25 17:34:59 | I |     + error = [1.2426]
24-11-25 17:35:00 | I |       - range scale = [    1.0000]
24-11-25 17:35:00 | I |         sum  error  = [   12.2800]
24-11-25 17:35:00 | I |         best error  = [   12.2800]
24-11-25 17:35:00 | I |     + error = [12.2800]
24-11-25 17:35:00 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 17:35:01 | I |       - range scale = [    1.0000]
24-11-25 17:35:01 | I |         sum  error  = [    2.6147]
24-11-25 17:35:01 | I |         best error  = [    2.6147]
24-11-25 17:35:01 | I |     + error = [2.6147]
24-11-25 17:35:01 | I |       - range scale = [    1.0000]
24-11-25 17:35:01 | I |         sum  error  = [   14.1936]
24-11-25 17:35:01 | I |         best error  = [   14.1936]
24-11-25 17:35:01 | I |     + error = [14.1936]
24-11-25 17:35:02 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 17:35:03 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 17:35:04 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 17:35:06 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 17:35:07 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 17:35:09 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 17:35:10 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 17:35:13 | I | quantizing activations for layer model.layers.0
24-11-25 17:35:13 | I | collecting info in model.layers.0
24-11-25 17:35:13 | I | collecting info in model.layers.0
24-11-25 17:35:13 | I | collecting info in model.layers.0
24-11-25 17:35:13 | I | collecting info in model.layers.0
24-11-25 17:35:14 | I | collecting calibration activations in model.layers.0
24-11-25 17:35:14 | I | collecting calibration activations in model.layers.0
24-11-25 17:35:14 | I | collecting calibration activations in model.layers.0
24-11-25 17:35:14 | I | collecting calibration activations in model.layers.0
24-11-25 17:35:16 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 17:35:16 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 17:35:16 | I | - Evaluator: gptq
24-11-25 17:35:16 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 17:35:16 | I | - Batch_size: 8
24-11-25 17:35:16 | I |   + Max_seq_length: 2048
24-11-25 17:35:57 | I |     - Results:
24-11-25 17:35:57 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 17:35:57 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 17:35:57 | I |       |wikitext |      1|word_perplexity|7.9041|  |7.9041|
24-11-25 17:35:57 | I |       |val_valid|      1|word_perplexity|9.1352|  |9.1352|
24-11-25 17:35:57 | I |       
24-11-25 17:35:57 | I | forward this layer
24-11-25 17:35:57 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/85.pt
24-11-25 17:35:57 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/85.pt
24-11-25 17:35:57 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 17:35:57 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 17:35:57 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 17:35:57 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 17:35:57 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 17:35:57 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 17:35:57 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 17:35:57 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 17:35:57 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 17:35:57 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 17:35:57 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 17:35:57 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 17:35:57 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 17:35:57 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 17:35:58 | I | [28] done with optimizer step
24-11-25 17:35:58 | I | epoch 001:     43 / 409600000 loss=0.000231908, loss_per_token=0.474946, loss_sum=15563, wps=153.4, ups=0, wpb=32768, bsz=64, num_updates=29, lr=8.7e-05, gnorm=51.154, clip=100, loss_scale=0.0078, train_wall=213, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=9488, lmquant_ppl_result_wikitext_in_train_no_quant=7.93948, lmquant_ppl_result_val_in_train_no_quant=9.10919, lmquant_ppl_result_wikitext_in_train_with_quant=7.90408, lmquant_ppl_result_val_in_train_with_quant=9.13516
24-11-25 17:35:58 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 17:35:58 | I | in layer model.layers.0
24-11-25 17:35:58 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 17:35:58 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 17:35:58 | I | - Evaluator: gptq
24-11-25 17:35:58 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 17:35:58 | I | - Batch_size: 8
24-11-25 17:35:58 | I |   + Max_seq_length: 2048
24-11-25 17:36:36 | I |     - Results:
24-11-25 17:36:36 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 17:36:36 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 17:36:36 | I |       |wikitext |      1|word_perplexity|7.9462|  |7.9462|
24-11-25 17:36:36 | I |       |val_valid|      1|word_perplexity|9.1149|  |9.1149|
24-11-25 17:36:36 | I |       
24-11-25 17:36:36 | I | quantizing weights for layer model.layers.0
24-11-25 17:36:36 | I | collecting info in model.layers.0
24-11-25 17:36:36 | I | collecting info in model.layers.0
24-11-25 17:36:36 | I | collecting info in model.layers.0
24-11-25 17:36:36 | I | collecting info in model.layers.0
24-11-25 17:36:37 | I | collecting calibration activations in model.layers.0
24-11-25 17:36:37 | I | collecting calibration activations in model.layers.0
24-11-25 17:36:37 | I | collecting calibration activations in model.layers.0
24-11-25 17:36:37 | I | collecting calibration activations in model.layers.0
24-11-25 17:36:37 | I | - Quantizing decoder layer model.layers.0
24-11-25 17:36:37 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 17:36:38 | I |       - range scale = [    1.0000]
24-11-25 17:36:38 | I |         sum  error  = [    0.0554]
24-11-25 17:36:38 | I |         best error  = [    0.0554]
24-11-25 17:36:38 | I |     + error = [0.0554]
24-11-25 17:36:39 | I |       - range scale = [    1.0000]
24-11-25 17:36:39 | I |         sum  error  = [    0.6371]
24-11-25 17:36:39 | I |         best error  = [    0.6371]
24-11-25 17:36:39 | I |     + error = [0.6371]
24-11-25 17:36:39 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 17:36:40 | I |       - range scale = [    1.0000]
24-11-25 17:36:40 | I |         sum  error  = [    0.0758]
24-11-25 17:36:40 | I |         best error  = [    0.0758]
24-11-25 17:36:40 | I |     + error = [0.0758]
24-11-25 17:36:40 | I |       - range scale = [    1.0000]
24-11-25 17:36:40 | I |         sum  error  = [    0.5982]
24-11-25 17:36:40 | I |         best error  = [    0.5982]
24-11-25 17:36:40 | I |     + error = [0.5982]
24-11-25 17:36:41 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 17:36:41 | I |       - range scale = [    1.0000]
24-11-25 17:36:41 | I |         sum  error  = [    0.2341]
24-11-25 17:36:41 | I |         best error  = [    0.2341]
24-11-25 17:36:41 | I |     + error = [0.2341]
24-11-25 17:36:42 | I |       - range scale = [    1.0000]
24-11-25 17:36:42 | I |         sum  error  = [    1.8282]
24-11-25 17:36:42 | I |         best error  = [    1.8282]
24-11-25 17:36:42 | I |     + error = [1.8282]
24-11-25 17:36:42 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 17:36:43 | I |       - range scale = [    1.0000]
24-11-25 17:36:43 | I |         sum  error  = [    0.0644]
24-11-25 17:36:43 | I |         best error  = [    0.0644]
24-11-25 17:36:43 | I |     + error = [0.0644]
24-11-25 17:36:43 | I |       - range scale = [    1.0000]
24-11-25 17:36:43 | I |         sum  error  = [    0.6229]
24-11-25 17:36:43 | I |         best error  = [    0.6229]
24-11-25 17:36:43 | I |     + error = [0.6229]
24-11-25 17:36:44 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 17:36:44 | I |       - range scale = [    1.0000]
24-11-25 17:36:44 | I |         sum  error  = [    1.1181]
24-11-25 17:36:44 | I |         best error  = [    1.1181]
24-11-25 17:36:44 | I |     + error = [1.1181]
24-11-25 17:36:45 | I |       - range scale = [    1.0000]
24-11-25 17:36:45 | I |         sum  error  = [   12.3965]
24-11-25 17:36:45 | I |         best error  = [   12.3965]
24-11-25 17:36:45 | I |     + error = [12.3965]
24-11-25 17:36:45 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 17:36:46 | I |       - range scale = [    1.0000]
24-11-25 17:36:46 | I |         sum  error  = [    1.2956]
24-11-25 17:36:46 | I |         best error  = [    1.2956]
24-11-25 17:36:46 | I |     + error = [1.2956]
24-11-25 17:36:47 | I |       - range scale = [    1.0000]
24-11-25 17:36:47 | I |         sum  error  = [   12.8122]
24-11-25 17:36:47 | I |         best error  = [   12.8122]
24-11-25 17:36:47 | I |     + error = [12.8122]
24-11-25 17:36:47 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 17:36:48 | I |       - range scale = [    1.0000]
24-11-25 17:36:48 | I |         sum  error  = [    2.1924]
24-11-25 17:36:48 | I |         best error  = [    2.1924]
24-11-25 17:36:48 | I |     + error = [2.1924]
24-11-25 17:36:48 | I |       - range scale = [    1.0000]
24-11-25 17:36:48 | I |         sum  error  = [   12.0124]
24-11-25 17:36:48 | I |         best error  = [   12.0124]
24-11-25 17:36:48 | I |     + error = [12.0124]
24-11-25 17:36:49 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 17:36:50 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 17:36:51 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 17:36:53 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 17:36:54 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 17:36:55 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 17:36:57 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 17:37:00 | I | quantizing activations for layer model.layers.0
24-11-25 17:37:00 | I | collecting info in model.layers.0
24-11-25 17:37:00 | I | collecting info in model.layers.0
24-11-25 17:37:00 | I | collecting info in model.layers.0
24-11-25 17:37:00 | I | collecting info in model.layers.0
24-11-25 17:37:01 | I | collecting calibration activations in model.layers.0
24-11-25 17:37:01 | I | collecting calibration activations in model.layers.0
24-11-25 17:37:01 | I | collecting calibration activations in model.layers.0
24-11-25 17:37:01 | I | collecting calibration activations in model.layers.0
24-11-25 17:37:03 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 17:37:03 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 17:37:03 | I | - Evaluator: gptq
24-11-25 17:37:03 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 17:37:03 | I | - Batch_size: 8
24-11-25 17:37:03 | I |   + Max_seq_length: 2048
24-11-25 17:37:44 | I |     - Results:
24-11-25 17:37:44 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 17:37:44 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 17:37:44 | I |       |wikitext |      1|word_perplexity|7.8954|  |7.8954|
24-11-25 17:37:44 | I |       |val_valid|      1|word_perplexity|9.1087|  |9.1087|
24-11-25 17:37:44 | I |       
24-11-25 17:37:44 | I | forward this layer
24-11-25 17:37:44 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/86.pt
24-11-25 17:37:44 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/86.pt
24-11-25 17:37:44 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 17:37:44 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 17:37:44 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 17:37:44 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 17:37:44 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 17:37:44 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 17:37:44 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 17:37:44 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 17:37:44 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 17:37:44 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 17:37:44 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 17:37:44 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 17:37:44 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 17:37:44 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 17:37:44 | I | in layer model.layers.0
24-11-25 17:37:44 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 17:37:44 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 17:37:44 | I | - Evaluator: gptq
24-11-25 17:37:44 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 17:37:44 | I | - Batch_size: 8
24-11-25 17:37:44 | I |   + Max_seq_length: 2048
24-11-25 17:38:23 | I |     - Results:
24-11-25 17:38:23 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 17:38:23 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 17:38:23 | I |       |wikitext |      1|word_perplexity|7.9462|  |7.9462|
24-11-25 17:38:23 | I |       |val_valid|      1|word_perplexity|9.1149|  |9.1149|
24-11-25 17:38:23 | I |       
24-11-25 17:38:23 | I | quantizing weights for layer model.layers.0
24-11-25 17:38:23 | I | collecting info in model.layers.0
24-11-25 17:38:23 | I | collecting info in model.layers.0
24-11-25 17:38:23 | I | collecting info in model.layers.0
24-11-25 17:38:23 | I | collecting info in model.layers.0
24-11-25 17:38:23 | I | collecting calibration activations in model.layers.0
24-11-25 17:38:23 | I | collecting calibration activations in model.layers.0
24-11-25 17:38:23 | I | collecting calibration activations in model.layers.0
24-11-25 17:38:24 | I | collecting calibration activations in model.layers.0
24-11-25 17:38:24 | I | - Quantizing decoder layer model.layers.0
24-11-25 17:38:24 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 17:38:25 | I |       - range scale = [    1.0000]
24-11-25 17:38:25 | I |         sum  error  = [    0.0529]
24-11-25 17:38:25 | I |         best error  = [    0.0529]
24-11-25 17:38:25 | I |     + error = [0.0529]
24-11-25 17:38:25 | I |       - range scale = [    1.0000]
24-11-25 17:38:25 | I |         sum  error  = [    0.6393]
24-11-25 17:38:25 | I |         best error  = [    0.6393]
24-11-25 17:38:25 | I |     + error = [0.6393]
24-11-25 17:38:25 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 17:38:26 | I |       - range scale = [    1.0000]
24-11-25 17:38:26 | I |         sum  error  = [    0.0706]
24-11-25 17:38:26 | I |         best error  = [    0.0706]
24-11-25 17:38:26 | I |     + error = [0.0706]
24-11-25 17:38:27 | I |       - range scale = [    1.0000]
24-11-25 17:38:27 | I |         sum  error  = [    0.5566]
24-11-25 17:38:27 | I |         best error  = [    0.5566]
24-11-25 17:38:27 | I |     + error = [0.5566]
24-11-25 17:38:27 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 17:38:28 | I |       - range scale = [    1.0000]
24-11-25 17:38:28 | I |         sum  error  = [    0.2335]
24-11-25 17:38:28 | I |         best error  = [    0.2335]
24-11-25 17:38:28 | I |     + error = [0.2335]
24-11-25 17:38:29 | I |       - range scale = [    1.0000]
24-11-25 17:38:29 | I |         sum  error  = [    1.7946]
24-11-25 17:38:29 | I |         best error  = [    1.7946]
24-11-25 17:38:29 | I |     + error = [1.7946]
24-11-25 17:38:29 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 17:38:30 | I |       - range scale = [    1.0000]
24-11-25 17:38:30 | I |         sum  error  = [    0.0631]
24-11-25 17:38:30 | I |         best error  = [    0.0631]
24-11-25 17:38:30 | I |     + error = [0.0631]
24-11-25 17:38:30 | I |       - range scale = [    1.0000]
24-11-25 17:38:30 | I |         sum  error  = [    0.6102]
24-11-25 17:38:30 | I |         best error  = [    0.6102]
24-11-25 17:38:30 | I |     + error = [0.6102]
24-11-25 17:38:31 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 17:38:31 | I |       - range scale = [    1.0000]
24-11-25 17:38:31 | I |         sum  error  = [    1.0855]
24-11-25 17:38:31 | I |         best error  = [    1.0855]
24-11-25 17:38:31 | I |     + error = [1.0855]
24-11-25 17:38:32 | I |       - range scale = [    1.0000]
24-11-25 17:38:32 | I |         sum  error  = [   12.0422]
24-11-25 17:38:32 | I |         best error  = [   12.0422]
24-11-25 17:38:32 | I |     + error = [12.0422]
24-11-25 17:38:32 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 17:38:33 | I |       - range scale = [    1.0000]
24-11-25 17:38:33 | I |         sum  error  = [    1.2570]
24-11-25 17:38:33 | I |         best error  = [    1.2570]
24-11-25 17:38:33 | I |     + error = [1.2570]
24-11-25 17:38:34 | I |       - range scale = [    1.0000]
24-11-25 17:38:34 | I |         sum  error  = [   12.4306]
24-11-25 17:38:34 | I |         best error  = [   12.4306]
24-11-25 17:38:34 | I |     + error = [12.4306]
24-11-25 17:38:34 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 17:38:35 | I |       - range scale = [    1.0000]
24-11-25 17:38:35 | I |         sum  error  = [    2.7479]
24-11-25 17:38:35 | I |         best error  = [    2.7479]
24-11-25 17:38:35 | I |     + error = [2.7479]
24-11-25 17:38:35 | I |       - range scale = [    1.0000]
24-11-25 17:38:35 | I |         sum  error  = [   15.0207]
24-11-25 17:38:35 | I |         best error  = [   15.0207]
24-11-25 17:38:35 | I |     + error = [15.0207]
24-11-25 17:38:36 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 17:38:37 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 17:38:38 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 17:38:40 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 17:38:41 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 17:38:43 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 17:38:44 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 17:38:47 | I | quantizing activations for layer model.layers.0
24-11-25 17:38:47 | I | collecting info in model.layers.0
24-11-25 17:38:47 | I | collecting info in model.layers.0
24-11-25 17:38:47 | I | collecting info in model.layers.0
24-11-25 17:38:47 | I | collecting info in model.layers.0
24-11-25 17:38:48 | I | collecting calibration activations in model.layers.0
24-11-25 17:38:48 | I | collecting calibration activations in model.layers.0
24-11-25 17:38:48 | I | collecting calibration activations in model.layers.0
24-11-25 17:38:48 | I | collecting calibration activations in model.layers.0
24-11-25 17:38:50 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 17:38:50 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 17:38:50 | I | - Evaluator: gptq
24-11-25 17:38:50 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 17:38:50 | I | - Batch_size: 8
24-11-25 17:38:50 | I |   + Max_seq_length: 2048
24-11-25 17:39:31 | I |     - Results:
24-11-25 17:39:31 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 17:39:31 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 17:39:31 | I |       |wikitext |      1|word_perplexity|7.8853|  |7.8853|
24-11-25 17:39:31 | I |       |val_valid|      1|word_perplexity|9.1034|  |9.1034|
24-11-25 17:39:31 | I |       
24-11-25 17:39:31 | I | forward this layer
24-11-25 17:39:31 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/87.pt
24-11-25 17:39:31 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/87.pt
24-11-25 17:39:32 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 17:39:32 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 17:39:32 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 17:39:32 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 17:39:32 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 17:39:32 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 17:39:32 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 17:39:32 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 17:39:32 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 17:39:32 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 17:39:32 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 17:39:32 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 17:39:32 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 17:39:32 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 17:39:32 | I | [29] done with optimizer step
24-11-25 17:39:32 | I | epoch 001:     44 / 409600000 loss=9.57093e-05, loss_per_token=0.196013, loss_sum=6422.94, wps=153.1, ups=0, wpb=32768, bsz=64, num_updates=30, lr=9e-05, gnorm=26.503, clip=100, loss_scale=0.0078, train_wall=214, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=9702, lmquant_ppl_result_wikitext_in_train_no_quant=7.94623, lmquant_ppl_result_val_in_train_no_quant=9.11487, lmquant_ppl_result_wikitext_in_train_with_quant=7.88532, lmquant_ppl_result_val_in_train_with_quant=9.10342
24-11-25 17:39:32 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 17:39:32 | I | in layer model.layers.0
24-11-25 17:39:32 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 17:39:32 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 17:39:32 | I | - Evaluator: gptq
24-11-25 17:39:32 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 17:39:32 | I | - Batch_size: 8
24-11-25 17:39:32 | I |   + Max_seq_length: 2048
24-11-25 17:40:10 | I |     - Results:
24-11-25 17:40:10 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 17:40:10 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 17:40:10 | I |       |wikitext |      1|word_perplexity|7.9463|  |7.9463|
24-11-25 17:40:10 | I |       |val_valid|      1|word_perplexity|9.1140|  |9.1140|
24-11-25 17:40:10 | I |       
24-11-25 17:40:10 | I | quantizing weights for layer model.layers.0
24-11-25 17:40:10 | I | collecting info in model.layers.0
24-11-25 17:40:10 | I | collecting info in model.layers.0
24-11-25 17:40:10 | I | collecting info in model.layers.0
24-11-25 17:40:10 | I | collecting info in model.layers.0
24-11-25 17:40:11 | I | collecting calibration activations in model.layers.0
24-11-25 17:40:11 | I | collecting calibration activations in model.layers.0
24-11-25 17:40:11 | I | collecting calibration activations in model.layers.0
24-11-25 17:40:11 | I | collecting calibration activations in model.layers.0
24-11-25 17:40:11 | I | - Quantizing decoder layer model.layers.0
24-11-25 17:40:11 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 17:40:12 | I |       - range scale = [    1.0000]
24-11-25 17:40:12 | I |         sum  error  = [    0.0563]
24-11-25 17:40:12 | I |         best error  = [    0.0563]
24-11-25 17:40:12 | I |     + error = [0.0563]
24-11-25 17:40:13 | I |       - range scale = [    1.0000]
24-11-25 17:40:13 | I |         sum  error  = [    0.6783]
24-11-25 17:40:13 | I |         best error  = [    0.6783]
24-11-25 17:40:13 | I |     + error = [0.6783]
24-11-25 17:40:13 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 17:40:14 | I |       - range scale = [    1.0000]
24-11-25 17:40:14 | I |         sum  error  = [    0.0717]
24-11-25 17:40:14 | I |         best error  = [    0.0717]
24-11-25 17:40:14 | I |     + error = [0.0717]
24-11-25 17:40:14 | I |       - range scale = [    1.0000]
24-11-25 17:40:14 | I |         sum  error  = [    0.5845]
24-11-25 17:40:14 | I |         best error  = [    0.5845]
24-11-25 17:40:14 | I |     + error = [0.5845]
24-11-25 17:40:15 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 17:40:15 | I |       - range scale = [    1.0000]
24-11-25 17:40:15 | I |         sum  error  = [    0.2344]
24-11-25 17:40:15 | I |         best error  = [    0.2344]
24-11-25 17:40:15 | I |     + error = [0.2344]
24-11-25 17:40:16 | I |       - range scale = [    1.0000]
24-11-25 17:40:16 | I |         sum  error  = [    1.8371]
24-11-25 17:40:16 | I |         best error  = [    1.8371]
24-11-25 17:40:16 | I |     + error = [1.8371]
24-11-25 17:40:16 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 17:40:17 | I |       - range scale = [    1.0000]
24-11-25 17:40:17 | I |         sum  error  = [    0.0589]
24-11-25 17:40:17 | I |         best error  = [    0.0589]
24-11-25 17:40:17 | I |     + error = [0.0589]
24-11-25 17:40:17 | I |       - range scale = [    1.0000]
24-11-25 17:40:17 | I |         sum  error  = [    0.5645]
24-11-25 17:40:17 | I |         best error  = [    0.5645]
24-11-25 17:40:17 | I |     + error = [0.5645]
24-11-25 17:40:18 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 17:40:18 | I |       - range scale = [    1.0000]
24-11-25 17:40:18 | I |         sum  error  = [    1.0334]
24-11-25 17:40:18 | I |         best error  = [    1.0334]
24-11-25 17:40:18 | I |     + error = [1.0334]
24-11-25 17:40:19 | I |       - range scale = [    1.0000]
24-11-25 17:40:19 | I |         sum  error  = [   11.4709]
24-11-25 17:40:19 | I |         best error  = [   11.4709]
24-11-25 17:40:19 | I |     + error = [11.4709]
24-11-25 17:40:19 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 17:40:20 | I |       - range scale = [    1.0000]
24-11-25 17:40:20 | I |         sum  error  = [    1.1973]
24-11-25 17:40:20 | I |         best error  = [    1.1973]
24-11-25 17:40:20 | I |     + error = [1.1973]
24-11-25 17:40:21 | I |       - range scale = [    1.0000]
24-11-25 17:40:21 | I |         sum  error  = [   11.8254]
24-11-25 17:40:21 | I |         best error  = [   11.8254]
24-11-25 17:40:21 | I |     + error = [11.8254]
24-11-25 17:40:21 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 17:40:22 | I |       - range scale = [    1.0000]
24-11-25 17:40:22 | I |         sum  error  = [    2.8279]
24-11-25 17:40:22 | I |         best error  = [    2.8279]
24-11-25 17:40:22 | I |     + error = [2.8279]
24-11-25 17:40:22 | I |       - range scale = [    1.0000]
24-11-25 17:40:22 | I |         sum  error  = [   15.7527]
24-11-25 17:40:22 | I |         best error  = [   15.7527]
24-11-25 17:40:22 | I |     + error = [15.7527]
24-11-25 17:40:23 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 17:40:24 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 17:40:25 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 17:40:27 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 17:40:28 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 17:40:30 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 17:40:31 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 17:40:34 | I | quantizing activations for layer model.layers.0
24-11-25 17:40:34 | I | collecting info in model.layers.0
24-11-25 17:40:34 | I | collecting info in model.layers.0
24-11-25 17:40:34 | I | collecting info in model.layers.0
24-11-25 17:40:34 | I | collecting info in model.layers.0
24-11-25 17:40:35 | I | collecting calibration activations in model.layers.0
24-11-25 17:40:35 | I | collecting calibration activations in model.layers.0
24-11-25 17:40:35 | I | collecting calibration activations in model.layers.0
24-11-25 17:40:35 | I | collecting calibration activations in model.layers.0
24-11-25 17:40:37 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 17:40:37 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 17:40:37 | I | - Evaluator: gptq
24-11-25 17:40:37 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 17:40:37 | I | - Batch_size: 8
24-11-25 17:40:37 | I |   + Max_seq_length: 2048
24-11-25 17:41:18 | I |     - Results:
24-11-25 17:41:18 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 17:41:18 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 17:41:18 | I |       |wikitext |      1|word_perplexity|7.8844|  |7.8844|
24-11-25 17:41:18 | I |       |val_valid|      1|word_perplexity|9.0925|  |9.0925|
24-11-25 17:41:18 | I |       
24-11-25 17:41:18 | I | forward this layer
24-11-25 17:41:18 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/88.pt
24-11-25 17:41:18 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/88.pt
24-11-25 17:41:19 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 17:41:19 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 17:41:19 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 17:41:19 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 17:41:19 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 17:41:19 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 17:41:19 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 17:41:19 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 17:41:19 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 17:41:19 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 17:41:19 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 17:41:19 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 17:41:19 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 17:41:19 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 17:41:19 | I | in layer model.layers.0
24-11-25 17:41:19 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 17:41:19 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 17:41:19 | I | - Evaluator: gptq
24-11-25 17:41:19 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 17:41:19 | I | - Batch_size: 8
24-11-25 17:41:19 | I |   + Max_seq_length: 2048
24-11-25 17:41:57 | I |     - Results:
24-11-25 17:41:57 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 17:41:57 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 17:41:57 | I |       |wikitext |      1|word_perplexity|7.9463|  |7.9463|
24-11-25 17:41:57 | I |       |val_valid|      1|word_perplexity|9.1140|  |9.1140|
24-11-25 17:41:57 | I |       
24-11-25 17:41:57 | I | quantizing weights for layer model.layers.0
24-11-25 17:41:57 | I | collecting info in model.layers.0
24-11-25 17:41:57 | I | collecting info in model.layers.0
24-11-25 17:41:57 | I | collecting info in model.layers.0
24-11-25 17:41:57 | I | collecting info in model.layers.0
24-11-25 17:41:58 | I | collecting calibration activations in model.layers.0
24-11-25 17:41:58 | I | collecting calibration activations in model.layers.0
24-11-25 17:41:58 | I | collecting calibration activations in model.layers.0
24-11-25 17:41:58 | I | collecting calibration activations in model.layers.0
24-11-25 17:41:58 | I | - Quantizing decoder layer model.layers.0
24-11-25 17:41:58 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 17:41:59 | I |       - range scale = [    1.0000]
24-11-25 17:41:59 | I |         sum  error  = [    0.0561]
24-11-25 17:41:59 | I |         best error  = [    0.0561]
24-11-25 17:41:59 | I |     + error = [0.0561]
24-11-25 17:42:00 | I |       - range scale = [    1.0000]
24-11-25 17:42:00 | I |         sum  error  = [    0.6508]
24-11-25 17:42:00 | I |         best error  = [    0.6508]
24-11-25 17:42:00 | I |     + error = [0.6508]
24-11-25 17:42:00 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 17:42:00 | I |       - range scale = [    1.0000]
24-11-25 17:42:00 | I |         sum  error  = [    0.0699]
24-11-25 17:42:00 | I |         best error  = [    0.0699]
24-11-25 17:42:00 | I |     + error = [0.0699]
24-11-25 17:42:01 | I |       - range scale = [    1.0000]
24-11-25 17:42:01 | I |         sum  error  = [    0.5691]
24-11-25 17:42:01 | I |         best error  = [    0.5691]
24-11-25 17:42:01 | I |     + error = [0.5691]
24-11-25 17:42:01 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 17:42:02 | I |       - range scale = [    1.0000]
24-11-25 17:42:02 | I |         sum  error  = [    0.2302]
24-11-25 17:42:02 | I |         best error  = [    0.2302]
24-11-25 17:42:02 | I |     + error = [0.2302]
24-11-25 17:42:03 | I |       - range scale = [    1.0000]
24-11-25 17:42:03 | I |         sum  error  = [    1.8094]
24-11-25 17:42:03 | I |         best error  = [    1.8094]
24-11-25 17:42:03 | I |     + error = [1.8094]
24-11-25 17:42:03 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 17:42:04 | I |       - range scale = [    1.0000]
24-11-25 17:42:04 | I |         sum  error  = [    0.0625]
24-11-25 17:42:04 | I |         best error  = [    0.0625]
24-11-25 17:42:04 | I |     + error = [0.0625]
24-11-25 17:42:04 | I |       - range scale = [    1.0000]
24-11-25 17:42:04 | I |         sum  error  = [    0.6040]
24-11-25 17:42:04 | I |         best error  = [    0.6040]
24-11-25 17:42:04 | I |     + error = [0.6040]
24-11-25 17:42:04 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 17:42:05 | I |       - range scale = [    1.0000]
24-11-25 17:42:05 | I |         sum  error  = [    1.1017]
24-11-25 17:42:05 | I |         best error  = [    1.1017]
24-11-25 17:42:05 | I |     + error = [1.1017]
24-11-25 17:42:06 | I |       - range scale = [    1.0000]
24-11-25 17:42:06 | I |         sum  error  = [   12.2230]
24-11-25 17:42:06 | I |         best error  = [   12.2230]
24-11-25 17:42:06 | I |     + error = [12.2230]
24-11-25 17:42:06 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 17:42:07 | I |       - range scale = [    1.0000]
24-11-25 17:42:07 | I |         sum  error  = [    1.2771]
24-11-25 17:42:07 | I |         best error  = [    1.2771]
24-11-25 17:42:07 | I |     + error = [1.2771]
24-11-25 17:42:08 | I |       - range scale = [    1.0000]
24-11-25 17:42:08 | I |         sum  error  = [   12.6390]
24-11-25 17:42:08 | I |         best error  = [   12.6390]
24-11-25 17:42:08 | I |     + error = [12.6390]
24-11-25 17:42:08 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 17:42:08 | I |       - range scale = [    1.0000]
24-11-25 17:42:08 | I |         sum  error  = [    3.1823]
24-11-25 17:42:08 | I |         best error  = [    3.1823]
24-11-25 17:42:08 | I |     + error = [3.1823]
24-11-25 17:42:09 | I |       - range scale = [    1.0000]
24-11-25 17:42:09 | I |         sum  error  = [   17.3868]
24-11-25 17:42:09 | I |         best error  = [   17.3868]
24-11-25 17:42:09 | I |     + error = [17.3868]
24-11-25 17:42:09 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 17:42:11 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 17:42:12 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 17:42:14 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 17:42:16 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 17:42:17 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 17:42:19 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 17:42:23 | I | quantizing activations for layer model.layers.0
24-11-25 17:42:23 | I | collecting info in model.layers.0
24-11-25 17:42:23 | I | collecting info in model.layers.0
24-11-25 17:42:23 | I | collecting info in model.layers.0
24-11-25 17:42:23 | I | collecting info in model.layers.0
24-11-25 17:42:24 | I | collecting calibration activations in model.layers.0
24-11-25 17:42:24 | I | collecting calibration activations in model.layers.0
24-11-25 17:42:24 | I | collecting calibration activations in model.layers.0
24-11-25 17:42:24 | I | collecting calibration activations in model.layers.0
24-11-25 17:42:26 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 17:42:26 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 17:42:26 | I | - Evaluator: gptq
24-11-25 17:42:26 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 17:42:26 | I | - Batch_size: 8
24-11-25 17:42:26 | I |   + Max_seq_length: 2048
24-11-25 17:43:08 | I |     - Results:
24-11-25 17:43:08 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 17:43:08 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 17:43:08 | I |       |wikitext |      1|word_perplexity|7.8934|  |7.8934|
24-11-25 17:43:08 | I |       |val_valid|      1|word_perplexity|9.0894|  |9.0894|
24-11-25 17:43:08 | I |       
24-11-25 17:43:08 | I | forward this layer
24-11-25 17:43:08 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/89.pt
24-11-25 17:43:08 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/89.pt
24-11-25 17:43:08 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 17:43:08 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 17:43:08 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 17:43:08 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 17:43:08 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 17:43:08 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 17:43:08 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 17:43:08 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 17:43:08 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 17:43:08 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 17:43:08 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 17:43:08 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 17:43:08 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 17:43:08 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 17:43:08 | I | [30] done with optimizer step
24-11-25 17:43:08 | I | epoch 001:     45 / 409600000 loss=0.000108616, loss_per_token=0.222445, loss_sum=7289.07, wps=151.4, ups=0, wpb=32768, bsz=64, num_updates=31, lr=9.3e-05, gnorm=16.989, clip=100, loss_scale=0.0078, train_wall=216, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=9918, lmquant_ppl_result_wikitext_in_train_no_quant=7.94627, lmquant_ppl_result_val_in_train_no_quant=9.11403, lmquant_ppl_result_wikitext_in_train_with_quant=7.89342, lmquant_ppl_result_val_in_train_with_quant=9.08941
24-11-25 17:43:08 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 17:43:08 | I | in layer model.layers.0
24-11-25 17:43:08 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 17:43:08 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 17:43:08 | I | - Evaluator: gptq
24-11-25 17:43:08 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 17:43:08 | I | - Batch_size: 8
24-11-25 17:43:08 | I |   + Max_seq_length: 2048
24-11-25 17:43:46 | I |     - Results:
24-11-25 17:43:46 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 17:43:46 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 17:43:46 | I |       |wikitext |      1|word_perplexity|7.9373|  |7.9373|
24-11-25 17:43:46 | I |       |val_valid|      1|word_perplexity|9.1050|  |9.1050|
24-11-25 17:43:46 | I |       
24-11-25 17:43:46 | I | quantizing weights for layer model.layers.0
24-11-25 17:43:46 | I | collecting info in model.layers.0
24-11-25 17:43:46 | I | collecting info in model.layers.0
24-11-25 17:43:46 | I | collecting info in model.layers.0
24-11-25 17:43:46 | I | collecting info in model.layers.0
24-11-25 17:43:47 | I | collecting calibration activations in model.layers.0
24-11-25 17:43:47 | I | collecting calibration activations in model.layers.0
24-11-25 17:43:47 | I | collecting calibration activations in model.layers.0
24-11-25 17:43:47 | I | collecting calibration activations in model.layers.0
24-11-25 17:43:48 | I | - Quantizing decoder layer model.layers.0
24-11-25 17:43:48 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 17:43:48 | I |       - range scale = [    1.0000]
24-11-25 17:43:48 | I |         sum  error  = [    0.0594]
24-11-25 17:43:48 | I |         best error  = [    0.0594]
24-11-25 17:43:48 | I |     + error = [0.0594]
24-11-25 17:43:49 | I |       - range scale = [    1.0000]
24-11-25 17:43:49 | I |         sum  error  = [    0.6474]
24-11-25 17:43:49 | I |         best error  = [    0.6474]
24-11-25 17:43:49 | I |     + error = [0.6474]
24-11-25 17:43:49 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 17:43:50 | I |       - range scale = [    1.0000]
24-11-25 17:43:50 | I |         sum  error  = [    0.0689]
24-11-25 17:43:50 | I |         best error  = [    0.0689]
24-11-25 17:43:50 | I |     + error = [0.0689]
24-11-25 17:43:51 | I |       - range scale = [    1.0000]
24-11-25 17:43:51 | I |         sum  error  = [    0.6394]
24-11-25 17:43:51 | I |         best error  = [    0.6394]
24-11-25 17:43:51 | I |     + error = [0.6394]
24-11-25 17:43:51 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 17:43:52 | I |       - range scale = [    1.0000]
24-11-25 17:43:52 | I |         sum  error  = [    0.2504]
24-11-25 17:43:52 | I |         best error  = [    0.2504]
24-11-25 17:43:52 | I |     + error = [0.2504]
24-11-25 17:43:52 | I |       - range scale = [    1.0000]
24-11-25 17:43:52 | I |         sum  error  = [    1.8515]
24-11-25 17:43:52 | I |         best error  = [    1.8515]
24-11-25 17:43:52 | I |     + error = [1.8515]
24-11-25 17:43:52 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 17:43:53 | I |       - range scale = [    1.0000]
24-11-25 17:43:53 | I |         sum  error  = [    0.0716]
24-11-25 17:43:53 | I |         best error  = [    0.0716]
24-11-25 17:43:53 | I |     + error = [0.0716]
24-11-25 17:43:54 | I |       - range scale = [    1.0000]
24-11-25 17:43:54 | I |         sum  error  = [    0.7064]
24-11-25 17:43:54 | I |         best error  = [    0.7064]
24-11-25 17:43:54 | I |     + error = [0.7064]
24-11-25 17:43:54 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 17:43:55 | I |       - range scale = [    1.0000]
24-11-25 17:43:55 | I |         sum  error  = [    1.1371]
24-11-25 17:43:55 | I |         best error  = [    1.1371]
24-11-25 17:43:55 | I |     + error = [1.1371]
24-11-25 17:43:56 | I |       - range scale = [    1.0000]
24-11-25 17:43:56 | I |         sum  error  = [   12.6258]
24-11-25 17:43:56 | I |         best error  = [   12.6258]
24-11-25 17:43:56 | I |     + error = [12.6258]
24-11-25 17:43:56 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 17:43:56 | I |       - range scale = [    1.0000]
24-11-25 17:43:56 | I |         sum  error  = [    1.3167]
24-11-25 17:43:56 | I |         best error  = [    1.3167]
24-11-25 17:43:56 | I |     + error = [1.3167]
24-11-25 17:43:57 | I |       - range scale = [    1.0000]
24-11-25 17:43:57 | I |         sum  error  = [   13.0686]
24-11-25 17:43:57 | I |         best error  = [   13.0686]
24-11-25 17:43:57 | I |     + error = [13.0686]
24-11-25 17:43:57 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 17:43:58 | I |       - range scale = [    1.0000]
24-11-25 17:43:58 | I |         sum  error  = [    2.2936]
24-11-25 17:43:58 | I |         best error  = [    2.2936]
24-11-25 17:43:58 | I |     + error = [2.2936]
24-11-25 17:43:59 | I |       - range scale = [    1.0000]
24-11-25 17:43:59 | I |         sum  error  = [   12.2277]
24-11-25 17:43:59 | I |         best error  = [   12.2277]
24-11-25 17:43:59 | I |     + error = [12.2277]
24-11-25 17:43:59 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 17:44:00 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 17:44:02 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 17:44:03 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 17:44:05 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 17:44:06 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 17:44:07 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 17:44:11 | I | quantizing activations for layer model.layers.0
24-11-25 17:44:11 | I | collecting info in model.layers.0
24-11-25 17:44:11 | I | collecting info in model.layers.0
24-11-25 17:44:11 | I | collecting info in model.layers.0
24-11-25 17:44:11 | I | collecting info in model.layers.0
24-11-25 17:44:11 | I | collecting calibration activations in model.layers.0
24-11-25 17:44:11 | I | collecting calibration activations in model.layers.0
24-11-25 17:44:11 | I | collecting calibration activations in model.layers.0
24-11-25 17:44:11 | I | collecting calibration activations in model.layers.0
24-11-25 17:44:13 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 17:44:13 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 17:44:13 | I | - Evaluator: gptq
24-11-25 17:44:13 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 17:44:13 | I | - Batch_size: 8
24-11-25 17:44:13 | I |   + Max_seq_length: 2048
24-11-25 17:44:55 | I |     - Results:
24-11-25 17:44:55 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 17:44:55 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 17:44:55 | I |       |wikitext |      1|word_perplexity|7.9283|  |7.9283|
24-11-25 17:44:55 | I |       |val_valid|      1|word_perplexity|9.1219|  |9.1219|
24-11-25 17:44:55 | I |       
24-11-25 17:44:55 | I | forward this layer
24-11-25 17:44:55 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/90.pt
24-11-25 17:44:55 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/90.pt
24-11-25 17:44:55 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 17:44:55 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 17:44:55 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 17:44:55 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 17:44:55 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 17:44:55 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 17:44:55 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 17:44:55 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 17:44:55 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 17:44:55 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 17:44:55 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 17:44:55 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 17:44:55 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 17:44:55 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 17:44:55 | I | in layer model.layers.0
24-11-25 17:44:55 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 17:44:55 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 17:44:55 | I | - Evaluator: gptq
24-11-25 17:44:55 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 17:44:55 | I | - Batch_size: 8
24-11-25 17:44:55 | I |   + Max_seq_length: 2048
24-11-25 17:45:33 | I |     - Results:
24-11-25 17:45:33 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 17:45:33 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 17:45:33 | I |       |wikitext |      1|word_perplexity|7.9373|  |7.9373|
24-11-25 17:45:33 | I |       |val_valid|      1|word_perplexity|9.1050|  |9.1050|
24-11-25 17:45:33 | I |       
24-11-25 17:45:33 | I | quantizing weights for layer model.layers.0
24-11-25 17:45:33 | I | collecting info in model.layers.0
24-11-25 17:45:33 | I | collecting info in model.layers.0
24-11-25 17:45:33 | I | collecting info in model.layers.0
24-11-25 17:45:33 | I | collecting info in model.layers.0
24-11-25 17:45:34 | I | collecting calibration activations in model.layers.0
24-11-25 17:45:34 | I | collecting calibration activations in model.layers.0
24-11-25 17:45:34 | I | collecting calibration activations in model.layers.0
24-11-25 17:45:34 | I | collecting calibration activations in model.layers.0
24-11-25 17:45:34 | I | - Quantizing decoder layer model.layers.0
24-11-25 17:45:34 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 17:45:35 | I |       - range scale = [    1.0000]
24-11-25 17:45:35 | I |         sum  error  = [    0.0572]
24-11-25 17:45:35 | I |         best error  = [    0.0572]
24-11-25 17:45:35 | I |     + error = [0.0572]
24-11-25 17:45:36 | I |       - range scale = [    1.0000]
24-11-25 17:45:36 | I |         sum  error  = [    0.6416]
24-11-25 17:45:36 | I |         best error  = [    0.6416]
24-11-25 17:45:36 | I |     + error = [0.6416]
24-11-25 17:45:36 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 17:45:37 | I |       - range scale = [    1.0000]
24-11-25 17:45:37 | I |         sum  error  = [    0.0711]
24-11-25 17:45:37 | I |         best error  = [    0.0711]
24-11-25 17:45:37 | I |     + error = [0.0711]
24-11-25 17:45:37 | I |       - range scale = [    1.0000]
24-11-25 17:45:37 | I |         sum  error  = [    0.5807]
24-11-25 17:45:37 | I |         best error  = [    0.5807]
24-11-25 17:45:37 | I |     + error = [0.5807]
24-11-25 17:45:38 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 17:45:38 | I |       - range scale = [    1.0000]
24-11-25 17:45:38 | I |         sum  error  = [    0.2409]
24-11-25 17:45:38 | I |         best error  = [    0.2409]
24-11-25 17:45:38 | I |     + error = [0.2409]
24-11-25 17:45:39 | I |       - range scale = [    1.0000]
24-11-25 17:45:39 | I |         sum  error  = [    1.8214]
24-11-25 17:45:39 | I |         best error  = [    1.8214]
24-11-25 17:45:39 | I |     + error = [1.8214]
24-11-25 17:45:39 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 17:45:40 | I |       - range scale = [    1.0000]
24-11-25 17:45:40 | I |         sum  error  = [    0.0616]
24-11-25 17:45:40 | I |         best error  = [    0.0616]
24-11-25 17:45:40 | I |     + error = [0.0616]
24-11-25 17:45:41 | I |       - range scale = [    1.0000]
24-11-25 17:45:41 | I |         sum  error  = [    0.5905]
24-11-25 17:45:41 | I |         best error  = [    0.5905]
24-11-25 17:45:41 | I |     + error = [0.5905]
24-11-25 17:45:41 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 17:45:41 | I |       - range scale = [    1.0000]
24-11-25 17:45:41 | I |         sum  error  = [    1.0686]
24-11-25 17:45:41 | I |         best error  = [    1.0686]
24-11-25 17:45:41 | I |     + error = [1.0686]
24-11-25 17:45:42 | I |       - range scale = [    1.0000]
24-11-25 17:45:42 | I |         sum  error  = [   11.8687]
24-11-25 17:45:42 | I |         best error  = [   11.8687]
24-11-25 17:45:42 | I |     + error = [11.8687]
24-11-25 17:45:42 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 17:45:43 | I |       - range scale = [    1.0000]
24-11-25 17:45:43 | I |         sum  error  = [    1.2401]
24-11-25 17:45:43 | I |         best error  = [    1.2401]
24-11-25 17:45:43 | I |     + error = [1.2401]
24-11-25 17:45:44 | I |       - range scale = [    1.0000]
24-11-25 17:45:44 | I |         sum  error  = [   12.2642]
24-11-25 17:45:44 | I |         best error  = [   12.2642]
24-11-25 17:45:44 | I |     + error = [12.2642]
24-11-25 17:45:44 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 17:45:45 | I |       - range scale = [    1.0000]
24-11-25 17:45:45 | I |         sum  error  = [    3.7847]
24-11-25 17:45:45 | I |         best error  = [    3.7847]
24-11-25 17:45:45 | I |     + error = [3.7847]
24-11-25 17:45:45 | I |       - range scale = [    1.0000]
24-11-25 17:45:45 | I |         sum  error  = [   20.5065]
24-11-25 17:45:45 | I |         best error  = [   20.5065]
24-11-25 17:45:45 | I |     + error = [20.5065]
24-11-25 17:45:46 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 17:45:47 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 17:45:49 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 17:45:50 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 17:45:51 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 17:45:53 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 17:45:54 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 17:45:57 | I | quantizing activations for layer model.layers.0
24-11-25 17:45:57 | I | collecting info in model.layers.0
24-11-25 17:45:57 | I | collecting info in model.layers.0
24-11-25 17:45:57 | I | collecting info in model.layers.0
24-11-25 17:45:57 | I | collecting info in model.layers.0
24-11-25 17:45:58 | I | collecting calibration activations in model.layers.0
24-11-25 17:45:58 | I | collecting calibration activations in model.layers.0
24-11-25 17:45:58 | I | collecting calibration activations in model.layers.0
24-11-25 17:45:58 | I | collecting calibration activations in model.layers.0
24-11-25 17:46:00 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 17:46:00 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 17:46:00 | I | - Evaluator: gptq
24-11-25 17:46:00 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 17:46:00 | I | - Batch_size: 8
24-11-25 17:46:00 | I |   + Max_seq_length: 2048
24-11-25 17:46:41 | I |     - Results:
24-11-25 17:46:41 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 17:46:41 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 17:46:41 | I |       |wikitext |      1|word_perplexity|7.8719|  |7.8719|
24-11-25 17:46:41 | I |       |val_valid|      1|word_perplexity|9.0765|  |9.0765|
24-11-25 17:46:41 | I |       
24-11-25 17:46:41 | I | forward this layer
24-11-25 17:46:41 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/91.pt
24-11-25 17:46:41 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/91.pt
24-11-25 17:46:42 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 17:46:42 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 17:46:42 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 17:46:42 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 17:46:42 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 17:46:42 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 17:46:42 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 17:46:42 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 17:46:42 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 17:46:42 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 17:46:42 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 17:46:42 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 17:46:42 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 17:46:42 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 17:46:42 | I | [31] done with optimizer step
24-11-25 17:46:42 | I | epoch 001:     46 / 409600000 loss=7.66789e-05, loss_per_token=0.157038, loss_sum=5145.83, wps=153.4, ups=0, wpb=32768, bsz=64, num_updates=32, lr=9.6e-05, gnorm=14.988, clip=100, loss_scale=0.0078, train_wall=213, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=10132, lmquant_ppl_result_wikitext_in_train_no_quant=7.93732, lmquant_ppl_result_val_in_train_no_quant=9.10504, lmquant_ppl_result_wikitext_in_train_with_quant=7.87185, lmquant_ppl_result_val_in_train_with_quant=9.0765
24-11-25 17:46:42 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 17:46:42 | I | in layer model.layers.0
24-11-25 17:46:42 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 17:46:42 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 17:46:42 | I | - Evaluator: gptq
24-11-25 17:46:42 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 17:46:42 | I | - Batch_size: 8
24-11-25 17:46:42 | I |   + Max_seq_length: 2048
24-11-25 17:47:20 | I |     - Results:
24-11-25 17:47:20 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 17:47:20 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 17:47:20 | I |       |wikitext |      1|word_perplexity|7.9274|  |7.9274|
24-11-25 17:47:20 | I |       |val_valid|      1|word_perplexity|9.0953|  |9.0953|
24-11-25 17:47:20 | I |       
24-11-25 17:47:20 | I | quantizing weights for layer model.layers.0
24-11-25 17:47:20 | I | collecting info in model.layers.0
24-11-25 17:47:20 | I | collecting info in model.layers.0
24-11-25 17:47:20 | I | collecting info in model.layers.0
24-11-25 17:47:20 | I | collecting info in model.layers.0
24-11-25 17:47:21 | I | collecting calibration activations in model.layers.0
24-11-25 17:47:21 | I | collecting calibration activations in model.layers.0
24-11-25 17:47:21 | I | collecting calibration activations in model.layers.0
24-11-25 17:47:21 | I | collecting calibration activations in model.layers.0
24-11-25 17:47:21 | I | - Quantizing decoder layer model.layers.0
24-11-25 17:47:21 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 17:47:22 | I |       - range scale = [    1.0000]
24-11-25 17:47:22 | I |         sum  error  = [    0.0568]
24-11-25 17:47:22 | I |         best error  = [    0.0568]
24-11-25 17:47:22 | I |     + error = [0.0568]
24-11-25 17:47:23 | I |       - range scale = [    1.0000]
24-11-25 17:47:23 | I |         sum  error  = [    0.6255]
24-11-25 17:47:23 | I |         best error  = [    0.6255]
24-11-25 17:47:23 | I |     + error = [0.6255]
24-11-25 17:47:23 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 17:47:24 | I |       - range scale = [    1.0000]
24-11-25 17:47:24 | I |         sum  error  = [    0.0651]
24-11-25 17:47:24 | I |         best error  = [    0.0651]
24-11-25 17:47:24 | I |     + error = [0.0651]
24-11-25 17:47:24 | I |       - range scale = [    1.0000]
24-11-25 17:47:24 | I |         sum  error  = [    0.5451]
24-11-25 17:47:24 | I |         best error  = [    0.5451]
24-11-25 17:47:24 | I |     + error = [0.5451]
24-11-25 17:47:24 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 17:47:25 | I |       - range scale = [    1.0000]
24-11-25 17:47:25 | I |         sum  error  = [    0.2355]
24-11-25 17:47:25 | I |         best error  = [    0.2355]
24-11-25 17:47:25 | I |     + error = [0.2355]
24-11-25 17:47:26 | I |       - range scale = [    1.0000]
24-11-25 17:47:26 | I |         sum  error  = [    1.8160]
24-11-25 17:47:26 | I |         best error  = [    1.8160]
24-11-25 17:47:26 | I |     + error = [1.8160]
24-11-25 17:47:26 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 17:47:27 | I |       - range scale = [    1.0000]
24-11-25 17:47:27 | I |         sum  error  = [    0.0646]
24-11-25 17:47:27 | I |         best error  = [    0.0646]
24-11-25 17:47:27 | I |     + error = [0.0646]
24-11-25 17:47:27 | I |       - range scale = [    1.0000]
24-11-25 17:47:27 | I |         sum  error  = [    0.6093]
24-11-25 17:47:27 | I |         best error  = [    0.6093]
24-11-25 17:47:27 | I |     + error = [0.6093]
24-11-25 17:47:28 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 17:47:28 | I |       - range scale = [    1.0000]
24-11-25 17:47:28 | I |         sum  error  = [    1.0597]
24-11-25 17:47:28 | I |         best error  = [    1.0597]
24-11-25 17:47:28 | I |     + error = [1.0597]
24-11-25 17:47:29 | I |       - range scale = [    1.0000]
24-11-25 17:47:29 | I |         sum  error  = [   11.7412]
24-11-25 17:47:29 | I |         best error  = [   11.7412]
24-11-25 17:47:29 | I |     + error = [11.7412]
24-11-25 17:47:29 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 17:47:30 | I |       - range scale = [    1.0000]
24-11-25 17:47:30 | I |         sum  error  = [    1.2279]
24-11-25 17:47:30 | I |         best error  = [    1.2279]
24-11-25 17:47:30 | I |     + error = [1.2279]
24-11-25 17:47:31 | I |       - range scale = [    1.0000]
24-11-25 17:47:31 | I |         sum  error  = [   12.1255]
24-11-25 17:47:31 | I |         best error  = [   12.1255]
24-11-25 17:47:31 | I |     + error = [12.1255]
24-11-25 17:47:31 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 17:47:32 | I |       - range scale = [    1.0000]
24-11-25 17:47:32 | I |         sum  error  = [    2.7857]
24-11-25 17:47:32 | I |         best error  = [    2.7857]
24-11-25 17:47:32 | I |     + error = [2.7857]
24-11-25 17:47:32 | I |       - range scale = [    1.0000]
24-11-25 17:47:32 | I |         sum  error  = [   15.2961]
24-11-25 17:47:32 | I |         best error  = [   15.2961]
24-11-25 17:47:32 | I |     + error = [15.2961]
24-11-25 17:47:33 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 17:47:34 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 17:47:35 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 17:47:37 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 17:47:38 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 17:47:40 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 17:47:41 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 17:47:44 | I | quantizing activations for layer model.layers.0
24-11-25 17:47:44 | I | collecting info in model.layers.0
24-11-25 17:47:44 | I | collecting info in model.layers.0
24-11-25 17:47:44 | I | collecting info in model.layers.0
24-11-25 17:47:44 | I | collecting info in model.layers.0
24-11-25 17:47:45 | I | collecting calibration activations in model.layers.0
24-11-25 17:47:45 | I | collecting calibration activations in model.layers.0
24-11-25 17:47:45 | I | collecting calibration activations in model.layers.0
24-11-25 17:47:45 | I | collecting calibration activations in model.layers.0
24-11-25 17:47:47 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 17:47:47 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 17:47:47 | I | - Evaluator: gptq
24-11-25 17:47:47 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 17:47:47 | I | - Batch_size: 8
24-11-25 17:47:47 | I |   + Max_seq_length: 2048
24-11-25 17:48:28 | I |     - Results:
24-11-25 17:48:28 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 17:48:28 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 17:48:28 | I |       |wikitext |      1|word_perplexity|7.8620|  |7.8620|
24-11-25 17:48:28 | I |       |val_valid|      1|word_perplexity|9.0707|  |9.0707|
24-11-25 17:48:28 | I |       
24-11-25 17:48:28 | I | forward this layer
24-11-25 17:48:28 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/92.pt
24-11-25 17:48:28 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/92.pt
24-11-25 17:48:29 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 17:48:29 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 17:48:29 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 17:48:29 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 17:48:29 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 17:48:29 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 17:48:29 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 17:48:29 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 17:48:29 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 17:48:29 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 17:48:29 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 17:48:29 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 17:48:29 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 17:48:29 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 17:48:29 | I | in layer model.layers.0
24-11-25 17:48:29 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 17:48:29 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 17:48:29 | I | - Evaluator: gptq
24-11-25 17:48:29 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 17:48:29 | I | - Batch_size: 8
24-11-25 17:48:29 | I |   + Max_seq_length: 2048
24-11-25 17:49:07 | I |     - Results:
24-11-25 17:49:07 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 17:49:07 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 17:49:07 | I |       |wikitext |      1|word_perplexity|7.9274|  |7.9274|
24-11-25 17:49:07 | I |       |val_valid|      1|word_perplexity|9.0953|  |9.0953|
24-11-25 17:49:07 | I |       
24-11-25 17:49:07 | I | quantizing weights for layer model.layers.0
24-11-25 17:49:07 | I | collecting info in model.layers.0
24-11-25 17:49:07 | I | collecting info in model.layers.0
24-11-25 17:49:07 | I | collecting info in model.layers.0
24-11-25 17:49:07 | I | collecting info in model.layers.0
24-11-25 17:49:07 | I | collecting calibration activations in model.layers.0
24-11-25 17:49:08 | I | collecting calibration activations in model.layers.0
24-11-25 17:49:08 | I | collecting calibration activations in model.layers.0
24-11-25 17:49:08 | I | collecting calibration activations in model.layers.0
24-11-25 17:49:08 | I | - Quantizing decoder layer model.layers.0
24-11-25 17:49:08 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 17:49:09 | I |       - range scale = [    1.0000]
24-11-25 17:49:09 | I |         sum  error  = [    0.0570]
24-11-25 17:49:09 | I |         best error  = [    0.0570]
24-11-25 17:49:09 | I |     + error = [0.0570]
24-11-25 17:49:09 | I |       - range scale = [    1.0000]
24-11-25 17:49:09 | I |         sum  error  = [    0.6238]
24-11-25 17:49:09 | I |         best error  = [    0.6238]
24-11-25 17:49:09 | I |     + error = [0.6238]
24-11-25 17:49:10 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 17:49:10 | I |       - range scale = [    1.0000]
24-11-25 17:49:10 | I |         sum  error  = [    0.0682]
24-11-25 17:49:10 | I |         best error  = [    0.0682]
24-11-25 17:49:10 | I |     + error = [0.0682]
24-11-25 17:49:11 | I |       - range scale = [    1.0000]
24-11-25 17:49:11 | I |         sum  error  = [    0.5877]
24-11-25 17:49:11 | I |         best error  = [    0.5877]
24-11-25 17:49:11 | I |     + error = [0.5877]
24-11-25 17:49:11 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 17:49:12 | I |       - range scale = [    1.0000]
24-11-25 17:49:12 | I |         sum  error  = [    0.2296]
24-11-25 17:49:12 | I |         best error  = [    0.2296]
24-11-25 17:49:12 | I |     + error = [0.2296]
24-11-25 17:49:13 | I |       - range scale = [    1.0000]
24-11-25 17:49:13 | I |         sum  error  = [    1.7804]
24-11-25 17:49:13 | I |         best error  = [    1.7804]
24-11-25 17:49:13 | I |     + error = [1.7804]
24-11-25 17:49:13 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 17:49:14 | I |       - range scale = [    1.0000]
24-11-25 17:49:14 | I |         sum  error  = [    0.0633]
24-11-25 17:49:14 | I |         best error  = [    0.0633]
24-11-25 17:49:14 | I |     + error = [0.0633]
24-11-25 17:49:14 | I |       - range scale = [    1.0000]
24-11-25 17:49:14 | I |         sum  error  = [    0.5994]
24-11-25 17:49:14 | I |         best error  = [    0.5994]
24-11-25 17:49:14 | I |     + error = [0.5994]
24-11-25 17:49:14 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 17:49:15 | I |       - range scale = [    1.0000]
24-11-25 17:49:15 | I |         sum  error  = [    1.0942]
24-11-25 17:49:15 | I |         best error  = [    1.0942]
24-11-25 17:49:15 | I |     + error = [1.0942]
24-11-25 17:49:16 | I |       - range scale = [    1.0000]
24-11-25 17:49:16 | I |         sum  error  = [   12.1153]
24-11-25 17:49:16 | I |         best error  = [   12.1153]
24-11-25 17:49:16 | I |     + error = [12.1153]
24-11-25 17:49:16 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 17:49:17 | I |       - range scale = [    1.0000]
24-11-25 17:49:17 | I |         sum  error  = [    1.2666]
24-11-25 17:49:17 | I |         best error  = [    1.2666]
24-11-25 17:49:17 | I |     + error = [1.2666]
24-11-25 17:49:18 | I |       - range scale = [    1.0000]
24-11-25 17:49:18 | I |         sum  error  = [   12.5173]
24-11-25 17:49:18 | I |         best error  = [   12.5173]
24-11-25 17:49:18 | I |     + error = [12.5173]
24-11-25 17:49:18 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 17:49:18 | I |       - range scale = [    1.0000]
24-11-25 17:49:18 | I |         sum  error  = [    2.9665]
24-11-25 17:49:18 | I |         best error  = [    2.9665]
24-11-25 17:49:18 | I |     + error = [2.9665]
24-11-25 17:49:19 | I |       - range scale = [    1.0000]
24-11-25 17:49:19 | I |         sum  error  = [   16.2220]
24-11-25 17:49:19 | I |         best error  = [   16.2220]
24-11-25 17:49:19 | I |     + error = [16.2220]
24-11-25 17:49:19 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 17:49:21 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 17:49:22 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 17:49:24 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 17:49:25 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 17:49:26 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 17:49:28 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 17:49:31 | I | quantizing activations for layer model.layers.0
24-11-25 17:49:31 | I | collecting info in model.layers.0
24-11-25 17:49:31 | I | collecting info in model.layers.0
24-11-25 17:49:31 | I | collecting info in model.layers.0
24-11-25 17:49:31 | I | collecting info in model.layers.0
24-11-25 17:49:32 | I | collecting calibration activations in model.layers.0
24-11-25 17:49:32 | I | collecting calibration activations in model.layers.0
24-11-25 17:49:32 | I | collecting calibration activations in model.layers.0
24-11-25 17:49:32 | I | collecting calibration activations in model.layers.0
24-11-25 17:49:34 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 17:49:34 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 17:49:34 | I | - Evaluator: gptq
24-11-25 17:49:34 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 17:49:34 | I | - Batch_size: 8
24-11-25 17:49:34 | I |   + Max_seq_length: 2048
24-11-25 17:50:15 | I |     - Results:
24-11-25 17:50:15 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 17:50:15 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 17:50:15 | I |       |wikitext |      1|word_perplexity|7.9227|  |7.9227|
24-11-25 17:50:15 | I |       |val_valid|      1|word_perplexity|9.1119|  |9.1119|
24-11-25 17:50:15 | I |       
24-11-25 17:50:15 | I | forward this layer
24-11-25 17:50:15 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/93.pt
24-11-25 17:50:15 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/93.pt
24-11-25 17:50:15 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 17:50:15 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 17:50:15 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 17:50:15 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 17:50:15 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 17:50:15 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 17:50:15 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 17:50:15 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 17:50:15 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 17:50:15 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 17:50:15 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 17:50:15 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 17:50:15 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 17:50:15 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 17:50:15 | I | [32] done with optimizer step
24-11-25 17:50:15 | I | epoch 001:     47 / 409600000 loss=9.32937e-05, loss_per_token=0.191066, loss_sum=6260.84, wps=153.3, ups=0, wpb=32768, bsz=64, num_updates=33, lr=9.9e-05, gnorm=18.175, clip=100, loss_scale=0.0078, train_wall=213, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=10346, lmquant_ppl_result_wikitext_in_train_no_quant=7.92743, lmquant_ppl_result_val_in_train_no_quant=9.09525, lmquant_ppl_result_wikitext_in_train_with_quant=7.92266, lmquant_ppl_result_val_in_train_with_quant=9.11186
24-11-25 17:50:16 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 17:50:16 | I | in layer model.layers.0
24-11-25 17:50:16 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 17:50:16 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 17:50:16 | I | - Evaluator: gptq
24-11-25 17:50:16 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 17:50:16 | I | - Batch_size: 8
24-11-25 17:50:16 | I |   + Max_seq_length: 2048
24-11-25 17:50:54 | I |     - Results:
24-11-25 17:50:54 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 17:50:54 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 17:50:54 | I |       |wikitext |      1|word_perplexity|7.9147|  |7.9147|
24-11-25 17:50:54 | I |       |val_valid|      1|word_perplexity|9.0837|  |9.0837|
24-11-25 17:50:54 | I |       
24-11-25 17:50:54 | I | quantizing weights for layer model.layers.0
24-11-25 17:50:54 | I | collecting info in model.layers.0
24-11-25 17:50:54 | I | collecting info in model.layers.0
24-11-25 17:50:54 | I | collecting info in model.layers.0
24-11-25 17:50:54 | I | collecting info in model.layers.0
24-11-25 17:50:54 | I | collecting calibration activations in model.layers.0
24-11-25 17:50:55 | I | collecting calibration activations in model.layers.0
24-11-25 17:50:55 | I | collecting calibration activations in model.layers.0
24-11-25 17:50:55 | I | collecting calibration activations in model.layers.0
24-11-25 17:50:55 | I | - Quantizing decoder layer model.layers.0
24-11-25 17:50:55 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 17:50:56 | I |       - range scale = [    1.0000]
24-11-25 17:50:56 | I |         sum  error  = [    0.0578]
24-11-25 17:50:56 | I |         best error  = [    0.0578]
24-11-25 17:50:56 | I |     + error = [0.0578]
24-11-25 17:50:56 | I |       - range scale = [    1.0000]
24-11-25 17:50:56 | I |         sum  error  = [    0.6474]
24-11-25 17:50:56 | I |         best error  = [    0.6474]
24-11-25 17:50:56 | I |     + error = [0.6474]
24-11-25 17:50:57 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 17:50:57 | I |       - range scale = [    1.0000]
24-11-25 17:50:57 | I |         sum  error  = [    0.0698]
24-11-25 17:50:57 | I |         best error  = [    0.0698]
24-11-25 17:50:57 | I |     + error = [0.0698]
24-11-25 17:50:58 | I |       - range scale = [    1.0000]
24-11-25 17:50:58 | I |         sum  error  = [    0.6332]
24-11-25 17:50:58 | I |         best error  = [    0.6332]
24-11-25 17:50:58 | I |     + error = [0.6332]
24-11-25 17:50:58 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 17:50:59 | I |       - range scale = [    1.0000]
24-11-25 17:50:59 | I |         sum  error  = [    0.2450]
24-11-25 17:50:59 | I |         best error  = [    0.2450]
24-11-25 17:50:59 | I |     + error = [0.2450]
24-11-25 17:51:00 | I |       - range scale = [    1.0000]
24-11-25 17:51:00 | I |         sum  error  = [    1.8765]
24-11-25 17:51:00 | I |         best error  = [    1.8765]
24-11-25 17:51:00 | I |     + error = [1.8765]
24-11-25 17:51:00 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 17:51:00 | I |       - range scale = [    1.0000]
24-11-25 17:51:00 | I |         sum  error  = [    0.0661]
24-11-25 17:51:00 | I |         best error  = [    0.0661]
24-11-25 17:51:00 | I |     + error = [0.0661]
24-11-25 17:51:01 | I |       - range scale = [    1.0000]
24-11-25 17:51:01 | I |         sum  error  = [    0.6357]
24-11-25 17:51:01 | I |         best error  = [    0.6357]
24-11-25 17:51:01 | I |     + error = [0.6357]
24-11-25 17:51:01 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 17:51:02 | I |       - range scale = [    1.0000]
24-11-25 17:51:02 | I |         sum  error  = [    1.1193]
24-11-25 17:51:02 | I |         best error  = [    1.1193]
24-11-25 17:51:02 | I |     + error = [1.1193]
24-11-25 17:51:03 | I |       - range scale = [    1.0000]
24-11-25 17:51:03 | I |         sum  error  = [   12.3911]
24-11-25 17:51:03 | I |         best error  = [   12.3911]
24-11-25 17:51:03 | I |     + error = [12.3911]
24-11-25 17:51:03 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 17:51:04 | I |       - range scale = [    1.0000]
24-11-25 17:51:04 | I |         sum  error  = [    1.2977]
24-11-25 17:51:04 | I |         best error  = [    1.2977]
24-11-25 17:51:04 | I |     + error = [1.2977]
24-11-25 17:51:04 | I |       - range scale = [    1.0000]
24-11-25 17:51:04 | I |         sum  error  = [   12.8156]
24-11-25 17:51:04 | I |         best error  = [   12.8156]
24-11-25 17:51:04 | I |     + error = [12.8156]
24-11-25 17:51:05 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 17:51:05 | I |       - range scale = [    1.0000]
24-11-25 17:51:05 | I |         sum  error  = [    2.3936]
24-11-25 17:51:05 | I |         best error  = [    2.3936]
24-11-25 17:51:05 | I |     + error = [2.3936]
24-11-25 17:51:06 | I |       - range scale = [    1.0000]
24-11-25 17:51:06 | I |         sum  error  = [   13.0209]
24-11-25 17:51:06 | I |         best error  = [   13.0209]
24-11-25 17:51:06 | I |     + error = [13.0209]
24-11-25 17:51:06 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 17:51:08 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 17:51:09 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 17:51:10 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 17:51:12 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 17:51:13 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 17:51:15 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 17:51:18 | I | quantizing activations for layer model.layers.0
24-11-25 17:51:18 | I | collecting info in model.layers.0
24-11-25 17:51:18 | I | collecting info in model.layers.0
24-11-25 17:51:18 | I | collecting info in model.layers.0
24-11-25 17:51:18 | I | collecting info in model.layers.0
24-11-25 17:51:18 | I | collecting calibration activations in model.layers.0
24-11-25 17:51:18 | I | collecting calibration activations in model.layers.0
24-11-25 17:51:19 | I | collecting calibration activations in model.layers.0
24-11-25 17:51:19 | I | collecting calibration activations in model.layers.0
24-11-25 17:51:21 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 17:51:21 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 17:51:21 | I | - Evaluator: gptq
24-11-25 17:51:21 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 17:51:21 | I | - Batch_size: 8
24-11-25 17:51:21 | I |   + Max_seq_length: 2048
24-11-25 17:52:02 | I |     - Results:
24-11-25 17:52:02 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 17:52:02 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 17:52:02 | I |       |wikitext |      1|word_perplexity|7.8937|  |7.8937|
24-11-25 17:52:02 | I |       |val_valid|      1|word_perplexity|9.0950|  |9.0950|
24-11-25 17:52:02 | I |       
24-11-25 17:52:02 | I | forward this layer
24-11-25 17:52:02 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/94.pt
24-11-25 17:52:02 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/94.pt
24-11-25 17:52:02 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 17:52:02 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 17:52:02 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 17:52:02 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 17:52:02 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 17:52:02 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 17:52:02 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 17:52:02 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 17:52:02 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 17:52:02 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 17:52:02 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 17:52:02 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 17:52:02 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 17:52:02 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 17:52:02 | I | in layer model.layers.0
24-11-25 17:52:02 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 17:52:02 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 17:52:02 | I | - Evaluator: gptq
24-11-25 17:52:02 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 17:52:02 | I | - Batch_size: 8
24-11-25 17:52:02 | I |   + Max_seq_length: 2048
24-11-25 17:52:40 | I |     - Results:
24-11-25 17:52:40 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 17:52:40 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 17:52:40 | I |       |wikitext |      1|word_perplexity|7.9147|  |7.9147|
24-11-25 17:52:40 | I |       |val_valid|      1|word_perplexity|9.0837|  |9.0837|
24-11-25 17:52:40 | I |       
24-11-25 17:52:40 | I | quantizing weights for layer model.layers.0
24-11-25 17:52:40 | I | collecting info in model.layers.0
24-11-25 17:52:40 | I | collecting info in model.layers.0
24-11-25 17:52:40 | I | collecting info in model.layers.0
24-11-25 17:52:40 | I | collecting info in model.layers.0
24-11-25 17:52:41 | I | collecting calibration activations in model.layers.0
24-11-25 17:52:41 | I | collecting calibration activations in model.layers.0
24-11-25 17:52:41 | I | collecting calibration activations in model.layers.0
24-11-25 17:52:41 | I | collecting calibration activations in model.layers.0
24-11-25 17:52:42 | I | - Quantizing decoder layer model.layers.0
24-11-25 17:52:42 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 17:52:42 | I |       - range scale = [    1.0000]
24-11-25 17:52:42 | I |         sum  error  = [    0.0574]
24-11-25 17:52:42 | I |         best error  = [    0.0574]
24-11-25 17:52:42 | I |     + error = [0.0574]
24-11-25 17:52:43 | I |       - range scale = [    1.0000]
24-11-25 17:52:43 | I |         sum  error  = [    0.6497]
24-11-25 17:52:43 | I |         best error  = [    0.6497]
24-11-25 17:52:43 | I |     + error = [0.6497]
24-11-25 17:52:43 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 17:52:44 | I |       - range scale = [    1.0000]
24-11-25 17:52:44 | I |         sum  error  = [    0.0684]
24-11-25 17:52:44 | I |         best error  = [    0.0684]
24-11-25 17:52:44 | I |     + error = [0.0684]
24-11-25 17:52:45 | I |       - range scale = [    1.0000]
24-11-25 17:52:45 | I |         sum  error  = [    0.6205]
24-11-25 17:52:45 | I |         best error  = [    0.6205]
24-11-25 17:52:45 | I |     + error = [0.6205]
24-11-25 17:52:45 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 17:52:46 | I |       - range scale = [    1.0000]
24-11-25 17:52:46 | I |         sum  error  = [    0.2423]
24-11-25 17:52:46 | I |         best error  = [    0.2423]
24-11-25 17:52:46 | I |     + error = [0.2423]
24-11-25 17:52:46 | I |       - range scale = [    1.0000]
24-11-25 17:52:46 | I |         sum  error  = [    1.8632]
24-11-25 17:52:46 | I |         best error  = [    1.8632]
24-11-25 17:52:46 | I |     + error = [1.8632]
24-11-25 17:52:47 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 17:52:47 | I |       - range scale = [    1.0000]
24-11-25 17:52:47 | I |         sum  error  = [    0.0653]
24-11-25 17:52:47 | I |         best error  = [    0.0653]
24-11-25 17:52:47 | I |     + error = [0.0653]
24-11-25 17:52:48 | I |       - range scale = [    1.0000]
24-11-25 17:52:48 | I |         sum  error  = [    0.6265]
24-11-25 17:52:48 | I |         best error  = [    0.6265]
24-11-25 17:52:48 | I |     + error = [0.6265]
24-11-25 17:52:48 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 17:52:49 | I |       - range scale = [    1.0000]
24-11-25 17:52:49 | I |         sum  error  = [    1.1093]
24-11-25 17:52:49 | I |         best error  = [    1.1093]
24-11-25 17:52:49 | I |     + error = [1.1093]
24-11-25 17:52:50 | I |       - range scale = [    1.0000]
24-11-25 17:52:50 | I |         sum  error  = [   12.2825]
24-11-25 17:52:50 | I |         best error  = [   12.2825]
24-11-25 17:52:50 | I |     + error = [12.2825]
24-11-25 17:52:50 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 17:52:50 | I |       - range scale = [    1.0000]
24-11-25 17:52:50 | I |         sum  error  = [    1.2836]
24-11-25 17:52:50 | I |         best error  = [    1.2836]
24-11-25 17:52:50 | I |     + error = [1.2836]
24-11-25 17:52:51 | I |       - range scale = [    1.0000]
24-11-25 17:52:51 | I |         sum  error  = [   12.6959]
24-11-25 17:52:51 | I |         best error  = [   12.6959]
24-11-25 17:52:51 | I |     + error = [12.6959]
24-11-25 17:52:51 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 17:52:52 | I |       - range scale = [    1.0000]
24-11-25 17:52:52 | I |         sum  error  = [    2.9425]
24-11-25 17:52:52 | I |         best error  = [    2.9425]
24-11-25 17:52:52 | I |     + error = [2.9425]
24-11-25 17:52:53 | I |       - range scale = [    1.0000]
24-11-25 17:52:53 | I |         sum  error  = [   16.1195]
24-11-25 17:52:53 | I |         best error  = [   16.1195]
24-11-25 17:52:53 | I |     + error = [16.1195]
24-11-25 17:52:53 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 17:52:54 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 17:52:56 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 17:52:57 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 17:52:59 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 17:53:00 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 17:53:01 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 17:53:05 | I | quantizing activations for layer model.layers.0
24-11-25 17:53:05 | I | collecting info in model.layers.0
24-11-25 17:53:05 | I | collecting info in model.layers.0
24-11-25 17:53:05 | I | collecting info in model.layers.0
24-11-25 17:53:05 | I | collecting info in model.layers.0
24-11-25 17:53:05 | I | collecting calibration activations in model.layers.0
24-11-25 17:53:05 | I | collecting calibration activations in model.layers.0
24-11-25 17:53:05 | I | collecting calibration activations in model.layers.0
24-11-25 17:53:05 | I | collecting calibration activations in model.layers.0
24-11-25 17:53:07 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 17:53:07 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 17:53:07 | I | - Evaluator: gptq
24-11-25 17:53:07 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 17:53:07 | I | - Batch_size: 8
24-11-25 17:53:07 | I |   + Max_seq_length: 2048
24-11-25 17:53:49 | I |     - Results:
24-11-25 17:53:49 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 17:53:49 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 17:53:49 | I |       |wikitext |      1|word_perplexity|7.8915|  |7.8915|
24-11-25 17:53:49 | I |       |val_valid|      1|word_perplexity|9.0943|  |9.0943|
24-11-25 17:53:49 | I |       
24-11-25 17:53:49 | I | forward this layer
24-11-25 17:53:49 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/95.pt
24-11-25 17:53:49 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/95.pt
24-11-25 17:53:49 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 17:53:49 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 17:53:49 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 17:53:49 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 17:53:49 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 17:53:49 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 17:53:49 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 17:53:49 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 17:53:49 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 17:53:49 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 17:53:49 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 17:53:49 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 17:53:49 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 17:53:49 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 17:53:49 | I | [33] done with optimizer step
24-11-25 17:53:49 | I | epoch 001:     48 / 409600000 loss=0.000126097, loss_per_token=0.258247, loss_sum=8462.25, wps=153.5, ups=0, wpb=32768, bsz=64, num_updates=34, lr=0.000102, gnorm=53.743, clip=100, loss_scale=0.0078, train_wall=213, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=10559, lmquant_ppl_result_wikitext_in_train_no_quant=7.9147, lmquant_ppl_result_val_in_train_no_quant=9.08367, lmquant_ppl_result_wikitext_in_train_with_quant=7.89145, lmquant_ppl_result_val_in_train_with_quant=9.09425
24-11-25 17:53:49 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 17:53:49 | I | in layer model.layers.0
24-11-25 17:53:49 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 17:53:49 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 17:53:49 | I | - Evaluator: gptq
24-11-25 17:53:49 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 17:53:49 | I | - Batch_size: 8
24-11-25 17:53:49 | I |   + Max_seq_length: 2048
24-11-25 17:54:27 | I |     - Results:
24-11-25 17:54:27 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 17:54:27 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 17:54:27 | I |       |wikitext |      1|word_perplexity|7.9019|  |7.9019|
24-11-25 17:54:27 | I |       |val_valid|      1|word_perplexity|9.0725|  |9.0725|
24-11-25 17:54:27 | I |       
24-11-25 17:54:27 | I | quantizing weights for layer model.layers.0
24-11-25 17:54:27 | I | collecting info in model.layers.0
24-11-25 17:54:27 | I | collecting info in model.layers.0
24-11-25 17:54:27 | I | collecting info in model.layers.0
24-11-25 17:54:27 | I | collecting info in model.layers.0
24-11-25 17:54:28 | I | collecting calibration activations in model.layers.0
24-11-25 17:54:28 | I | collecting calibration activations in model.layers.0
24-11-25 17:54:28 | I | collecting calibration activations in model.layers.0
24-11-25 17:54:28 | I | collecting calibration activations in model.layers.0
24-11-25 17:54:28 | I | - Quantizing decoder layer model.layers.0
24-11-25 17:54:28 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 17:54:29 | I |       - range scale = [    1.0000]
24-11-25 17:54:29 | I |         sum  error  = [    0.0587]
24-11-25 17:54:29 | I |         best error  = [    0.0587]
24-11-25 17:54:29 | I |     + error = [0.0587]
24-11-25 17:54:30 | I |       - range scale = [    1.0000]
24-11-25 17:54:30 | I |         sum  error  = [    0.6210]
24-11-25 17:54:30 | I |         best error  = [    0.6210]
24-11-25 17:54:30 | I |     + error = [0.6210]
24-11-25 17:54:30 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 17:54:31 | I |       - range scale = [    1.0000]
24-11-25 17:54:31 | I |         sum  error  = [    0.0686]
24-11-25 17:54:31 | I |         best error  = [    0.0686]
24-11-25 17:54:31 | I |     + error = [0.0686]
24-11-25 17:54:31 | I |       - range scale = [    1.0000]
24-11-25 17:54:31 | I |         sum  error  = [    0.6331]
24-11-25 17:54:31 | I |         best error  = [    0.6331]
24-11-25 17:54:31 | I |     + error = [0.6331]
24-11-25 17:54:32 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 17:54:32 | I |       - range scale = [    1.0000]
24-11-25 17:54:32 | I |         sum  error  = [    0.2442]
24-11-25 17:54:32 | I |         best error  = [    0.2442]
24-11-25 17:54:32 | I |     + error = [0.2442]
24-11-25 17:54:33 | I |       - range scale = [    1.0000]
24-11-25 17:54:33 | I |         sum  error  = [    1.8349]
24-11-25 17:54:33 | I |         best error  = [    1.8349]
24-11-25 17:54:33 | I |     + error = [1.8349]
24-11-25 17:54:33 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 17:54:34 | I |       - range scale = [    1.0000]
24-11-25 17:54:34 | I |         sum  error  = [    0.0630]
24-11-25 17:54:34 | I |         best error  = [    0.0630]
24-11-25 17:54:34 | I |     + error = [0.0630]
24-11-25 17:54:35 | I |       - range scale = [    1.0000]
24-11-25 17:54:35 | I |         sum  error  = [    0.6119]
24-11-25 17:54:35 | I |         best error  = [    0.6119]
24-11-25 17:54:35 | I |     + error = [0.6119]
24-11-25 17:54:35 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 17:54:36 | I |       - range scale = [    1.0000]
24-11-25 17:54:36 | I |         sum  error  = [    1.1064]
24-11-25 17:54:36 | I |         best error  = [    1.1064]
24-11-25 17:54:36 | I |     + error = [1.1064]
24-11-25 17:54:36 | I |       - range scale = [    1.0000]
24-11-25 17:54:36 | I |         sum  error  = [   12.2601]
24-11-25 17:54:36 | I |         best error  = [   12.2601]
24-11-25 17:54:36 | I |     + error = [12.2601]
24-11-25 17:54:36 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 17:54:37 | I |       - range scale = [    1.0000]
24-11-25 17:54:37 | I |         sum  error  = [    1.2845]
24-11-25 17:54:37 | I |         best error  = [    1.2845]
24-11-25 17:54:37 | I |     + error = [1.2845]
24-11-25 17:54:38 | I |       - range scale = [    1.0000]
24-11-25 17:54:38 | I |         sum  error  = [   12.6828]
24-11-25 17:54:38 | I |         best error  = [   12.6828]
24-11-25 17:54:38 | I |     + error = [12.6828]
24-11-25 17:54:38 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 17:54:39 | I |       - range scale = [    1.0000]
24-11-25 17:54:39 | I |         sum  error  = [    2.3244]
24-11-25 17:54:39 | I |         best error  = [    2.3244]
24-11-25 17:54:39 | I |     + error = [2.3244]
24-11-25 17:54:40 | I |       - range scale = [    1.0000]
24-11-25 17:54:40 | I |         sum  error  = [   12.7076]
24-11-25 17:54:40 | I |         best error  = [   12.7076]
24-11-25 17:54:40 | I |     + error = [12.7076]
24-11-25 17:54:40 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 17:54:41 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 17:54:43 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 17:54:44 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 17:54:45 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 17:54:47 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 17:54:48 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 17:54:51 | I | quantizing activations for layer model.layers.0
24-11-25 17:54:51 | I | collecting info in model.layers.0
24-11-25 17:54:51 | I | collecting info in model.layers.0
24-11-25 17:54:51 | I | collecting info in model.layers.0
24-11-25 17:54:51 | I | collecting info in model.layers.0
24-11-25 17:54:52 | I | collecting calibration activations in model.layers.0
24-11-25 17:54:52 | I | collecting calibration activations in model.layers.0
24-11-25 17:54:52 | I | collecting calibration activations in model.layers.0
24-11-25 17:54:52 | I | collecting calibration activations in model.layers.0
24-11-25 17:54:54 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 17:54:54 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 17:54:54 | I | - Evaluator: gptq
24-11-25 17:54:54 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 17:54:54 | I | - Batch_size: 8
24-11-25 17:54:54 | I |   + Max_seq_length: 2048
24-11-25 17:55:35 | I |     - Results:
24-11-25 17:55:35 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 17:55:35 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 17:55:35 | I |       |wikitext |      1|word_perplexity|7.8857|  |7.8857|
24-11-25 17:55:35 | I |       |val_valid|      1|word_perplexity|9.0768|  |9.0768|
24-11-25 17:55:35 | I |       
24-11-25 17:55:35 | I | forward this layer
24-11-25 17:55:35 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/96.pt
24-11-25 17:55:35 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/96.pt
24-11-25 17:55:36 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 17:55:36 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 17:55:36 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 17:55:36 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 17:55:36 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 17:55:36 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 17:55:36 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 17:55:36 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 17:55:36 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 17:55:36 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 17:55:36 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 17:55:36 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 17:55:36 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 17:55:36 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 17:55:36 | I | in layer model.layers.0
24-11-25 17:55:36 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 17:55:36 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 17:55:36 | I | - Evaluator: gptq
24-11-25 17:55:36 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 17:55:36 | I | - Batch_size: 8
24-11-25 17:55:36 | I |   + Max_seq_length: 2048
24-11-25 17:56:14 | I |     - Results:
24-11-25 17:56:14 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 17:56:14 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 17:56:14 | I |       |wikitext |      1|word_perplexity|7.9019|  |7.9019|
24-11-25 17:56:14 | I |       |val_valid|      1|word_perplexity|9.0725|  |9.0725|
24-11-25 17:56:14 | I |       
24-11-25 17:56:14 | I | quantizing weights for layer model.layers.0
24-11-25 17:56:14 | I | collecting info in model.layers.0
24-11-25 17:56:14 | I | collecting info in model.layers.0
24-11-25 17:56:14 | I | collecting info in model.layers.0
24-11-25 17:56:14 | I | collecting info in model.layers.0
24-11-25 17:56:14 | I | collecting calibration activations in model.layers.0
24-11-25 17:56:15 | I | collecting calibration activations in model.layers.0
24-11-25 17:56:15 | I | collecting calibration activations in model.layers.0
24-11-25 17:56:15 | I | collecting calibration activations in model.layers.0
24-11-25 17:56:15 | I | - Quantizing decoder layer model.layers.0
24-11-25 17:56:15 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 17:56:16 | I |       - range scale = [    1.0000]
24-11-25 17:56:16 | I |         sum  error  = [    0.0587]
24-11-25 17:56:16 | I |         best error  = [    0.0587]
24-11-25 17:56:16 | I |     + error = [0.0587]
24-11-25 17:56:16 | I |       - range scale = [    1.0000]
24-11-25 17:56:16 | I |         sum  error  = [    0.6336]
24-11-25 17:56:16 | I |         best error  = [    0.6336]
24-11-25 17:56:16 | I |     + error = [0.6336]
24-11-25 17:56:17 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 17:56:17 | I |       - range scale = [    1.0000]
24-11-25 17:56:17 | I |         sum  error  = [    0.0685]
24-11-25 17:56:17 | I |         best error  = [    0.0685]
24-11-25 17:56:17 | I |     + error = [0.0685]
24-11-25 17:56:18 | I |       - range scale = [    1.0000]
24-11-25 17:56:18 | I |         sum  error  = [    0.6428]
24-11-25 17:56:18 | I |         best error  = [    0.6428]
24-11-25 17:56:18 | I |     + error = [0.6428]
24-11-25 17:56:18 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 17:56:19 | I |       - range scale = [    1.0000]
24-11-25 17:56:19 | I |         sum  error  = [    0.2498]
24-11-25 17:56:19 | I |         best error  = [    0.2498]
24-11-25 17:56:19 | I |     + error = [0.2498]
24-11-25 17:56:20 | I |       - range scale = [    1.0000]
24-11-25 17:56:20 | I |         sum  error  = [    1.8674]
24-11-25 17:56:20 | I |         best error  = [    1.8674]
24-11-25 17:56:20 | I |     + error = [1.8674]
24-11-25 17:56:20 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 17:56:20 | I |       - range scale = [    1.0000]
24-11-25 17:56:20 | I |         sum  error  = [    0.0628]
24-11-25 17:56:20 | I |         best error  = [    0.0628]
24-11-25 17:56:20 | I |     + error = [0.0628]
24-11-25 17:56:21 | I |       - range scale = [    1.0000]
24-11-25 17:56:21 | I |         sum  error  = [    0.6124]
24-11-25 17:56:21 | I |         best error  = [    0.6124]
24-11-25 17:56:21 | I |     + error = [0.6124]
24-11-25 17:56:21 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 17:56:22 | I |       - range scale = [    1.0000]
24-11-25 17:56:22 | I |         sum  error  = [    1.0922]
24-11-25 17:56:22 | I |         best error  = [    1.0922]
24-11-25 17:56:22 | I |     + error = [1.0922]
24-11-25 17:56:23 | I |       - range scale = [    1.0000]
24-11-25 17:56:23 | I |         sum  error  = [   12.0962]
24-11-25 17:56:23 | I |         best error  = [   12.0962]
24-11-25 17:56:23 | I |     + error = [12.0962]
24-11-25 17:56:23 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 17:56:24 | I |       - range scale = [    1.0000]
24-11-25 17:56:24 | I |         sum  error  = [    1.2660]
24-11-25 17:56:24 | I |         best error  = [    1.2660]
24-11-25 17:56:24 | I |     + error = [1.2660]
24-11-25 17:56:24 | I |       - range scale = [    1.0000]
24-11-25 17:56:24 | I |         sum  error  = [   12.5079]
24-11-25 17:56:24 | I |         best error  = [   12.5079]
24-11-25 17:56:24 | I |     + error = [12.5079]
24-11-25 17:56:25 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 17:56:25 | I |       - range scale = [    1.0000]
24-11-25 17:56:25 | I |         sum  error  = [    2.3832]
24-11-25 17:56:25 | I |         best error  = [    2.3832]
24-11-25 17:56:25 | I |     + error = [2.3832]
24-11-25 17:56:26 | I |       - range scale = [    1.0000]
24-11-25 17:56:26 | I |         sum  error  = [   13.0505]
24-11-25 17:56:26 | I |         best error  = [   13.0505]
24-11-25 17:56:26 | I |     + error = [13.0505]
24-11-25 17:56:26 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 17:56:28 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 17:56:29 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 17:56:30 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 17:56:32 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 17:56:33 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 17:56:35 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 17:56:38 | I | quantizing activations for layer model.layers.0
24-11-25 17:56:38 | I | collecting info in model.layers.0
24-11-25 17:56:38 | I | collecting info in model.layers.0
24-11-25 17:56:38 | I | collecting info in model.layers.0
24-11-25 17:56:38 | I | collecting info in model.layers.0
24-11-25 17:56:38 | I | collecting calibration activations in model.layers.0
24-11-25 17:56:39 | I | collecting calibration activations in model.layers.0
24-11-25 17:56:39 | I | collecting calibration activations in model.layers.0
24-11-25 17:56:39 | I | collecting calibration activations in model.layers.0
24-11-25 17:56:41 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 17:56:41 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 17:56:41 | I | - Evaluator: gptq
24-11-25 17:56:41 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 17:56:41 | I | - Batch_size: 8
24-11-25 17:56:41 | I |   + Max_seq_length: 2048
24-11-25 17:57:22 | I |     - Results:
24-11-25 17:57:22 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 17:57:22 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 17:57:22 | I |       |wikitext |      1|word_perplexity|7.8935|  |7.8935|
24-11-25 17:57:22 | I |       |val_valid|      1|word_perplexity|9.0825|  |9.0825|
24-11-25 17:57:22 | I |       
24-11-25 17:57:22 | I | forward this layer
24-11-25 17:57:22 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/97.pt
24-11-25 17:57:22 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/97.pt
24-11-25 17:57:22 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 17:57:22 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 17:57:22 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 17:57:22 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 17:57:22 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 17:57:22 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 17:57:22 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 17:57:22 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 17:57:22 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 17:57:22 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 17:57:22 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 17:57:22 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 17:57:22 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 17:57:22 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 17:57:22 | I | [34] done with optimizer step
24-11-25 17:57:22 | I | epoch 001:     49 / 409600000 loss=0.00018033, loss_per_token=0.369315, loss_sum=12101.7, wps=153.5, ups=0, wpb=32768, bsz=64, num_updates=35, lr=0.000105, gnorm=71.286, clip=100, loss_scale=0.0078, train_wall=213, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=10773, lmquant_ppl_result_wikitext_in_train_no_quant=7.90189, lmquant_ppl_result_val_in_train_no_quant=9.07248, lmquant_ppl_result_wikitext_in_train_with_quant=7.89351, lmquant_ppl_result_val_in_train_with_quant=9.08252
24-11-25 17:57:23 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 17:57:23 | I | in layer model.layers.0
24-11-25 17:57:23 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 17:57:23 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 17:57:23 | I | - Evaluator: gptq
24-11-25 17:57:23 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 17:57:23 | I | - Batch_size: 8
24-11-25 17:57:23 | I |   + Max_seq_length: 2048
24-11-25 17:58:01 | I |     - Results:
24-11-25 17:58:01 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 17:58:01 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 17:58:01 | I |       |wikitext |      1|word_perplexity|7.8898|  |7.8898|
24-11-25 17:58:01 | I |       |val_valid|      1|word_perplexity|9.0631|  |9.0631|
24-11-25 17:58:01 | I |       
24-11-25 17:58:01 | I | quantizing weights for layer model.layers.0
24-11-25 17:58:01 | I | collecting info in model.layers.0
24-11-25 17:58:01 | I | collecting info in model.layers.0
24-11-25 17:58:01 | I | collecting info in model.layers.0
24-11-25 17:58:01 | I | collecting info in model.layers.0
24-11-25 17:58:01 | I | collecting calibration activations in model.layers.0
24-11-25 17:58:02 | I | collecting calibration activations in model.layers.0
24-11-25 17:58:02 | I | collecting calibration activations in model.layers.0
24-11-25 17:58:02 | I | collecting calibration activations in model.layers.0
24-11-25 17:58:02 | I | - Quantizing decoder layer model.layers.0
24-11-25 17:58:02 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 17:58:03 | I |       - range scale = [    1.0000]
24-11-25 17:58:03 | I |         sum  error  = [    0.0588]
24-11-25 17:58:03 | I |         best error  = [    0.0588]
24-11-25 17:58:03 | I |     + error = [0.0588]
24-11-25 17:58:03 | I |       - range scale = [    1.0000]
24-11-25 17:58:03 | I |         sum  error  = [    0.6241]
24-11-25 17:58:03 | I |         best error  = [    0.6241]
24-11-25 17:58:03 | I |     + error = [0.6241]
24-11-25 17:58:04 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 17:58:04 | I |       - range scale = [    1.0000]
24-11-25 17:58:04 | I |         sum  error  = [    0.0745]
24-11-25 17:58:04 | I |         best error  = [    0.0745]
24-11-25 17:58:04 | I |     + error = [0.0745]
24-11-25 17:58:05 | I |       - range scale = [    1.0000]
24-11-25 17:58:05 | I |         sum  error  = [    0.6545]
24-11-25 17:58:05 | I |         best error  = [    0.6545]
24-11-25 17:58:05 | I |     + error = [0.6545]
24-11-25 17:58:05 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 17:58:06 | I |       - range scale = [    1.0000]
24-11-25 17:58:06 | I |         sum  error  = [    0.2515]
24-11-25 17:58:06 | I |         best error  = [    0.2515]
24-11-25 17:58:06 | I |     + error = [0.2515]
24-11-25 17:58:07 | I |       - range scale = [    1.0000]
24-11-25 17:58:07 | I |         sum  error  = [    1.8404]
24-11-25 17:58:07 | I |         best error  = [    1.8404]
24-11-25 17:58:07 | I |     + error = [1.8404]
24-11-25 17:58:07 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 17:58:07 | I |       - range scale = [    1.0000]
24-11-25 17:58:07 | I |         sum  error  = [    0.0620]
24-11-25 17:58:07 | I |         best error  = [    0.0620]
24-11-25 17:58:07 | I |     + error = [0.0620]
24-11-25 17:58:08 | I |       - range scale = [    1.0000]
24-11-25 17:58:08 | I |         sum  error  = [    0.6037]
24-11-25 17:58:08 | I |         best error  = [    0.6037]
24-11-25 17:58:08 | I |     + error = [0.6037]
24-11-25 17:58:08 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 17:58:09 | I |       - range scale = [    1.0000]
24-11-25 17:58:09 | I |         sum  error  = [    1.1082]
24-11-25 17:58:09 | I |         best error  = [    1.1082]
24-11-25 17:58:09 | I |     + error = [1.1082]
24-11-25 17:58:10 | I |       - range scale = [    1.0000]
24-11-25 17:58:10 | I |         sum  error  = [   12.2849]
24-11-25 17:58:10 | I |         best error  = [   12.2849]
24-11-25 17:58:10 | I |     + error = [12.2849]
24-11-25 17:58:10 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 17:58:11 | I |       - range scale = [    1.0000]
24-11-25 17:58:11 | I |         sum  error  = [    1.2812]
24-11-25 17:58:11 | I |         best error  = [    1.2812]
24-11-25 17:58:11 | I |     + error = [1.2812]
24-11-25 17:58:12 | I |       - range scale = [    1.0000]
24-11-25 17:58:12 | I |         sum  error  = [   12.7059]
24-11-25 17:58:12 | I |         best error  = [   12.7059]
24-11-25 17:58:12 | I |     + error = [12.7059]
24-11-25 17:58:12 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 17:58:12 | I |       - range scale = [    1.0000]
24-11-25 17:58:12 | I |         sum  error  = [    2.4943]
24-11-25 17:58:12 | I |         best error  = [    2.4943]
24-11-25 17:58:12 | I |     + error = [2.4943]
24-11-25 17:58:13 | I |       - range scale = [    1.0000]
24-11-25 17:58:13 | I |         sum  error  = [   13.8904]
24-11-25 17:58:13 | I |         best error  = [   13.8904]
24-11-25 17:58:13 | I |     + error = [13.8904]
24-11-25 17:58:13 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 17:58:15 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 17:58:16 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 17:58:18 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 17:58:19 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 17:58:20 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 17:58:22 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 17:58:25 | I | quantizing activations for layer model.layers.0
24-11-25 17:58:25 | I | collecting info in model.layers.0
24-11-25 17:58:25 | I | collecting info in model.layers.0
24-11-25 17:58:25 | I | collecting info in model.layers.0
24-11-25 17:58:25 | I | collecting info in model.layers.0
24-11-25 17:58:26 | I | collecting calibration activations in model.layers.0
24-11-25 17:58:26 | I | collecting calibration activations in model.layers.0
24-11-25 17:58:26 | I | collecting calibration activations in model.layers.0
24-11-25 17:58:26 | I | collecting calibration activations in model.layers.0
24-11-25 17:58:28 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 17:58:28 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 17:58:28 | I | - Evaluator: gptq
24-11-25 17:58:28 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 17:58:28 | I | - Batch_size: 8
24-11-25 17:58:28 | I |   + Max_seq_length: 2048
24-11-25 17:59:09 | I |     - Results:
24-11-25 17:59:09 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 17:59:09 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 17:59:09 | I |       |wikitext |      1|word_perplexity|7.8784|  |7.8784|
24-11-25 17:59:09 | I |       |val_valid|      1|word_perplexity|9.0732|  |9.0732|
24-11-25 17:59:09 | I |       
24-11-25 17:59:09 | I | forward this layer
24-11-25 17:59:09 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/98.pt
24-11-25 17:59:09 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/98.pt
24-11-25 17:59:09 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 17:59:09 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 17:59:09 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 17:59:09 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 17:59:09 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 17:59:09 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 17:59:09 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 17:59:09 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 17:59:09 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 17:59:09 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 17:59:09 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 17:59:09 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 17:59:09 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 17:59:09 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 17:59:09 | I | in layer model.layers.0
24-11-25 17:59:09 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 17:59:09 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 17:59:09 | I | - Evaluator: gptq
24-11-25 17:59:09 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 17:59:09 | I | - Batch_size: 8
24-11-25 17:59:09 | I |   + Max_seq_length: 2048
24-11-25 17:59:48 | I |     - Results:
24-11-25 17:59:48 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 17:59:48 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 17:59:48 | I |       |wikitext |      1|word_perplexity|7.8898|  |7.8898|
24-11-25 17:59:48 | I |       |val_valid|      1|word_perplexity|9.0631|  |9.0631|
24-11-25 17:59:48 | I |       
24-11-25 17:59:48 | I | quantizing weights for layer model.layers.0
24-11-25 17:59:48 | I | collecting info in model.layers.0
24-11-25 17:59:48 | I | collecting info in model.layers.0
24-11-25 17:59:48 | I | collecting info in model.layers.0
24-11-25 17:59:48 | I | collecting info in model.layers.0
24-11-25 17:59:48 | I | collecting calibration activations in model.layers.0
24-11-25 17:59:48 | I | collecting calibration activations in model.layers.0
24-11-25 17:59:48 | I | collecting calibration activations in model.layers.0
24-11-25 17:59:48 | I | collecting calibration activations in model.layers.0
24-11-25 17:59:49 | I | - Quantizing decoder layer model.layers.0
24-11-25 17:59:49 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 17:59:50 | I |       - range scale = [    1.0000]
24-11-25 17:59:50 | I |         sum  error  = [    0.0594]
24-11-25 17:59:50 | I |         best error  = [    0.0594]
24-11-25 17:59:50 | I |     + error = [0.0594]
24-11-25 17:59:50 | I |       - range scale = [    1.0000]
24-11-25 17:59:50 | I |         sum  error  = [    0.6290]
24-11-25 17:59:50 | I |         best error  = [    0.6290]
24-11-25 17:59:50 | I |     + error = [0.6290]
24-11-25 17:59:50 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 17:59:51 | I |       - range scale = [    1.0000]
24-11-25 17:59:51 | I |         sum  error  = [    0.0757]
24-11-25 17:59:51 | I |         best error  = [    0.0757]
24-11-25 17:59:51 | I |     + error = [0.0757]
24-11-25 17:59:52 | I |       - range scale = [    1.0000]
24-11-25 17:59:52 | I |         sum  error  = [    0.6565]
24-11-25 17:59:52 | I |         best error  = [    0.6565]
24-11-25 17:59:52 | I |     + error = [0.6565]
24-11-25 17:59:52 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 17:59:53 | I |       - range scale = [    1.0000]
24-11-25 17:59:53 | I |         sum  error  = [    0.2513]
24-11-25 17:59:53 | I |         best error  = [    0.2513]
24-11-25 17:59:53 | I |     + error = [0.2513]
24-11-25 17:59:53 | I |       - range scale = [    1.0000]
24-11-25 17:59:53 | I |         sum  error  = [    1.8482]
24-11-25 17:59:53 | I |         best error  = [    1.8482]
24-11-25 17:59:53 | I |     + error = [1.8482]
24-11-25 17:59:54 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 17:59:54 | I |       - range scale = [    1.0000]
24-11-25 17:59:54 | I |         sum  error  = [    0.0622]
24-11-25 17:59:54 | I |         best error  = [    0.0622]
24-11-25 17:59:54 | I |     + error = [0.0622]
24-11-25 17:59:55 | I |       - range scale = [    1.0000]
24-11-25 17:59:55 | I |         sum  error  = [    0.6038]
24-11-25 17:59:55 | I |         best error  = [    0.6038]
24-11-25 17:59:55 | I |     + error = [0.6038]
24-11-25 17:59:55 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 17:59:56 | I |       - range scale = [    1.0000]
24-11-25 17:59:56 | I |         sum  error  = [    1.1098]
24-11-25 17:59:56 | I |         best error  = [    1.1098]
24-11-25 17:59:56 | I |     + error = [1.1098]
24-11-25 17:59:57 | I |       - range scale = [    1.0000]
24-11-25 17:59:57 | I |         sum  error  = [   12.3129]
24-11-25 17:59:57 | I |         best error  = [   12.3129]
24-11-25 17:59:57 | I |     + error = [12.3129]
24-11-25 17:59:57 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 17:59:58 | I |       - range scale = [    1.0000]
24-11-25 17:59:58 | I |         sum  error  = [    1.2845]
24-11-25 17:59:58 | I |         best error  = [    1.2845]
24-11-25 17:59:58 | I |     + error = [1.2845]
24-11-25 17:59:58 | I |       - range scale = [    1.0000]
24-11-25 17:59:58 | I |         sum  error  = [   12.7349]
24-11-25 17:59:58 | I |         best error  = [   12.7349]
24-11-25 17:59:58 | I |     + error = [12.7349]
24-11-25 17:59:59 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 17:59:59 | I |       - range scale = [    1.0000]
24-11-25 17:59:59 | I |         sum  error  = [    1.8438]
24-11-25 17:59:59 | I |         best error  = [    1.8438]
24-11-25 17:59:59 | I |     + error = [1.8438]
24-11-25 18:00:00 | I |       - range scale = [    1.0000]
24-11-25 18:00:00 | I |         sum  error  = [   10.1924]
24-11-25 18:00:00 | I |         best error  = [   10.1924]
24-11-25 18:00:00 | I |     + error = [10.1924]
24-11-25 18:00:00 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 18:00:02 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 18:00:03 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 18:00:04 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 18:00:06 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 18:00:07 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 18:00:08 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 18:00:12 | I | quantizing activations for layer model.layers.0
24-11-25 18:00:12 | I | collecting info in model.layers.0
24-11-25 18:00:12 | I | collecting info in model.layers.0
24-11-25 18:00:12 | I | collecting info in model.layers.0
24-11-25 18:00:12 | I | collecting info in model.layers.0
24-11-25 18:00:12 | I | collecting calibration activations in model.layers.0
24-11-25 18:00:12 | I | collecting calibration activations in model.layers.0
24-11-25 18:00:12 | I | collecting calibration activations in model.layers.0
24-11-25 18:00:13 | I | collecting calibration activations in model.layers.0
24-11-25 18:00:14 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 18:00:14 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 18:00:14 | I | - Evaluator: gptq
24-11-25 18:00:14 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 18:00:14 | I | - Batch_size: 8
24-11-25 18:00:14 | I |   + Max_seq_length: 2048
24-11-25 18:00:56 | I |     - Results:
24-11-25 18:00:56 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 18:00:56 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 18:00:56 | I |       |wikitext |      1|word_perplexity|7.8956|  |7.8956|
24-11-25 18:00:56 | I |       |val_valid|      1|word_perplexity|9.0747|  |9.0747|
24-11-25 18:00:56 | I |       
24-11-25 18:00:56 | I | forward this layer
24-11-25 18:00:56 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/99.pt
24-11-25 18:00:56 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/99.pt
24-11-25 18:00:56 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 18:00:56 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 18:00:56 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 18:00:56 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 18:00:56 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 18:00:56 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 18:00:56 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 18:00:56 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 18:00:56 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 18:00:56 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 18:00:56 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 18:00:56 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 18:00:56 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 18:00:56 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 18:00:56 | I | [35] done with optimizer step
24-11-25 18:00:56 | I | epoch 001:     50 / 409600000 loss=0.000128584, loss_per_token=0.26334, loss_sum=8629.12, wps=153.2, ups=0, wpb=32768, bsz=64, num_updates=36, lr=0.000108, gnorm=39.079, clip=100, loss_scale=0.0078, train_wall=214, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=10987, lmquant_ppl_result_wikitext_in_train_no_quant=7.88983, lmquant_ppl_result_val_in_train_no_quant=9.06309, lmquant_ppl_result_wikitext_in_train_with_quant=7.89561, lmquant_ppl_result_val_in_train_with_quant=9.07466
24-11-25 18:00:57 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 18:00:57 | I | in layer model.layers.0
24-11-25 18:00:57 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 18:00:57 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 18:00:57 | I | - Evaluator: gptq
24-11-25 18:00:57 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 18:00:57 | I | - Batch_size: 8
24-11-25 18:00:57 | I |   + Max_seq_length: 2048
24-11-25 18:01:35 | I |     - Results:
24-11-25 18:01:35 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 18:01:35 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 18:01:35 | I |       |wikitext |      1|word_perplexity|7.8776|  |7.8776|
24-11-25 18:01:35 | I |       |val_valid|      1|word_perplexity|9.0545|  |9.0545|
24-11-25 18:01:35 | I |       
24-11-25 18:01:35 | I | quantizing weights for layer model.layers.0
24-11-25 18:01:35 | I | collecting info in model.layers.0
24-11-25 18:01:35 | I | collecting info in model.layers.0
24-11-25 18:01:35 | I | collecting info in model.layers.0
24-11-25 18:01:35 | I | collecting info in model.layers.0
24-11-25 18:01:35 | I | collecting calibration activations in model.layers.0
24-11-25 18:01:35 | I | collecting calibration activations in model.layers.0
24-11-25 18:01:36 | I | collecting calibration activations in model.layers.0
24-11-25 18:01:36 | I | collecting calibration activations in model.layers.0
24-11-25 18:01:36 | I | - Quantizing decoder layer model.layers.0
24-11-25 18:01:36 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 18:01:37 | I |       - range scale = [    1.0000]
24-11-25 18:01:37 | I |         sum  error  = [    0.0547]
24-11-25 18:01:37 | I |         best error  = [    0.0547]
24-11-25 18:01:37 | I |     + error = [0.0547]
24-11-25 18:01:37 | I |       - range scale = [    1.0000]
24-11-25 18:01:37 | I |         sum  error  = [    0.6183]
24-11-25 18:01:37 | I |         best error  = [    0.6183]
24-11-25 18:01:37 | I |     + error = [0.6183]
24-11-25 18:01:38 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 18:01:38 | I |       - range scale = [    1.0000]
24-11-25 18:01:38 | I |         sum  error  = [    0.0751]
24-11-25 18:01:38 | I |         best error  = [    0.0751]
24-11-25 18:01:38 | I |     + error = [0.0751]
24-11-25 18:01:39 | I |       - range scale = [    1.0000]
24-11-25 18:01:39 | I |         sum  error  = [    0.6338]
24-11-25 18:01:39 | I |         best error  = [    0.6338]
24-11-25 18:01:39 | I |     + error = [0.6338]
24-11-25 18:01:39 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 18:01:40 | I |       - range scale = [    1.0000]
24-11-25 18:01:40 | I |         sum  error  = [    0.2516]
24-11-25 18:01:40 | I |         best error  = [    0.2516]
24-11-25 18:01:40 | I |     + error = [0.2516]
24-11-25 18:01:41 | I |       - range scale = [    1.0000]
24-11-25 18:01:41 | I |         sum  error  = [    1.8525]
24-11-25 18:01:41 | I |         best error  = [    1.8525]
24-11-25 18:01:41 | I |     + error = [1.8525]
24-11-25 18:01:41 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 18:01:41 | I |       - range scale = [    1.0000]
24-11-25 18:01:41 | I |         sum  error  = [    0.0627]
24-11-25 18:01:41 | I |         best error  = [    0.0627]
24-11-25 18:01:41 | I |     + error = [0.0627]
24-11-25 18:01:42 | I |       - range scale = [    1.0000]
24-11-25 18:01:42 | I |         sum  error  = [    0.6072]
24-11-25 18:01:42 | I |         best error  = [    0.6072]
24-11-25 18:01:42 | I |     + error = [0.6072]
24-11-25 18:01:42 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 18:01:43 | I |       - range scale = [    1.0000]
24-11-25 18:01:43 | I |         sum  error  = [    1.1115]
24-11-25 18:01:43 | I |         best error  = [    1.1115]
24-11-25 18:01:43 | I |     + error = [1.1115]
24-11-25 18:01:44 | I |       - range scale = [    1.0000]
24-11-25 18:01:44 | I |         sum  error  = [   12.3168]
24-11-25 18:01:44 | I |         best error  = [   12.3168]
24-11-25 18:01:44 | I |     + error = [12.3168]
24-11-25 18:01:44 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 18:01:45 | I |       - range scale = [    1.0000]
24-11-25 18:01:45 | I |         sum  error  = [    1.2857]
24-11-25 18:01:45 | I |         best error  = [    1.2857]
24-11-25 18:01:45 | I |     + error = [1.2857]
24-11-25 18:01:45 | I |       - range scale = [    1.0000]
24-11-25 18:01:45 | I |         sum  error  = [   12.7373]
24-11-25 18:01:45 | I |         best error  = [   12.7373]
24-11-25 18:01:45 | I |     + error = [12.7373]
24-11-25 18:01:46 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 18:01:46 | I |       - range scale = [    1.0000]
24-11-25 18:01:46 | I |         sum  error  = [    2.9683]
24-11-25 18:01:46 | I |         best error  = [    2.9683]
24-11-25 18:01:46 | I |     + error = [2.9683]
24-11-25 18:01:47 | I |       - range scale = [    1.0000]
24-11-25 18:01:47 | I |         sum  error  = [   16.2604]
24-11-25 18:01:47 | I |         best error  = [   16.2604]
24-11-25 18:01:47 | I |     + error = [16.2604]
24-11-25 18:01:47 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 18:01:49 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 18:01:50 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 18:01:52 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 18:01:53 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 18:01:54 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 18:01:56 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 18:01:59 | I | quantizing activations for layer model.layers.0
24-11-25 18:01:59 | I | collecting info in model.layers.0
24-11-25 18:01:59 | I | collecting info in model.layers.0
24-11-25 18:01:59 | I | collecting info in model.layers.0
24-11-25 18:01:59 | I | collecting info in model.layers.0
24-11-25 18:01:59 | I | collecting calibration activations in model.layers.0
24-11-25 18:02:00 | I | collecting calibration activations in model.layers.0
24-11-25 18:02:00 | I | collecting calibration activations in model.layers.0
24-11-25 18:02:00 | I | collecting calibration activations in model.layers.0
24-11-25 18:02:02 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 18:02:02 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 18:02:02 | I | - Evaluator: gptq
24-11-25 18:02:02 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 18:02:02 | I | - Batch_size: 8
24-11-25 18:02:02 | I |   + Max_seq_length: 2048
24-11-25 18:02:43 | I |     - Results:
24-11-25 18:02:43 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 18:02:43 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 18:02:43 | I |       |wikitext |      1|word_perplexity|7.8740|  |7.8740|
24-11-25 18:02:43 | I |       |val_valid|      1|word_perplexity|9.0658|  |9.0658|
24-11-25 18:02:43 | I |       
24-11-25 18:02:43 | I | forward this layer
24-11-25 18:02:43 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/100.pt
24-11-25 18:02:43 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/100.pt
24-11-25 18:02:43 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 18:02:43 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 18:02:43 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 18:02:43 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 18:02:43 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 18:02:43 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 18:02:43 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 18:02:43 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 18:02:43 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 18:02:43 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 18:02:43 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 18:02:43 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 18:02:43 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 18:02:43 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 18:02:43 | I | in layer model.layers.0
24-11-25 18:02:43 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 18:02:43 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 18:02:43 | I | - Evaluator: gptq
24-11-25 18:02:43 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 18:02:43 | I | - Batch_size: 8
24-11-25 18:02:43 | I |   + Max_seq_length: 2048
24-11-25 18:03:22 | I |     - Results:
24-11-25 18:03:22 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 18:03:22 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 18:03:22 | I |       |wikitext |      1|word_perplexity|7.8776|  |7.8776|
24-11-25 18:03:22 | I |       |val_valid|      1|word_perplexity|9.0545|  |9.0545|
24-11-25 18:03:22 | I |       
24-11-25 18:03:22 | I | quantizing weights for layer model.layers.0
24-11-25 18:03:22 | I | collecting info in model.layers.0
24-11-25 18:03:22 | I | collecting info in model.layers.0
24-11-25 18:03:22 | I | collecting info in model.layers.0
24-11-25 18:03:22 | I | collecting info in model.layers.0
24-11-25 18:03:22 | I | collecting calibration activations in model.layers.0
24-11-25 18:03:22 | I | collecting calibration activations in model.layers.0
24-11-25 18:03:22 | I | collecting calibration activations in model.layers.0
24-11-25 18:03:22 | I | collecting calibration activations in model.layers.0
24-11-25 18:03:23 | I | - Quantizing decoder layer model.layers.0
24-11-25 18:03:23 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 18:03:23 | I |       - range scale = [    1.0000]
24-11-25 18:03:23 | I |         sum  error  = [    0.0550]
24-11-25 18:03:23 | I |         best error  = [    0.0550]
24-11-25 18:03:23 | I |     + error = [0.0550]
24-11-25 18:03:24 | I |       - range scale = [    1.0000]
24-11-25 18:03:24 | I |         sum  error  = [    0.6186]
24-11-25 18:03:24 | I |         best error  = [    0.6186]
24-11-25 18:03:24 | I |     + error = [0.6186]
24-11-25 18:03:24 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 18:03:25 | I |       - range scale = [    1.0000]
24-11-25 18:03:25 | I |         sum  error  = [    0.0760]
24-11-25 18:03:25 | I |         best error  = [    0.0760]
24-11-25 18:03:25 | I |     + error = [0.0760]
24-11-25 18:03:26 | I |       - range scale = [    1.0000]
24-11-25 18:03:26 | I |         sum  error  = [    0.6437]
24-11-25 18:03:26 | I |         best error  = [    0.6437]
24-11-25 18:03:26 | I |     + error = [0.6437]
24-11-25 18:03:26 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 18:03:27 | I |       - range scale = [    1.0000]
24-11-25 18:03:27 | I |         sum  error  = [    0.2551]
24-11-25 18:03:27 | I |         best error  = [    0.2551]
24-11-25 18:03:27 | I |     + error = [0.2551]
24-11-25 18:03:27 | I |       - range scale = [    1.0000]
24-11-25 18:03:27 | I |         sum  error  = [    1.8673]
24-11-25 18:03:27 | I |         best error  = [    1.8673]
24-11-25 18:03:27 | I |     + error = [1.8673]
24-11-25 18:03:28 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 18:03:28 | I |       - range scale = [    1.0000]
24-11-25 18:03:28 | I |         sum  error  = [    0.0612]
24-11-25 18:03:28 | I |         best error  = [    0.0612]
24-11-25 18:03:28 | I |     + error = [0.0612]
24-11-25 18:03:29 | I |       - range scale = [    1.0000]
24-11-25 18:03:29 | I |         sum  error  = [    0.5919]
24-11-25 18:03:29 | I |         best error  = [    0.5919]
24-11-25 18:03:29 | I |     + error = [0.5919]
24-11-25 18:03:29 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 18:03:30 | I |       - range scale = [    1.0000]
24-11-25 18:03:30 | I |         sum  error  = [    1.1093]
24-11-25 18:03:30 | I |         best error  = [    1.1093]
24-11-25 18:03:30 | I |     + error = [1.1093]
24-11-25 18:03:30 | I |       - range scale = [    1.0000]
24-11-25 18:03:30 | I |         sum  error  = [   12.2926]
24-11-25 18:03:30 | I |         best error  = [   12.2926]
24-11-25 18:03:30 | I |     + error = [12.2926]
24-11-25 18:03:31 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 18:03:31 | I |       - range scale = [    1.0000]
24-11-25 18:03:31 | I |         sum  error  = [    1.2843]
24-11-25 18:03:31 | I |         best error  = [    1.2843]
24-11-25 18:03:31 | I |     + error = [1.2843]
24-11-25 18:03:32 | I |       - range scale = [    1.0000]
24-11-25 18:03:32 | I |         sum  error  = [   12.7184]
24-11-25 18:03:32 | I |         best error  = [   12.7184]
24-11-25 18:03:32 | I |     + error = [12.7184]
24-11-25 18:03:32 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 18:03:33 | I |       - range scale = [    1.0000]
24-11-25 18:03:33 | I |         sum  error  = [    2.8311]
24-11-25 18:03:33 | I |         best error  = [    2.8311]
24-11-25 18:03:33 | I |     + error = [2.8311]
24-11-25 18:03:34 | I |       - range scale = [    1.0000]
24-11-25 18:03:34 | I |         sum  error  = [   15.4664]
24-11-25 18:03:34 | I |         best error  = [   15.4664]
24-11-25 18:03:34 | I |     + error = [15.4664]
24-11-25 18:03:34 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 18:03:35 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 18:03:37 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 18:03:38 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 18:03:40 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 18:03:41 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 18:03:42 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 18:03:46 | I | quantizing activations for layer model.layers.0
24-11-25 18:03:46 | I | collecting info in model.layers.0
24-11-25 18:03:46 | I | collecting info in model.layers.0
24-11-25 18:03:46 | I | collecting info in model.layers.0
24-11-25 18:03:46 | I | collecting info in model.layers.0
24-11-25 18:03:46 | I | collecting calibration activations in model.layers.0
24-11-25 18:03:46 | I | collecting calibration activations in model.layers.0
24-11-25 18:03:46 | I | collecting calibration activations in model.layers.0
24-11-25 18:03:47 | I | collecting calibration activations in model.layers.0
24-11-25 18:03:48 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 18:03:48 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 18:03:48 | I | - Evaluator: gptq
24-11-25 18:03:48 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 18:03:48 | I | - Batch_size: 8
24-11-25 18:03:48 | I |   + Max_seq_length: 2048
24-11-25 18:04:30 | I |     - Results:
24-11-25 18:04:30 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 18:04:30 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 18:04:30 | I |       |wikitext |      1|word_perplexity|7.8726|  |7.8726|
24-11-25 18:04:30 | I |       |val_valid|      1|word_perplexity|9.0671|  |9.0671|
24-11-25 18:04:30 | I |       
24-11-25 18:04:30 | I | forward this layer
24-11-25 18:04:30 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/101.pt
24-11-25 18:04:30 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/101.pt
24-11-25 18:04:30 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 18:04:30 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 18:04:30 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 18:04:30 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 18:04:30 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 18:04:30 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 18:04:30 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 18:04:30 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 18:04:30 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 18:04:30 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 18:04:30 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 18:04:30 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 18:04:30 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 18:04:30 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 18:04:30 | I | [36] done with optimizer step
24-11-25 18:04:30 | I | epoch 001:     51 / 409600000 loss=0.000125237, loss_per_token=0.256486, loss_sum=8404.54, wps=153.2, ups=0, wpb=32768, bsz=64, num_updates=37, lr=0.000111, gnorm=35.261, clip=100, loss_scale=0.0078, train_wall=214, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=11201, lmquant_ppl_result_wikitext_in_train_no_quant=7.87761, lmquant_ppl_result_val_in_train_no_quant=9.05451, lmquant_ppl_result_wikitext_in_train_with_quant=7.87264, lmquant_ppl_result_val_in_train_with_quant=9.06709
24-11-25 18:04:30 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 18:04:30 | I | in layer model.layers.0
24-11-25 18:04:30 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 18:04:30 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 18:04:30 | I | - Evaluator: gptq
24-11-25 18:04:30 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 18:04:30 | I | - Batch_size: 8
24-11-25 18:04:30 | I |   + Max_seq_length: 2048
24-11-25 18:05:09 | I |     - Results:
24-11-25 18:05:09 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 18:05:09 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 18:05:09 | I |       |wikitext |      1|word_perplexity|7.8660|  |7.8660|
24-11-25 18:05:09 | I |       |val_valid|      1|word_perplexity|9.0468|  |9.0468|
24-11-25 18:05:09 | I |       
24-11-25 18:05:09 | I | quantizing weights for layer model.layers.0
24-11-25 18:05:09 | I | collecting info in model.layers.0
24-11-25 18:05:09 | I | collecting info in model.layers.0
24-11-25 18:05:09 | I | collecting info in model.layers.0
24-11-25 18:05:09 | I | collecting info in model.layers.0
24-11-25 18:05:09 | I | collecting calibration activations in model.layers.0
24-11-25 18:05:09 | I | collecting calibration activations in model.layers.0
24-11-25 18:05:10 | I | collecting calibration activations in model.layers.0
24-11-25 18:05:10 | I | collecting calibration activations in model.layers.0
24-11-25 18:05:10 | I | - Quantizing decoder layer model.layers.0
24-11-25 18:05:10 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 18:05:11 | I |       - range scale = [    1.0000]
24-11-25 18:05:11 | I |         sum  error  = [    0.0669]
24-11-25 18:05:11 | I |         best error  = [    0.0669]
24-11-25 18:05:11 | I |     + error = [0.0669]
24-11-25 18:05:11 | I |       - range scale = [    1.0000]
24-11-25 18:05:11 | I |         sum  error  = [    0.6192]
24-11-25 18:05:11 | I |         best error  = [    0.6192]
24-11-25 18:05:11 | I |     + error = [0.6192]
24-11-25 18:05:12 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 18:05:12 | I |       - range scale = [    1.0000]
24-11-25 18:05:12 | I |         sum  error  = [    0.0760]
24-11-25 18:05:12 | I |         best error  = [    0.0760]
24-11-25 18:05:12 | I |     + error = [0.0760]
24-11-25 18:05:13 | I |       - range scale = [    1.0000]
24-11-25 18:05:13 | I |         sum  error  = [    0.6153]
24-11-25 18:05:13 | I |         best error  = [    0.6153]
24-11-25 18:05:13 | I |     + error = [0.6153]
24-11-25 18:05:13 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 18:05:14 | I |       - range scale = [    1.0000]
24-11-25 18:05:14 | I |         sum  error  = [    0.2486]
24-11-25 18:05:14 | I |         best error  = [    0.2486]
24-11-25 18:05:14 | I |     + error = [0.2486]
24-11-25 18:05:15 | I |       - range scale = [    1.0000]
24-11-25 18:05:15 | I |         sum  error  = [    1.8621]
24-11-25 18:05:15 | I |         best error  = [    1.8621]
24-11-25 18:05:15 | I |     + error = [1.8621]
24-11-25 18:05:15 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 18:05:15 | I |       - range scale = [    1.0000]
24-11-25 18:05:15 | I |         sum  error  = [    0.0615]
24-11-25 18:05:15 | I |         best error  = [    0.0615]
24-11-25 18:05:15 | I |     + error = [0.0615]
24-11-25 18:05:16 | I |       - range scale = [    1.0000]
24-11-25 18:05:16 | I |         sum  error  = [    0.5972]
24-11-25 18:05:16 | I |         best error  = [    0.5972]
24-11-25 18:05:16 | I |     + error = [0.5972]
24-11-25 18:05:16 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 18:05:17 | I |       - range scale = [    1.0000]
24-11-25 18:05:17 | I |         sum  error  = [    1.1121]
24-11-25 18:05:17 | I |         best error  = [    1.1121]
24-11-25 18:05:17 | I |     + error = [1.1121]
24-11-25 18:05:18 | I |       - range scale = [    1.0000]
24-11-25 18:05:18 | I |         sum  error  = [   12.3413]
24-11-25 18:05:18 | I |         best error  = [   12.3413]
24-11-25 18:05:18 | I |     + error = [12.3413]
24-11-25 18:05:18 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 18:05:19 | I |       - range scale = [    1.0000]
24-11-25 18:05:19 | I |         sum  error  = [    1.2896]
24-11-25 18:05:19 | I |         best error  = [    1.2896]
24-11-25 18:05:19 | I |     + error = [1.2896]
24-11-25 18:05:20 | I |       - range scale = [    1.0000]
24-11-25 18:05:20 | I |         sum  error  = [   12.7652]
24-11-25 18:05:20 | I |         best error  = [   12.7652]
24-11-25 18:05:20 | I |     + error = [12.7652]
24-11-25 18:05:20 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 18:05:20 | I |       - range scale = [    1.0000]
24-11-25 18:05:20 | I |         sum  error  = [    2.3907]
24-11-25 18:05:20 | I |         best error  = [    2.3907]
24-11-25 18:05:20 | I |     + error = [2.3907]
24-11-25 18:05:21 | I |       - range scale = [    1.0000]
24-11-25 18:05:21 | I |         sum  error  = [   13.1989]
24-11-25 18:05:21 | I |         best error  = [   13.1989]
24-11-25 18:05:21 | I |     + error = [13.1989]
24-11-25 18:05:21 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 18:05:23 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 18:05:24 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 18:05:26 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 18:05:27 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 18:05:28 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 18:05:30 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 18:05:33 | I | quantizing activations for layer model.layers.0
24-11-25 18:05:33 | I | collecting info in model.layers.0
24-11-25 18:05:33 | I | collecting info in model.layers.0
24-11-25 18:05:33 | I | collecting info in model.layers.0
24-11-25 18:05:33 | I | collecting info in model.layers.0
24-11-25 18:05:34 | I | collecting calibration activations in model.layers.0
24-11-25 18:05:34 | I | collecting calibration activations in model.layers.0
24-11-25 18:05:34 | I | collecting calibration activations in model.layers.0
24-11-25 18:05:34 | I | collecting calibration activations in model.layers.0
24-11-25 18:05:36 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 18:05:36 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 18:05:36 | I | - Evaluator: gptq
24-11-25 18:05:36 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 18:05:36 | I | - Batch_size: 8
24-11-25 18:05:36 | I |   + Max_seq_length: 2048
24-11-25 18:06:17 | I |     - Results:
24-11-25 18:06:17 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 18:06:17 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 18:06:17 | I |       |wikitext |      1|word_perplexity|7.8399|  |7.8399|
24-11-25 18:06:17 | I |       |val_valid|      1|word_perplexity|9.0620|  |9.0620|
24-11-25 18:06:17 | I |       
24-11-25 18:06:17 | I | forward this layer
24-11-25 18:06:17 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/102.pt
24-11-25 18:06:17 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/102.pt
24-11-25 18:06:18 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 18:06:18 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 18:06:18 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 18:06:18 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 18:06:18 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 18:06:18 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 18:06:18 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 18:06:18 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 18:06:18 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 18:06:18 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 18:06:18 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 18:06:18 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 18:06:18 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 18:06:18 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 18:06:18 | I | in layer model.layers.0
24-11-25 18:06:18 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 18:06:18 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 18:06:18 | I | - Evaluator: gptq
24-11-25 18:06:18 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 18:06:18 | I | - Batch_size: 8
24-11-25 18:06:18 | I |   + Max_seq_length: 2048
24-11-25 18:06:56 | I |     - Results:
24-11-25 18:06:56 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 18:06:56 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 18:06:56 | I |       |wikitext |      1|word_perplexity|7.8660|  |7.8660|
24-11-25 18:06:56 | I |       |val_valid|      1|word_perplexity|9.0468|  |9.0468|
24-11-25 18:06:56 | I |       
24-11-25 18:06:56 | I | quantizing weights for layer model.layers.0
24-11-25 18:06:56 | I | collecting info in model.layers.0
24-11-25 18:06:56 | I | collecting info in model.layers.0
24-11-25 18:06:56 | I | collecting info in model.layers.0
24-11-25 18:06:56 | I | collecting info in model.layers.0
24-11-25 18:06:56 | I | collecting calibration activations in model.layers.0
24-11-25 18:06:57 | I | collecting calibration activations in model.layers.0
24-11-25 18:06:57 | I | collecting calibration activations in model.layers.0
24-11-25 18:06:57 | I | collecting calibration activations in model.layers.0
24-11-25 18:06:57 | I | - Quantizing decoder layer model.layers.0
24-11-25 18:06:57 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 18:06:58 | I |       - range scale = [    1.0000]
24-11-25 18:06:58 | I |         sum  error  = [    0.0671]
24-11-25 18:06:58 | I |         best error  = [    0.0671]
24-11-25 18:06:58 | I |     + error = [0.0671]
24-11-25 18:06:58 | I |       - range scale = [    1.0000]
24-11-25 18:06:58 | I |         sum  error  = [    0.6243]
24-11-25 18:06:58 | I |         best error  = [    0.6243]
24-11-25 18:06:58 | I |     + error = [0.6243]
24-11-25 18:06:59 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 18:06:59 | I |       - range scale = [    1.0000]
24-11-25 18:06:59 | I |         sum  error  = [    0.0775]
24-11-25 18:06:59 | I |         best error  = [    0.0775]
24-11-25 18:06:59 | I |     + error = [0.0775]
24-11-25 18:07:00 | I |       - range scale = [    1.0000]
24-11-25 18:07:00 | I |         sum  error  = [    0.6061]
24-11-25 18:07:00 | I |         best error  = [    0.6061]
24-11-25 18:07:00 | I |     + error = [0.6061]
24-11-25 18:07:00 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 18:07:01 | I |       - range scale = [    1.0000]
24-11-25 18:07:01 | I |         sum  error  = [    0.2476]
24-11-25 18:07:01 | I |         best error  = [    0.2476]
24-11-25 18:07:01 | I |     + error = [0.2476]
24-11-25 18:07:02 | I |       - range scale = [    1.0000]
24-11-25 18:07:02 | I |         sum  error  = [    1.8598]
24-11-25 18:07:02 | I |         best error  = [    1.8598]
24-11-25 18:07:02 | I |     + error = [1.8598]
24-11-25 18:07:02 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 18:07:02 | I |       - range scale = [    1.0000]
24-11-25 18:07:02 | I |         sum  error  = [    0.0633]
24-11-25 18:07:02 | I |         best error  = [    0.0633]
24-11-25 18:07:02 | I |     + error = [0.0633]
24-11-25 18:07:03 | I |       - range scale = [    1.0000]
24-11-25 18:07:03 | I |         sum  error  = [    0.6099]
24-11-25 18:07:03 | I |         best error  = [    0.6099]
24-11-25 18:07:03 | I |     + error = [0.6099]
24-11-25 18:07:03 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 18:07:04 | I |       - range scale = [    1.0000]
24-11-25 18:07:04 | I |         sum  error  = [    1.1032]
24-11-25 18:07:04 | I |         best error  = [    1.1032]
24-11-25 18:07:04 | I |     + error = [1.1032]
24-11-25 18:07:05 | I |       - range scale = [    1.0000]
24-11-25 18:07:05 | I |         sum  error  = [   12.2237]
24-11-25 18:07:05 | I |         best error  = [   12.2237]
24-11-25 18:07:05 | I |     + error = [12.2237]
24-11-25 18:07:05 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 18:07:06 | I |       - range scale = [    1.0000]
24-11-25 18:07:06 | I |         sum  error  = [    1.2760]
24-11-25 18:07:06 | I |         best error  = [    1.2760]
24-11-25 18:07:06 | I |     + error = [1.2760]
24-11-25 18:07:06 | I |       - range scale = [    1.0000]
24-11-25 18:07:06 | I |         sum  error  = [   12.6285]
24-11-25 18:07:06 | I |         best error  = [   12.6285]
24-11-25 18:07:06 | I |     + error = [12.6285]
24-11-25 18:07:07 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 18:07:07 | I |       - range scale = [    1.0000]
24-11-25 18:07:07 | I |         sum  error  = [    2.7263]
24-11-25 18:07:07 | I |         best error  = [    2.7263]
24-11-25 18:07:07 | I |     + error = [2.7263]
24-11-25 18:07:08 | I |       - range scale = [    1.0000]
24-11-25 18:07:08 | I |         sum  error  = [   15.1348]
24-11-25 18:07:08 | I |         best error  = [   15.1348]
24-11-25 18:07:08 | I |     + error = [15.1348]
24-11-25 18:07:08 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 18:07:10 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 18:07:11 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 18:07:13 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 18:07:14 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 18:07:15 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 18:07:17 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 18:07:20 | I | quantizing activations for layer model.layers.0
24-11-25 18:07:20 | I | collecting info in model.layers.0
24-11-25 18:07:20 | I | collecting info in model.layers.0
24-11-25 18:07:20 | I | collecting info in model.layers.0
24-11-25 18:07:20 | I | collecting info in model.layers.0
24-11-25 18:07:20 | I | collecting calibration activations in model.layers.0
24-11-25 18:07:21 | I | collecting calibration activations in model.layers.0
24-11-25 18:07:21 | I | collecting calibration activations in model.layers.0
24-11-25 18:07:21 | I | collecting calibration activations in model.layers.0
24-11-25 18:07:23 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 18:07:23 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 18:07:23 | I | - Evaluator: gptq
24-11-25 18:07:23 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 18:07:23 | I | - Batch_size: 8
24-11-25 18:07:23 | I |   + Max_seq_length: 2048
24-11-25 18:08:04 | I |     - Results:
24-11-25 18:08:04 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 18:08:04 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 18:08:04 | I |       |wikitext |      1|word_perplexity|7.8669|  |7.8669|
24-11-25 18:08:04 | I |       |val_valid|      1|word_perplexity|9.0800|  |9.0800|
24-11-25 18:08:04 | I |       
24-11-25 18:08:04 | I | forward this layer
24-11-25 18:08:04 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/103.pt
24-11-25 18:08:04 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/103.pt
24-11-25 18:08:04 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 18:08:04 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 18:08:04 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 18:08:04 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 18:08:04 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 18:08:04 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 18:08:04 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 18:08:04 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 18:08:04 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 18:08:04 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 18:08:04 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 18:08:04 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 18:08:04 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 18:08:04 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 18:08:04 | I | [37] done with optimizer step
24-11-25 18:08:04 | I | epoch 001:     52 / 409600000 loss=0.000125978, loss_per_token=0.258004, loss_sum=8454.26, wps=153.1, ups=0, wpb=32768, bsz=64, num_updates=38, lr=0.000114, gnorm=40.241, clip=100, loss_scale=0.0078, train_wall=214, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=11415, lmquant_ppl_result_wikitext_in_train_no_quant=7.866, lmquant_ppl_result_val_in_train_no_quant=9.04677, lmquant_ppl_result_wikitext_in_train_with_quant=7.86686, lmquant_ppl_result_val_in_train_with_quant=9.07995
24-11-25 18:08:05 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 18:08:05 | I | in layer model.layers.0
24-11-25 18:08:05 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 18:08:05 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 18:08:05 | I | - Evaluator: gptq
24-11-25 18:08:05 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 18:08:05 | I | - Batch_size: 8
24-11-25 18:08:05 | I |   + Max_seq_length: 2048
24-11-25 18:08:43 | I |     - Results:
24-11-25 18:08:43 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 18:08:43 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 18:08:43 | I |       |wikitext |      1|word_perplexity|7.8523|  |7.8523|
24-11-25 18:08:43 | I |       |val_valid|      1|word_perplexity|9.0398|  |9.0398|
24-11-25 18:08:43 | I |       
24-11-25 18:08:43 | I | quantizing weights for layer model.layers.0
24-11-25 18:08:43 | I | collecting info in model.layers.0
24-11-25 18:08:43 | I | collecting info in model.layers.0
24-11-25 18:08:43 | I | collecting info in model.layers.0
24-11-25 18:08:43 | I | collecting info in model.layers.0
24-11-25 18:08:43 | I | collecting calibration activations in model.layers.0
24-11-25 18:08:43 | I | collecting calibration activations in model.layers.0
24-11-25 18:08:43 | I | collecting calibration activations in model.layers.0
24-11-25 18:08:44 | I | collecting calibration activations in model.layers.0
24-11-25 18:08:44 | I | - Quantizing decoder layer model.layers.0
24-11-25 18:08:44 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 18:08:45 | I |       - range scale = [    1.0000]
24-11-25 18:08:45 | I |         sum  error  = [    0.0660]
24-11-25 18:08:45 | I |         best error  = [    0.0660]
24-11-25 18:08:45 | I |     + error = [0.0660]
24-11-25 18:08:45 | I |       - range scale = [    1.0000]
24-11-25 18:08:45 | I |         sum  error  = [    0.6213]
24-11-25 18:08:45 | I |         best error  = [    0.6213]
24-11-25 18:08:45 | I |     + error = [0.6213]
24-11-25 18:08:45 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 18:08:46 | I |       - range scale = [    1.0000]
24-11-25 18:08:46 | I |         sum  error  = [    0.0767]
24-11-25 18:08:46 | I |         best error  = [    0.0767]
24-11-25 18:08:46 | I |     + error = [0.0767]
24-11-25 18:08:47 | I |       - range scale = [    1.0000]
24-11-25 18:08:47 | I |         sum  error  = [    0.5865]
24-11-25 18:08:47 | I |         best error  = [    0.5865]
24-11-25 18:08:47 | I |     + error = [0.5865]
24-11-25 18:08:47 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 18:08:48 | I |       - range scale = [    1.0000]
24-11-25 18:08:48 | I |         sum  error  = [    0.2499]
24-11-25 18:08:48 | I |         best error  = [    0.2499]
24-11-25 18:08:48 | I |     + error = [0.2499]
24-11-25 18:08:48 | I |       - range scale = [    1.0000]
24-11-25 18:08:48 | I |         sum  error  = [    1.8591]
24-11-25 18:08:48 | I |         best error  = [    1.8591]
24-11-25 18:08:48 | I |     + error = [1.8591]
24-11-25 18:08:49 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 18:08:49 | I |       - range scale = [    1.0000]
24-11-25 18:08:49 | I |         sum  error  = [    0.0625]
24-11-25 18:08:49 | I |         best error  = [    0.0625]
24-11-25 18:08:49 | I |     + error = [0.0625]
24-11-25 18:08:50 | I |       - range scale = [    1.0000]
24-11-25 18:08:50 | I |         sum  error  = [    0.6042]
24-11-25 18:08:50 | I |         best error  = [    0.6042]
24-11-25 18:08:50 | I |     + error = [0.6042]
24-11-25 18:08:50 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 18:08:51 | I |       - range scale = [    1.0000]
24-11-25 18:08:51 | I |         sum  error  = [    1.0966]
24-11-25 18:08:51 | I |         best error  = [    1.0966]
24-11-25 18:08:51 | I |     + error = [1.0966]
24-11-25 18:08:52 | I |       - range scale = [    1.0000]
24-11-25 18:08:52 | I |         sum  error  = [   12.1823]
24-11-25 18:08:52 | I |         best error  = [   12.1823]
24-11-25 18:08:52 | I |     + error = [12.1823]
24-11-25 18:08:52 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 18:08:53 | I |       - range scale = [    1.0000]
24-11-25 18:08:53 | I |         sum  error  = [    1.2725]
24-11-25 18:08:53 | I |         best error  = [    1.2725]
24-11-25 18:08:53 | I |     + error = [1.2725]
24-11-25 18:08:53 | I |       - range scale = [    1.0000]
24-11-25 18:08:53 | I |         sum  error  = [   12.6000]
24-11-25 18:08:53 | I |         best error  = [   12.6000]
24-11-25 18:08:53 | I |     + error = [12.6000]
24-11-25 18:08:54 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 18:08:54 | I |       - range scale = [    1.0000]
24-11-25 18:08:54 | I |         sum  error  = [    2.8265]
24-11-25 18:08:54 | I |         best error  = [    2.8265]
24-11-25 18:08:54 | I |     + error = [2.8265]
24-11-25 18:08:55 | I |       - range scale = [    1.0000]
24-11-25 18:08:55 | I |         sum  error  = [   15.5788]
24-11-25 18:08:55 | I |         best error  = [   15.5788]
24-11-25 18:08:55 | I |     + error = [15.5788]
24-11-25 18:08:55 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 18:08:57 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 18:08:58 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 18:09:00 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 18:09:01 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 18:09:02 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 18:09:04 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 18:09:07 | I | quantizing activations for layer model.layers.0
24-11-25 18:09:07 | I | collecting info in model.layers.0
24-11-25 18:09:07 | I | collecting info in model.layers.0
24-11-25 18:09:07 | I | collecting info in model.layers.0
24-11-25 18:09:07 | I | collecting info in model.layers.0
24-11-25 18:09:07 | I | collecting calibration activations in model.layers.0
24-11-25 18:09:08 | I | collecting calibration activations in model.layers.0
24-11-25 18:09:08 | I | collecting calibration activations in model.layers.0
24-11-25 18:09:08 | I | collecting calibration activations in model.layers.0
24-11-25 18:09:10 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 18:09:10 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 18:09:10 | I | - Evaluator: gptq
24-11-25 18:09:10 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 18:09:10 | I | - Batch_size: 8
24-11-25 18:09:10 | I |   + Max_seq_length: 2048
24-11-25 18:09:51 | I |     - Results:
24-11-25 18:09:51 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 18:09:51 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 18:09:51 | I |       |wikitext |      1|word_perplexity|7.8674|  |7.8674|
24-11-25 18:09:51 | I |       |val_valid|      1|word_perplexity|9.0864|  |9.0864|
24-11-25 18:09:51 | I |       
24-11-25 18:09:51 | I | forward this layer
24-11-25 18:09:51 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/104.pt
24-11-25 18:09:51 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/104.pt
24-11-25 18:09:51 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 18:09:51 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 18:09:51 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 18:09:51 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 18:09:51 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 18:09:51 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 18:09:51 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 18:09:51 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 18:09:51 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 18:09:51 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 18:09:51 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 18:09:51 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 18:09:51 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 18:09:51 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 18:09:51 | I | in layer model.layers.0
24-11-25 18:09:51 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 18:09:51 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 18:09:51 | I | - Evaluator: gptq
24-11-25 18:09:51 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 18:09:51 | I | - Batch_size: 8
24-11-25 18:09:51 | I |   + Max_seq_length: 2048
24-11-25 18:10:29 | I |     - Results:
24-11-25 18:10:30 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 18:10:30 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 18:10:30 | I |       |wikitext |      1|word_perplexity|7.8523|  |7.8523|
24-11-25 18:10:30 | I |       |val_valid|      1|word_perplexity|9.0398|  |9.0398|
24-11-25 18:10:30 | I |       
24-11-25 18:10:30 | I | quantizing weights for layer model.layers.0
24-11-25 18:10:30 | I | collecting info in model.layers.0
24-11-25 18:10:30 | I | collecting info in model.layers.0
24-11-25 18:10:30 | I | collecting info in model.layers.0
24-11-25 18:10:30 | I | collecting info in model.layers.0
24-11-25 18:10:30 | I | collecting calibration activations in model.layers.0
24-11-25 18:10:30 | I | collecting calibration activations in model.layers.0
24-11-25 18:10:30 | I | collecting calibration activations in model.layers.0
24-11-25 18:10:30 | I | collecting calibration activations in model.layers.0
24-11-25 18:10:31 | I | - Quantizing decoder layer model.layers.0
24-11-25 18:10:31 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 18:10:31 | I |       - range scale = [    1.0000]
24-11-25 18:10:31 | I |         sum  error  = [    0.0663]
24-11-25 18:10:31 | I |         best error  = [    0.0663]
24-11-25 18:10:31 | I |     + error = [0.0663]
24-11-25 18:10:32 | I |       - range scale = [    1.0000]
24-11-25 18:10:32 | I |         sum  error  = [    0.6193]
24-11-25 18:10:32 | I |         best error  = [    0.6193]
24-11-25 18:10:32 | I |     + error = [0.6193]
24-11-25 18:10:32 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 18:10:33 | I |       - range scale = [    1.0000]
24-11-25 18:10:33 | I |         sum  error  = [    0.0751]
24-11-25 18:10:33 | I |         best error  = [    0.0751]
24-11-25 18:10:33 | I |     + error = [0.0751]
24-11-25 18:10:34 | I |       - range scale = [    1.0000]
24-11-25 18:10:34 | I |         sum  error  = [    0.5887]
24-11-25 18:10:34 | I |         best error  = [    0.5887]
24-11-25 18:10:34 | I |     + error = [0.5887]
24-11-25 18:10:34 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 18:10:35 | I |       - range scale = [    1.0000]
24-11-25 18:10:35 | I |         sum  error  = [    0.2457]
24-11-25 18:10:35 | I |         best error  = [    0.2457]
24-11-25 18:10:35 | I |     + error = [0.2457]
24-11-25 18:10:35 | I |       - range scale = [    1.0000]
24-11-25 18:10:35 | I |         sum  error  = [    1.8432]
24-11-25 18:10:35 | I |         best error  = [    1.8432]
24-11-25 18:10:35 | I |     + error = [1.8432]
24-11-25 18:10:36 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 18:10:36 | I |       - range scale = [    1.0000]
24-11-25 18:10:36 | I |         sum  error  = [    0.0599]
24-11-25 18:10:36 | I |         best error  = [    0.0599]
24-11-25 18:10:36 | I |     + error = [0.0599]
24-11-25 18:10:37 | I |       - range scale = [    1.0000]
24-11-25 18:10:37 | I |         sum  error  = [    0.5787]
24-11-25 18:10:37 | I |         best error  = [    0.5787]
24-11-25 18:10:37 | I |     + error = [0.5787]
24-11-25 18:10:37 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 18:10:38 | I |       - range scale = [    1.0000]
24-11-25 18:10:38 | I |         sum  error  = [    1.1010]
24-11-25 18:10:38 | I |         best error  = [    1.1010]
24-11-25 18:10:38 | I |     + error = [1.1010]
24-11-25 18:10:39 | I |       - range scale = [    1.0000]
24-11-25 18:10:39 | I |         sum  error  = [   12.2330]
24-11-25 18:10:39 | I |         best error  = [   12.2330]
24-11-25 18:10:39 | I |     + error = [12.2330]
24-11-25 18:10:39 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 18:10:39 | I |       - range scale = [    1.0000]
24-11-25 18:10:39 | I |         sum  error  = [    1.2778]
24-11-25 18:10:39 | I |         best error  = [    1.2778]
24-11-25 18:10:39 | I |     + error = [1.2778]
24-11-25 18:10:40 | I |       - range scale = [    1.0000]
24-11-25 18:10:40 | I |         sum  error  = [   12.6396]
24-11-25 18:10:40 | I |         best error  = [   12.6396]
24-11-25 18:10:40 | I |     + error = [12.6396]
24-11-25 18:10:40 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 18:10:41 | I |       - range scale = [    1.0000]
24-11-25 18:10:41 | I |         sum  error  = [    2.3183]
24-11-25 18:10:41 | I |         best error  = [    2.3183]
24-11-25 18:10:41 | I |     + error = [2.3183]
24-11-25 18:10:42 | I |       - range scale = [    1.0000]
24-11-25 18:10:42 | I |         sum  error  = [   12.8364]
24-11-25 18:10:42 | I |         best error  = [   12.8364]
24-11-25 18:10:42 | I |     + error = [12.8364]
24-11-25 18:10:42 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 18:10:43 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 18:10:45 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 18:10:46 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 18:10:48 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 18:10:49 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 18:10:50 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 18:10:54 | I | quantizing activations for layer model.layers.0
24-11-25 18:10:54 | I | collecting info in model.layers.0
24-11-25 18:10:54 | I | collecting info in model.layers.0
24-11-25 18:10:54 | I | collecting info in model.layers.0
24-11-25 18:10:54 | I | collecting info in model.layers.0
24-11-25 18:10:54 | I | collecting calibration activations in model.layers.0
24-11-25 18:10:54 | I | collecting calibration activations in model.layers.0
24-11-25 18:10:54 | I | collecting calibration activations in model.layers.0
24-11-25 18:10:54 | I | collecting calibration activations in model.layers.0
24-11-25 18:10:56 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 18:10:56 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 18:10:56 | I | - Evaluator: gptq
24-11-25 18:10:56 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 18:10:56 | I | - Batch_size: 8
24-11-25 18:10:56 | I |   + Max_seq_length: 2048
24-11-25 18:11:38 | I |     - Results:
24-11-25 18:11:38 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 18:11:38 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 18:11:38 | I |       |wikitext |      1|word_perplexity|7.8512|  |7.8512|
24-11-25 18:11:38 | I |       |val_valid|      1|word_perplexity|9.0747|  |9.0747|
24-11-25 18:11:38 | I |       
24-11-25 18:11:38 | I | forward this layer
24-11-25 18:11:38 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/105.pt
24-11-25 18:11:38 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/105.pt
24-11-25 18:11:38 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 18:11:38 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 18:11:38 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 18:11:38 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 18:11:38 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 18:11:38 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 18:11:38 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 18:11:38 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 18:11:38 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 18:11:38 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 18:11:38 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 18:11:38 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 18:11:38 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 18:11:38 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 18:11:38 | I | [38] done with optimizer step
24-11-25 18:11:38 | I | epoch 001:     53 / 409600000 loss=0.000120625, loss_per_token=0.247041, loss_sum=8095.03, wps=153.3, ups=0, wpb=32768, bsz=64, num_updates=39, lr=0.000117, gnorm=30.616, clip=100, loss_scale=0.0078, train_wall=214, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=11628, lmquant_ppl_result_wikitext_in_train_no_quant=7.85229, lmquant_ppl_result_val_in_train_no_quant=9.0398, lmquant_ppl_result_wikitext_in_train_with_quant=7.85124, lmquant_ppl_result_val_in_train_with_quant=9.07472
24-11-25 18:11:38 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 18:11:38 | I | in layer model.layers.0
24-11-25 18:11:38 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 18:11:38 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 18:11:38 | I | - Evaluator: gptq
24-11-25 18:11:38 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 18:11:38 | I | - Batch_size: 8
24-11-25 18:11:38 | I |   + Max_seq_length: 2048
24-11-25 18:12:16 | I |     - Results:
24-11-25 18:12:16 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 18:12:16 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 18:12:16 | I |       |wikitext |      1|word_perplexity|7.8374|  |7.8374|
24-11-25 18:12:16 | I |       |val_valid|      1|word_perplexity|9.0327|  |9.0327|
24-11-25 18:12:16 | I |       
24-11-25 18:12:16 | I | quantizing weights for layer model.layers.0
24-11-25 18:12:16 | I | collecting info in model.layers.0
24-11-25 18:12:16 | I | collecting info in model.layers.0
24-11-25 18:12:16 | I | collecting info in model.layers.0
24-11-25 18:12:16 | I | collecting info in model.layers.0
24-11-25 18:12:17 | I | collecting calibration activations in model.layers.0
24-11-25 18:12:17 | I | collecting calibration activations in model.layers.0
24-11-25 18:12:17 | I | collecting calibration activations in model.layers.0
24-11-25 18:12:17 | I | collecting calibration activations in model.layers.0
24-11-25 18:12:18 | I | - Quantizing decoder layer model.layers.0
24-11-25 18:12:18 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 18:12:18 | I |       - range scale = [    1.0000]
24-11-25 18:12:18 | I |         sum  error  = [    0.0639]
24-11-25 18:12:18 | I |         best error  = [    0.0639]
24-11-25 18:12:18 | I |     + error = [0.0639]
24-11-25 18:12:19 | I |       - range scale = [    1.0000]
24-11-25 18:12:19 | I |         sum  error  = [    0.6335]
24-11-25 18:12:19 | I |         best error  = [    0.6335]
24-11-25 18:12:19 | I |     + error = [0.6335]
24-11-25 18:12:19 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 18:12:20 | I |       - range scale = [    1.0000]
24-11-25 18:12:20 | I |         sum  error  = [    0.0783]
24-11-25 18:12:20 | I |         best error  = [    0.0783]
24-11-25 18:12:20 | I |     + error = [0.0783]
24-11-25 18:12:21 | I |       - range scale = [    1.0000]
24-11-25 18:12:21 | I |         sum  error  = [    0.6005]
24-11-25 18:12:21 | I |         best error  = [    0.6005]
24-11-25 18:12:21 | I |     + error = [0.6005]
24-11-25 18:12:21 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 18:12:22 | I |       - range scale = [    1.0000]
24-11-25 18:12:22 | I |         sum  error  = [    0.2398]
24-11-25 18:12:22 | I |         best error  = [    0.2398]
24-11-25 18:12:22 | I |     + error = [0.2398]
24-11-25 18:12:22 | I |       - range scale = [    1.0000]
24-11-25 18:12:22 | I |         sum  error  = [    1.8490]
24-11-25 18:12:22 | I |         best error  = [    1.8490]
24-11-25 18:12:22 | I |     + error = [1.8490]
24-11-25 18:12:22 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 18:12:23 | I |       - range scale = [    1.0000]
24-11-25 18:12:23 | I |         sum  error  = [    0.0609]
24-11-25 18:12:23 | I |         best error  = [    0.0609]
24-11-25 18:12:23 | I |     + error = [0.0609]
24-11-25 18:12:24 | I |       - range scale = [    1.0000]
24-11-25 18:12:24 | I |         sum  error  = [    0.5955]
24-11-25 18:12:24 | I |         best error  = [    0.5955]
24-11-25 18:12:24 | I |     + error = [0.5955]
24-11-25 18:12:24 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 18:12:25 | I |       - range scale = [    1.0000]
24-11-25 18:12:25 | I |         sum  error  = [    1.1000]
24-11-25 18:12:25 | I |         best error  = [    1.1000]
24-11-25 18:12:25 | I |     + error = [1.1000]
24-11-25 18:12:25 | I |       - range scale = [    1.0000]
24-11-25 18:12:25 | I |         sum  error  = [   12.2276]
24-11-25 18:12:25 | I |         best error  = [   12.2276]
24-11-25 18:12:25 | I |     + error = [12.2276]
24-11-25 18:12:26 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 18:12:26 | I |       - range scale = [    1.0000]
24-11-25 18:12:26 | I |         sum  error  = [    1.2757]
24-11-25 18:12:26 | I |         best error  = [    1.2757]
24-11-25 18:12:26 | I |     + error = [1.2757]
24-11-25 18:12:27 | I |       - range scale = [    1.0000]
24-11-25 18:12:27 | I |         sum  error  = [   12.6396]
24-11-25 18:12:27 | I |         best error  = [   12.6396]
24-11-25 18:12:27 | I |     + error = [12.6396]
24-11-25 18:12:27 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 18:12:28 | I |       - range scale = [    1.0000]
24-11-25 18:12:28 | I |         sum  error  = [    2.2895]
24-11-25 18:12:28 | I |         best error  = [    2.2895]
24-11-25 18:12:28 | I |     + error = [2.2895]
24-11-25 18:12:29 | I |       - range scale = [    1.0000]
24-11-25 18:12:29 | I |         sum  error  = [   12.4980]
24-11-25 18:12:29 | I |         best error  = [   12.4980]
24-11-25 18:12:29 | I |     + error = [12.4980]
24-11-25 18:12:29 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 18:12:30 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 18:12:32 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 18:12:33 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 18:12:35 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 18:12:36 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 18:12:37 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 18:12:41 | I | quantizing activations for layer model.layers.0
24-11-25 18:12:41 | I | collecting info in model.layers.0
24-11-25 18:12:41 | I | collecting info in model.layers.0
24-11-25 18:12:41 | I | collecting info in model.layers.0
24-11-25 18:12:41 | I | collecting info in model.layers.0
24-11-25 18:12:41 | I | collecting calibration activations in model.layers.0
24-11-25 18:12:41 | I | collecting calibration activations in model.layers.0
24-11-25 18:12:41 | I | collecting calibration activations in model.layers.0
24-11-25 18:12:41 | I | collecting calibration activations in model.layers.0
24-11-25 18:12:43 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 18:12:43 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 18:12:43 | I | - Evaluator: gptq
24-11-25 18:12:43 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 18:12:43 | I | - Batch_size: 8
24-11-25 18:12:43 | I |   + Max_seq_length: 2048
24-11-25 18:13:25 | I |     - Results:
24-11-25 18:13:25 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 18:13:25 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 18:13:25 | I |       |wikitext |      1|word_perplexity|7.8414|  |7.8414|
24-11-25 18:13:25 | I |       |val_valid|      1|word_perplexity|9.0713|  |9.0713|
24-11-25 18:13:25 | I |       
24-11-25 18:13:25 | I | forward this layer
24-11-25 18:13:25 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/106.pt
24-11-25 18:13:25 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/106.pt
24-11-25 18:13:25 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 18:13:25 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 18:13:25 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 18:13:25 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 18:13:25 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 18:13:25 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 18:13:25 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 18:13:25 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 18:13:25 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 18:13:25 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 18:13:25 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 18:13:25 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 18:13:25 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 18:13:25 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 18:13:25 | I | in layer model.layers.0
24-11-25 18:13:25 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 18:13:25 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 18:13:25 | I | - Evaluator: gptq
24-11-25 18:13:25 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 18:13:25 | I | - Batch_size: 8
24-11-25 18:13:25 | I |   + Max_seq_length: 2048
24-11-25 18:14:03 | I |     - Results:
24-11-25 18:14:03 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 18:14:03 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 18:14:03 | I |       |wikitext |      1|word_perplexity|7.8374|  |7.8374|
24-11-25 18:14:03 | I |       |val_valid|      1|word_perplexity|9.0327|  |9.0327|
24-11-25 18:14:03 | I |       
24-11-25 18:14:03 | I | quantizing weights for layer model.layers.0
24-11-25 18:14:03 | I | collecting info in model.layers.0
24-11-25 18:14:03 | I | collecting info in model.layers.0
24-11-25 18:14:03 | I | collecting info in model.layers.0
24-11-25 18:14:03 | I | collecting info in model.layers.0
24-11-25 18:14:04 | I | collecting calibration activations in model.layers.0
24-11-25 18:14:04 | I | collecting calibration activations in model.layers.0
24-11-25 18:14:04 | I | collecting calibration activations in model.layers.0
24-11-25 18:14:04 | I | collecting calibration activations in model.layers.0
24-11-25 18:14:04 | I | - Quantizing decoder layer model.layers.0
24-11-25 18:14:04 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 18:14:05 | I |       - range scale = [    1.0000]
24-11-25 18:14:05 | I |         sum  error  = [    0.0625]
24-11-25 18:14:05 | I |         best error  = [    0.0625]
24-11-25 18:14:05 | I |     + error = [0.0625]
24-11-25 18:14:06 | I |       - range scale = [    1.0000]
24-11-25 18:14:06 | I |         sum  error  = [    0.6265]
24-11-25 18:14:06 | I |         best error  = [    0.6265]
24-11-25 18:14:06 | I |     + error = [0.6265]
24-11-25 18:14:06 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 18:14:07 | I |       - range scale = [    1.0000]
24-11-25 18:14:07 | I |         sum  error  = [    0.0759]
24-11-25 18:14:07 | I |         best error  = [    0.0759]
24-11-25 18:14:07 | I |     + error = [0.0759]
24-11-25 18:14:07 | I |       - range scale = [    1.0000]
24-11-25 18:14:07 | I |         sum  error  = [    0.5891]
24-11-25 18:14:07 | I |         best error  = [    0.5891]
24-11-25 18:14:07 | I |     + error = [0.5891]
24-11-25 18:14:08 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 18:14:08 | I |       - range scale = [    1.0000]
24-11-25 18:14:08 | I |         sum  error  = [    0.2435]
24-11-25 18:14:08 | I |         best error  = [    0.2435]
24-11-25 18:14:08 | I |     + error = [0.2435]
24-11-25 18:14:09 | I |       - range scale = [    1.0000]
24-11-25 18:14:09 | I |         sum  error  = [    1.8427]
24-11-25 18:14:09 | I |         best error  = [    1.8427]
24-11-25 18:14:09 | I |     + error = [1.8427]
24-11-25 18:14:09 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 18:14:10 | I |       - range scale = [    1.0000]
24-11-25 18:14:10 | I |         sum  error  = [    0.0609]
24-11-25 18:14:10 | I |         best error  = [    0.0609]
24-11-25 18:14:10 | I |     + error = [0.0609]
24-11-25 18:14:10 | I |       - range scale = [    1.0000]
24-11-25 18:14:10 | I |         sum  error  = [    0.5898]
24-11-25 18:14:10 | I |         best error  = [    0.5898]
24-11-25 18:14:10 | I |     + error = [0.5898]
24-11-25 18:14:11 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 18:14:11 | I |       - range scale = [    1.0000]
24-11-25 18:14:11 | I |         sum  error  = [    1.0810]
24-11-25 18:14:11 | I |         best error  = [    1.0810]
24-11-25 18:14:11 | I |     + error = [1.0810]
24-11-25 18:14:12 | I |       - range scale = [    1.0000]
24-11-25 18:14:12 | I |         sum  error  = [   11.9934]
24-11-25 18:14:12 | I |         best error  = [   11.9934]
24-11-25 18:14:12 | I |     + error = [11.9934]
24-11-25 18:14:12 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 18:14:13 | I |       - range scale = [    1.0000]
24-11-25 18:14:13 | I |         sum  error  = [    1.2511]
24-11-25 18:14:13 | I |         best error  = [    1.2511]
24-11-25 18:14:13 | I |     + error = [1.2511]
24-11-25 18:14:14 | I |       - range scale = [    1.0000]
24-11-25 18:14:14 | I |         sum  error  = [   12.4018]
24-11-25 18:14:14 | I |         best error  = [   12.4018]
24-11-25 18:14:14 | I |     + error = [12.4018]
24-11-25 18:14:14 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 18:14:15 | I |       - range scale = [    1.0000]
24-11-25 18:14:15 | I |         sum  error  = [    2.6815]
24-11-25 18:14:15 | I |         best error  = [    2.6815]
24-11-25 18:14:15 | I |     + error = [2.6815]
24-11-25 18:14:15 | I |       - range scale = [    1.0000]
24-11-25 18:14:15 | I |         sum  error  = [   14.8793]
24-11-25 18:14:15 | I |         best error  = [   14.8793]
24-11-25 18:14:15 | I |     + error = [14.8793]
24-11-25 18:14:16 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 18:14:17 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 18:14:18 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 18:14:20 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 18:14:21 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 18:14:23 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 18:14:24 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 18:14:27 | I | quantizing activations for layer model.layers.0
24-11-25 18:14:27 | I | collecting info in model.layers.0
24-11-25 18:14:27 | I | collecting info in model.layers.0
24-11-25 18:14:27 | I | collecting info in model.layers.0
24-11-25 18:14:27 | I | collecting info in model.layers.0
24-11-25 18:14:28 | I | collecting calibration activations in model.layers.0
24-11-25 18:14:28 | I | collecting calibration activations in model.layers.0
24-11-25 18:14:28 | I | collecting calibration activations in model.layers.0
24-11-25 18:14:28 | I | collecting calibration activations in model.layers.0
24-11-25 18:14:30 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 18:14:30 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 18:14:30 | I | - Evaluator: gptq
24-11-25 18:14:30 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 18:14:30 | I | - Batch_size: 8
24-11-25 18:14:30 | I |   + Max_seq_length: 2048
24-11-25 18:15:11 | I |     - Results:
24-11-25 18:15:11 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 18:15:11 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 18:15:11 | I |       |wikitext |      1|word_perplexity|7.8469|  |7.8469|
24-11-25 18:15:11 | I |       |val_valid|      1|word_perplexity|9.0727|  |9.0727|
24-11-25 18:15:11 | I |       
24-11-25 18:15:11 | I | forward this layer
24-11-25 18:15:11 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/107.pt
24-11-25 18:15:11 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/107.pt
24-11-25 18:15:12 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 18:15:12 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 18:15:12 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 18:15:12 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 18:15:12 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 18:15:12 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 18:15:12 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 18:15:12 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 18:15:12 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 18:15:12 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 18:15:12 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 18:15:12 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 18:15:12 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 18:15:12 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 18:15:12 | I | [39] done with optimizer step
24-11-25 18:15:12 | I | epoch 001:     54 / 409600000 loss=9.1061e-05, loss_per_token=0.186493, loss_sum=6111, wps=153.4, ups=0, wpb=32768, bsz=64, num_updates=40, lr=0.00012, gnorm=26.906, clip=100, loss_scale=0.0078, train_wall=213, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=11842, lmquant_ppl_result_wikitext_in_train_no_quant=7.83744, lmquant_ppl_result_val_in_train_no_quant=9.03275, lmquant_ppl_result_wikitext_in_train_with_quant=7.84693, lmquant_ppl_result_val_in_train_with_quant=9.07269
24-11-25 18:15:12 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 18:15:12 | I | in layer model.layers.0
24-11-25 18:15:12 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 18:15:12 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 18:15:12 | I | - Evaluator: gptq
24-11-25 18:15:12 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 18:15:12 | I | - Batch_size: 8
24-11-25 18:15:12 | I |   + Max_seq_length: 2048
24-11-25 18:15:50 | I |     - Results:
24-11-25 18:15:50 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 18:15:50 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 18:15:50 | I |       |wikitext |      1|word_perplexity|7.8224|  |7.8224|
24-11-25 18:15:50 | I |       |val_valid|      1|word_perplexity|9.0273|  |9.0273|
24-11-25 18:15:50 | I |       
24-11-25 18:15:50 | I | quantizing weights for layer model.layers.0
24-11-25 18:15:50 | I | collecting info in model.layers.0
24-11-25 18:15:50 | I | collecting info in model.layers.0
24-11-25 18:15:50 | I | collecting info in model.layers.0
24-11-25 18:15:50 | I | collecting info in model.layers.0
24-11-25 18:15:51 | I | collecting calibration activations in model.layers.0
24-11-25 18:15:51 | I | collecting calibration activations in model.layers.0
24-11-25 18:15:51 | I | collecting calibration activations in model.layers.0
24-11-25 18:15:51 | I | collecting calibration activations in model.layers.0
24-11-25 18:15:51 | I | - Quantizing decoder layer model.layers.0
24-11-25 18:15:51 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 18:15:52 | I |       - range scale = [    1.0000]
24-11-25 18:15:52 | I |         sum  error  = [    0.0587]
24-11-25 18:15:52 | I |         best error  = [    0.0587]
24-11-25 18:15:52 | I |     + error = [0.0587]
24-11-25 18:15:53 | I |       - range scale = [    1.0000]
24-11-25 18:15:53 | I |         sum  error  = [    0.6446]
24-11-25 18:15:53 | I |         best error  = [    0.6446]
24-11-25 18:15:53 | I |     + error = [0.6446]
24-11-25 18:15:53 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 18:15:54 | I |       - range scale = [    1.0000]
24-11-25 18:15:54 | I |         sum  error  = [    0.0772]
24-11-25 18:15:54 | I |         best error  = [    0.0772]
24-11-25 18:15:54 | I |     + error = [0.0772]
24-11-25 18:15:54 | I |       - range scale = [    1.0000]
24-11-25 18:15:54 | I |         sum  error  = [    0.6028]
24-11-25 18:15:54 | I |         best error  = [    0.6028]
24-11-25 18:15:54 | I |     + error = [0.6028]
24-11-25 18:15:55 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 18:15:55 | I |       - range scale = [    1.0000]
24-11-25 18:15:55 | I |         sum  error  = [    0.2433]
24-11-25 18:15:55 | I |         best error  = [    0.2433]
24-11-25 18:15:55 | I |     + error = [0.2433]
24-11-25 18:15:56 | I |       - range scale = [    1.0000]
24-11-25 18:15:56 | I |         sum  error  = [    1.8756]
24-11-25 18:15:56 | I |         best error  = [    1.8756]
24-11-25 18:15:56 | I |     + error = [1.8756]
24-11-25 18:15:56 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 18:15:57 | I |       - range scale = [    1.0000]
24-11-25 18:15:57 | I |         sum  error  = [    0.0621]
24-11-25 18:15:57 | I |         best error  = [    0.0621]
24-11-25 18:15:57 | I |     + error = [0.0621]
24-11-25 18:15:58 | I |       - range scale = [    1.0000]
24-11-25 18:15:58 | I |         sum  error  = [    0.6046]
24-11-25 18:15:58 | I |         best error  = [    0.6046]
24-11-25 18:15:58 | I |     + error = [0.6046]
24-11-25 18:15:58 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 18:15:58 | I |       - range scale = [    1.0000]
24-11-25 18:15:58 | I |         sum  error  = [    1.0956]
24-11-25 18:15:58 | I |         best error  = [    1.0956]
24-11-25 18:15:58 | I |     + error = [1.0956]
24-11-25 18:15:59 | I |       - range scale = [    1.0000]
24-11-25 18:15:59 | I |         sum  error  = [   12.1461]
24-11-25 18:15:59 | I |         best error  = [   12.1461]
24-11-25 18:15:59 | I |     + error = [12.1461]
24-11-25 18:15:59 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 18:16:00 | I |       - range scale = [    1.0000]
24-11-25 18:16:00 | I |         sum  error  = [    1.2662]
24-11-25 18:16:00 | I |         best error  = [    1.2662]
24-11-25 18:16:00 | I |     + error = [1.2662]
24-11-25 18:16:01 | I |       - range scale = [    1.0000]
24-11-25 18:16:01 | I |         sum  error  = [   12.5607]
24-11-25 18:16:01 | I |         best error  = [   12.5607]
24-11-25 18:16:01 | I |     + error = [12.5607]
24-11-25 18:16:01 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 18:16:02 | I |       - range scale = [    1.0000]
24-11-25 18:16:02 | I |         sum  error  = [    1.6501]
24-11-25 18:16:02 | I |         best error  = [    1.6501]
24-11-25 18:16:02 | I |     + error = [1.6501]
24-11-25 18:16:02 | I |       - range scale = [    1.0000]
24-11-25 18:16:02 | I |         sum  error  = [    8.9088]
24-11-25 18:16:02 | I |         best error  = [    8.9088]
24-11-25 18:16:02 | I |     + error = [8.9088]
24-11-25 18:16:03 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 18:16:04 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 18:16:05 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 18:16:07 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 18:16:08 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 18:16:10 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 18:16:11 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 18:16:14 | I | quantizing activations for layer model.layers.0
24-11-25 18:16:14 | I | collecting info in model.layers.0
24-11-25 18:16:14 | I | collecting info in model.layers.0
24-11-25 18:16:14 | I | collecting info in model.layers.0
24-11-25 18:16:14 | I | collecting info in model.layers.0
24-11-25 18:16:15 | I | collecting calibration activations in model.layers.0
24-11-25 18:16:15 | I | collecting calibration activations in model.layers.0
24-11-25 18:16:15 | I | collecting calibration activations in model.layers.0
24-11-25 18:16:15 | I | collecting calibration activations in model.layers.0
24-11-25 18:16:17 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 18:16:17 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 18:16:17 | I | - Evaluator: gptq
24-11-25 18:16:17 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 18:16:17 | I | - Batch_size: 8
24-11-25 18:16:17 | I |   + Max_seq_length: 2048
24-11-25 18:16:59 | I |     - Results:
24-11-25 18:16:59 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 18:16:59 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 18:16:59 | I |       |wikitext |      1|word_perplexity|7.8320|  |7.8320|
24-11-25 18:16:59 | I |       |val_valid|      1|word_perplexity|9.0692|  |9.0692|
24-11-25 18:16:59 | I |       
24-11-25 18:16:59 | I | forward this layer
24-11-25 18:16:59 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/108.pt
24-11-25 18:16:59 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/108.pt
24-11-25 18:16:59 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 18:16:59 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 18:16:59 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 18:16:59 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 18:16:59 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 18:16:59 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 18:16:59 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 18:16:59 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 18:16:59 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 18:16:59 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 18:16:59 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 18:16:59 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 18:16:59 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 18:16:59 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 18:16:59 | I | in layer model.layers.0
24-11-25 18:16:59 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 18:16:59 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 18:16:59 | I | - Evaluator: gptq
24-11-25 18:16:59 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 18:16:59 | I | - Batch_size: 8
24-11-25 18:16:59 | I |   + Max_seq_length: 2048
24-11-25 18:17:37 | I |     - Results:
24-11-25 18:17:37 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 18:17:37 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 18:17:37 | I |       |wikitext |      1|word_perplexity|7.8224|  |7.8224|
24-11-25 18:17:37 | I |       |val_valid|      1|word_perplexity|9.0273|  |9.0273|
24-11-25 18:17:37 | I |       
24-11-25 18:17:37 | I | quantizing weights for layer model.layers.0
24-11-25 18:17:37 | I | collecting info in model.layers.0
24-11-25 18:17:37 | I | collecting info in model.layers.0
24-11-25 18:17:37 | I | collecting info in model.layers.0
24-11-25 18:17:37 | I | collecting info in model.layers.0
24-11-25 18:17:38 | I | collecting calibration activations in model.layers.0
24-11-25 18:17:38 | I | collecting calibration activations in model.layers.0
24-11-25 18:17:38 | I | collecting calibration activations in model.layers.0
24-11-25 18:17:38 | I | collecting calibration activations in model.layers.0
24-11-25 18:17:38 | I | - Quantizing decoder layer model.layers.0
24-11-25 18:17:38 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 18:17:39 | I |       - range scale = [    1.0000]
24-11-25 18:17:39 | I |         sum  error  = [    0.0584]
24-11-25 18:17:39 | I |         best error  = [    0.0584]
24-11-25 18:17:39 | I |     + error = [0.0584]
24-11-25 18:17:40 | I |       - range scale = [    1.0000]
24-11-25 18:17:40 | I |         sum  error  = [    0.6441]
24-11-25 18:17:40 | I |         best error  = [    0.6441]
24-11-25 18:17:40 | I |     + error = [0.6441]
24-11-25 18:17:40 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 18:17:40 | I |       - range scale = [    1.0000]
24-11-25 18:17:40 | I |         sum  error  = [    0.0776]
24-11-25 18:17:40 | I |         best error  = [    0.0776]
24-11-25 18:17:40 | I |     + error = [0.0776]
24-11-25 18:17:41 | I |       - range scale = [    1.0000]
24-11-25 18:17:41 | I |         sum  error  = [    0.6077]
24-11-25 18:17:41 | I |         best error  = [    0.6077]
24-11-25 18:17:41 | I |     + error = [0.6077]
24-11-25 18:17:41 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 18:17:42 | I |       - range scale = [    1.0000]
24-11-25 18:17:42 | I |         sum  error  = [    0.2398]
24-11-25 18:17:42 | I |         best error  = [    0.2398]
24-11-25 18:17:42 | I |     + error = [0.2398]
24-11-25 18:17:43 | I |       - range scale = [    1.0000]
24-11-25 18:17:43 | I |         sum  error  = [    1.8682]
24-11-25 18:17:43 | I |         best error  = [    1.8682]
24-11-25 18:17:43 | I |     + error = [1.8682]
24-11-25 18:17:43 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 18:17:44 | I |       - range scale = [    1.0000]
24-11-25 18:17:44 | I |         sum  error  = [    0.0620]
24-11-25 18:17:44 | I |         best error  = [    0.0620]
24-11-25 18:17:44 | I |     + error = [0.0620]
24-11-25 18:17:44 | I |       - range scale = [    1.0000]
24-11-25 18:17:44 | I |         sum  error  = [    0.6066]
24-11-25 18:17:44 | I |         best error  = [    0.6066]
24-11-25 18:17:44 | I |     + error = [0.6066]
24-11-25 18:17:45 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 18:17:45 | I |       - range scale = [    1.0000]
24-11-25 18:17:45 | I |         sum  error  = [    1.1098]
24-11-25 18:17:45 | I |         best error  = [    1.1098]
24-11-25 18:17:45 | I |     + error = [1.1098]
24-11-25 18:17:46 | I |       - range scale = [    1.0000]
24-11-25 18:17:46 | I |         sum  error  = [   12.3071]
24-11-25 18:17:46 | I |         best error  = [   12.3071]
24-11-25 18:17:46 | I |     + error = [12.3071]
24-11-25 18:17:46 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 18:17:47 | I |       - range scale = [    1.0000]
24-11-25 18:17:47 | I |         sum  error  = [    1.2819]
24-11-25 18:17:47 | I |         best error  = [    1.2819]
24-11-25 18:17:47 | I |     + error = [1.2819]
24-11-25 18:17:48 | I |       - range scale = [    1.0000]
24-11-25 18:17:48 | I |         sum  error  = [   12.7221]
24-11-25 18:17:48 | I |         best error  = [   12.7221]
24-11-25 18:17:48 | I |     + error = [12.7221]
24-11-25 18:17:48 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 18:17:49 | I |       - range scale = [    1.0000]
24-11-25 18:17:49 | I |         sum  error  = [    1.6573]
24-11-25 18:17:49 | I |         best error  = [    1.6573]
24-11-25 18:17:49 | I |     + error = [1.6573]
24-11-25 18:17:49 | I |       - range scale = [    1.0000]
24-11-25 18:17:49 | I |         sum  error  = [    8.7217]
24-11-25 18:17:49 | I |         best error  = [    8.7217]
24-11-25 18:17:49 | I |     + error = [8.7217]
24-11-25 18:17:50 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 18:17:51 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 18:17:52 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 18:17:54 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 18:17:55 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 18:17:56 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 18:17:58 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 18:18:02 | I | quantizing activations for layer model.layers.0
24-11-25 18:18:02 | I | collecting info in model.layers.0
24-11-25 18:18:02 | I | collecting info in model.layers.0
24-11-25 18:18:02 | I | collecting info in model.layers.0
24-11-25 18:18:02 | I | collecting info in model.layers.0
24-11-25 18:18:02 | I | collecting calibration activations in model.layers.0
24-11-25 18:18:03 | I | collecting calibration activations in model.layers.0
24-11-25 18:18:03 | I | collecting calibration activations in model.layers.0
24-11-25 18:18:03 | I | collecting calibration activations in model.layers.0
24-11-25 18:18:04 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 18:18:04 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 18:18:04 | I | - Evaluator: gptq
24-11-25 18:18:04 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 18:18:04 | I | - Batch_size: 8
24-11-25 18:18:04 | I |   + Max_seq_length: 2048
24-11-25 18:18:46 | I |     - Results:
24-11-25 18:18:46 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 18:18:46 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 18:18:46 | I |       |wikitext |      1|word_perplexity|7.8289|  |7.8289|
24-11-25 18:18:46 | I |       |val_valid|      1|word_perplexity|9.0740|  |9.0740|
24-11-25 18:18:46 | I |       
24-11-25 18:18:46 | I | forward this layer
24-11-25 18:18:46 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/109.pt
24-11-25 18:18:46 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/109.pt
24-11-25 18:18:46 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 18:18:46 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 18:18:46 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 18:18:46 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 18:18:46 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 18:18:46 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 18:18:46 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 18:18:46 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 18:18:46 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 18:18:46 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 18:18:46 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 18:18:46 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 18:18:46 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 18:18:46 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 18:18:46 | I | [40] done with optimizer step
24-11-25 18:18:46 | I | epoch 001:     55 / 409600000 loss=8.59217e-05, loss_per_token=0.175968, loss_sum=5766.11, wps=152.7, ups=0, wpb=32768, bsz=64, num_updates=41, lr=0.000123, gnorm=31.607, clip=100, loss_scale=0.0078, train_wall=214, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=12057, lmquant_ppl_result_wikitext_in_train_no_quant=7.82238, lmquant_ppl_result_val_in_train_no_quant=9.02732, lmquant_ppl_result_wikitext_in_train_with_quant=7.82887, lmquant_ppl_result_val_in_train_with_quant=9.07399
24-11-25 18:18:46 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 18:18:46 | I | in layer model.layers.0
24-11-25 18:18:47 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 18:18:47 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 18:18:47 | I | - Evaluator: gptq
24-11-25 18:18:47 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 18:18:47 | I | - Batch_size: 8
24-11-25 18:18:47 | I |   + Max_seq_length: 2048
24-11-25 18:19:25 | I |     - Results:
24-11-25 18:19:25 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 18:19:25 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 18:19:25 | I |       |wikitext |      1|word_perplexity|7.8089|  |7.8089|
24-11-25 18:19:25 | I |       |val_valid|      1|word_perplexity|9.0240|  |9.0240|
24-11-25 18:19:25 | I |       
24-11-25 18:19:25 | I | quantizing weights for layer model.layers.0
24-11-25 18:19:25 | I | collecting info in model.layers.0
24-11-25 18:19:25 | I | collecting info in model.layers.0
24-11-25 18:19:25 | I | collecting info in model.layers.0
24-11-25 18:19:25 | I | collecting info in model.layers.0
24-11-25 18:19:25 | I | collecting calibration activations in model.layers.0
24-11-25 18:19:25 | I | collecting calibration activations in model.layers.0
24-11-25 18:19:26 | I | collecting calibration activations in model.layers.0
24-11-25 18:19:26 | I | collecting calibration activations in model.layers.0
24-11-25 18:19:26 | I | - Quantizing decoder layer model.layers.0
24-11-25 18:19:26 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 18:19:27 | I |       - range scale = [    1.0000]
24-11-25 18:19:27 | I |         sum  error  = [    0.0618]
24-11-25 18:19:27 | I |         best error  = [    0.0618]
24-11-25 18:19:27 | I |     + error = [0.0618]
24-11-25 18:19:27 | I |       - range scale = [    1.0000]
24-11-25 18:19:27 | I |         sum  error  = [    0.6345]
24-11-25 18:19:27 | I |         best error  = [    0.6345]
24-11-25 18:19:27 | I |     + error = [0.6345]
24-11-25 18:19:28 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 18:19:28 | I |       - range scale = [    1.0000]
24-11-25 18:19:28 | I |         sum  error  = [    0.0750]
24-11-25 18:19:28 | I |         best error  = [    0.0750]
24-11-25 18:19:28 | I |     + error = [0.0750]
24-11-25 18:19:29 | I |       - range scale = [    1.0000]
24-11-25 18:19:29 | I |         sum  error  = [    0.5648]
24-11-25 18:19:29 | I |         best error  = [    0.5648]
24-11-25 18:19:29 | I |     + error = [0.5648]
24-11-25 18:19:29 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 18:19:30 | I |       - range scale = [    1.0000]
24-11-25 18:19:30 | I |         sum  error  = [    0.2358]
24-11-25 18:19:30 | I |         best error  = [    0.2358]
24-11-25 18:19:30 | I |     + error = [0.2358]
24-11-25 18:19:30 | I |       - range scale = [    1.0000]
24-11-25 18:19:30 | I |         sum  error  = [    1.8559]
24-11-25 18:19:30 | I |         best error  = [    1.8559]
24-11-25 18:19:30 | I |     + error = [1.8559]
24-11-25 18:19:31 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 18:19:31 | I |       - range scale = [    1.0000]
24-11-25 18:19:31 | I |         sum  error  = [    0.0614]
24-11-25 18:19:31 | I |         best error  = [    0.0614]
24-11-25 18:19:31 | I |     + error = [0.0614]
24-11-25 18:19:32 | I |       - range scale = [    1.0000]
24-11-25 18:19:32 | I |         sum  error  = [    0.5950]
24-11-25 18:19:32 | I |         best error  = [    0.5950]
24-11-25 18:19:32 | I |     + error = [0.5950]
24-11-25 18:19:32 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 18:19:33 | I |       - range scale = [    1.0000]
24-11-25 18:19:33 | I |         sum  error  = [    1.0961]
24-11-25 18:19:33 | I |         best error  = [    1.0961]
24-11-25 18:19:33 | I |     + error = [1.0961]
24-11-25 18:19:34 | I |       - range scale = [    1.0000]
24-11-25 18:19:34 | I |         sum  error  = [   12.1484]
24-11-25 18:19:34 | I |         best error  = [   12.1484]
24-11-25 18:19:34 | I |     + error = [12.1484]
24-11-25 18:19:34 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 18:19:34 | I |       - range scale = [    1.0000]
24-11-25 18:19:34 | I |         sum  error  = [    1.2687]
24-11-25 18:19:34 | I |         best error  = [    1.2687]
24-11-25 18:19:34 | I |     + error = [1.2687]
24-11-25 18:19:35 | I |       - range scale = [    1.0000]
24-11-25 18:19:35 | I |         sum  error  = [   12.5806]
24-11-25 18:19:35 | I |         best error  = [   12.5806]
24-11-25 18:19:35 | I |     + error = [12.5806]
24-11-25 18:19:35 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 18:19:36 | I |       - range scale = [    1.0000]
24-11-25 18:19:36 | I |         sum  error  = [    3.5774]
24-11-25 18:19:36 | I |         best error  = [    3.5774]
24-11-25 18:19:36 | I |     + error = [3.5774]
24-11-25 18:19:37 | I |       - range scale = [    1.0000]
24-11-25 18:19:37 | I |         sum  error  = [   19.6863]
24-11-25 18:19:37 | I |         best error  = [   19.6863]
24-11-25 18:19:37 | I |     + error = [19.6863]
24-11-25 18:19:37 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 18:19:38 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 18:19:40 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 18:19:41 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 18:19:43 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 18:19:44 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 18:19:45 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 18:19:49 | I | quantizing activations for layer model.layers.0
24-11-25 18:19:49 | I | collecting info in model.layers.0
24-11-25 18:19:49 | I | collecting info in model.layers.0
24-11-25 18:19:49 | I | collecting info in model.layers.0
24-11-25 18:19:49 | I | collecting info in model.layers.0
24-11-25 18:19:49 | I | collecting calibration activations in model.layers.0
24-11-25 18:19:49 | I | collecting calibration activations in model.layers.0
24-11-25 18:19:49 | I | collecting calibration activations in model.layers.0
24-11-25 18:19:49 | I | collecting calibration activations in model.layers.0
24-11-25 18:19:51 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 18:19:51 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 18:19:51 | I | - Evaluator: gptq
24-11-25 18:19:51 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 18:19:51 | I | - Batch_size: 8
24-11-25 18:19:51 | I |   + Max_seq_length: 2048
24-11-25 18:20:33 | I |     - Results:
24-11-25 18:20:33 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 18:20:33 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 18:20:33 | I |       |wikitext |      1|word_perplexity|7.8443|  |7.8443|
24-11-25 18:20:33 | I |       |val_valid|      1|word_perplexity|9.0713|  |9.0713|
24-11-25 18:20:33 | I |       
24-11-25 18:20:33 | I | forward this layer
24-11-25 18:20:33 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/110.pt
24-11-25 18:20:33 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/110.pt
24-11-25 18:20:33 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 18:20:33 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 18:20:33 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 18:20:33 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 18:20:33 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 18:20:33 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 18:20:33 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 18:20:33 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 18:20:33 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 18:20:33 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 18:20:33 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 18:20:33 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 18:20:33 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 18:20:33 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 18:20:33 | I | in layer model.layers.0
24-11-25 18:20:33 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 18:20:33 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 18:20:33 | I | - Evaluator: gptq
24-11-25 18:20:33 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 18:20:33 | I | - Batch_size: 8
24-11-25 18:20:33 | I |   + Max_seq_length: 2048
24-11-25 18:21:11 | I |     - Results:
24-11-25 18:21:11 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 18:21:11 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 18:21:11 | I |       |wikitext |      1|word_perplexity|7.8089|  |7.8089|
24-11-25 18:21:11 | I |       |val_valid|      1|word_perplexity|9.0240|  |9.0240|
24-11-25 18:21:11 | I |       
24-11-25 18:21:11 | I | quantizing weights for layer model.layers.0
24-11-25 18:21:11 | I | collecting info in model.layers.0
24-11-25 18:21:11 | I | collecting info in model.layers.0
24-11-25 18:21:11 | I | collecting info in model.layers.0
24-11-25 18:21:11 | I | collecting info in model.layers.0
24-11-25 18:21:12 | I | collecting calibration activations in model.layers.0
24-11-25 18:21:12 | I | collecting calibration activations in model.layers.0
24-11-25 18:21:12 | I | collecting calibration activations in model.layers.0
24-11-25 18:21:12 | I | collecting calibration activations in model.layers.0
24-11-25 18:21:12 | I | - Quantizing decoder layer model.layers.0
24-11-25 18:21:12 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 18:21:13 | I |       - range scale = [    1.0000]
24-11-25 18:21:13 | I |         sum  error  = [    0.0610]
24-11-25 18:21:13 | I |         best error  = [    0.0610]
24-11-25 18:21:13 | I |     + error = [0.0610]
24-11-25 18:21:14 | I |       - range scale = [    1.0000]
24-11-25 18:21:14 | I |         sum  error  = [    0.6106]
24-11-25 18:21:14 | I |         best error  = [    0.6106]
24-11-25 18:21:14 | I |     + error = [0.6106]
24-11-25 18:21:14 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 18:21:15 | I |       - range scale = [    1.0000]
24-11-25 18:21:15 | I |         sum  error  = [    0.0686]
24-11-25 18:21:15 | I |         best error  = [    0.0686]
24-11-25 18:21:15 | I |     + error = [0.0686]
24-11-25 18:21:15 | I |       - range scale = [    1.0000]
24-11-25 18:21:15 | I |         sum  error  = [    0.5459]
24-11-25 18:21:15 | I |         best error  = [    0.5459]
24-11-25 18:21:15 | I |     + error = [0.5459]
24-11-25 18:21:15 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 18:21:16 | I |       - range scale = [    1.0000]
24-11-25 18:21:16 | I |         sum  error  = [    0.2305]
24-11-25 18:21:16 | I |         best error  = [    0.2305]
24-11-25 18:21:16 | I |     + error = [0.2305]
24-11-25 18:21:17 | I |       - range scale = [    1.0000]
24-11-25 18:21:17 | I |         sum  error  = [    1.8325]
24-11-25 18:21:17 | I |         best error  = [    1.8325]
24-11-25 18:21:17 | I |     + error = [1.8325]
24-11-25 18:21:17 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 18:21:18 | I |       - range scale = [    1.0000]
24-11-25 18:21:18 | I |         sum  error  = [    0.0640]
24-11-25 18:21:18 | I |         best error  = [    0.0640]
24-11-25 18:21:18 | I |     + error = [0.0640]
24-11-25 18:21:18 | I |       - range scale = [    1.0000]
24-11-25 18:21:18 | I |         sum  error  = [    0.6108]
24-11-25 18:21:18 | I |         best error  = [    0.6108]
24-11-25 18:21:18 | I |     + error = [0.6108]
24-11-25 18:21:19 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 18:21:19 | I |       - range scale = [    1.0000]
24-11-25 18:21:19 | I |         sum  error  = [    1.0733]
24-11-25 18:21:19 | I |         best error  = [    1.0733]
24-11-25 18:21:19 | I |     + error = [1.0733]
24-11-25 18:21:20 | I |       - range scale = [    1.0000]
24-11-25 18:21:20 | I |         sum  error  = [   11.9012]
24-11-25 18:21:20 | I |         best error  = [   11.9012]
24-11-25 18:21:20 | I |     + error = [11.9012]
24-11-25 18:21:20 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 18:21:21 | I |       - range scale = [    1.0000]
24-11-25 18:21:21 | I |         sum  error  = [    1.2444]
24-11-25 18:21:21 | I |         best error  = [    1.2444]
24-11-25 18:21:21 | I |     + error = [1.2444]
24-11-25 18:21:22 | I |       - range scale = [    1.0000]
24-11-25 18:21:22 | I |         sum  error  = [   12.3027]
24-11-25 18:21:22 | I |         best error  = [   12.3027]
24-11-25 18:21:22 | I |     + error = [12.3027]
24-11-25 18:21:22 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 18:21:23 | I |       - range scale = [    1.0000]
24-11-25 18:21:23 | I |         sum  error  = [    2.5738]
24-11-25 18:21:23 | I |         best error  = [    2.5738]
24-11-25 18:21:23 | I |     + error = [2.5738]
24-11-25 18:21:23 | I |       - range scale = [    1.0000]
24-11-25 18:21:23 | I |         sum  error  = [   14.5531]
24-11-25 18:21:23 | I |         best error  = [   14.5531]
24-11-25 18:21:23 | I |     + error = [14.5531]
24-11-25 18:21:24 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 18:21:25 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 18:21:26 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 18:21:28 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 18:21:29 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 18:21:30 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 18:21:32 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 18:21:35 | I | quantizing activations for layer model.layers.0
24-11-25 18:21:35 | I | collecting info in model.layers.0
24-11-25 18:21:35 | I | collecting info in model.layers.0
24-11-25 18:21:35 | I | collecting info in model.layers.0
24-11-25 18:21:35 | I | collecting info in model.layers.0
24-11-25 18:21:36 | I | collecting calibration activations in model.layers.0
24-11-25 18:21:36 | I | collecting calibration activations in model.layers.0
24-11-25 18:21:36 | I | collecting calibration activations in model.layers.0
24-11-25 18:21:36 | I | collecting calibration activations in model.layers.0
24-11-25 18:21:38 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 18:21:38 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 18:21:38 | I | - Evaluator: gptq
24-11-25 18:21:38 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 18:21:38 | I | - Batch_size: 8
24-11-25 18:21:38 | I |   + Max_seq_length: 2048
24-11-25 18:22:19 | I |     - Results:
24-11-25 18:22:19 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 18:22:19 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 18:22:19 | I |       |wikitext |      1|word_perplexity|7.8157|  |7.8157|
24-11-25 18:22:19 | I |       |val_valid|      1|word_perplexity|9.0679|  |9.0679|
24-11-25 18:22:19 | I |       
24-11-25 18:22:19 | I | forward this layer
24-11-25 18:22:19 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/111.pt
24-11-25 18:22:19 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/111.pt
24-11-25 18:22:19 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 18:22:19 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 18:22:19 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 18:22:19 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 18:22:19 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 18:22:19 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 18:22:19 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 18:22:19 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 18:22:19 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 18:22:19 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 18:22:20 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 18:22:20 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 18:22:20 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 18:22:20 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 18:22:20 | I | [41] done with optimizer step
24-11-25 18:22:20 | I | epoch 001:     56 / 409600000 loss=0.000111545, loss_per_token=0.228445, loss_sum=7485.69, wps=153.6, ups=0, wpb=32768, bsz=64, num_updates=42, lr=0.000126, gnorm=19.254, clip=100, loss_scale=0.0078, train_wall=213, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=12270, lmquant_ppl_result_wikitext_in_train_no_quant=7.80887, lmquant_ppl_result_val_in_train_no_quant=9.02399, lmquant_ppl_result_wikitext_in_train_with_quant=7.81566, lmquant_ppl_result_val_in_train_with_quant=9.06789
24-11-25 18:22:20 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 18:22:20 | I | in layer model.layers.0
24-11-25 18:22:20 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 18:22:20 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 18:22:20 | I | - Evaluator: gptq
24-11-25 18:22:20 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 18:22:20 | I | - Batch_size: 8
24-11-25 18:22:20 | I |   + Max_seq_length: 2048
24-11-25 18:22:58 | I |     - Results:
24-11-25 18:22:58 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 18:22:58 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 18:22:58 | I |       |wikitext |      1|word_perplexity|7.7967|  |7.7967|
24-11-25 18:22:58 | I |       |val_valid|      1|word_perplexity|9.0207|  |9.0207|
24-11-25 18:22:58 | I |       
24-11-25 18:22:58 | I | quantizing weights for layer model.layers.0
24-11-25 18:22:58 | I | collecting info in model.layers.0
24-11-25 18:22:58 | I | collecting info in model.layers.0
24-11-25 18:22:58 | I | collecting info in model.layers.0
24-11-25 18:22:58 | I | collecting info in model.layers.0
24-11-25 18:22:59 | I | collecting calibration activations in model.layers.0
24-11-25 18:22:59 | I | collecting calibration activations in model.layers.0
24-11-25 18:22:59 | I | collecting calibration activations in model.layers.0
24-11-25 18:22:59 | I | collecting calibration activations in model.layers.0
24-11-25 18:22:59 | I | - Quantizing decoder layer model.layers.0
24-11-25 18:22:59 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 18:23:00 | I |       - range scale = [    1.0000]
24-11-25 18:23:00 | I |         sum  error  = [    0.0678]
24-11-25 18:23:00 | I |         best error  = [    0.0678]
24-11-25 18:23:00 | I |     + error = [0.0678]
24-11-25 18:23:01 | I |       - range scale = [    1.0000]
24-11-25 18:23:01 | I |         sum  error  = [    0.6757]
24-11-25 18:23:01 | I |         best error  = [    0.6757]
24-11-25 18:23:01 | I |     + error = [0.6757]
24-11-25 18:23:01 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 18:23:02 | I |       - range scale = [    1.0000]
24-11-25 18:23:02 | I |         sum  error  = [    0.0713]
24-11-25 18:23:02 | I |         best error  = [    0.0713]
24-11-25 18:23:02 | I |     + error = [0.0713]
24-11-25 18:23:02 | I |       - range scale = [    1.0000]
24-11-25 18:23:02 | I |         sum  error  = [    0.6173]
24-11-25 18:23:02 | I |         best error  = [    0.6173]
24-11-25 18:23:02 | I |     + error = [0.6173]
24-11-25 18:23:03 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 18:23:03 | I |       - range scale = [    1.0000]
24-11-25 18:23:03 | I |         sum  error  = [    0.2272]
24-11-25 18:23:03 | I |         best error  = [    0.2272]
24-11-25 18:23:03 | I |     + error = [0.2272]
24-11-25 18:23:04 | I |       - range scale = [    1.0000]
24-11-25 18:23:04 | I |         sum  error  = [    1.8384]
24-11-25 18:23:04 | I |         best error  = [    1.8384]
24-11-25 18:23:04 | I |     + error = [1.8384]
24-11-25 18:23:04 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 18:23:05 | I |       - range scale = [    1.0000]
24-11-25 18:23:05 | I |         sum  error  = [    0.0720]
24-11-25 18:23:05 | I |         best error  = [    0.0720]
24-11-25 18:23:05 | I |     + error = [0.0720]
24-11-25 18:23:05 | I |       - range scale = [    1.0000]
24-11-25 18:23:05 | I |         sum  error  = [    0.6994]
24-11-25 18:23:05 | I |         best error  = [    0.6994]
24-11-25 18:23:05 | I |     + error = [0.6994]
24-11-25 18:23:06 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 18:23:06 | I |       - range scale = [    1.0000]
24-11-25 18:23:06 | I |         sum  error  = [    1.1248]
24-11-25 18:23:06 | I |         best error  = [    1.1248]
24-11-25 18:23:06 | I |     + error = [1.1248]
24-11-25 18:23:07 | I |       - range scale = [    1.0000]
24-11-25 18:23:07 | I |         sum  error  = [   12.5044]
24-11-25 18:23:07 | I |         best error  = [   12.5044]
24-11-25 18:23:07 | I |     + error = [12.5044]
24-11-25 18:23:07 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 18:23:08 | I |       - range scale = [    1.0000]
24-11-25 18:23:08 | I |         sum  error  = [    1.3089]
24-11-25 18:23:08 | I |         best error  = [    1.3089]
24-11-25 18:23:08 | I |     + error = [1.3089]
24-11-25 18:23:09 | I |       - range scale = [    1.0000]
24-11-25 18:23:09 | I |         sum  error  = [   12.9226]
24-11-25 18:23:09 | I |         best error  = [   12.9226]
24-11-25 18:23:09 | I |     + error = [12.9226]
24-11-25 18:23:09 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 18:23:10 | I |       - range scale = [    1.0000]
24-11-25 18:23:10 | I |         sum  error  = [    2.4415]
24-11-25 18:23:10 | I |         best error  = [    2.4415]
24-11-25 18:23:10 | I |     + error = [2.4415]
24-11-25 18:23:10 | I |       - range scale = [    1.0000]
24-11-25 18:23:10 | I |         sum  error  = [   13.6316]
24-11-25 18:23:10 | I |         best error  = [   13.6316]
24-11-25 18:23:10 | I |     + error = [13.6316]
24-11-25 18:23:11 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 18:23:12 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 18:23:13 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 18:23:15 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 18:23:16 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 18:23:18 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 18:23:19 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 18:23:22 | I | quantizing activations for layer model.layers.0
24-11-25 18:23:22 | I | collecting info in model.layers.0
24-11-25 18:23:22 | I | collecting info in model.layers.0
24-11-25 18:23:22 | I | collecting info in model.layers.0
24-11-25 18:23:22 | I | collecting info in model.layers.0
24-11-25 18:23:23 | I | collecting calibration activations in model.layers.0
24-11-25 18:23:23 | I | collecting calibration activations in model.layers.0
24-11-25 18:23:23 | I | collecting calibration activations in model.layers.0
24-11-25 18:23:23 | I | collecting calibration activations in model.layers.0
24-11-25 18:23:25 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 18:23:25 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 18:23:25 | I | - Evaluator: gptq
24-11-25 18:23:25 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 18:23:25 | I | - Batch_size: 8
24-11-25 18:23:25 | I |   + Max_seq_length: 2048
24-11-25 18:24:07 | I |     - Results:
24-11-25 18:24:07 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 18:24:07 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 18:24:07 | I |       |wikitext |      1|word_perplexity|7.8241|  |7.8241|
24-11-25 18:24:07 | I |       |val_valid|      1|word_perplexity|9.0745|  |9.0745|
24-11-25 18:24:07 | I |       
24-11-25 18:24:07 | I | forward this layer
24-11-25 18:24:07 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/112.pt
24-11-25 18:24:07 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/112.pt
24-11-25 18:24:07 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 18:24:07 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 18:24:07 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 18:24:07 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 18:24:07 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 18:24:07 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 18:24:07 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 18:24:07 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 18:24:07 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 18:24:07 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 18:24:07 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 18:24:07 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 18:24:07 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 18:24:07 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 18:24:07 | I | in layer model.layers.0
24-11-25 18:24:07 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 18:24:07 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 18:24:07 | I | - Evaluator: gptq
24-11-25 18:24:07 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 18:24:07 | I | - Batch_size: 8
24-11-25 18:24:07 | I |   + Max_seq_length: 2048
24-11-25 18:24:45 | I |     - Results:
24-11-25 18:24:45 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 18:24:45 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 18:24:45 | I |       |wikitext |      1|word_perplexity|7.7967|  |7.7967|
24-11-25 18:24:45 | I |       |val_valid|      1|word_perplexity|9.0207|  |9.0207|
24-11-25 18:24:45 | I |       
24-11-25 18:24:45 | I | quantizing weights for layer model.layers.0
24-11-25 18:24:45 | I | collecting info in model.layers.0
24-11-25 18:24:45 | I | collecting info in model.layers.0
24-11-25 18:24:45 | I | collecting info in model.layers.0
24-11-25 18:24:45 | I | collecting info in model.layers.0
24-11-25 18:24:46 | I | collecting calibration activations in model.layers.0
24-11-25 18:24:46 | I | collecting calibration activations in model.layers.0
24-11-25 18:24:46 | I | collecting calibration activations in model.layers.0
24-11-25 18:24:46 | I | collecting calibration activations in model.layers.0
24-11-25 18:24:46 | I | - Quantizing decoder layer model.layers.0
24-11-25 18:24:46 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 18:24:47 | I |       - range scale = [    1.0000]
24-11-25 18:24:47 | I |         sum  error  = [    0.0594]
24-11-25 18:24:47 | I |         best error  = [    0.0594]
24-11-25 18:24:47 | I |     + error = [0.0594]
24-11-25 18:24:48 | I |       - range scale = [    1.0000]
24-11-25 18:24:48 | I |         sum  error  = [    0.6220]
24-11-25 18:24:48 | I |         best error  = [    0.6220]
24-11-25 18:24:48 | I |     + error = [0.6220]
24-11-25 18:24:48 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 18:24:49 | I |       - range scale = [    1.0000]
24-11-25 18:24:49 | I |         sum  error  = [    0.0751]
24-11-25 18:24:49 | I |         best error  = [    0.0751]
24-11-25 18:24:49 | I |     + error = [0.0751]
24-11-25 18:24:49 | I |       - range scale = [    1.0000]
24-11-25 18:24:49 | I |         sum  error  = [    0.5839]
24-11-25 18:24:49 | I |         best error  = [    0.5839]
24-11-25 18:24:49 | I |     + error = [0.5839]
24-11-25 18:24:49 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 18:24:50 | I |       - range scale = [    1.0000]
24-11-25 18:24:50 | I |         sum  error  = [    0.2263]
24-11-25 18:24:50 | I |         best error  = [    0.2263]
24-11-25 18:24:50 | I |     + error = [0.2263]
24-11-25 18:24:51 | I |       - range scale = [    1.0000]
24-11-25 18:24:51 | I |         sum  error  = [    1.8467]
24-11-25 18:24:51 | I |         best error  = [    1.8467]
24-11-25 18:24:51 | I |     + error = [1.8467]
24-11-25 18:24:51 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 18:24:52 | I |       - range scale = [    1.0000]
24-11-25 18:24:52 | I |         sum  error  = [    0.0645]
24-11-25 18:24:52 | I |         best error  = [    0.0645]
24-11-25 18:24:52 | I |     + error = [0.0645]
24-11-25 18:24:52 | I |       - range scale = [    1.0000]
24-11-25 18:24:52 | I |         sum  error  = [    0.6270]
24-11-25 18:24:52 | I |         best error  = [    0.6270]
24-11-25 18:24:52 | I |     + error = [0.6270]
24-11-25 18:24:53 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 18:24:53 | I |       - range scale = [    1.0000]
24-11-25 18:24:53 | I |         sum  error  = [    1.1255]
24-11-25 18:24:53 | I |         best error  = [    1.1255]
24-11-25 18:24:53 | I |     + error = [1.1255]
24-11-25 18:24:54 | I |       - range scale = [    1.0000]
24-11-25 18:24:54 | I |         sum  error  = [   12.4839]
24-11-25 18:24:54 | I |         best error  = [   12.4839]
24-11-25 18:24:54 | I |     + error = [12.4839]
24-11-25 18:24:54 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 18:24:55 | I |       - range scale = [    1.0000]
24-11-25 18:24:55 | I |         sum  error  = [    1.3063]
24-11-25 18:24:55 | I |         best error  = [    1.3063]
24-11-25 18:24:55 | I |     + error = [1.3063]
24-11-25 18:24:56 | I |       - range scale = [    1.0000]
24-11-25 18:24:56 | I |         sum  error  = [   12.9183]
24-11-25 18:24:56 | I |         best error  = [   12.9183]
24-11-25 18:24:56 | I |     + error = [12.9183]
24-11-25 18:24:56 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 18:24:57 | I |       - range scale = [    1.0000]
24-11-25 18:24:57 | I |         sum  error  = [    2.9471]
24-11-25 18:24:57 | I |         best error  = [    2.9471]
24-11-25 18:24:57 | I |     + error = [2.9471]
24-11-25 18:24:57 | I |       - range scale = [    1.0000]
24-11-25 18:24:57 | I |         sum  error  = [   16.6191]
24-11-25 18:24:57 | I |         best error  = [   16.6191]
24-11-25 18:24:57 | I |     + error = [16.6191]
24-11-25 18:24:58 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 18:24:59 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 18:25:00 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 18:25:02 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 18:25:03 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 18:25:04 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 18:25:06 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 18:25:09 | I | quantizing activations for layer model.layers.0
24-11-25 18:25:09 | I | collecting info in model.layers.0
24-11-25 18:25:09 | I | collecting info in model.layers.0
24-11-25 18:25:09 | I | collecting info in model.layers.0
24-11-25 18:25:09 | I | collecting info in model.layers.0
24-11-25 18:25:10 | I | collecting calibration activations in model.layers.0
24-11-25 18:25:10 | I | collecting calibration activations in model.layers.0
24-11-25 18:25:10 | I | collecting calibration activations in model.layers.0
24-11-25 18:25:10 | I | collecting calibration activations in model.layers.0
24-11-25 18:25:12 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 18:25:12 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 18:25:12 | I | - Evaluator: gptq
24-11-25 18:25:12 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 18:25:12 | I | - Batch_size: 8
24-11-25 18:25:12 | I |   + Max_seq_length: 2048
24-11-25 18:25:53 | I |     - Results:
24-11-25 18:25:53 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 18:25:53 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 18:25:53 | I |       |wikitext |      1|word_perplexity|7.8165|  |7.8165|
24-11-25 18:25:53 | I |       |val_valid|      1|word_perplexity|9.0749|  |9.0749|
24-11-25 18:25:53 | I |       
24-11-25 18:25:53 | I | forward this layer
24-11-25 18:25:53 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/113.pt
24-11-25 18:25:53 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/113.pt
24-11-25 18:25:53 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 18:25:53 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 18:25:53 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 18:25:53 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 18:25:53 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 18:25:53 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 18:25:53 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 18:25:53 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 18:25:53 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 18:25:53 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 18:25:53 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 18:25:53 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 18:25:53 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 18:25:53 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 18:25:54 | I | [42] done with optimizer step
24-11-25 18:25:54 | I | epoch 001:     57 / 409600000 loss=0.000110595, loss_per_token=0.226499, loss_sum=7421.9, wps=153.2, ups=0, wpb=32768, bsz=64, num_updates=43, lr=0.000129, gnorm=40.517, clip=100, loss_scale=0.0078, train_wall=214, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=12484, lmquant_ppl_result_wikitext_in_train_no_quant=7.79668, lmquant_ppl_result_val_in_train_no_quant=9.02065, lmquant_ppl_result_wikitext_in_train_with_quant=7.81649, lmquant_ppl_result_val_in_train_with_quant=9.07486
24-11-25 18:25:54 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 18:25:54 | I | in layer model.layers.0
24-11-25 18:25:54 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 18:25:54 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 18:25:54 | I | - Evaluator: gptq
24-11-25 18:25:54 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 18:25:54 | I | - Batch_size: 8
24-11-25 18:25:54 | I |   + Max_seq_length: 2048
24-11-25 18:26:32 | I |     - Results:
24-11-25 18:26:32 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 18:26:32 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 18:26:32 | I |       |wikitext |      1|word_perplexity|7.7871|  |7.7871|
24-11-25 18:26:32 | I |       |val_valid|      1|word_perplexity|9.0197|  |9.0197|
24-11-25 18:26:32 | I |       
24-11-25 18:26:32 | I | quantizing weights for layer model.layers.0
24-11-25 18:26:32 | I | collecting info in model.layers.0
24-11-25 18:26:32 | I | collecting info in model.layers.0
24-11-25 18:26:32 | I | collecting info in model.layers.0
24-11-25 18:26:32 | I | collecting info in model.layers.0
24-11-25 18:26:33 | I | collecting calibration activations in model.layers.0
24-11-25 18:26:33 | I | collecting calibration activations in model.layers.0
24-11-25 18:26:33 | I | collecting calibration activations in model.layers.0
24-11-25 18:26:33 | I | collecting calibration activations in model.layers.0
24-11-25 18:26:33 | I | - Quantizing decoder layer model.layers.0
24-11-25 18:26:33 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 18:26:34 | I |       - range scale = [    1.0000]
24-11-25 18:26:34 | I |         sum  error  = [    0.0608]
24-11-25 18:26:34 | I |         best error  = [    0.0608]
24-11-25 18:26:34 | I |     + error = [0.0608]
24-11-25 18:26:35 | I |       - range scale = [    1.0000]
24-11-25 18:26:35 | I |         sum  error  = [    0.6312]
24-11-25 18:26:35 | I |         best error  = [    0.6312]
24-11-25 18:26:35 | I |     + error = [0.6312]
24-11-25 18:26:35 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 18:26:36 | I |       - range scale = [    1.0000]
24-11-25 18:26:36 | I |         sum  error  = [    0.0659]
24-11-25 18:26:36 | I |         best error  = [    0.0659]
24-11-25 18:26:36 | I |     + error = [0.0659]
24-11-25 18:26:36 | I |       - range scale = [    1.0000]
24-11-25 18:26:36 | I |         sum  error  = [    0.5580]
24-11-25 18:26:36 | I |         best error  = [    0.5580]
24-11-25 18:26:36 | I |     + error = [0.5580]
24-11-25 18:26:36 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 18:26:37 | I |       - range scale = [    1.0000]
24-11-25 18:26:37 | I |         sum  error  = [    0.2367]
24-11-25 18:26:37 | I |         best error  = [    0.2367]
24-11-25 18:26:37 | I |     + error = [0.2367]
24-11-25 18:26:38 | I |       - range scale = [    1.0000]
24-11-25 18:26:38 | I |         sum  error  = [    1.8446]
24-11-25 18:26:38 | I |         best error  = [    1.8446]
24-11-25 18:26:38 | I |     + error = [1.8446]
24-11-25 18:26:38 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 18:26:39 | I |       - range scale = [    1.0000]
24-11-25 18:26:39 | I |         sum  error  = [    0.0671]
24-11-25 18:26:39 | I |         best error  = [    0.0671]
24-11-25 18:26:39 | I |     + error = [0.0671]
24-11-25 18:26:39 | I |       - range scale = [    1.0000]
24-11-25 18:26:39 | I |         sum  error  = [    0.6448]
24-11-25 18:26:39 | I |         best error  = [    0.6448]
24-11-25 18:26:39 | I |     + error = [0.6448]
24-11-25 18:26:40 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 18:26:40 | I |       - range scale = [    1.0000]
24-11-25 18:26:40 | I |         sum  error  = [    1.1149]
24-11-25 18:26:40 | I |         best error  = [    1.1149]
24-11-25 18:26:40 | I |     + error = [1.1149]
24-11-25 18:26:41 | I |       - range scale = [    1.0000]
24-11-25 18:26:41 | I |         sum  error  = [   12.3663]
24-11-25 18:26:41 | I |         best error  = [   12.3663]
24-11-25 18:26:41 | I |     + error = [12.3663]
24-11-25 18:26:41 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 18:26:42 | I |       - range scale = [    1.0000]
24-11-25 18:26:42 | I |         sum  error  = [    1.2906]
24-11-25 18:26:42 | I |         best error  = [    1.2906]
24-11-25 18:26:42 | I |     + error = [1.2906]
24-11-25 18:26:43 | I |       - range scale = [    1.0000]
24-11-25 18:26:43 | I |         sum  error  = [   12.8050]
24-11-25 18:26:43 | I |         best error  = [   12.8050]
24-11-25 18:26:43 | I |     + error = [12.8050]
24-11-25 18:26:43 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 18:26:44 | I |       - range scale = [    1.0000]
24-11-25 18:26:44 | I |         sum  error  = [    3.0092]
24-11-25 18:26:44 | I |         best error  = [    3.0092]
24-11-25 18:26:44 | I |     + error = [3.0092]
24-11-25 18:26:44 | I |       - range scale = [    1.0000]
24-11-25 18:26:44 | I |         sum  error  = [   17.0928]
24-11-25 18:26:44 | I |         best error  = [   17.0928]
24-11-25 18:26:44 | I |     + error = [17.0928]
24-11-25 18:26:45 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 18:26:46 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 18:26:47 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 18:26:49 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 18:26:50 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 18:26:51 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 18:26:53 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 18:26:56 | I | quantizing activations for layer model.layers.0
24-11-25 18:26:56 | I | collecting info in model.layers.0
24-11-25 18:26:56 | I | collecting info in model.layers.0
24-11-25 18:26:56 | I | collecting info in model.layers.0
24-11-25 18:26:56 | I | collecting info in model.layers.0
24-11-25 18:26:56 | I | collecting calibration activations in model.layers.0
24-11-25 18:26:57 | I | collecting calibration activations in model.layers.0
24-11-25 18:26:57 | I | collecting calibration activations in model.layers.0
24-11-25 18:26:57 | I | collecting calibration activations in model.layers.0
24-11-25 18:26:59 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 18:26:59 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 18:26:59 | I | - Evaluator: gptq
24-11-25 18:26:59 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 18:26:59 | I | - Batch_size: 8
24-11-25 18:26:59 | I |   + Max_seq_length: 2048
24-11-25 18:27:40 | I |     - Results:
24-11-25 18:27:40 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 18:27:40 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 18:27:40 | I |       |wikitext |      1|word_perplexity|7.8163|  |7.8163|
24-11-25 18:27:40 | I |       |val_valid|      1|word_perplexity|9.0796|  |9.0796|
24-11-25 18:27:40 | I |       
24-11-25 18:27:40 | I | forward this layer
24-11-25 18:27:40 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/114.pt
24-11-25 18:27:40 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/114.pt
24-11-25 18:27:40 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 18:27:40 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 18:27:40 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 18:27:40 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 18:27:40 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 18:27:40 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 18:27:40 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 18:27:40 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 18:27:40 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 18:27:40 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 18:27:40 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 18:27:40 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 18:27:40 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 18:27:40 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 18:27:40 | I | in layer model.layers.0
24-11-25 18:27:40 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 18:27:40 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 18:27:40 | I | - Evaluator: gptq
24-11-25 18:27:40 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 18:27:40 | I | - Batch_size: 8
24-11-25 18:27:40 | I |   + Max_seq_length: 2048
24-11-25 18:28:19 | I |     - Results:
24-11-25 18:28:19 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 18:28:19 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 18:28:19 | I |       |wikitext |      1|word_perplexity|7.7871|  |7.7871|
24-11-25 18:28:19 | I |       |val_valid|      1|word_perplexity|9.0197|  |9.0197|
24-11-25 18:28:19 | I |       
24-11-25 18:28:19 | I | quantizing weights for layer model.layers.0
24-11-25 18:28:19 | I | collecting info in model.layers.0
24-11-25 18:28:19 | I | collecting info in model.layers.0
24-11-25 18:28:19 | I | collecting info in model.layers.0
24-11-25 18:28:19 | I | collecting info in model.layers.0
24-11-25 18:28:19 | I | collecting calibration activations in model.layers.0
24-11-25 18:28:19 | I | collecting calibration activations in model.layers.0
24-11-25 18:28:19 | I | collecting calibration activations in model.layers.0
24-11-25 18:28:20 | I | collecting calibration activations in model.layers.0
24-11-25 18:28:20 | I | - Quantizing decoder layer model.layers.0
24-11-25 18:28:20 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 18:28:21 | I |       - range scale = [    1.0000]
24-11-25 18:28:21 | I |         sum  error  = [    0.0620]
24-11-25 18:28:21 | I |         best error  = [    0.0620]
24-11-25 18:28:21 | I |     + error = [0.0620]
24-11-25 18:28:21 | I |       - range scale = [    1.0000]
24-11-25 18:28:21 | I |         sum  error  = [    0.6382]
24-11-25 18:28:21 | I |         best error  = [    0.6382]
24-11-25 18:28:21 | I |     + error = [0.6382]
24-11-25 18:28:21 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 18:28:22 | I |       - range scale = [    1.0000]
24-11-25 18:28:22 | I |         sum  error  = [    0.0727]
24-11-25 18:28:22 | I |         best error  = [    0.0727]
24-11-25 18:28:22 | I |     + error = [0.0727]
24-11-25 18:28:23 | I |       - range scale = [    1.0000]
24-11-25 18:28:23 | I |         sum  error  = [    0.6018]
24-11-25 18:28:23 | I |         best error  = [    0.6018]
24-11-25 18:28:23 | I |     + error = [0.6018]
24-11-25 18:28:23 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 18:28:24 | I |       - range scale = [    1.0000]
24-11-25 18:28:24 | I |         sum  error  = [    0.2398]
24-11-25 18:28:24 | I |         best error  = [    0.2398]
24-11-25 18:28:24 | I |     + error = [0.2398]
24-11-25 18:28:24 | I |       - range scale = [    1.0000]
24-11-25 18:28:24 | I |         sum  error  = [    1.8731]
24-11-25 18:28:24 | I |         best error  = [    1.8731]
24-11-25 18:28:24 | I |     + error = [1.8731]
24-11-25 18:28:25 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 18:28:25 | I |       - range scale = [    1.0000]
24-11-25 18:28:25 | I |         sum  error  = [    0.0665]
24-11-25 18:28:25 | I |         best error  = [    0.0665]
24-11-25 18:28:25 | I |     + error = [0.0665]
24-11-25 18:28:26 | I |       - range scale = [    1.0000]
24-11-25 18:28:26 | I |         sum  error  = [    0.6456]
24-11-25 18:28:26 | I |         best error  = [    0.6456]
24-11-25 18:28:26 | I |     + error = [0.6456]
24-11-25 18:28:26 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 18:28:27 | I |       - range scale = [    1.0000]
24-11-25 18:28:27 | I |         sum  error  = [    1.1015]
24-11-25 18:28:27 | I |         best error  = [    1.1015]
24-11-25 18:28:27 | I |     + error = [1.1015]
24-11-25 18:28:28 | I |       - range scale = [    1.0000]
24-11-25 18:28:28 | I |         sum  error  = [   12.2027]
24-11-25 18:28:28 | I |         best error  = [   12.2027]
24-11-25 18:28:28 | I |     + error = [12.2027]
24-11-25 18:28:28 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 18:28:29 | I |       - range scale = [    1.0000]
24-11-25 18:28:29 | I |         sum  error  = [    1.2748]
24-11-25 18:28:29 | I |         best error  = [    1.2748]
24-11-25 18:28:29 | I |     + error = [1.2748]
24-11-25 18:28:29 | I |       - range scale = [    1.0000]
24-11-25 18:28:29 | I |         sum  error  = [   12.6260]
24-11-25 18:28:29 | I |         best error  = [   12.6260]
24-11-25 18:28:29 | I |     + error = [12.6260]
24-11-25 18:28:30 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 18:28:30 | I |       - range scale = [    1.0000]
24-11-25 18:28:30 | I |         sum  error  = [    2.6259]
24-11-25 18:28:30 | I |         best error  = [    2.6259]
24-11-25 18:28:30 | I |     + error = [2.6259]
24-11-25 18:28:31 | I |       - range scale = [    1.0000]
24-11-25 18:28:31 | I |         sum  error  = [   15.0880]
24-11-25 18:28:31 | I |         best error  = [   15.0880]
24-11-25 18:28:31 | I |     + error = [15.0880]
24-11-25 18:28:31 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 18:28:33 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 18:28:34 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 18:28:35 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 18:28:37 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 18:28:38 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 18:28:40 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 18:28:43 | I | quantizing activations for layer model.layers.0
24-11-25 18:28:43 | I | collecting info in model.layers.0
24-11-25 18:28:43 | I | collecting info in model.layers.0
24-11-25 18:28:43 | I | collecting info in model.layers.0
24-11-25 18:28:43 | I | collecting info in model.layers.0
24-11-25 18:28:43 | I | collecting calibration activations in model.layers.0
24-11-25 18:28:43 | I | collecting calibration activations in model.layers.0
24-11-25 18:28:44 | I | collecting calibration activations in model.layers.0
24-11-25 18:28:44 | I | collecting calibration activations in model.layers.0
24-11-25 18:28:45 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 18:28:46 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 18:28:46 | I | - Evaluator: gptq
24-11-25 18:28:46 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 18:28:46 | I | - Batch_size: 8
24-11-25 18:28:46 | I |   + Max_seq_length: 2048
24-11-25 18:29:27 | I |     - Results:
24-11-25 18:29:27 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 18:29:27 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 18:29:27 | I |       |wikitext |      1|word_perplexity|7.8168|  |7.8168|
24-11-25 18:29:27 | I |       |val_valid|      1|word_perplexity|9.0733|  |9.0733|
24-11-25 18:29:27 | I |       
24-11-25 18:29:27 | I | forward this layer
24-11-25 18:29:27 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/115.pt
24-11-25 18:29:27 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/115.pt
24-11-25 18:29:27 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 18:29:27 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 18:29:27 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 18:29:27 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 18:29:27 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 18:29:27 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 18:29:27 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 18:29:27 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 18:29:27 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 18:29:27 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 18:29:27 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 18:29:27 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 18:29:27 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 18:29:27 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 18:29:27 | I | [43] done with optimizer step
24-11-25 18:29:27 | I | epoch 001:     58 / 409600000 loss=9.49782e-05, loss_per_token=0.194515, loss_sum=6373.88, wps=153.4, ups=0, wpb=32768, bsz=64, num_updates=44, lr=0.000132, gnorm=21.651, clip=100, loss_scale=0.0078, train_wall=213, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=12698, lmquant_ppl_result_wikitext_in_train_no_quant=7.78707, lmquant_ppl_result_val_in_train_no_quant=9.01966, lmquant_ppl_result_wikitext_in_train_with_quant=7.81679, lmquant_ppl_result_val_in_train_with_quant=9.07328
24-11-25 18:29:27 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 18:29:27 | I | in layer model.layers.0
24-11-25 18:29:27 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 18:29:27 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 18:29:27 | I | - Evaluator: gptq
24-11-25 18:29:27 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 18:29:27 | I | - Batch_size: 8
24-11-25 18:29:27 | I |   + Max_seq_length: 2048
24-11-25 18:30:06 | I |     - Results:
24-11-25 18:30:06 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 18:30:06 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 18:30:06 | I |       |wikitext |      1|word_perplexity|7.7815|  |7.7815|
24-11-25 18:30:06 | I |       |val_valid|      1|word_perplexity|9.0211|  |9.0211|
24-11-25 18:30:06 | I |       
24-11-25 18:30:06 | I | quantizing weights for layer model.layers.0
24-11-25 18:30:06 | I | collecting info in model.layers.0
24-11-25 18:30:06 | I | collecting info in model.layers.0
24-11-25 18:30:06 | I | collecting info in model.layers.0
24-11-25 18:30:06 | I | collecting info in model.layers.0
24-11-25 18:30:06 | I | collecting calibration activations in model.layers.0
24-11-25 18:30:06 | I | collecting calibration activations in model.layers.0
24-11-25 18:30:06 | I | collecting calibration activations in model.layers.0
24-11-25 18:30:06 | I | collecting calibration activations in model.layers.0
24-11-25 18:30:07 | I | - Quantizing decoder layer model.layers.0
24-11-25 18:30:07 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 18:30:07 | I |       - range scale = [    1.0000]
24-11-25 18:30:07 | I |         sum  error  = [    0.0619]
24-11-25 18:30:07 | I |         best error  = [    0.0619]
24-11-25 18:30:07 | I |     + error = [0.0619]
24-11-25 18:30:08 | I |       - range scale = [    1.0000]
24-11-25 18:30:08 | I |         sum  error  = [    0.6398]
24-11-25 18:30:08 | I |         best error  = [    0.6398]
24-11-25 18:30:08 | I |     + error = [0.6398]
24-11-25 18:30:08 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 18:30:09 | I |       - range scale = [    1.0000]
24-11-25 18:30:09 | I |         sum  error  = [    0.0739]
24-11-25 18:30:09 | I |         best error  = [    0.0739]
24-11-25 18:30:09 | I |     + error = [0.0739]
24-11-25 18:30:10 | I |       - range scale = [    1.0000]
24-11-25 18:30:10 | I |         sum  error  = [    0.6106]
24-11-25 18:30:10 | I |         best error  = [    0.6106]
24-11-25 18:30:10 | I |     + error = [0.6106]
24-11-25 18:30:10 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 18:30:11 | I |       - range scale = [    1.0000]
24-11-25 18:30:11 | I |         sum  error  = [    0.2451]
24-11-25 18:30:11 | I |         best error  = [    0.2451]
24-11-25 18:30:11 | I |     + error = [0.2451]
24-11-25 18:30:11 | I |       - range scale = [    1.0000]
24-11-25 18:30:11 | I |         sum  error  = [    1.8722]
24-11-25 18:30:11 | I |         best error  = [    1.8722]
24-11-25 18:30:11 | I |     + error = [1.8722]
24-11-25 18:30:11 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 18:30:12 | I |       - range scale = [    1.0000]
24-11-25 18:30:12 | I |         sum  error  = [    0.0683]
24-11-25 18:30:12 | I |         best error  = [    0.0683]
24-11-25 18:30:12 | I |     + error = [0.0683]
24-11-25 18:30:13 | I |       - range scale = [    1.0000]
24-11-25 18:30:13 | I |         sum  error  = [    0.6568]
24-11-25 18:30:13 | I |         best error  = [    0.6568]
24-11-25 18:30:13 | I |     + error = [0.6568]
24-11-25 18:30:13 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 18:30:14 | I |       - range scale = [    1.0000]
24-11-25 18:30:14 | I |         sum  error  = [    1.1433]
24-11-25 18:30:14 | I |         best error  = [    1.1433]
24-11-25 18:30:14 | I |     + error = [1.1433]
24-11-25 18:30:15 | I |       - range scale = [    1.0000]
24-11-25 18:30:15 | I |         sum  error  = [   12.7096]
24-11-25 18:30:15 | I |         best error  = [   12.7096]
24-11-25 18:30:15 | I |     + error = [12.7096]
24-11-25 18:30:15 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 18:30:15 | I |       - range scale = [    1.0000]
24-11-25 18:30:15 | I |         sum  error  = [    1.3239]
24-11-25 18:30:15 | I |         best error  = [    1.3239]
24-11-25 18:30:15 | I |     + error = [1.3239]
24-11-25 18:30:16 | I |       - range scale = [    1.0000]
24-11-25 18:30:16 | I |         sum  error  = [   13.1879]
24-11-25 18:30:16 | I |         best error  = [   13.1879]
24-11-25 18:30:16 | I |     + error = [13.1879]
24-11-25 18:30:16 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 18:30:17 | I |       - range scale = [    1.0000]
24-11-25 18:30:17 | I |         sum  error  = [    2.2490]
24-11-25 18:30:17 | I |         best error  = [    2.2490]
24-11-25 18:30:17 | I |     + error = [2.2490]
24-11-25 18:30:18 | I |       - range scale = [    1.0000]
24-11-25 18:30:18 | I |         sum  error  = [   12.7149]
24-11-25 18:30:18 | I |         best error  = [   12.7149]
24-11-25 18:30:18 | I |     + error = [12.7149]
24-11-25 18:30:18 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 18:30:19 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 18:30:21 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 18:30:22 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 18:30:24 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 18:30:25 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 18:30:26 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 18:30:30 | I | quantizing activations for layer model.layers.0
24-11-25 18:30:30 | I | collecting info in model.layers.0
24-11-25 18:30:30 | I | collecting info in model.layers.0
24-11-25 18:30:30 | I | collecting info in model.layers.0
24-11-25 18:30:30 | I | collecting info in model.layers.0
24-11-25 18:30:30 | I | collecting calibration activations in model.layers.0
24-11-25 18:30:30 | I | collecting calibration activations in model.layers.0
24-11-25 18:30:30 | I | collecting calibration activations in model.layers.0
24-11-25 18:30:31 | I | collecting calibration activations in model.layers.0
24-11-25 18:30:32 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 18:30:32 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 18:30:32 | I | - Evaluator: gptq
24-11-25 18:30:32 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 18:30:32 | I | - Batch_size: 8
24-11-25 18:30:32 | I |   + Max_seq_length: 2048
24-11-25 18:31:14 | I |     - Results:
24-11-25 18:31:14 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 18:31:14 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 18:31:14 | I |       |wikitext |      1|word_perplexity|7.8120|  |7.8120|
24-11-25 18:31:14 | I |       |val_valid|      1|word_perplexity|9.0806|  |9.0806|
24-11-25 18:31:14 | I |       
24-11-25 18:31:14 | I | forward this layer
24-11-25 18:31:14 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/116.pt
24-11-25 18:31:14 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/116.pt
24-11-25 18:31:14 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 18:31:14 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 18:31:14 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 18:31:14 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 18:31:14 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 18:31:14 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 18:31:14 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 18:31:14 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 18:31:14 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 18:31:14 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 18:31:14 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 18:31:14 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 18:31:14 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 18:31:14 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 18:31:14 | I | in layer model.layers.0
24-11-25 18:31:14 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 18:31:14 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 18:31:14 | I | - Evaluator: gptq
24-11-25 18:31:14 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 18:31:14 | I | - Batch_size: 8
24-11-25 18:31:14 | I |   + Max_seq_length: 2048
24-11-25 18:31:52 | I |     - Results:
24-11-25 18:31:52 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 18:31:52 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 18:31:52 | I |       |wikitext |      1|word_perplexity|7.7815|  |7.7815|
24-11-25 18:31:52 | I |       |val_valid|      1|word_perplexity|9.0211|  |9.0211|
24-11-25 18:31:52 | I |       
24-11-25 18:31:52 | I | quantizing weights for layer model.layers.0
24-11-25 18:31:52 | I | collecting info in model.layers.0
24-11-25 18:31:52 | I | collecting info in model.layers.0
24-11-25 18:31:52 | I | collecting info in model.layers.0
24-11-25 18:31:52 | I | collecting info in model.layers.0
24-11-25 18:31:53 | I | collecting calibration activations in model.layers.0
24-11-25 18:31:53 | I | collecting calibration activations in model.layers.0
24-11-25 18:31:53 | I | collecting calibration activations in model.layers.0
24-11-25 18:31:53 | I | collecting calibration activations in model.layers.0
24-11-25 18:31:53 | I | - Quantizing decoder layer model.layers.0
24-11-25 18:31:53 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 18:31:54 | I |       - range scale = [    1.0000]
24-11-25 18:31:54 | I |         sum  error  = [    0.0615]
24-11-25 18:31:54 | I |         best error  = [    0.0615]
24-11-25 18:31:54 | I |     + error = [0.0615]
24-11-25 18:31:55 | I |       - range scale = [    1.0000]
24-11-25 18:31:55 | I |         sum  error  = [    0.6435]
24-11-25 18:31:55 | I |         best error  = [    0.6435]
24-11-25 18:31:55 | I |     + error = [0.6435]
24-11-25 18:31:55 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 18:31:56 | I |       - range scale = [    1.0000]
24-11-25 18:31:56 | I |         sum  error  = [    0.0706]
24-11-25 18:31:56 | I |         best error  = [    0.0706]
24-11-25 18:31:56 | I |     + error = [0.0706]
24-11-25 18:31:56 | I |       - range scale = [    1.0000]
24-11-25 18:31:56 | I |         sum  error  = [    0.6158]
24-11-25 18:31:56 | I |         best error  = [    0.6158]
24-11-25 18:31:56 | I |     + error = [0.6158]
24-11-25 18:31:56 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 18:31:57 | I |       - range scale = [    1.0000]
24-11-25 18:31:57 | I |         sum  error  = [    0.2431]
24-11-25 18:31:57 | I |         best error  = [    0.2431]
24-11-25 18:31:57 | I |     + error = [0.2431]
24-11-25 18:31:58 | I |       - range scale = [    1.0000]
24-11-25 18:31:58 | I |         sum  error  = [    1.8551]
24-11-25 18:31:58 | I |         best error  = [    1.8551]
24-11-25 18:31:58 | I |     + error = [1.8551]
24-11-25 18:31:58 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 18:31:59 | I |       - range scale = [    1.0000]
24-11-25 18:31:59 | I |         sum  error  = [    0.0663]
24-11-25 18:31:59 | I |         best error  = [    0.0663]
24-11-25 18:31:59 | I |     + error = [0.0663]
24-11-25 18:31:59 | I |       - range scale = [    1.0000]
24-11-25 18:31:59 | I |         sum  error  = [    0.6401]
24-11-25 18:31:59 | I |         best error  = [    0.6401]
24-11-25 18:31:59 | I |     + error = [0.6401]
24-11-25 18:32:00 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 18:32:00 | I |       - range scale = [    1.0000]
24-11-25 18:32:00 | I |         sum  error  = [    1.1531]
24-11-25 18:32:00 | I |         best error  = [    1.1531]
24-11-25 18:32:00 | I |     + error = [1.1531]
24-11-25 18:32:01 | I |       - range scale = [    1.0000]
24-11-25 18:32:01 | I |         sum  error  = [   12.8254]
24-11-25 18:32:01 | I |         best error  = [   12.8254]
24-11-25 18:32:01 | I |     + error = [12.8254]
24-11-25 18:32:01 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 18:32:02 | I |       - range scale = [    1.0000]
24-11-25 18:32:02 | I |         sum  error  = [    1.3346]
24-11-25 18:32:02 | I |         best error  = [    1.3346]
24-11-25 18:32:02 | I |     + error = [1.3346]
24-11-25 18:32:03 | I |       - range scale = [    1.0000]
24-11-25 18:32:03 | I |         sum  error  = [   13.3102]
24-11-25 18:32:03 | I |         best error  = [   13.3102]
24-11-25 18:32:03 | I |     + error = [13.3102]
24-11-25 18:32:03 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 18:32:04 | I |       - range scale = [    1.0000]
24-11-25 18:32:04 | I |         sum  error  = [    2.6046]
24-11-25 18:32:04 | I |         best error  = [    2.6046]
24-11-25 18:32:04 | I |     + error = [2.6046]
24-11-25 18:32:04 | I |       - range scale = [    1.0000]
24-11-25 18:32:04 | I |         sum  error  = [   14.3371]
24-11-25 18:32:04 | I |         best error  = [   14.3371]
24-11-25 18:32:04 | I |     + error = [14.3371]
24-11-25 18:32:05 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 18:32:06 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 18:32:07 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 18:32:09 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 18:32:10 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 18:32:11 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 18:32:13 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 18:32:16 | I | quantizing activations for layer model.layers.0
24-11-25 18:32:16 | I | collecting info in model.layers.0
24-11-25 18:32:16 | I | collecting info in model.layers.0
24-11-25 18:32:16 | I | collecting info in model.layers.0
24-11-25 18:32:16 | I | collecting info in model.layers.0
24-11-25 18:32:17 | I | collecting calibration activations in model.layers.0
24-11-25 18:32:17 | I | collecting calibration activations in model.layers.0
24-11-25 18:32:17 | I | collecting calibration activations in model.layers.0
24-11-25 18:32:17 | I | collecting calibration activations in model.layers.0
24-11-25 18:32:19 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 18:32:19 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 18:32:19 | I | - Evaluator: gptq
24-11-25 18:32:19 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 18:32:19 | I | - Batch_size: 8
24-11-25 18:32:19 | I |   + Max_seq_length: 2048
24-11-25 18:33:00 | I |     - Results:
24-11-25 18:33:00 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 18:33:00 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 18:33:00 | I |       |wikitext |      1|word_perplexity|7.8187|  |7.8187|
24-11-25 18:33:00 | I |       |val_valid|      1|word_perplexity|9.0791|  |9.0791|
24-11-25 18:33:00 | I |       
24-11-25 18:33:00 | I | forward this layer
24-11-25 18:33:00 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/117.pt
24-11-25 18:33:00 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/117.pt
24-11-25 18:33:00 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 18:33:00 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 18:33:00 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 18:33:00 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 18:33:00 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 18:33:00 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 18:33:00 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 18:33:00 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 18:33:00 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 18:33:00 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 18:33:00 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 18:33:00 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 18:33:00 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 18:33:00 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 18:33:01 | I | [44] done with optimizer step
24-11-25 18:33:01 | I | epoch 001:     59 / 409600000 loss=0.000180728, loss_per_token=0.370132, loss_sum=12128.5, wps=153.6, ups=0, wpb=32768, bsz=64, num_updates=45, lr=0.000135, gnorm=60.471, clip=100, loss_scale=0.0078, train_wall=213, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=12911, lmquant_ppl_result_wikitext_in_train_no_quant=7.78152, lmquant_ppl_result_val_in_train_no_quant=9.02112, lmquant_ppl_result_wikitext_in_train_with_quant=7.81875, lmquant_ppl_result_val_in_train_with_quant=9.07911
24-11-25 18:33:01 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 18:33:01 | I | in layer model.layers.0
24-11-25 18:33:01 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 18:33:01 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 18:33:01 | I | - Evaluator: gptq
24-11-25 18:33:01 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 18:33:01 | I | - Batch_size: 8
24-11-25 18:33:01 | I |   + Max_seq_length: 2048
24-11-25 18:33:39 | I |     - Results:
24-11-25 18:33:39 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 18:33:39 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 18:33:39 | I |       |wikitext |      1|word_perplexity|7.7816|  |7.7816|
24-11-25 18:33:39 | I |       |val_valid|      1|word_perplexity|9.0249|  |9.0249|
24-11-25 18:33:39 | I |       
24-11-25 18:33:39 | I | quantizing weights for layer model.layers.0
24-11-25 18:33:39 | I | collecting info in model.layers.0
24-11-25 18:33:39 | I | collecting info in model.layers.0
24-11-25 18:33:39 | I | collecting info in model.layers.0
24-11-25 18:33:39 | I | collecting info in model.layers.0
24-11-25 18:33:40 | I | collecting calibration activations in model.layers.0
24-11-25 18:33:40 | I | collecting calibration activations in model.layers.0
24-11-25 18:33:40 | I | collecting calibration activations in model.layers.0
24-11-25 18:33:40 | I | collecting calibration activations in model.layers.0
24-11-25 18:33:40 | I | - Quantizing decoder layer model.layers.0
24-11-25 18:33:40 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 18:33:41 | I |       - range scale = [    1.0000]
24-11-25 18:33:41 | I |         sum  error  = [    0.0623]
24-11-25 18:33:41 | I |         best error  = [    0.0623]
24-11-25 18:33:41 | I |     + error = [0.0623]
24-11-25 18:33:42 | I |       - range scale = [    1.0000]
24-11-25 18:33:42 | I |         sum  error  = [    0.6150]
24-11-25 18:33:42 | I |         best error  = [    0.6150]
24-11-25 18:33:42 | I |     + error = [0.6150]
24-11-25 18:33:42 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 18:33:43 | I |       - range scale = [    1.0000]
24-11-25 18:33:43 | I |         sum  error  = [    0.0718]
24-11-25 18:33:43 | I |         best error  = [    0.0718]
24-11-25 18:33:43 | I |     + error = [0.0718]
24-11-25 18:33:43 | I |       - range scale = [    1.0000]
24-11-25 18:33:43 | I |         sum  error  = [    0.5573]
24-11-25 18:33:43 | I |         best error  = [    0.5573]
24-11-25 18:33:43 | I |     + error = [0.5573]
24-11-25 18:33:44 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 18:33:44 | I |       - range scale = [    1.0000]
24-11-25 18:33:44 | I |         sum  error  = [    0.2401]
24-11-25 18:33:44 | I |         best error  = [    0.2401]
24-11-25 18:33:44 | I |     + error = [0.2401]
24-11-25 18:33:45 | I |       - range scale = [    1.0000]
24-11-25 18:33:45 | I |         sum  error  = [    1.8464]
24-11-25 18:33:45 | I |         best error  = [    1.8464]
24-11-25 18:33:45 | I |     + error = [1.8464]
24-11-25 18:33:45 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 18:33:46 | I |       - range scale = [    1.0000]
24-11-25 18:33:46 | I |         sum  error  = [    0.0604]
24-11-25 18:33:46 | I |         best error  = [    0.0604]
24-11-25 18:33:46 | I |     + error = [0.0604]
24-11-25 18:33:46 | I |       - range scale = [    1.0000]
24-11-25 18:33:46 | I |         sum  error  = [    0.5721]
24-11-25 18:33:46 | I |         best error  = [    0.5721]
24-11-25 18:33:46 | I |     + error = [0.5721]
24-11-25 18:33:47 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 18:33:47 | I |       - range scale = [    1.0000]
24-11-25 18:33:47 | I |         sum  error  = [    1.0641]
24-11-25 18:33:47 | I |         best error  = [    1.0641]
24-11-25 18:33:47 | I |     + error = [1.0641]
24-11-25 18:33:48 | I |       - range scale = [    1.0000]
24-11-25 18:33:48 | I |         sum  error  = [   11.7970]
24-11-25 18:33:48 | I |         best error  = [   11.7970]
24-11-25 18:33:48 | I |     + error = [11.7970]
24-11-25 18:33:48 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 18:33:49 | I |       - range scale = [    1.0000]
24-11-25 18:33:49 | I |         sum  error  = [    1.2317]
24-11-25 18:33:49 | I |         best error  = [    1.2317]
24-11-25 18:33:49 | I |     + error = [1.2317]
24-11-25 18:33:50 | I |       - range scale = [    1.0000]
24-11-25 18:33:50 | I |         sum  error  = [   12.1821]
24-11-25 18:33:50 | I |         best error  = [   12.1821]
24-11-25 18:33:50 | I |     + error = [12.1821]
24-11-25 18:33:50 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 18:33:51 | I |       - range scale = [    1.0000]
24-11-25 18:33:51 | I |         sum  error  = [    3.3272]
24-11-25 18:33:51 | I |         best error  = [    3.3272]
24-11-25 18:33:51 | I |     + error = [3.3272]
24-11-25 18:33:51 | I |       - range scale = [    1.0000]
24-11-25 18:33:51 | I |         sum  error  = [   18.9811]
24-11-25 18:33:51 | I |         best error  = [   18.9811]
24-11-25 18:33:51 | I |     + error = [18.9811]
24-11-25 18:33:52 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 18:33:53 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 18:33:55 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 18:33:56 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 18:33:57 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 18:33:59 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 18:34:00 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 18:34:03 | I | quantizing activations for layer model.layers.0
24-11-25 18:34:03 | I | collecting info in model.layers.0
24-11-25 18:34:03 | I | collecting info in model.layers.0
24-11-25 18:34:03 | I | collecting info in model.layers.0
24-11-25 18:34:03 | I | collecting info in model.layers.0
24-11-25 18:34:04 | I | collecting calibration activations in model.layers.0
24-11-25 18:34:04 | I | collecting calibration activations in model.layers.0
24-11-25 18:34:04 | I | collecting calibration activations in model.layers.0
24-11-25 18:34:04 | I | collecting calibration activations in model.layers.0
24-11-25 18:34:06 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 18:34:06 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 18:34:06 | I | - Evaluator: gptq
24-11-25 18:34:06 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 18:34:06 | I | - Batch_size: 8
24-11-25 18:34:06 | I |   + Max_seq_length: 2048
24-11-25 18:34:47 | I |     - Results:
24-11-25 18:34:47 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 18:34:47 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 18:34:47 | I |       |wikitext |      1|word_perplexity|7.8343|  |7.8343|
24-11-25 18:34:47 | I |       |val_valid|      1|word_perplexity|9.1078|  |9.1078|
24-11-25 18:34:47 | I |       
24-11-25 18:34:47 | I | forward this layer
24-11-25 18:34:47 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/118.pt
24-11-25 18:34:47 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/118.pt
24-11-25 18:34:48 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 18:34:48 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 18:34:48 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 18:34:48 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 18:34:48 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 18:34:48 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 18:34:48 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 18:34:48 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 18:34:48 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 18:34:48 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 18:34:48 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 18:34:48 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 18:34:48 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 18:34:48 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 18:34:48 | I | in layer model.layers.0
24-11-25 18:34:48 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 18:34:48 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 18:34:48 | I | - Evaluator: gptq
24-11-25 18:34:48 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 18:34:48 | I | - Batch_size: 8
24-11-25 18:34:48 | I |   + Max_seq_length: 2048
24-11-25 18:35:26 | I |     - Results:
24-11-25 18:35:26 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 18:35:26 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 18:35:26 | I |       |wikitext |      1|word_perplexity|7.7816|  |7.7816|
24-11-25 18:35:26 | I |       |val_valid|      1|word_perplexity|9.0249|  |9.0249|
24-11-25 18:35:26 | I |       
24-11-25 18:35:26 | I | quantizing weights for layer model.layers.0
24-11-25 18:35:26 | I | collecting info in model.layers.0
24-11-25 18:35:26 | I | collecting info in model.layers.0
24-11-25 18:35:26 | I | collecting info in model.layers.0
24-11-25 18:35:26 | I | collecting info in model.layers.0
24-11-25 18:35:27 | I | collecting calibration activations in model.layers.0
24-11-25 18:35:27 | I | collecting calibration activations in model.layers.0
24-11-25 18:35:27 | I | collecting calibration activations in model.layers.0
24-11-25 18:35:27 | I | collecting calibration activations in model.layers.0
24-11-25 18:35:27 | I | - Quantizing decoder layer model.layers.0
24-11-25 18:35:27 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 18:35:28 | I |       - range scale = [    1.0000]
24-11-25 18:35:28 | I |         sum  error  = [    0.0640]
24-11-25 18:35:28 | I |         best error  = [    0.0640]
24-11-25 18:35:28 | I |     + error = [0.0640]
24-11-25 18:35:29 | I |       - range scale = [    1.0000]
24-11-25 18:35:29 | I |         sum  error  = [    0.6336]
24-11-25 18:35:29 | I |         best error  = [    0.6336]
24-11-25 18:35:29 | I |     + error = [0.6336]
24-11-25 18:35:29 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 18:35:29 | I |       - range scale = [    1.0000]
24-11-25 18:35:29 | I |         sum  error  = [    0.0733]
24-11-25 18:35:29 | I |         best error  = [    0.0733]
24-11-25 18:35:29 | I |     + error = [0.0733]
24-11-25 18:35:30 | I |       - range scale = [    1.0000]
24-11-25 18:35:30 | I |         sum  error  = [    0.5600]
24-11-25 18:35:30 | I |         best error  = [    0.5600]
24-11-25 18:35:30 | I |     + error = [0.5600]
24-11-25 18:35:30 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 18:35:31 | I |       - range scale = [    1.0000]
24-11-25 18:35:31 | I |         sum  error  = [    0.2434]
24-11-25 18:35:31 | I |         best error  = [    0.2434]
24-11-25 18:35:31 | I |     + error = [0.2434]
24-11-25 18:35:32 | I |       - range scale = [    1.0000]
24-11-25 18:35:32 | I |         sum  error  = [    1.8416]
24-11-25 18:35:32 | I |         best error  = [    1.8416]
24-11-25 18:35:32 | I |     + error = [1.8416]
24-11-25 18:35:32 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 18:35:33 | I |       - range scale = [    1.0000]
24-11-25 18:35:33 | I |         sum  error  = [    0.0676]
24-11-25 18:35:33 | I |         best error  = [    0.0676]
24-11-25 18:35:33 | I |     + error = [0.0676]
24-11-25 18:35:33 | I |       - range scale = [    1.0000]
24-11-25 18:35:33 | I |         sum  error  = [    0.6412]
24-11-25 18:35:33 | I |         best error  = [    0.6412]
24-11-25 18:35:33 | I |     + error = [0.6412]
24-11-25 18:35:34 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 18:35:34 | I |       - range scale = [    1.0000]
24-11-25 18:35:34 | I |         sum  error  = [    1.0320]
24-11-25 18:35:34 | I |         best error  = [    1.0320]
24-11-25 18:35:34 | I |     + error = [1.0320]
24-11-25 18:35:35 | I |       - range scale = [    1.0000]
24-11-25 18:35:35 | I |         sum  error  = [   11.4296]
24-11-25 18:35:35 | I |         best error  = [   11.4296]
24-11-25 18:35:35 | I |     + error = [11.4296]
24-11-25 18:35:35 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 18:35:36 | I |       - range scale = [    1.0000]
24-11-25 18:35:36 | I |         sum  error  = [    1.1930]
24-11-25 18:35:36 | I |         best error  = [    1.1930]
24-11-25 18:35:36 | I |     + error = [1.1930]
24-11-25 18:35:37 | I |       - range scale = [    1.0000]
24-11-25 18:35:37 | I |         sum  error  = [   11.8153]
24-11-25 18:35:37 | I |         best error  = [   11.8153]
24-11-25 18:35:37 | I |     + error = [11.8153]
24-11-25 18:35:37 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 18:35:38 | I |       - range scale = [    1.0000]
24-11-25 18:35:38 | I |         sum  error  = [    2.8606]
24-11-25 18:35:38 | I |         best error  = [    2.8606]
24-11-25 18:35:38 | I |     + error = [2.8606]
24-11-25 18:35:38 | I |       - range scale = [    1.0000]
24-11-25 18:35:38 | I |         sum  error  = [   15.7853]
24-11-25 18:35:38 | I |         best error  = [   15.7853]
24-11-25 18:35:38 | I |     + error = [15.7853]
24-11-25 18:35:39 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 18:35:40 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 18:35:41 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 18:35:43 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 18:35:44 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 18:35:46 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 18:35:47 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 18:35:50 | I | quantizing activations for layer model.layers.0
24-11-25 18:35:50 | I | collecting info in model.layers.0
24-11-25 18:35:50 | I | collecting info in model.layers.0
24-11-25 18:35:50 | I | collecting info in model.layers.0
24-11-25 18:35:50 | I | collecting info in model.layers.0
24-11-25 18:35:51 | I | collecting calibration activations in model.layers.0
24-11-25 18:35:51 | I | collecting calibration activations in model.layers.0
24-11-25 18:35:51 | I | collecting calibration activations in model.layers.0
24-11-25 18:35:51 | I | collecting calibration activations in model.layers.0
24-11-25 18:35:53 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 18:35:53 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 18:35:53 | I | - Evaluator: gptq
24-11-25 18:35:53 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 18:35:53 | I | - Batch_size: 8
24-11-25 18:35:53 | I |   + Max_seq_length: 2048
24-11-25 18:36:35 | I |     - Results:
24-11-25 18:36:35 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 18:36:35 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 18:36:35 | I |       |wikitext |      1|word_perplexity|7.8437|  |7.8437|
24-11-25 18:36:35 | I |       |val_valid|      1|word_perplexity|9.1169|  |9.1169|
24-11-25 18:36:35 | I |       
24-11-25 18:36:35 | I | forward this layer
24-11-25 18:36:35 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/119.pt
24-11-25 18:36:35 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/119.pt
24-11-25 18:36:35 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 18:36:35 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 18:36:35 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 18:36:35 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 18:36:35 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 18:36:35 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 18:36:35 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 18:36:35 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 18:36:35 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 18:36:35 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 18:36:35 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 18:36:35 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 18:36:35 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 18:36:35 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 18:36:35 | I | [45] done with optimizer step
24-11-25 18:36:35 | I | epoch 001:     60 / 409600000 loss=0.000119469, loss_per_token=0.244672, loss_sum=8017.4, wps=152.9, ups=0, wpb=32768, bsz=64, num_updates=46, lr=0.000138, gnorm=40.827, clip=100, loss_scale=0.0078, train_wall=214, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=13125, lmquant_ppl_result_wikitext_in_train_no_quant=7.78159, lmquant_ppl_result_val_in_train_no_quant=9.02488, lmquant_ppl_result_wikitext_in_train_with_quant=7.84368, lmquant_ppl_result_val_in_train_with_quant=9.11692
24-11-25 18:36:35 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 18:36:35 | I | in layer model.layers.0
24-11-25 18:36:35 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 18:36:35 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 18:36:35 | I | - Evaluator: gptq
24-11-25 18:36:35 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 18:36:35 | I | - Batch_size: 8
24-11-25 18:36:35 | I |   + Max_seq_length: 2048
24-11-25 18:37:13 | I |     - Results:
24-11-25 18:37:13 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 18:37:13 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 18:37:13 | I |       |wikitext |      1|word_perplexity|7.7818|  |7.7818|
24-11-25 18:37:13 | I |       |val_valid|      1|word_perplexity|9.0276|  |9.0276|
24-11-25 18:37:13 | I |       
24-11-25 18:37:13 | I | quantizing weights for layer model.layers.0
24-11-25 18:37:13 | I | collecting info in model.layers.0
24-11-25 18:37:13 | I | collecting info in model.layers.0
24-11-25 18:37:13 | I | collecting info in model.layers.0
24-11-25 18:37:13 | I | collecting info in model.layers.0
24-11-25 18:37:14 | I | collecting calibration activations in model.layers.0
24-11-25 18:37:14 | I | collecting calibration activations in model.layers.0
24-11-25 18:37:14 | I | collecting calibration activations in model.layers.0
24-11-25 18:37:14 | I | collecting calibration activations in model.layers.0
24-11-25 18:37:15 | I | - Quantizing decoder layer model.layers.0
24-11-25 18:37:15 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 18:37:15 | I |       - range scale = [    1.0000]
24-11-25 18:37:15 | I |         sum  error  = [    0.0613]
24-11-25 18:37:15 | I |         best error  = [    0.0613]
24-11-25 18:37:15 | I |     + error = [0.0613]
24-11-25 18:37:16 | I |       - range scale = [    1.0000]
24-11-25 18:37:16 | I |         sum  error  = [    0.6441]
24-11-25 18:37:16 | I |         best error  = [    0.6441]
24-11-25 18:37:16 | I |     + error = [0.6441]
24-11-25 18:37:16 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 18:37:17 | I |       - range scale = [    1.0000]
24-11-25 18:37:17 | I |         sum  error  = [    0.0751]
24-11-25 18:37:17 | I |         best error  = [    0.0751]
24-11-25 18:37:17 | I |     + error = [0.0751]
24-11-25 18:37:18 | I |       - range scale = [    1.0000]
24-11-25 18:37:18 | I |         sum  error  = [    0.5778]
24-11-25 18:37:18 | I |         best error  = [    0.5778]
24-11-25 18:37:18 | I |     + error = [0.5778]
24-11-25 18:37:18 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 18:37:18 | I |       - range scale = [    1.0000]
24-11-25 18:37:18 | I |         sum  error  = [    0.2458]
24-11-25 18:37:18 | I |         best error  = [    0.2458]
24-11-25 18:37:18 | I |     + error = [0.2458]
24-11-25 18:37:19 | I |       - range scale = [    1.0000]
24-11-25 18:37:19 | I |         sum  error  = [    1.8694]
24-11-25 18:37:19 | I |         best error  = [    1.8694]
24-11-25 18:37:19 | I |     + error = [1.8694]
24-11-25 18:37:19 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 18:37:20 | I |       - range scale = [    1.0000]
24-11-25 18:37:20 | I |         sum  error  = [    0.0663]
24-11-25 18:37:20 | I |         best error  = [    0.0663]
24-11-25 18:37:20 | I |     + error = [0.0663]
24-11-25 18:37:21 | I |       - range scale = [    1.0000]
24-11-25 18:37:21 | I |         sum  error  = [    0.6360]
24-11-25 18:37:21 | I |         best error  = [    0.6360]
24-11-25 18:37:21 | I |     + error = [0.6360]
24-11-25 18:37:21 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 18:37:22 | I |       - range scale = [    1.0000]
24-11-25 18:37:22 | I |         sum  error  = [    1.0958]
24-11-25 18:37:22 | I |         best error  = [    1.0958]
24-11-25 18:37:22 | I |     + error = [1.0958]
24-11-25 18:37:22 | I |       - range scale = [    1.0000]
24-11-25 18:37:22 | I |         sum  error  = [   12.1588]
24-11-25 18:37:22 | I |         best error  = [   12.1588]
24-11-25 18:37:22 | I |     + error = [12.1588]
24-11-25 18:37:23 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 18:37:23 | I |       - range scale = [    1.0000]
24-11-25 18:37:23 | I |         sum  error  = [    1.2673]
24-11-25 18:37:23 | I |         best error  = [    1.2673]
24-11-25 18:37:23 | I |     + error = [1.2673]
24-11-25 18:37:24 | I |       - range scale = [    1.0000]
24-11-25 18:37:24 | I |         sum  error  = [   12.5711]
24-11-25 18:37:24 | I |         best error  = [   12.5711]
24-11-25 18:37:24 | I |     + error = [12.5711]
24-11-25 18:37:24 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 18:37:25 | I |       - range scale = [    1.0000]
24-11-25 18:37:25 | I |         sum  error  = [    2.4628]
24-11-25 18:37:25 | I |         best error  = [    2.4628]
24-11-25 18:37:25 | I |     + error = [2.4628]
24-11-25 18:37:26 | I |       - range scale = [    1.0000]
24-11-25 18:37:26 | I |         sum  error  = [   14.2670]
24-11-25 18:37:26 | I |         best error  = [   14.2670]
24-11-25 18:37:26 | I |     + error = [14.2670]
24-11-25 18:37:26 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 18:37:27 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 18:37:29 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 18:37:30 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 18:37:32 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 18:37:33 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 18:37:34 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 18:37:38 | I | quantizing activations for layer model.layers.0
24-11-25 18:37:38 | I | collecting info in model.layers.0
24-11-25 18:37:38 | I | collecting info in model.layers.0
24-11-25 18:37:38 | I | collecting info in model.layers.0
24-11-25 18:37:38 | I | collecting info in model.layers.0
24-11-25 18:37:38 | I | collecting calibration activations in model.layers.0
24-11-25 18:37:38 | I | collecting calibration activations in model.layers.0
24-11-25 18:37:38 | I | collecting calibration activations in model.layers.0
24-11-25 18:37:38 | I | collecting calibration activations in model.layers.0
24-11-25 18:37:40 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 18:37:40 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 18:37:40 | I | - Evaluator: gptq
24-11-25 18:37:40 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 18:37:40 | I | - Batch_size: 8
24-11-25 18:37:40 | I |   + Max_seq_length: 2048
24-11-25 18:38:22 | I |     - Results:
24-11-25 18:38:22 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 18:38:22 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 18:38:22 | I |       |wikitext |      1|word_perplexity|7.8164|  |7.8164|
24-11-25 18:38:22 | I |       |val_valid|      1|word_perplexity|9.0961|  |9.0961|
24-11-25 18:38:22 | I |       
24-11-25 18:38:22 | I | forward this layer
24-11-25 18:38:22 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/120.pt
24-11-25 18:38:22 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/120.pt
24-11-25 18:38:23 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 18:38:23 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 18:38:23 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 18:38:23 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 18:38:23 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 18:38:23 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 18:38:23 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 18:38:23 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 18:38:23 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 18:38:23 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 18:38:23 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 18:38:23 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 18:38:23 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 18:38:23 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 18:38:23 | I | in layer model.layers.0
24-11-25 18:38:23 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 18:38:23 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 18:38:23 | I | - Evaluator: gptq
24-11-25 18:38:23 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 18:38:23 | I | - Batch_size: 8
24-11-25 18:38:23 | I |   + Max_seq_length: 2048
24-11-25 18:39:01 | I |     - Results:
24-11-25 18:39:01 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 18:39:01 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 18:39:01 | I |       |wikitext |      1|word_perplexity|7.7818|  |7.7818|
24-11-25 18:39:01 | I |       |val_valid|      1|word_perplexity|9.0276|  |9.0276|
24-11-25 18:39:01 | I |       
24-11-25 18:39:01 | I | quantizing weights for layer model.layers.0
24-11-25 18:39:01 | I | collecting info in model.layers.0
24-11-25 18:39:01 | I | collecting info in model.layers.0
24-11-25 18:39:01 | I | collecting info in model.layers.0
24-11-25 18:39:01 | I | collecting info in model.layers.0
24-11-25 18:39:01 | I | collecting calibration activations in model.layers.0
24-11-25 18:39:02 | I | collecting calibration activations in model.layers.0
24-11-25 18:39:02 | I | collecting calibration activations in model.layers.0
24-11-25 18:39:02 | I | collecting calibration activations in model.layers.0
24-11-25 18:39:02 | I | - Quantizing decoder layer model.layers.0
24-11-25 18:39:02 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 18:39:03 | I |       - range scale = [    1.0000]
24-11-25 18:39:03 | I |         sum  error  = [    0.0604]
24-11-25 18:39:03 | I |         best error  = [    0.0604]
24-11-25 18:39:03 | I |     + error = [0.0604]
24-11-25 18:39:03 | I |       - range scale = [    1.0000]
24-11-25 18:39:03 | I |         sum  error  = [    0.6296]
24-11-25 18:39:03 | I |         best error  = [    0.6296]
24-11-25 18:39:03 | I |     + error = [0.6296]
24-11-25 18:39:04 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 18:39:04 | I |       - range scale = [    1.0000]
24-11-25 18:39:04 | I |         sum  error  = [    0.0714]
24-11-25 18:39:04 | I |         best error  = [    0.0714]
24-11-25 18:39:04 | I |     + error = [0.0714]
24-11-25 18:39:05 | I |       - range scale = [    1.0000]
24-11-25 18:39:05 | I |         sum  error  = [    0.6005]
24-11-25 18:39:05 | I |         best error  = [    0.6005]
24-11-25 18:39:05 | I |     + error = [0.6005]
24-11-25 18:39:05 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 18:39:06 | I |       - range scale = [    1.0000]
24-11-25 18:39:06 | I |         sum  error  = [    0.2342]
24-11-25 18:39:06 | I |         best error  = [    0.2342]
24-11-25 18:39:06 | I |     + error = [0.2342]
24-11-25 18:39:07 | I |       - range scale = [    1.0000]
24-11-25 18:39:07 | I |         sum  error  = [    1.8254]
24-11-25 18:39:07 | I |         best error  = [    1.8254]
24-11-25 18:39:07 | I |     + error = [1.8254]
24-11-25 18:39:07 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 18:39:08 | I |       - range scale = [    1.0000]
24-11-25 18:39:08 | I |         sum  error  = [    0.0749]
24-11-25 18:39:08 | I |         best error  = [    0.0749]
24-11-25 18:39:08 | I |     + error = [0.0749]
24-11-25 18:39:09 | I |       - range scale = [    1.0000]
24-11-25 18:39:09 | I |         sum  error  = [    0.7286]
24-11-25 18:39:09 | I |         best error  = [    0.7286]
24-11-25 18:39:09 | I |     + error = [0.7286]
24-11-25 18:39:09 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 18:39:09 | I |       - range scale = [    1.0000]
24-11-25 18:39:09 | I |         sum  error  = [    1.1443]
24-11-25 18:39:09 | I |         best error  = [    1.1443]
24-11-25 18:39:09 | I |     + error = [1.1443]
24-11-25 18:39:10 | I |       - range scale = [    1.0000]
24-11-25 18:39:10 | I |         sum  error  = [   12.7220]
24-11-25 18:39:10 | I |         best error  = [   12.7220]
24-11-25 18:39:10 | I |     + error = [12.7220]
24-11-25 18:39:10 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 18:39:11 | I |       - range scale = [    1.0000]
24-11-25 18:39:11 | I |         sum  error  = [    1.3260]
24-11-25 18:39:11 | I |         best error  = [    1.3260]
24-11-25 18:39:11 | I |     + error = [1.3260]
24-11-25 18:39:12 | I |       - range scale = [    1.0000]
24-11-25 18:39:12 | I |         sum  error  = [   13.1525]
24-11-25 18:39:12 | I |         best error  = [   13.1525]
24-11-25 18:39:12 | I |     + error = [13.1525]
24-11-25 18:39:12 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 18:39:13 | I |       - range scale = [    1.0000]
24-11-25 18:39:13 | I |         sum  error  = [    2.1087]
24-11-25 18:39:13 | I |         best error  = [    2.1087]
24-11-25 18:39:13 | I |     + error = [2.1087]
24-11-25 18:39:13 | I |       - range scale = [    1.0000]
24-11-25 18:39:13 | I |         sum  error  = [   11.5261]
24-11-25 18:39:13 | I |         best error  = [   11.5261]
24-11-25 18:39:13 | I |     + error = [11.5261]
24-11-25 18:39:14 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 18:39:15 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 18:39:16 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 18:39:18 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 18:39:19 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 18:39:21 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 18:39:22 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 18:39:25 | I | quantizing activations for layer model.layers.0
24-11-25 18:39:25 | I | collecting info in model.layers.0
24-11-25 18:39:25 | I | collecting info in model.layers.0
24-11-25 18:39:25 | I | collecting info in model.layers.0
24-11-25 18:39:25 | I | collecting info in model.layers.0
24-11-25 18:39:26 | I | collecting calibration activations in model.layers.0
24-11-25 18:39:26 | I | collecting calibration activations in model.layers.0
24-11-25 18:39:26 | I | collecting calibration activations in model.layers.0
24-11-25 18:39:26 | I | collecting calibration activations in model.layers.0
24-11-25 18:39:28 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 18:39:28 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 18:39:28 | I | - Evaluator: gptq
24-11-25 18:39:28 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 18:39:28 | I | - Batch_size: 8
24-11-25 18:39:28 | I |   + Max_seq_length: 2048
24-11-25 18:40:09 | I |     - Results:
24-11-25 18:40:09 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 18:40:09 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 18:40:09 | I |       |wikitext |      1|word_perplexity|7.8172|  |7.8172|
24-11-25 18:40:09 | I |       |val_valid|      1|word_perplexity|9.0981|  |9.0981|
24-11-25 18:40:09 | I |       
24-11-25 18:40:09 | I | forward this layer
24-11-25 18:40:09 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/121.pt
24-11-25 18:40:09 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/121.pt
24-11-25 18:40:10 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 18:40:10 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 18:40:10 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 18:40:10 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 18:40:10 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 18:40:10 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 18:40:10 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 18:40:10 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 18:40:10 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 18:40:10 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 18:40:10 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 18:40:10 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 18:40:10 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 18:40:10 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 18:40:10 | I | [46] done with optimizer step
24-11-25 18:40:10 | I | epoch 001:     61 / 409600000 loss=0.000133439, loss_per_token=0.273283, loss_sum=8954.93, wps=152.5, ups=0, wpb=32768, bsz=64, num_updates=47, lr=0.000141, gnorm=20.804, clip=100, loss_scale=0.0078, train_wall=215, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=13340, lmquant_ppl_result_wikitext_in_train_no_quant=7.78179, lmquant_ppl_result_val_in_train_no_quant=9.02765, lmquant_ppl_result_wikitext_in_train_with_quant=7.81716, lmquant_ppl_result_val_in_train_with_quant=9.09809
24-11-25 18:40:10 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 18:40:10 | I | in layer model.layers.0
24-11-25 18:40:10 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 18:40:10 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 18:40:10 | I | - Evaluator: gptq
24-11-25 18:40:10 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 18:40:10 | I | - Batch_size: 8
24-11-25 18:40:10 | I |   + Max_seq_length: 2048
24-11-25 18:40:48 | I |     - Results:
24-11-25 18:40:48 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 18:40:48 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 18:40:48 | I |       |wikitext |      1|word_perplexity|7.7947|  |7.7947|
24-11-25 18:40:48 | I |       |val_valid|      1|word_perplexity|9.0399|  |9.0399|
24-11-25 18:40:48 | I |       
24-11-25 18:40:48 | I | quantizing weights for layer model.layers.0
24-11-25 18:40:48 | I | collecting info in model.layers.0
24-11-25 18:40:48 | I | collecting info in model.layers.0
24-11-25 18:40:48 | I | collecting info in model.layers.0
24-11-25 18:40:48 | I | collecting info in model.layers.0
24-11-25 18:40:49 | I | collecting calibration activations in model.layers.0
24-11-25 18:40:49 | I | collecting calibration activations in model.layers.0
24-11-25 18:40:49 | I | collecting calibration activations in model.layers.0
24-11-25 18:40:49 | I | collecting calibration activations in model.layers.0
24-11-25 18:40:49 | I | - Quantizing decoder layer model.layers.0
24-11-25 18:40:49 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 18:40:50 | I |       - range scale = [    1.0000]
24-11-25 18:40:50 | I |         sum  error  = [    0.0624]
24-11-25 18:40:50 | I |         best error  = [    0.0624]
24-11-25 18:40:50 | I |     + error = [0.0624]
24-11-25 18:40:51 | I |       - range scale = [    1.0000]
24-11-25 18:40:51 | I |         sum  error  = [    0.6239]
24-11-25 18:40:51 | I |         best error  = [    0.6239]
24-11-25 18:40:51 | I |     + error = [0.6239]
24-11-25 18:40:51 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 18:40:52 | I |       - range scale = [    1.0000]
24-11-25 18:40:52 | I |         sum  error  = [    0.0706]
24-11-25 18:40:52 | I |         best error  = [    0.0706]
24-11-25 18:40:52 | I |     + error = [0.0706]
24-11-25 18:40:52 | I |       - range scale = [    1.0000]
24-11-25 18:40:52 | I |         sum  error  = [    0.5942]
24-11-25 18:40:52 | I |         best error  = [    0.5942]
24-11-25 18:40:52 | I |     + error = [0.5942]
24-11-25 18:40:53 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 18:40:53 | I |       - range scale = [    1.0000]
24-11-25 18:40:53 | I |         sum  error  = [    0.2408]
24-11-25 18:40:53 | I |         best error  = [    0.2408]
24-11-25 18:40:53 | I |     + error = [0.2408]
24-11-25 18:40:54 | I |       - range scale = [    1.0000]
24-11-25 18:40:54 | I |         sum  error  = [    1.8850]
24-11-25 18:40:54 | I |         best error  = [    1.8850]
24-11-25 18:40:54 | I |     + error = [1.8850]
24-11-25 18:40:54 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 18:40:55 | I |       - range scale = [    1.0000]
24-11-25 18:40:55 | I |         sum  error  = [    0.0716]
24-11-25 18:40:55 | I |         best error  = [    0.0716]
24-11-25 18:40:55 | I |     + error = [0.0716]
24-11-25 18:40:56 | I |       - range scale = [    1.0000]
24-11-25 18:40:56 | I |         sum  error  = [    0.6980]
24-11-25 18:40:56 | I |         best error  = [    0.6980]
24-11-25 18:40:56 | I |     + error = [0.6980]
24-11-25 18:40:56 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 18:40:57 | I |       - range scale = [    1.0000]
24-11-25 18:40:57 | I |         sum  error  = [    1.1767]
24-11-25 18:40:57 | I |         best error  = [    1.1767]
24-11-25 18:40:57 | I |     + error = [1.1767]
24-11-25 18:40:57 | I |       - range scale = [    1.0000]
24-11-25 18:40:57 | I |         sum  error  = [   13.0601]
24-11-25 18:40:57 | I |         best error  = [   13.0601]
24-11-25 18:40:57 | I |     + error = [13.0601]
24-11-25 18:40:58 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 18:40:58 | I |       - range scale = [    1.0000]
24-11-25 18:40:58 | I |         sum  error  = [    1.3629]
24-11-25 18:40:58 | I |         best error  = [    1.3629]
24-11-25 18:40:58 | I |     + error = [1.3629]
24-11-25 18:40:59 | I |       - range scale = [    1.0000]
24-11-25 18:40:59 | I |         sum  error  = [   13.5469]
24-11-25 18:40:59 | I |         best error  = [   13.5469]
24-11-25 18:40:59 | I |     + error = [13.5469]
24-11-25 18:40:59 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 18:41:00 | I |       - range scale = [    1.0000]
24-11-25 18:41:00 | I |         sum  error  = [    2.3579]
24-11-25 18:41:00 | I |         best error  = [    2.3579]
24-11-25 18:41:00 | I |     + error = [2.3579]
24-11-25 18:41:01 | I |       - range scale = [    1.0000]
24-11-25 18:41:01 | I |         sum  error  = [   13.3808]
24-11-25 18:41:01 | I |         best error  = [   13.3808]
24-11-25 18:41:01 | I |     + error = [13.3808]
24-11-25 18:41:01 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 18:41:02 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 18:41:04 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 18:41:05 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 18:41:06 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 18:41:08 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 18:41:09 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 18:41:13 | I | quantizing activations for layer model.layers.0
24-11-25 18:41:13 | I | collecting info in model.layers.0
24-11-25 18:41:13 | I | collecting info in model.layers.0
24-11-25 18:41:13 | I | collecting info in model.layers.0
24-11-25 18:41:13 | I | collecting info in model.layers.0
24-11-25 18:41:13 | I | collecting calibration activations in model.layers.0
24-11-25 18:41:13 | I | collecting calibration activations in model.layers.0
24-11-25 18:41:13 | I | collecting calibration activations in model.layers.0
24-11-25 18:41:14 | I | collecting calibration activations in model.layers.0
24-11-25 18:41:15 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 18:41:15 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 18:41:15 | I | - Evaluator: gptq
24-11-25 18:41:15 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 18:41:15 | I | - Batch_size: 8
24-11-25 18:41:15 | I |   + Max_seq_length: 2048
24-11-25 18:41:57 | I |     - Results:
24-11-25 18:41:57 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 18:41:57 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 18:41:57 | I |       |wikitext |      1|word_perplexity|7.8632|  |7.8632|
24-11-25 18:41:57 | I |       |val_valid|      1|word_perplexity|9.1216|  |9.1216|
24-11-25 18:41:57 | I |       
24-11-25 18:41:57 | I | forward this layer
24-11-25 18:41:57 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/122.pt
24-11-25 18:41:57 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/122.pt
24-11-25 18:41:57 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 18:41:57 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 18:41:57 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 18:41:57 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 18:41:57 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 18:41:57 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 18:41:57 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 18:41:57 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 18:41:57 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 18:41:57 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 18:41:57 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 18:41:57 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 18:41:57 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 18:41:57 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 18:41:57 | I | in layer model.layers.0
24-11-25 18:41:57 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 18:41:57 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 18:41:57 | I | - Evaluator: gptq
24-11-25 18:41:57 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 18:41:57 | I | - Batch_size: 8
24-11-25 18:41:57 | I |   + Max_seq_length: 2048
24-11-25 18:42:36 | I |     - Results:
24-11-25 18:42:36 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 18:42:36 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 18:42:36 | I |       |wikitext |      1|word_perplexity|7.7947|  |7.7947|
24-11-25 18:42:36 | I |       |val_valid|      1|word_perplexity|9.0399|  |9.0399|
24-11-25 18:42:36 | I |       
24-11-25 18:42:36 | I | quantizing weights for layer model.layers.0
24-11-25 18:42:36 | I | collecting info in model.layers.0
24-11-25 18:42:36 | I | collecting info in model.layers.0
24-11-25 18:42:36 | I | collecting info in model.layers.0
24-11-25 18:42:36 | I | collecting info in model.layers.0
24-11-25 18:42:36 | I | collecting calibration activations in model.layers.0
24-11-25 18:42:36 | I | collecting calibration activations in model.layers.0
24-11-25 18:42:36 | I | collecting calibration activations in model.layers.0
24-11-25 18:42:36 | I | collecting calibration activations in model.layers.0
24-11-25 18:42:37 | I | - Quantizing decoder layer model.layers.0
24-11-25 18:42:37 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 18:42:38 | I |       - range scale = [    1.0000]
24-11-25 18:42:38 | I |         sum  error  = [    0.0588]
24-11-25 18:42:38 | I |         best error  = [    0.0588]
24-11-25 18:42:38 | I |     + error = [0.0588]
24-11-25 18:42:38 | I |       - range scale = [    1.0000]
24-11-25 18:42:38 | I |         sum  error  = [    0.5870]
24-11-25 18:42:38 | I |         best error  = [    0.5870]
24-11-25 18:42:38 | I |     + error = [0.5870]
24-11-25 18:42:38 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 18:42:39 | I |       - range scale = [    1.0000]
24-11-25 18:42:39 | I |         sum  error  = [    0.0663]
24-11-25 18:42:39 | I |         best error  = [    0.0663]
24-11-25 18:42:39 | I |     + error = [0.0663]
24-11-25 18:42:40 | I |       - range scale = [    1.0000]
24-11-25 18:42:40 | I |         sum  error  = [    0.5679]
24-11-25 18:42:40 | I |         best error  = [    0.5679]
24-11-25 18:42:40 | I |     + error = [0.5679]
24-11-25 18:42:40 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 18:42:41 | I |       - range scale = [    1.0000]
24-11-25 18:42:41 | I |         sum  error  = [    0.2343]
24-11-25 18:42:41 | I |         best error  = [    0.2343]
24-11-25 18:42:41 | I |     + error = [0.2343]
24-11-25 18:42:41 | I |       - range scale = [    1.0000]
24-11-25 18:42:41 | I |         sum  error  = [    1.8468]
24-11-25 18:42:41 | I |         best error  = [    1.8468]
24-11-25 18:42:41 | I |     + error = [1.8468]
24-11-25 18:42:42 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 18:42:42 | I |       - range scale = [    1.0000]
24-11-25 18:42:42 | I |         sum  error  = [    0.0649]
24-11-25 18:42:42 | I |         best error  = [    0.0649]
24-11-25 18:42:42 | I |     + error = [0.0649]
24-11-25 18:42:43 | I |       - range scale = [    1.0000]
24-11-25 18:42:43 | I |         sum  error  = [    0.6276]
24-11-25 18:42:43 | I |         best error  = [    0.6276]
24-11-25 18:42:43 | I |     + error = [0.6276]
24-11-25 18:42:43 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 18:42:44 | I |       - range scale = [    1.0000]
24-11-25 18:42:44 | I |         sum  error  = [    1.1270]
24-11-25 18:42:44 | I |         best error  = [    1.1270]
24-11-25 18:42:44 | I |     + error = [1.1270]
24-11-25 18:42:45 | I |       - range scale = [    1.0000]
24-11-25 18:42:45 | I |         sum  error  = [   12.4973]
24-11-25 18:42:45 | I |         best error  = [   12.4973]
24-11-25 18:42:45 | I |     + error = [12.4973]
24-11-25 18:42:45 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 18:42:46 | I |       - range scale = [    1.0000]
24-11-25 18:42:46 | I |         sum  error  = [    1.3061]
24-11-25 18:42:46 | I |         best error  = [    1.3061]
24-11-25 18:42:46 | I |     + error = [1.3061]
24-11-25 18:42:46 | I |       - range scale = [    1.0000]
24-11-25 18:42:46 | I |         sum  error  = [   12.9206]
24-11-25 18:42:46 | I |         best error  = [   12.9206]
24-11-25 18:42:46 | I |     + error = [12.9206]
24-11-25 18:42:47 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 18:42:47 | I |       - range scale = [    1.0000]
24-11-25 18:42:47 | I |         sum  error  = [    2.8455]
24-11-25 18:42:47 | I |         best error  = [    2.8455]
24-11-25 18:42:47 | I |     + error = [2.8455]
24-11-25 18:42:48 | I |       - range scale = [    1.0000]
24-11-25 18:42:48 | I |         sum  error  = [   16.1963]
24-11-25 18:42:48 | I |         best error  = [   16.1963]
24-11-25 18:42:48 | I |     + error = [16.1963]
24-11-25 18:42:48 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 18:42:50 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 18:42:51 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 18:42:52 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 18:42:54 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 18:42:55 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 18:42:57 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 18:43:00 | I | quantizing activations for layer model.layers.0
24-11-25 18:43:00 | I | collecting info in model.layers.0
24-11-25 18:43:00 | I | collecting info in model.layers.0
24-11-25 18:43:00 | I | collecting info in model.layers.0
24-11-25 18:43:00 | I | collecting info in model.layers.0
24-11-25 18:43:00 | I | collecting calibration activations in model.layers.0
24-11-25 18:43:01 | I | collecting calibration activations in model.layers.0
24-11-25 18:43:01 | I | collecting calibration activations in model.layers.0
24-11-25 18:43:01 | I | collecting calibration activations in model.layers.0
24-11-25 18:43:03 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 18:43:03 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 18:43:03 | I | - Evaluator: gptq
24-11-25 18:43:03 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 18:43:03 | I | - Batch_size: 8
24-11-25 18:43:03 | I |   + Max_seq_length: 2048
24-11-25 18:43:44 | I |     - Results:
24-11-25 18:43:44 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 18:43:44 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 18:43:44 | I |       |wikitext |      1|word_perplexity|7.8551|  |7.8551|
24-11-25 18:43:44 | I |       |val_valid|      1|word_perplexity|9.1266|  |9.1266|
24-11-25 18:43:44 | I |       
24-11-25 18:43:44 | I | forward this layer
24-11-25 18:43:44 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/123.pt
24-11-25 18:43:44 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/123.pt
24-11-25 18:43:45 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 18:43:45 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 18:43:45 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 18:43:45 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 18:43:45 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 18:43:45 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 18:43:45 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 18:43:45 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 18:43:45 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 18:43:45 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 18:43:45 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 18:43:45 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 18:43:45 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 18:43:45 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 18:43:45 | I | [47] done with optimizer step
24-11-25 18:43:45 | I | epoch 001:     62 / 409600000 loss=0.000202988, loss_per_token=0.41572, loss_sum=13622.3, wps=152.5, ups=0, wpb=32768, bsz=64, num_updates=48, lr=0.000144, gnorm=47.678, clip=100, loss_scale=0.0078, train_wall=215, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=13555, lmquant_ppl_result_wikitext_in_train_no_quant=7.79468, lmquant_ppl_result_val_in_train_no_quant=9.03995, lmquant_ppl_result_wikitext_in_train_with_quant=7.8551, lmquant_ppl_result_val_in_train_with_quant=9.12657
24-11-25 18:43:45 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 18:43:45 | I | in layer model.layers.0
24-11-25 18:43:45 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 18:43:45 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 18:43:45 | I | - Evaluator: gptq
24-11-25 18:43:45 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 18:43:45 | I | - Batch_size: 8
24-11-25 18:43:45 | I |   + Max_seq_length: 2048
24-11-25 18:44:23 | I |     - Results:
24-11-25 18:44:23 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 18:44:23 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 18:44:23 | I |       |wikitext |      1|word_perplexity|7.7994|  |7.7994|
24-11-25 18:44:23 | I |       |val_valid|      1|word_perplexity|9.0458|  |9.0458|
24-11-25 18:44:23 | I |       
24-11-25 18:44:23 | I | quantizing weights for layer model.layers.0
24-11-25 18:44:23 | I | collecting info in model.layers.0
24-11-25 18:44:23 | I | collecting info in model.layers.0
24-11-25 18:44:23 | I | collecting info in model.layers.0
24-11-25 18:44:23 | I | collecting info in model.layers.0
24-11-25 18:44:24 | I | collecting calibration activations in model.layers.0
24-11-25 18:44:24 | I | collecting calibration activations in model.layers.0
24-11-25 18:44:24 | I | collecting calibration activations in model.layers.0
24-11-25 18:44:24 | I | collecting calibration activations in model.layers.0
24-11-25 18:44:24 | I | - Quantizing decoder layer model.layers.0
24-11-25 18:44:24 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 18:44:25 | I |       - range scale = [    1.0000]
24-11-25 18:44:25 | I |         sum  error  = [    0.0598]
24-11-25 18:44:25 | I |         best error  = [    0.0598]
24-11-25 18:44:25 | I |     + error = [0.0598]
24-11-25 18:44:26 | I |       - range scale = [    1.0000]
24-11-25 18:44:26 | I |         sum  error  = [    0.5966]
24-11-25 18:44:26 | I |         best error  = [    0.5966]
24-11-25 18:44:26 | I |     + error = [0.5966]
24-11-25 18:44:26 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 18:44:27 | I |       - range scale = [    1.0000]
24-11-25 18:44:27 | I |         sum  error  = [    0.0640]
24-11-25 18:44:27 | I |         best error  = [    0.0640]
24-11-25 18:44:27 | I |     + error = [0.0640]
24-11-25 18:44:27 | I |       - range scale = [    1.0000]
24-11-25 18:44:27 | I |         sum  error  = [    0.5444]
24-11-25 18:44:27 | I |         best error  = [    0.5444]
24-11-25 18:44:27 | I |     + error = [0.5444]
24-11-25 18:44:28 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 18:44:28 | I |       - range scale = [    1.0000]
24-11-25 18:44:28 | I |         sum  error  = [    0.2400]
24-11-25 18:44:28 | I |         best error  = [    0.2400]
24-11-25 18:44:28 | I |     + error = [0.2400]
24-11-25 18:44:29 | I |       - range scale = [    1.0000]
24-11-25 18:44:29 | I |         sum  error  = [    1.8568]
24-11-25 18:44:29 | I |         best error  = [    1.8568]
24-11-25 18:44:29 | I |     + error = [1.8568]
24-11-25 18:44:29 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 18:44:30 | I |       - range scale = [    1.0000]
24-11-25 18:44:30 | I |         sum  error  = [    0.0629]
24-11-25 18:44:30 | I |         best error  = [    0.0629]
24-11-25 18:44:30 | I |     + error = [0.0629]
24-11-25 18:44:31 | I |       - range scale = [    1.0000]
24-11-25 18:44:31 | I |         sum  error  = [    0.5967]
24-11-25 18:44:31 | I |         best error  = [    0.5967]
24-11-25 18:44:31 | I |     + error = [0.5967]
24-11-25 18:44:31 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 18:44:31 | I |       - range scale = [    1.0000]
24-11-25 18:44:31 | I |         sum  error  = [    1.0795]
24-11-25 18:44:31 | I |         best error  = [    1.0795]
24-11-25 18:44:31 | I |     + error = [1.0795]
24-11-25 18:44:32 | I |       - range scale = [    1.0000]
24-11-25 18:44:32 | I |         sum  error  = [   11.9619]
24-11-25 18:44:32 | I |         best error  = [   11.9619]
24-11-25 18:44:32 | I |     + error = [11.9619]
24-11-25 18:44:32 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 18:44:33 | I |       - range scale = [    1.0000]
24-11-25 18:44:33 | I |         sum  error  = [    1.2483]
24-11-25 18:44:33 | I |         best error  = [    1.2483]
24-11-25 18:44:33 | I |     + error = [1.2483]
24-11-25 18:44:34 | I |       - range scale = [    1.0000]
24-11-25 18:44:34 | I |         sum  error  = [   12.3602]
24-11-25 18:44:34 | I |         best error  = [   12.3602]
24-11-25 18:44:34 | I |     + error = [12.3602]
24-11-25 18:44:34 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 18:44:35 | I |       - range scale = [    1.0000]
24-11-25 18:44:35 | I |         sum  error  = [    2.7514]
24-11-25 18:44:35 | I |         best error  = [    2.7514]
24-11-25 18:44:35 | I |     + error = [2.7514]
24-11-25 18:44:36 | I |       - range scale = [    1.0000]
24-11-25 18:44:36 | I |         sum  error  = [   16.0745]
24-11-25 18:44:36 | I |         best error  = [   16.0745]
24-11-25 18:44:36 | I |     + error = [16.0745]
24-11-25 18:44:36 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 18:44:37 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 18:44:39 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 18:44:40 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 18:44:41 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 18:44:43 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 18:44:44 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 18:44:48 | I | quantizing activations for layer model.layers.0
24-11-25 18:44:48 | I | collecting info in model.layers.0
24-11-25 18:44:48 | I | collecting info in model.layers.0
24-11-25 18:44:48 | I | collecting info in model.layers.0
24-11-25 18:44:48 | I | collecting info in model.layers.0
24-11-25 18:44:48 | I | collecting calibration activations in model.layers.0
24-11-25 18:44:48 | I | collecting calibration activations in model.layers.0
24-11-25 18:44:48 | I | collecting calibration activations in model.layers.0
24-11-25 18:44:48 | I | collecting calibration activations in model.layers.0
24-11-25 18:44:50 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 18:44:50 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 18:44:50 | I | - Evaluator: gptq
24-11-25 18:44:50 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 18:44:50 | I | - Batch_size: 8
24-11-25 18:44:50 | I |   + Max_seq_length: 2048
24-11-25 18:45:32 | I |     - Results:
24-11-25 18:45:32 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 18:45:32 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 18:45:32 | I |       |wikitext |      1|word_perplexity|7.8957|  |7.8957|
24-11-25 18:45:32 | I |       |val_valid|      1|word_perplexity|9.1302|  |9.1302|
24-11-25 18:45:32 | I |       
24-11-25 18:45:32 | I | forward this layer
24-11-25 18:45:32 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/124.pt
24-11-25 18:45:32 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/124.pt
24-11-25 18:45:32 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 18:45:32 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 18:45:32 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 18:45:32 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 18:45:32 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 18:45:32 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 18:45:32 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 18:45:32 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 18:45:32 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 18:45:32 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 18:45:32 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 18:45:32 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 18:45:32 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 18:45:32 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 18:45:32 | I | in layer model.layers.0
24-11-25 18:45:32 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 18:45:32 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 18:45:32 | I | - Evaluator: gptq
24-11-25 18:45:32 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 18:45:32 | I | - Batch_size: 8
24-11-25 18:45:32 | I |   + Max_seq_length: 2048
24-11-25 18:46:10 | I |     - Results:
24-11-25 18:46:10 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 18:46:10 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 18:46:10 | I |       |wikitext |      1|word_perplexity|7.7994|  |7.7994|
24-11-25 18:46:10 | I |       |val_valid|      1|word_perplexity|9.0458|  |9.0458|
24-11-25 18:46:10 | I |       
24-11-25 18:46:10 | I | quantizing weights for layer model.layers.0
24-11-25 18:46:10 | I | collecting info in model.layers.0
24-11-25 18:46:10 | I | collecting info in model.layers.0
24-11-25 18:46:10 | I | collecting info in model.layers.0
24-11-25 18:46:10 | I | collecting info in model.layers.0
24-11-25 18:46:11 | I | collecting calibration activations in model.layers.0
24-11-25 18:46:11 | I | collecting calibration activations in model.layers.0
24-11-25 18:46:11 | I | collecting calibration activations in model.layers.0
24-11-25 18:46:11 | I | collecting calibration activations in model.layers.0
24-11-25 18:46:12 | I | - Quantizing decoder layer model.layers.0
24-11-25 18:46:12 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 18:46:12 | I |       - range scale = [    1.0000]
24-11-25 18:46:12 | I |         sum  error  = [    0.0598]
24-11-25 18:46:12 | I |         best error  = [    0.0598]
24-11-25 18:46:12 | I |     + error = [0.0598]
24-11-25 18:46:13 | I |       - range scale = [    1.0000]
24-11-25 18:46:13 | I |         sum  error  = [    0.5980]
24-11-25 18:46:13 | I |         best error  = [    0.5980]
24-11-25 18:46:13 | I |     + error = [0.5980]
24-11-25 18:46:13 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 18:46:14 | I |       - range scale = [    1.0000]
24-11-25 18:46:14 | I |         sum  error  = [    0.0659]
24-11-25 18:46:14 | I |         best error  = [    0.0659]
24-11-25 18:46:14 | I |     + error = [0.0659]
24-11-25 18:46:15 | I |       - range scale = [    1.0000]
24-11-25 18:46:15 | I |         sum  error  = [    0.5644]
24-11-25 18:46:15 | I |         best error  = [    0.5644]
24-11-25 18:46:15 | I |     + error = [0.5644]
24-11-25 18:46:15 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 18:46:16 | I |       - range scale = [    1.0000]
24-11-25 18:46:16 | I |         sum  error  = [    0.2402]
24-11-25 18:46:16 | I |         best error  = [    0.2402]
24-11-25 18:46:16 | I |     + error = [0.2402]
24-11-25 18:46:16 | I |       - range scale = [    1.0000]
24-11-25 18:46:16 | I |         sum  error  = [    1.8580]
24-11-25 18:46:16 | I |         best error  = [    1.8580]
24-11-25 18:46:16 | I |     + error = [1.8580]
24-11-25 18:46:16 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 18:46:17 | I |       - range scale = [    1.0000]
24-11-25 18:46:17 | I |         sum  error  = [    0.0651]
24-11-25 18:46:17 | I |         best error  = [    0.0651]
24-11-25 18:46:17 | I |     + error = [0.0651]
24-11-25 18:46:18 | I |       - range scale = [    1.0000]
24-11-25 18:46:18 | I |         sum  error  = [    0.6286]
24-11-25 18:46:18 | I |         best error  = [    0.6286]
24-11-25 18:46:18 | I |     + error = [0.6286]
24-11-25 18:46:18 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 18:46:19 | I |       - range scale = [    1.0000]
24-11-25 18:46:19 | I |         sum  error  = [    1.1126]
24-11-25 18:46:19 | I |         best error  = [    1.1126]
24-11-25 18:46:19 | I |     + error = [1.1126]
24-11-25 18:46:19 | I |       - range scale = [    1.0000]
24-11-25 18:46:19 | I |         sum  error  = [   12.3454]
24-11-25 18:46:19 | I |         best error  = [   12.3454]
24-11-25 18:46:19 | I |     + error = [12.3454]
24-11-25 18:46:20 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 18:46:20 | I |       - range scale = [    1.0000]
24-11-25 18:46:20 | I |         sum  error  = [    1.2884]
24-11-25 18:46:20 | I |         best error  = [    1.2884]
24-11-25 18:46:20 | I |     + error = [1.2884]
24-11-25 18:46:21 | I |       - range scale = [    1.0000]
24-11-25 18:46:21 | I |         sum  error  = [   12.7753]
24-11-25 18:46:21 | I |         best error  = [   12.7753]
24-11-25 18:46:21 | I |     + error = [12.7753]
24-11-25 18:46:21 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 18:46:22 | I |       - range scale = [    1.0000]
24-11-25 18:46:22 | I |         sum  error  = [    2.8112]
24-11-25 18:46:22 | I |         best error  = [    2.8112]
24-11-25 18:46:22 | I |     + error = [2.8112]
24-11-25 18:46:23 | I |       - range scale = [    1.0000]
24-11-25 18:46:23 | I |         sum  error  = [   16.0846]
24-11-25 18:46:23 | I |         best error  = [   16.0846]
24-11-25 18:46:23 | I |     + error = [16.0846]
24-11-25 18:46:23 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 18:46:24 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 18:46:26 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 18:46:27 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 18:46:29 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 18:46:30 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 18:46:31 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 18:46:35 | I | quantizing activations for layer model.layers.0
24-11-25 18:46:35 | I | collecting info in model.layers.0
24-11-25 18:46:35 | I | collecting info in model.layers.0
24-11-25 18:46:35 | I | collecting info in model.layers.0
24-11-25 18:46:35 | I | collecting info in model.layers.0
24-11-25 18:46:35 | I | collecting calibration activations in model.layers.0
24-11-25 18:46:35 | I | collecting calibration activations in model.layers.0
24-11-25 18:46:35 | I | collecting calibration activations in model.layers.0
24-11-25 18:46:35 | I | collecting calibration activations in model.layers.0
24-11-25 18:46:37 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 18:46:37 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 18:46:37 | I | - Evaluator: gptq
24-11-25 18:46:37 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 18:46:37 | I | - Batch_size: 8
24-11-25 18:46:37 | I |   + Max_seq_length: 2048
24-11-25 18:47:19 | I |     - Results:
24-11-25 18:47:19 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 18:47:19 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 18:47:19 | I |       |wikitext |      1|word_perplexity|7.8765|  |7.8765|
24-11-25 18:47:19 | I |       |val_valid|      1|word_perplexity|9.1239|  |9.1239|
24-11-25 18:47:19 | I |       
24-11-25 18:47:19 | I | forward this layer
24-11-25 18:47:19 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/125.pt
24-11-25 18:47:19 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/125.pt
24-11-25 18:47:19 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 18:47:19 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 18:47:19 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 18:47:19 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 18:47:19 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 18:47:19 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 18:47:19 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 18:47:19 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 18:47:19 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 18:47:19 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 18:47:19 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 18:47:19 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 18:47:19 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 18:47:19 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 18:47:19 | I | [48] done with optimizer step
24-11-25 18:47:19 | I | epoch 001:     63 / 409600000 loss=0.000184085, loss_per_token=0.377007, loss_sum=12353.8, wps=152.7, ups=0, wpb=32768, bsz=64, num_updates=49, lr=0.000147, gnorm=39.02, clip=100, loss_scale=0.0078, train_wall=214, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=13770, lmquant_ppl_result_wikitext_in_train_no_quant=7.79943, lmquant_ppl_result_val_in_train_no_quant=9.04576, lmquant_ppl_result_wikitext_in_train_with_quant=7.87645, lmquant_ppl_result_val_in_train_with_quant=9.12394
24-11-25 18:47:19 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 18:47:19 | I | in layer model.layers.0
24-11-25 18:47:19 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 18:47:19 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 18:47:19 | I | - Evaluator: gptq
24-11-25 18:47:19 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 18:47:19 | I | - Batch_size: 8
24-11-25 18:47:19 | I |   + Max_seq_length: 2048
24-11-25 18:47:58 | I |     - Results:
24-11-25 18:47:58 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 18:47:58 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 18:47:58 | I |       |wikitext |      1|word_perplexity|7.7987|  |7.7987|
24-11-25 18:47:58 | I |       |val_valid|      1|word_perplexity|9.0461|  |9.0461|
24-11-25 18:47:58 | I |       
24-11-25 18:47:58 | I | quantizing weights for layer model.layers.0
24-11-25 18:47:58 | I | collecting info in model.layers.0
24-11-25 18:47:58 | I | collecting info in model.layers.0
24-11-25 18:47:58 | I | collecting info in model.layers.0
24-11-25 18:47:58 | I | collecting info in model.layers.0
24-11-25 18:47:58 | I | collecting calibration activations in model.layers.0
24-11-25 18:47:58 | I | collecting calibration activations in model.layers.0
24-11-25 18:47:58 | I | collecting calibration activations in model.layers.0
24-11-25 18:47:59 | I | collecting calibration activations in model.layers.0
24-11-25 18:47:59 | I | - Quantizing decoder layer model.layers.0
24-11-25 18:47:59 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 18:48:00 | I |       - range scale = [    1.0000]
24-11-25 18:48:00 | I |         sum  error  = [    0.0604]
24-11-25 18:48:00 | I |         best error  = [    0.0604]
24-11-25 18:48:00 | I |     + error = [0.0604]
24-11-25 18:48:00 | I |       - range scale = [    1.0000]
24-11-25 18:48:00 | I |         sum  error  = [    0.6163]
24-11-25 18:48:00 | I |         best error  = [    0.6163]
24-11-25 18:48:00 | I |     + error = [0.6163]
24-11-25 18:48:01 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 18:48:01 | I |       - range scale = [    1.0000]
24-11-25 18:48:01 | I |         sum  error  = [    0.0610]
24-11-25 18:48:01 | I |         best error  = [    0.0610]
24-11-25 18:48:01 | I |     + error = [0.0610]
24-11-25 18:48:02 | I |       - range scale = [    1.0000]
24-11-25 18:48:02 | I |         sum  error  = [    0.5344]
24-11-25 18:48:02 | I |         best error  = [    0.5344]
24-11-25 18:48:02 | I |     + error = [0.5344]
24-11-25 18:48:02 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 18:48:03 | I |       - range scale = [    1.0000]
24-11-25 18:48:03 | I |         sum  error  = [    0.2415]
24-11-25 18:48:03 | I |         best error  = [    0.2415]
24-11-25 18:48:03 | I |     + error = [0.2415]
24-11-25 18:48:04 | I |       - range scale = [    1.0000]
24-11-25 18:48:04 | I |         sum  error  = [    1.8333]
24-11-25 18:48:04 | I |         best error  = [    1.8333]
24-11-25 18:48:04 | I |     + error = [1.8333]
24-11-25 18:48:04 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 18:48:04 | I |       - range scale = [    1.0000]
24-11-25 18:48:04 | I |         sum  error  = [    0.0583]
24-11-25 18:48:04 | I |         best error  = [    0.0583]
24-11-25 18:48:04 | I |     + error = [0.0583]
24-11-25 18:48:05 | I |       - range scale = [    1.0000]
24-11-25 18:48:05 | I |         sum  error  = [    0.5515]
24-11-25 18:48:05 | I |         best error  = [    0.5515]
24-11-25 18:48:05 | I |     + error = [0.5515]
24-11-25 18:48:05 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 18:48:06 | I |       - range scale = [    1.0000]
24-11-25 18:48:06 | I |         sum  error  = [    1.0644]
24-11-25 18:48:06 | I |         best error  = [    1.0644]
24-11-25 18:48:06 | I |     + error = [1.0644]
24-11-25 18:48:07 | I |       - range scale = [    1.0000]
24-11-25 18:48:07 | I |         sum  error  = [   11.7870]
24-11-25 18:48:07 | I |         best error  = [   11.7870]
24-11-25 18:48:07 | I |     + error = [11.7870]
24-11-25 18:48:07 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 18:48:08 | I |       - range scale = [    1.0000]
24-11-25 18:48:08 | I |         sum  error  = [    1.2328]
24-11-25 18:48:08 | I |         best error  = [    1.2328]
24-11-25 18:48:08 | I |     + error = [1.2328]
24-11-25 18:48:09 | I |       - range scale = [    1.0000]
24-11-25 18:48:09 | I |         sum  error  = [   12.1727]
24-11-25 18:48:09 | I |         best error  = [   12.1727]
24-11-25 18:48:09 | I |     + error = [12.1727]
24-11-25 18:48:09 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 18:48:09 | I |       - range scale = [    1.0000]
24-11-25 18:48:09 | I |         sum  error  = [    3.3877]
24-11-25 18:48:09 | I |         best error  = [    3.3877]
24-11-25 18:48:09 | I |     + error = [3.3877]
24-11-25 18:48:10 | I |       - range scale = [    1.0000]
24-11-25 18:48:10 | I |         sum  error  = [   19.5666]
24-11-25 18:48:10 | I |         best error  = [   19.5666]
24-11-25 18:48:10 | I |     + error = [19.5666]
24-11-25 18:48:10 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 18:48:12 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 18:48:13 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 18:48:15 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 18:48:16 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 18:48:18 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 18:48:19 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 18:48:22 | I | quantizing activations for layer model.layers.0
24-11-25 18:48:22 | I | collecting info in model.layers.0
24-11-25 18:48:22 | I | collecting info in model.layers.0
24-11-25 18:48:22 | I | collecting info in model.layers.0
24-11-25 18:48:22 | I | collecting info in model.layers.0
24-11-25 18:48:23 | I | collecting calibration activations in model.layers.0
24-11-25 18:48:23 | I | collecting calibration activations in model.layers.0
24-11-25 18:48:23 | I | collecting calibration activations in model.layers.0
24-11-25 18:48:23 | I | collecting calibration activations in model.layers.0
24-11-25 18:48:25 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 18:48:25 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 18:48:25 | I | - Evaluator: gptq
24-11-25 18:48:25 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 18:48:25 | I | - Batch_size: 8
24-11-25 18:48:25 | I |   + Max_seq_length: 2048
24-11-25 18:49:06 | I |     - Results:
24-11-25 18:49:06 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 18:49:06 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 18:49:06 | I |       |wikitext |      1|word_perplexity|7.8647|  |7.8647|
24-11-25 18:49:06 | I |       |val_valid|      1|word_perplexity|9.1298|  |9.1298|
24-11-25 18:49:06 | I |       
24-11-25 18:49:06 | I | forward this layer
24-11-25 18:49:06 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/126.pt
24-11-25 18:49:06 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/126.pt
24-11-25 18:49:07 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 18:49:07 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 18:49:07 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 18:49:07 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 18:49:07 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 18:49:07 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 18:49:07 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 18:49:07 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 18:49:07 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 18:49:07 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 18:49:07 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 18:49:07 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 18:49:07 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 18:49:07 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 18:49:07 | I | in layer model.layers.0
24-11-25 18:49:07 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 18:49:07 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 18:49:07 | I | - Evaluator: gptq
24-11-25 18:49:07 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 18:49:07 | I | - Batch_size: 8
24-11-25 18:49:07 | I |   + Max_seq_length: 2048
24-11-25 18:49:45 | I |     - Results:
24-11-25 18:49:45 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 18:49:45 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 18:49:45 | I |       |wikitext |      1|word_perplexity|7.7987|  |7.7987|
24-11-25 18:49:45 | I |       |val_valid|      1|word_perplexity|9.0461|  |9.0461|
24-11-25 18:49:45 | I |       
24-11-25 18:49:45 | I | quantizing weights for layer model.layers.0
24-11-25 18:49:45 | I | collecting info in model.layers.0
24-11-25 18:49:45 | I | collecting info in model.layers.0
24-11-25 18:49:45 | I | collecting info in model.layers.0
24-11-25 18:49:45 | I | collecting info in model.layers.0
24-11-25 18:49:45 | I | collecting calibration activations in model.layers.0
24-11-25 18:49:46 | I | collecting calibration activations in model.layers.0
24-11-25 18:49:46 | I | collecting calibration activations in model.layers.0
24-11-25 18:49:46 | I | collecting calibration activations in model.layers.0
24-11-25 18:49:46 | I | - Quantizing decoder layer model.layers.0
24-11-25 18:49:46 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 18:49:47 | I |       - range scale = [    1.0000]
24-11-25 18:49:47 | I |         sum  error  = [    0.0633]
24-11-25 18:49:47 | I |         best error  = [    0.0633]
24-11-25 18:49:47 | I |     + error = [0.0633]
24-11-25 18:49:47 | I |       - range scale = [    1.0000]
24-11-25 18:49:47 | I |         sum  error  = [    0.6321]
24-11-25 18:49:47 | I |         best error  = [    0.6321]
24-11-25 18:49:47 | I |     + error = [0.6321]
24-11-25 18:49:48 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 18:49:48 | I |       - range scale = [    1.0000]
24-11-25 18:49:48 | I |         sum  error  = [    0.0655]
24-11-25 18:49:48 | I |         best error  = [    0.0655]
24-11-25 18:49:48 | I |     + error = [0.0655]
24-11-25 18:49:49 | I |       - range scale = [    1.0000]
24-11-25 18:49:49 | I |         sum  error  = [    0.5738]
24-11-25 18:49:49 | I |         best error  = [    0.5738]
24-11-25 18:49:49 | I |     + error = [0.5738]
24-11-25 18:49:49 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 18:49:50 | I |       - range scale = [    1.0000]
24-11-25 18:49:50 | I |         sum  error  = [    0.2461]
24-11-25 18:49:50 | I |         best error  = [    0.2461]
24-11-25 18:49:50 | I |     + error = [0.2461]
24-11-25 18:49:51 | I |       - range scale = [    1.0000]
24-11-25 18:49:51 | I |         sum  error  = [    1.8607]
24-11-25 18:49:51 | I |         best error  = [    1.8607]
24-11-25 18:49:51 | I |     + error = [1.8607]
24-11-25 18:49:51 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 18:49:52 | I |       - range scale = [    1.0000]
24-11-25 18:49:52 | I |         sum  error  = [    0.0651]
24-11-25 18:49:52 | I |         best error  = [    0.0651]
24-11-25 18:49:52 | I |     + error = [0.0651]
24-11-25 18:49:52 | I |       - range scale = [    1.0000]
24-11-25 18:49:52 | I |         sum  error  = [    0.6147]
24-11-25 18:49:52 | I |         best error  = [    0.6147]
24-11-25 18:49:52 | I |     + error = [0.6147]
24-11-25 18:49:52 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 18:49:53 | I |       - range scale = [    1.0000]
24-11-25 18:49:53 | I |         sum  error  = [    1.0720]
24-11-25 18:49:53 | I |         best error  = [    1.0720]
24-11-25 18:49:53 | I |     + error = [1.0720]
24-11-25 18:49:54 | I |       - range scale = [    1.0000]
24-11-25 18:49:54 | I |         sum  error  = [   11.8700]
24-11-25 18:49:54 | I |         best error  = [   11.8700]
24-11-25 18:49:54 | I |     + error = [11.8700]
24-11-25 18:49:54 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 18:49:55 | I |       - range scale = [    1.0000]
24-11-25 18:49:55 | I |         sum  error  = [    1.2391]
24-11-25 18:49:55 | I |         best error  = [    1.2391]
24-11-25 18:49:55 | I |     + error = [1.2391]
24-11-25 18:49:56 | I |       - range scale = [    1.0000]
24-11-25 18:49:56 | I |         sum  error  = [   12.2607]
24-11-25 18:49:56 | I |         best error  = [   12.2607]
24-11-25 18:49:56 | I |     + error = [12.2607]
24-11-25 18:49:56 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 18:49:56 | I |       - range scale = [    1.0000]
24-11-25 18:49:56 | I |         sum  error  = [    3.3053]
24-11-25 18:49:56 | I |         best error  = [    3.3053]
24-11-25 18:49:56 | I |     + error = [3.3053]
24-11-25 18:49:57 | I |       - range scale = [    1.0000]
24-11-25 18:49:57 | I |         sum  error  = [   18.6427]
24-11-25 18:49:57 | I |         best error  = [   18.6427]
24-11-25 18:49:57 | I |     + error = [18.6427]
24-11-25 18:49:57 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 18:49:59 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 18:50:00 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 18:50:02 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 18:50:03 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 18:50:04 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 18:50:06 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 18:50:09 | I | quantizing activations for layer model.layers.0
24-11-25 18:50:09 | I | collecting info in model.layers.0
24-11-25 18:50:09 | I | collecting info in model.layers.0
24-11-25 18:50:09 | I | collecting info in model.layers.0
24-11-25 18:50:09 | I | collecting info in model.layers.0
24-11-25 18:50:09 | I | collecting calibration activations in model.layers.0
24-11-25 18:50:10 | I | collecting calibration activations in model.layers.0
24-11-25 18:50:10 | I | collecting calibration activations in model.layers.0
24-11-25 18:50:10 | I | collecting calibration activations in model.layers.0
24-11-25 18:50:12 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 18:50:12 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 18:50:12 | I | - Evaluator: gptq
24-11-25 18:50:12 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 18:50:12 | I | - Batch_size: 8
24-11-25 18:50:12 | I |   + Max_seq_length: 2048
24-11-25 18:50:53 | I |     - Results:
24-11-25 18:50:53 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 18:50:53 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 18:50:53 | I |       |wikitext |      1|word_perplexity|7.8931|  |7.8931|
24-11-25 18:50:53 | I |       |val_valid|      1|word_perplexity|9.1188|  |9.1188|
24-11-25 18:50:53 | I |       
24-11-25 18:50:53 | I | forward this layer
24-11-25 18:50:53 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/127.pt
24-11-25 18:50:53 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/127.pt
24-11-25 18:50:53 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 18:50:53 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 18:50:53 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 18:50:53 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 18:50:53 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 18:50:53 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 18:50:53 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 18:50:53 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 18:50:53 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 18:50:53 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 18:50:53 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 18:50:53 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 18:50:53 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 18:50:53 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 18:50:53 | I | [49] done with optimizer step
24-11-25 18:50:53 | I | epoch 001:     64 / 409600000 loss=9.56264e-05, loss_per_token=0.195843, loss_sum=6417.38, wps=153, ups=0, wpb=32768, bsz=64, num_updates=50, lr=0.00015, gnorm=22.102, clip=100, loss_scale=0.0078, train_wall=214, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=13984, lmquant_ppl_result_wikitext_in_train_no_quant=7.79867, lmquant_ppl_result_val_in_train_no_quant=9.04605, lmquant_ppl_result_wikitext_in_train_with_quant=7.89313, lmquant_ppl_result_val_in_train_with_quant=9.11884
24-11-25 18:50:54 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 18:50:54 | I | in layer model.layers.0
24-11-25 18:50:54 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 18:50:54 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 18:50:54 | I | - Evaluator: gptq
24-11-25 18:50:54 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 18:50:54 | I | - Batch_size: 8
24-11-25 18:50:54 | I |   + Max_seq_length: 2048
24-11-25 18:51:32 | I |     - Results:
24-11-25 18:51:32 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 18:51:32 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 18:51:32 | I |       |wikitext |      1|word_perplexity|7.7947|  |7.7947|
24-11-25 18:51:32 | I |       |val_valid|      1|word_perplexity|9.0440|  |9.0440|
24-11-25 18:51:32 | I |       
24-11-25 18:51:32 | I | quantizing weights for layer model.layers.0
24-11-25 18:51:32 | I | collecting info in model.layers.0
24-11-25 18:51:32 | I | collecting info in model.layers.0
24-11-25 18:51:32 | I | collecting info in model.layers.0
24-11-25 18:51:32 | I | collecting info in model.layers.0
24-11-25 18:51:32 | I | collecting calibration activations in model.layers.0
24-11-25 18:51:33 | I | collecting calibration activations in model.layers.0
24-11-25 18:51:33 | I | collecting calibration activations in model.layers.0
24-11-25 18:51:33 | I | collecting calibration activations in model.layers.0
24-11-25 18:51:33 | I | - Quantizing decoder layer model.layers.0
24-11-25 18:51:33 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 18:51:34 | I |       - range scale = [    1.0000]
24-11-25 18:51:34 | I |         sum  error  = [    0.0610]
24-11-25 18:51:34 | I |         best error  = [    0.0610]
24-11-25 18:51:34 | I |     + error = [0.0610]
24-11-25 18:51:34 | I |       - range scale = [    1.0000]
24-11-25 18:51:34 | I |         sum  error  = [    0.6176]
24-11-25 18:51:34 | I |         best error  = [    0.6176]
24-11-25 18:51:34 | I |     + error = [0.6176]
24-11-25 18:51:35 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 18:51:35 | I |       - range scale = [    1.0000]
24-11-25 18:51:35 | I |         sum  error  = [    0.0686]
24-11-25 18:51:35 | I |         best error  = [    0.0686]
24-11-25 18:51:35 | I |     + error = [0.0686]
24-11-25 18:51:36 | I |       - range scale = [    1.0000]
24-11-25 18:51:36 | I |         sum  error  = [    0.5741]
24-11-25 18:51:36 | I |         best error  = [    0.5741]
24-11-25 18:51:36 | I |     + error = [0.5741]
24-11-25 18:51:36 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 18:51:37 | I |       - range scale = [    1.0000]
24-11-25 18:51:37 | I |         sum  error  = [    0.2455]
24-11-25 18:51:37 | I |         best error  = [    0.2455]
24-11-25 18:51:37 | I |     + error = [0.2455]
24-11-25 18:51:38 | I |       - range scale = [    1.0000]
24-11-25 18:51:38 | I |         sum  error  = [    1.8582]
24-11-25 18:51:38 | I |         best error  = [    1.8582]
24-11-25 18:51:38 | I |     + error = [1.8582]
24-11-25 18:51:38 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 18:51:39 | I |       - range scale = [    1.0000]
24-11-25 18:51:39 | I |         sum  error  = [    0.0622]
24-11-25 18:51:39 | I |         best error  = [    0.0622]
24-11-25 18:51:39 | I |     + error = [0.0622]
24-11-25 18:51:39 | I |       - range scale = [    1.0000]
24-11-25 18:51:39 | I |         sum  error  = [    0.5963]
24-11-25 18:51:39 | I |         best error  = [    0.5963]
24-11-25 18:51:39 | I |     + error = [0.5963]
24-11-25 18:51:40 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 18:51:40 | I |       - range scale = [    1.0000]
24-11-25 18:51:40 | I |         sum  error  = [    1.0839]
24-11-25 18:51:40 | I |         best error  = [    1.0839]
24-11-25 18:51:40 | I |     + error = [1.0839]
24-11-25 18:51:41 | I |       - range scale = [    1.0000]
24-11-25 18:51:41 | I |         sum  error  = [   11.9961]
24-11-25 18:51:41 | I |         best error  = [   11.9961]
24-11-25 18:51:41 | I |     + error = [11.9961]
24-11-25 18:51:41 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 18:51:42 | I |       - range scale = [    1.0000]
24-11-25 18:51:42 | I |         sum  error  = [    1.2506]
24-11-25 18:51:42 | I |         best error  = [    1.2506]
24-11-25 18:51:42 | I |     + error = [1.2506]
24-11-25 18:51:43 | I |       - range scale = [    1.0000]
24-11-25 18:51:43 | I |         sum  error  = [   12.3863]
24-11-25 18:51:43 | I |         best error  = [   12.3863]
24-11-25 18:51:43 | I |     + error = [12.3863]
24-11-25 18:51:43 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 18:51:44 | I |       - range scale = [    1.0000]
24-11-25 18:51:44 | I |         sum  error  = [    2.4236]
24-11-25 18:51:44 | I |         best error  = [    2.4236]
24-11-25 18:51:44 | I |     + error = [2.4236]
24-11-25 18:51:44 | I |       - range scale = [    1.0000]
24-11-25 18:51:44 | I |         sum  error  = [   13.6333]
24-11-25 18:51:44 | I |         best error  = [   13.6333]
24-11-25 18:51:44 | I |     + error = [13.6333]
24-11-25 18:51:45 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 18:51:46 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 18:51:47 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 18:51:49 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 18:51:50 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 18:51:52 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 18:51:53 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 18:51:56 | I | quantizing activations for layer model.layers.0
24-11-25 18:51:56 | I | collecting info in model.layers.0
24-11-25 18:51:56 | I | collecting info in model.layers.0
24-11-25 18:51:56 | I | collecting info in model.layers.0
24-11-25 18:51:56 | I | collecting info in model.layers.0
24-11-25 18:51:57 | I | collecting calibration activations in model.layers.0
24-11-25 18:51:57 | I | collecting calibration activations in model.layers.0
24-11-25 18:51:57 | I | collecting calibration activations in model.layers.0
24-11-25 18:51:57 | I | collecting calibration activations in model.layers.0
24-11-25 18:51:59 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 18:51:59 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 18:51:59 | I | - Evaluator: gptq
24-11-25 18:51:59 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 18:51:59 | I | - Batch_size: 8
24-11-25 18:51:59 | I |   + Max_seq_length: 2048
24-11-25 18:52:40 | I |     - Results:
24-11-25 18:52:40 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 18:52:40 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 18:52:40 | I |       |wikitext |      1|word_perplexity|7.8566|  |7.8566|
24-11-25 18:52:40 | I |       |val_valid|      1|word_perplexity|9.1124|  |9.1124|
24-11-25 18:52:40 | I |       
24-11-25 18:52:40 | I | forward this layer
24-11-25 18:52:40 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/128.pt
24-11-25 18:52:40 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/128.pt
24-11-25 18:52:41 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 18:52:41 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 18:52:41 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 18:52:41 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 18:52:41 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 18:52:41 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 18:52:41 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 18:52:41 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 18:52:41 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 18:52:41 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 18:52:41 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 18:52:41 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 18:52:41 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 18:52:41 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 18:52:41 | I | in layer model.layers.0
24-11-25 18:52:41 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 18:52:41 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 18:52:41 | I | - Evaluator: gptq
24-11-25 18:52:41 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 18:52:41 | I | - Batch_size: 8
24-11-25 18:52:41 | I |   + Max_seq_length: 2048
24-11-25 18:53:19 | I |     - Results:
24-11-25 18:53:19 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 18:53:19 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 18:53:19 | I |       |wikitext |      1|word_perplexity|7.7947|  |7.7947|
24-11-25 18:53:19 | I |       |val_valid|      1|word_perplexity|9.0440|  |9.0440|
24-11-25 18:53:19 | I |       
24-11-25 18:53:19 | I | quantizing weights for layer model.layers.0
24-11-25 18:53:19 | I | collecting info in model.layers.0
24-11-25 18:53:19 | I | collecting info in model.layers.0
24-11-25 18:53:19 | I | collecting info in model.layers.0
24-11-25 18:53:19 | I | collecting info in model.layers.0
24-11-25 18:53:19 | I | collecting calibration activations in model.layers.0
24-11-25 18:53:20 | I | collecting calibration activations in model.layers.0
24-11-25 18:53:20 | I | collecting calibration activations in model.layers.0
24-11-25 18:53:20 | I | collecting calibration activations in model.layers.0
24-11-25 18:53:20 | I | - Quantizing decoder layer model.layers.0
24-11-25 18:53:20 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 18:53:21 | I |       - range scale = [    1.0000]
24-11-25 18:53:21 | I |         sum  error  = [    0.0628]
24-11-25 18:53:21 | I |         best error  = [    0.0628]
24-11-25 18:53:21 | I |     + error = [0.0628]
24-11-25 18:53:21 | I |       - range scale = [    1.0000]
24-11-25 18:53:21 | I |         sum  error  = [    0.6356]
24-11-25 18:53:21 | I |         best error  = [    0.6356]
24-11-25 18:53:21 | I |     + error = [0.6356]
24-11-25 18:53:22 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 18:53:22 | I |       - range scale = [    1.0000]
24-11-25 18:53:22 | I |         sum  error  = [    0.0655]
24-11-25 18:53:22 | I |         best error  = [    0.0655]
24-11-25 18:53:22 | I |     + error = [0.0655]
24-11-25 18:53:23 | I |       - range scale = [    1.0000]
24-11-25 18:53:23 | I |         sum  error  = [    0.5848]
24-11-25 18:53:23 | I |         best error  = [    0.5848]
24-11-25 18:53:23 | I |     + error = [0.5848]
24-11-25 18:53:23 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 18:53:24 | I |       - range scale = [    1.0000]
24-11-25 18:53:24 | I |         sum  error  = [    0.2511]
24-11-25 18:53:24 | I |         best error  = [    0.2511]
24-11-25 18:53:24 | I |     + error = [0.2511]
24-11-25 18:53:25 | I |       - range scale = [    1.0000]
24-11-25 18:53:25 | I |         sum  error  = [    1.8819]
24-11-25 18:53:25 | I |         best error  = [    1.8819]
24-11-25 18:53:25 | I |     + error = [1.8819]
24-11-25 18:53:25 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 18:53:26 | I |       - range scale = [    1.0000]
24-11-25 18:53:26 | I |         sum  error  = [    0.0661]
24-11-25 18:53:26 | I |         best error  = [    0.0661]
24-11-25 18:53:26 | I |     + error = [0.0661]
24-11-25 18:53:26 | I |       - range scale = [    1.0000]
24-11-25 18:53:26 | I |         sum  error  = [    0.6292]
24-11-25 18:53:26 | I |         best error  = [    0.6292]
24-11-25 18:53:26 | I |     + error = [0.6292]
24-11-25 18:53:26 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 18:53:27 | I |       - range scale = [    1.0000]
24-11-25 18:53:27 | I |         sum  error  = [    1.0728]
24-11-25 18:53:27 | I |         best error  = [    1.0728]
24-11-25 18:53:27 | I |     + error = [1.0728]
24-11-25 18:53:28 | I |       - range scale = [    1.0000]
24-11-25 18:53:28 | I |         sum  error  = [   11.8865]
24-11-25 18:53:28 | I |         best error  = [   11.8865]
24-11-25 18:53:28 | I |     + error = [11.8865]
24-11-25 18:53:28 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 18:53:29 | I |       - range scale = [    1.0000]
24-11-25 18:53:29 | I |         sum  error  = [    1.2408]
24-11-25 18:53:29 | I |         best error  = [    1.2408]
24-11-25 18:53:29 | I |     + error = [1.2408]
24-11-25 18:53:29 | I |       - range scale = [    1.0000]
24-11-25 18:53:29 | I |         sum  error  = [   12.2972]
24-11-25 18:53:29 | I |         best error  = [   12.2972]
24-11-25 18:53:29 | I |     + error = [12.2972]
24-11-25 18:53:30 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 18:53:30 | I |       - range scale = [    1.0000]
24-11-25 18:53:30 | I |         sum  error  = [    2.6788]
24-11-25 18:53:30 | I |         best error  = [    2.6788]
24-11-25 18:53:30 | I |     + error = [2.6788]
24-11-25 18:53:31 | I |       - range scale = [    1.0000]
24-11-25 18:53:31 | I |         sum  error  = [   15.1830]
24-11-25 18:53:31 | I |         best error  = [   15.1830]
24-11-25 18:53:31 | I |     + error = [15.1830]
24-11-25 18:53:31 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 18:53:33 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 18:53:34 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 18:53:36 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 18:53:37 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 18:53:38 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 18:53:40 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 18:53:43 | I | quantizing activations for layer model.layers.0
24-11-25 18:53:43 | I | collecting info in model.layers.0
24-11-25 18:53:43 | I | collecting info in model.layers.0
24-11-25 18:53:43 | I | collecting info in model.layers.0
24-11-25 18:53:43 | I | collecting info in model.layers.0
24-11-25 18:53:44 | I | collecting calibration activations in model.layers.0
24-11-25 18:53:44 | I | collecting calibration activations in model.layers.0
24-11-25 18:53:44 | I | collecting calibration activations in model.layers.0
24-11-25 18:53:44 | I | collecting calibration activations in model.layers.0
24-11-25 18:53:46 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 18:53:46 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 18:53:46 | I | - Evaluator: gptq
24-11-25 18:53:46 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 18:53:46 | I | - Batch_size: 8
24-11-25 18:53:46 | I |   + Max_seq_length: 2048
24-11-25 18:54:27 | I |     - Results:
24-11-25 18:54:27 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 18:54:27 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 18:54:27 | I |       |wikitext |      1|word_perplexity|7.8729|  |7.8729|
24-11-25 18:54:27 | I |       |val_valid|      1|word_perplexity|9.1229|  |9.1229|
24-11-25 18:54:27 | I |       
24-11-25 18:54:27 | I | forward this layer
24-11-25 18:54:27 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/129.pt
24-11-25 18:54:27 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/129.pt
24-11-25 18:54:28 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 18:54:28 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 18:54:28 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 18:54:28 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 18:54:28 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 18:54:28 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 18:54:28 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 18:54:28 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 18:54:28 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 18:54:28 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 18:54:28 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 18:54:28 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 18:54:28 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 18:54:28 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 18:54:28 | I | [50] done with optimizer step
24-11-25 18:54:28 | I | epoch 001:     65 / 409600000 loss=0.000124487, loss_per_token=0.25495, loss_sum=8354.19, wps=153, ups=0, wpb=32768, bsz=64, num_updates=51, lr=0.000149999, gnorm=30.245, clip=100, loss_scale=0.0078, train_wall=214, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=14198, lmquant_ppl_result_wikitext_in_train_no_quant=7.79472, lmquant_ppl_result_val_in_train_no_quant=9.044, lmquant_ppl_result_wikitext_in_train_with_quant=7.87293, lmquant_ppl_result_val_in_train_with_quant=9.12292
24-11-25 18:54:28 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 18:54:28 | I | in layer model.layers.0
24-11-25 18:54:28 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 18:54:28 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 18:54:28 | I | - Evaluator: gptq
24-11-25 18:54:28 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 18:54:28 | I | - Batch_size: 8
24-11-25 18:54:28 | I |   + Max_seq_length: 2048
24-11-25 18:55:06 | I |     - Results:
24-11-25 18:55:06 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 18:55:06 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 18:55:06 | I |       |wikitext |      1|word_perplexity|7.7964|  |7.7964|
24-11-25 18:55:06 | I |       |val_valid|      1|word_perplexity|9.0436|  |9.0436|
24-11-25 18:55:06 | I |       
24-11-25 18:55:06 | I | quantizing weights for layer model.layers.0
24-11-25 18:55:06 | I | collecting info in model.layers.0
24-11-25 18:55:06 | I | collecting info in model.layers.0
24-11-25 18:55:06 | I | collecting info in model.layers.0
24-11-25 18:55:06 | I | collecting info in model.layers.0
24-11-25 18:55:07 | I | collecting calibration activations in model.layers.0
24-11-25 18:55:07 | I | collecting calibration activations in model.layers.0
24-11-25 18:55:07 | I | collecting calibration activations in model.layers.0
24-11-25 18:55:07 | I | collecting calibration activations in model.layers.0
24-11-25 18:55:07 | I | - Quantizing decoder layer model.layers.0
24-11-25 18:55:07 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 18:55:08 | I |       - range scale = [    1.0000]
24-11-25 18:55:08 | I |         sum  error  = [    0.0621]
24-11-25 18:55:08 | I |         best error  = [    0.0621]
24-11-25 18:55:08 | I |     + error = [0.0621]
24-11-25 18:55:09 | I |       - range scale = [    1.0000]
24-11-25 18:55:09 | I |         sum  error  = [    0.6338]
24-11-25 18:55:09 | I |         best error  = [    0.6338]
24-11-25 18:55:09 | I |     + error = [0.6338]
24-11-25 18:55:09 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 18:55:10 | I |       - range scale = [    1.0000]
24-11-25 18:55:10 | I |         sum  error  = [    0.0691]
24-11-25 18:55:10 | I |         best error  = [    0.0691]
24-11-25 18:55:10 | I |     + error = [0.0691]
24-11-25 18:55:10 | I |       - range scale = [    1.0000]
24-11-25 18:55:10 | I |         sum  error  = [    0.5893]
24-11-25 18:55:10 | I |         best error  = [    0.5893]
24-11-25 18:55:10 | I |     + error = [0.5893]
24-11-25 18:55:11 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 18:55:11 | I |       - range scale = [    1.0000]
24-11-25 18:55:11 | I |         sum  error  = [    0.2428]
24-11-25 18:55:11 | I |         best error  = [    0.2428]
24-11-25 18:55:11 | I |     + error = [0.2428]
24-11-25 18:55:12 | I |       - range scale = [    1.0000]
24-11-25 18:55:12 | I |         sum  error  = [    1.8677]
24-11-25 18:55:12 | I |         best error  = [    1.8677]
24-11-25 18:55:12 | I |     + error = [1.8677]
24-11-25 18:55:12 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 18:55:13 | I |       - range scale = [    1.0000]
24-11-25 18:55:13 | I |         sum  error  = [    0.0669]
24-11-25 18:55:13 | I |         best error  = [    0.0669]
24-11-25 18:55:13 | I |     + error = [0.0669]
24-11-25 18:55:13 | I |       - range scale = [    1.0000]
24-11-25 18:55:13 | I |         sum  error  = [    0.6368]
24-11-25 18:55:13 | I |         best error  = [    0.6368]
24-11-25 18:55:13 | I |     + error = [0.6368]
24-11-25 18:55:14 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 18:55:14 | I |       - range scale = [    1.0000]
24-11-25 18:55:14 | I |         sum  error  = [    1.0771]
24-11-25 18:55:14 | I |         best error  = [    1.0771]
24-11-25 18:55:14 | I |     + error = [1.0771]
24-11-25 18:55:15 | I |       - range scale = [    1.0000]
24-11-25 18:55:15 | I |         sum  error  = [   11.9263]
24-11-25 18:55:15 | I |         best error  = [   11.9263]
24-11-25 18:55:15 | I |     + error = [11.9263]
24-11-25 18:55:15 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 18:55:16 | I |       - range scale = [    1.0000]
24-11-25 18:55:16 | I |         sum  error  = [    1.2434]
24-11-25 18:55:16 | I |         best error  = [    1.2434]
24-11-25 18:55:16 | I |     + error = [1.2434]
24-11-25 18:55:17 | I |       - range scale = [    1.0000]
24-11-25 18:55:17 | I |         sum  error  = [   12.3433]
24-11-25 18:55:17 | I |         best error  = [   12.3433]
24-11-25 18:55:17 | I |     + error = [12.3433]
24-11-25 18:55:17 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 18:55:18 | I |       - range scale = [    1.0000]
24-11-25 18:55:18 | I |         sum  error  = [    2.7584]
24-11-25 18:55:18 | I |         best error  = [    2.7584]
24-11-25 18:55:18 | I |     + error = [2.7584]
24-11-25 18:55:18 | I |       - range scale = [    1.0000]
24-11-25 18:55:18 | I |         sum  error  = [   16.1932]
24-11-25 18:55:18 | I |         best error  = [   16.1932]
24-11-25 18:55:18 | I |     + error = [16.1932]
24-11-25 18:55:19 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 18:55:20 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 18:55:22 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 18:55:23 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 18:55:24 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 18:55:26 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 18:55:27 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 18:55:31 | I | quantizing activations for layer model.layers.0
24-11-25 18:55:31 | I | collecting info in model.layers.0
24-11-25 18:55:31 | I | collecting info in model.layers.0
24-11-25 18:55:31 | I | collecting info in model.layers.0
24-11-25 18:55:31 | I | collecting info in model.layers.0
24-11-25 18:55:31 | I | collecting calibration activations in model.layers.0
24-11-25 18:55:31 | I | collecting calibration activations in model.layers.0
24-11-25 18:55:31 | I | collecting calibration activations in model.layers.0
24-11-25 18:55:31 | I | collecting calibration activations in model.layers.0
24-11-25 18:55:33 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 18:55:33 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 18:55:33 | I | - Evaluator: gptq
24-11-25 18:55:33 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 18:55:33 | I | - Batch_size: 8
24-11-25 18:55:33 | I |   + Max_seq_length: 2048
24-11-25 18:56:15 | I |     - Results:
24-11-25 18:56:15 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 18:56:15 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 18:56:15 | I |       |wikitext |      1|word_perplexity|7.8686|  |7.8686|
24-11-25 18:56:15 | I |       |val_valid|      1|word_perplexity|9.1098|  |9.1098|
24-11-25 18:56:15 | I |       
24-11-25 18:56:15 | I | forward this layer
24-11-25 18:56:15 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/130.pt
24-11-25 18:56:15 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/130.pt
24-11-25 18:56:15 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 18:56:15 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 18:56:15 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 18:56:15 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 18:56:15 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 18:56:15 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 18:56:15 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 18:56:15 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 18:56:15 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 18:56:15 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 18:56:15 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 18:56:15 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 18:56:15 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 18:56:15 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 18:56:15 | I | in layer model.layers.0
24-11-25 18:56:15 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 18:56:15 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 18:56:15 | I | - Evaluator: gptq
24-11-25 18:56:15 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 18:56:15 | I | - Batch_size: 8
24-11-25 18:56:15 | I |   + Max_seq_length: 2048
24-11-25 18:56:53 | I |     - Results:
24-11-25 18:56:53 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 18:56:53 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 18:56:53 | I |       |wikitext |      1|word_perplexity|7.7964|  |7.7964|
24-11-25 18:56:53 | I |       |val_valid|      1|word_perplexity|9.0436|  |9.0436|
24-11-25 18:56:53 | I |       
24-11-25 18:56:53 | I | quantizing weights for layer model.layers.0
24-11-25 18:56:53 | I | collecting info in model.layers.0
24-11-25 18:56:53 | I | collecting info in model.layers.0
24-11-25 18:56:53 | I | collecting info in model.layers.0
24-11-25 18:56:53 | I | collecting info in model.layers.0
24-11-25 18:56:54 | I | collecting calibration activations in model.layers.0
24-11-25 18:56:54 | I | collecting calibration activations in model.layers.0
24-11-25 18:56:54 | I | collecting calibration activations in model.layers.0
24-11-25 18:56:54 | I | collecting calibration activations in model.layers.0
24-11-25 18:56:54 | I | - Quantizing decoder layer model.layers.0
24-11-25 18:56:54 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 18:56:55 | I |       - range scale = [    1.0000]
24-11-25 18:56:55 | I |         sum  error  = [    0.0618]
24-11-25 18:56:55 | I |         best error  = [    0.0618]
24-11-25 18:56:55 | I |     + error = [0.0618]
24-11-25 18:56:56 | I |       - range scale = [    1.0000]
24-11-25 18:56:56 | I |         sum  error  = [    0.6215]
24-11-25 18:56:56 | I |         best error  = [    0.6215]
24-11-25 18:56:56 | I |     + error = [0.6215]
24-11-25 18:56:56 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 18:56:57 | I |       - range scale = [    1.0000]
24-11-25 18:56:57 | I |         sum  error  = [    0.0681]
24-11-25 18:56:57 | I |         best error  = [    0.0681]
24-11-25 18:56:57 | I |     + error = [0.0681]
24-11-25 18:56:57 | I |       - range scale = [    1.0000]
24-11-25 18:56:57 | I |         sum  error  = [    0.5714]
24-11-25 18:56:57 | I |         best error  = [    0.5714]
24-11-25 18:56:57 | I |     + error = [0.5714]
24-11-25 18:56:58 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 18:56:58 | I |       - range scale = [    1.0000]
24-11-25 18:56:58 | I |         sum  error  = [    0.2372]
24-11-25 18:56:58 | I |         best error  = [    0.2372]
24-11-25 18:56:58 | I |     + error = [0.2372]
24-11-25 18:56:59 | I |       - range scale = [    1.0000]
24-11-25 18:56:59 | I |         sum  error  = [    1.8431]
24-11-25 18:56:59 | I |         best error  = [    1.8431]
24-11-25 18:56:59 | I |     + error = [1.8431]
24-11-25 18:56:59 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 18:57:00 | I |       - range scale = [    1.0000]
24-11-25 18:57:00 | I |         sum  error  = [    0.0666]
24-11-25 18:57:00 | I |         best error  = [    0.0666]
24-11-25 18:57:00 | I |     + error = [0.0666]
24-11-25 18:57:01 | I |       - range scale = [    1.0000]
24-11-25 18:57:01 | I |         sum  error  = [    0.6360]
24-11-25 18:57:01 | I |         best error  = [    0.6360]
24-11-25 18:57:01 | I |     + error = [0.6360]
24-11-25 18:57:01 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 18:57:01 | I |       - range scale = [    1.0000]
24-11-25 18:57:01 | I |         sum  error  = [    1.0916]
24-11-25 18:57:01 | I |         best error  = [    1.0916]
24-11-25 18:57:01 | I |     + error = [1.0916]
24-11-25 18:57:02 | I |       - range scale = [    1.0000]
24-11-25 18:57:02 | I |         sum  error  = [   12.0815]
24-11-25 18:57:02 | I |         best error  = [   12.0815]
24-11-25 18:57:02 | I |     + error = [12.0815]
24-11-25 18:57:02 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 18:57:03 | I |       - range scale = [    1.0000]
24-11-25 18:57:03 | I |         sum  error  = [    1.2565]
24-11-25 18:57:03 | I |         best error  = [    1.2565]
24-11-25 18:57:03 | I |     + error = [1.2565]
24-11-25 18:57:04 | I |       - range scale = [    1.0000]
24-11-25 18:57:04 | I |         sum  error  = [   12.5127]
24-11-25 18:57:04 | I |         best error  = [   12.5127]
24-11-25 18:57:04 | I |     + error = [12.5127]
24-11-25 18:57:04 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 18:57:05 | I |       - range scale = [    1.0000]
24-11-25 18:57:05 | I |         sum  error  = [    2.1678]
24-11-25 18:57:05 | I |         best error  = [    2.1678]
24-11-25 18:57:05 | I |     + error = [2.1678]
24-11-25 18:57:06 | I |       - range scale = [    1.0000]
24-11-25 18:57:06 | I |         sum  error  = [   12.1270]
24-11-25 18:57:06 | I |         best error  = [   12.1270]
24-11-25 18:57:06 | I |     + error = [12.1270]
24-11-25 18:57:06 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 18:57:07 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 18:57:09 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 18:57:10 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 18:57:11 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 18:57:13 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 18:57:14 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 18:57:17 | I | quantizing activations for layer model.layers.0
24-11-25 18:57:17 | I | collecting info in model.layers.0
24-11-25 18:57:17 | I | collecting info in model.layers.0
24-11-25 18:57:17 | I | collecting info in model.layers.0
24-11-25 18:57:17 | I | collecting info in model.layers.0
24-11-25 18:57:18 | I | collecting calibration activations in model.layers.0
24-11-25 18:57:18 | I | collecting calibration activations in model.layers.0
24-11-25 18:57:18 | I | collecting calibration activations in model.layers.0
24-11-25 18:57:18 | I | collecting calibration activations in model.layers.0
24-11-25 18:57:20 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 18:57:20 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 18:57:20 | I | - Evaluator: gptq
24-11-25 18:57:20 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 18:57:20 | I | - Batch_size: 8
24-11-25 18:57:20 | I |   + Max_seq_length: 2048
24-11-25 18:58:02 | I |     - Results:
24-11-25 18:58:02 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 18:58:02 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 18:58:02 | I |       |wikitext |      1|word_perplexity|7.8555|  |7.8555|
24-11-25 18:58:02 | I |       |val_valid|      1|word_perplexity|9.1031|  |9.1031|
24-11-25 18:58:02 | I |       
24-11-25 18:58:02 | I | forward this layer
24-11-25 18:58:02 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/131.pt
24-11-25 18:58:02 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/131.pt
24-11-25 18:58:02 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 18:58:02 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 18:58:02 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 18:58:02 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 18:58:02 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 18:58:02 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 18:58:02 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 18:58:02 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 18:58:02 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 18:58:02 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 18:58:02 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 18:58:02 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 18:58:02 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 18:58:02 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 18:58:02 | I | [51] done with optimizer step
24-11-25 18:58:02 | I | epoch 001:     66 / 409600000 loss=8.13476e-05, loss_per_token=0.1666, loss_sum=5459.15, wps=152.9, ups=0, wpb=32768, bsz=64, num_updates=52, lr=0.000149999, gnorm=25.026, clip=100, loss_scale=0.0078, train_wall=214, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=14412, lmquant_ppl_result_wikitext_in_train_no_quant=7.7964, lmquant_ppl_result_val_in_train_no_quant=9.04357, lmquant_ppl_result_wikitext_in_train_with_quant=7.85554, lmquant_ppl_result_val_in_train_with_quant=9.10308
24-11-25 18:58:02 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 18:58:02 | I | in layer model.layers.0
24-11-25 18:58:02 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 18:58:02 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 18:58:02 | I | - Evaluator: gptq
24-11-25 18:58:02 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 18:58:02 | I | - Batch_size: 8
24-11-25 18:58:02 | I |   + Max_seq_length: 2048
24-11-25 18:58:40 | I |     - Results:
24-11-25 18:58:40 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 18:58:40 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 18:58:40 | I |       |wikitext |      1|word_perplexity|7.8017|  |7.8017|
24-11-25 18:58:40 | I |       |val_valid|      1|word_perplexity|9.0474|  |9.0474|
24-11-25 18:58:40 | I |       
24-11-25 18:58:40 | I | quantizing weights for layer model.layers.0
24-11-25 18:58:40 | I | collecting info in model.layers.0
24-11-25 18:58:40 | I | collecting info in model.layers.0
24-11-25 18:58:40 | I | collecting info in model.layers.0
24-11-25 18:58:40 | I | collecting info in model.layers.0
24-11-25 18:58:41 | I | collecting calibration activations in model.layers.0
24-11-25 18:58:41 | I | collecting calibration activations in model.layers.0
24-11-25 18:58:41 | I | collecting calibration activations in model.layers.0
24-11-25 18:58:41 | I | collecting calibration activations in model.layers.0
24-11-25 18:58:42 | I | - Quantizing decoder layer model.layers.0
24-11-25 18:58:42 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 18:58:42 | I |       - range scale = [    1.0000]
24-11-25 18:58:42 | I |         sum  error  = [    0.0641]
24-11-25 18:58:42 | I |         best error  = [    0.0641]
24-11-25 18:58:42 | I |     + error = [0.0641]
24-11-25 18:58:43 | I |       - range scale = [    1.0000]
24-11-25 18:58:43 | I |         sum  error  = [    0.6530]
24-11-25 18:58:43 | I |         best error  = [    0.6530]
24-11-25 18:58:43 | I |     + error = [0.6530]
24-11-25 18:58:43 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 18:58:44 | I |       - range scale = [    1.0000]
24-11-25 18:58:44 | I |         sum  error  = [    0.0612]
24-11-25 18:58:44 | I |         best error  = [    0.0612]
24-11-25 18:58:44 | I |     + error = [0.0612]
24-11-25 18:58:45 | I |       - range scale = [    1.0000]
24-11-25 18:58:45 | I |         sum  error  = [    0.5650]
24-11-25 18:58:45 | I |         best error  = [    0.5650]
24-11-25 18:58:45 | I |     + error = [0.5650]
24-11-25 18:58:45 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 18:58:45 | I |       - range scale = [    1.0000]
24-11-25 18:58:45 | I |         sum  error  = [    0.2436]
24-11-25 18:58:45 | I |         best error  = [    0.2436]
24-11-25 18:58:45 | I |     + error = [0.2436]
24-11-25 18:58:46 | I |       - range scale = [    1.0000]
24-11-25 18:58:46 | I |         sum  error  = [    1.8858]
24-11-25 18:58:46 | I |         best error  = [    1.8858]
24-11-25 18:58:46 | I |     + error = [1.8858]
24-11-25 18:58:46 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 18:58:47 | I |       - range scale = [    1.0000]
24-11-25 18:58:47 | I |         sum  error  = [    0.0684]
24-11-25 18:58:47 | I |         best error  = [    0.0684]
24-11-25 18:58:47 | I |     + error = [0.0684]
24-11-25 18:58:48 | I |       - range scale = [    1.0000]
24-11-25 18:58:48 | I |         sum  error  = [    0.6481]
24-11-25 18:58:48 | I |         best error  = [    0.6481]
24-11-25 18:58:48 | I |     + error = [0.6481]
24-11-25 18:58:48 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 18:58:49 | I |       - range scale = [    1.0000]
24-11-25 18:58:49 | I |         sum  error  = [    1.0767]
24-11-25 18:58:49 | I |         best error  = [    1.0767]
24-11-25 18:58:49 | I |     + error = [1.0767]
24-11-25 18:58:49 | I |       - range scale = [    1.0000]
24-11-25 18:58:49 | I |         sum  error  = [   11.9159]
24-11-25 18:58:49 | I |         best error  = [   11.9159]
24-11-25 18:58:49 | I |     + error = [11.9159]
24-11-25 18:58:50 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 18:58:50 | I |       - range scale = [    1.0000]
24-11-25 18:58:50 | I |         sum  error  = [    1.2431]
24-11-25 18:58:50 | I |         best error  = [    1.2431]
24-11-25 18:58:50 | I |     + error = [1.2431]
24-11-25 18:58:51 | I |       - range scale = [    1.0000]
24-11-25 18:58:51 | I |         sum  error  = [   12.3236]
24-11-25 18:58:51 | I |         best error  = [   12.3236]
24-11-25 18:58:51 | I |     + error = [12.3236]
24-11-25 18:58:51 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 18:58:52 | I |       - range scale = [    1.0000]
24-11-25 18:58:52 | I |         sum  error  = [    3.4985]
24-11-25 18:58:52 | I |         best error  = [    3.4985]
24-11-25 18:58:52 | I |     + error = [3.4985]
24-11-25 18:58:53 | I |       - range scale = [    1.0000]
24-11-25 18:58:53 | I |         sum  error  = [   19.9067]
24-11-25 18:58:53 | I |         best error  = [   19.9067]
24-11-25 18:58:53 | I |     + error = [19.9067]
24-11-25 18:58:53 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 18:58:54 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 18:58:56 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 18:58:57 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 18:58:59 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 18:59:00 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 18:59:01 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 18:59:05 | I | quantizing activations for layer model.layers.0
24-11-25 18:59:05 | I | collecting info in model.layers.0
24-11-25 18:59:05 | I | collecting info in model.layers.0
24-11-25 18:59:05 | I | collecting info in model.layers.0
24-11-25 18:59:05 | I | collecting info in model.layers.0
24-11-25 18:59:05 | I | collecting calibration activations in model.layers.0
24-11-25 18:59:05 | I | collecting calibration activations in model.layers.0
24-11-25 18:59:05 | I | collecting calibration activations in model.layers.0
24-11-25 18:59:05 | I | collecting calibration activations in model.layers.0
24-11-25 18:59:07 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 18:59:07 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 18:59:07 | I | - Evaluator: gptq
24-11-25 18:59:07 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 18:59:07 | I | - Batch_size: 8
24-11-25 18:59:07 | I |   + Max_seq_length: 2048
24-11-25 18:59:49 | I |     - Results:
24-11-25 18:59:49 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 18:59:49 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 18:59:49 | I |       |wikitext |      1|word_perplexity|7.8751|  |7.8751|
24-11-25 18:59:49 | I |       |val_valid|      1|word_perplexity|9.1211|  |9.1211|
24-11-25 18:59:49 | I |       
24-11-25 18:59:49 | I | forward this layer
24-11-25 18:59:49 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/132.pt
24-11-25 18:59:49 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/132.pt
24-11-25 18:59:49 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 18:59:49 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 18:59:49 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 18:59:49 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 18:59:49 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 18:59:49 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 18:59:49 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 18:59:49 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 18:59:49 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 18:59:49 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 18:59:49 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 18:59:49 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 18:59:49 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 18:59:49 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 18:59:49 | I | in layer model.layers.0
24-11-25 18:59:49 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 18:59:49 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 18:59:49 | I | - Evaluator: gptq
24-11-25 18:59:49 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 18:59:49 | I | - Batch_size: 8
24-11-25 18:59:49 | I |   + Max_seq_length: 2048
24-11-25 19:00:27 | I |     - Results:
24-11-25 19:00:27 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 19:00:27 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 19:00:27 | I |       |wikitext |      1|word_perplexity|7.8017|  |7.8017|
24-11-25 19:00:27 | I |       |val_valid|      1|word_perplexity|9.0474|  |9.0474|
24-11-25 19:00:27 | I |       
24-11-25 19:00:27 | I | quantizing weights for layer model.layers.0
24-11-25 19:00:27 | I | collecting info in model.layers.0
24-11-25 19:00:27 | I | collecting info in model.layers.0
24-11-25 19:00:27 | I | collecting info in model.layers.0
24-11-25 19:00:27 | I | collecting info in model.layers.0
24-11-25 19:00:28 | I | collecting calibration activations in model.layers.0
24-11-25 19:00:28 | I | collecting calibration activations in model.layers.0
24-11-25 19:00:28 | I | collecting calibration activations in model.layers.0
24-11-25 19:00:28 | I | collecting calibration activations in model.layers.0
24-11-25 19:00:28 | I | - Quantizing decoder layer model.layers.0
24-11-25 19:00:28 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 19:00:29 | I |       - range scale = [    1.0000]
24-11-25 19:00:29 | I |         sum  error  = [    0.0644]
24-11-25 19:00:29 | I |         best error  = [    0.0644]
24-11-25 19:00:29 | I |     + error = [0.0644]
24-11-25 19:00:30 | I |       - range scale = [    1.0000]
24-11-25 19:00:30 | I |         sum  error  = [    0.6308]
24-11-25 19:00:30 | I |         best error  = [    0.6308]
24-11-25 19:00:30 | I |     + error = [0.6308]
24-11-25 19:00:30 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 19:00:30 | I |       - range scale = [    1.0000]
24-11-25 19:00:30 | I |         sum  error  = [    0.0612]
24-11-25 19:00:30 | I |         best error  = [    0.0612]
24-11-25 19:00:30 | I |     + error = [0.0612]
24-11-25 19:00:31 | I |       - range scale = [    1.0000]
24-11-25 19:00:31 | I |         sum  error  = [    0.5536]
24-11-25 19:00:31 | I |         best error  = [    0.5536]
24-11-25 19:00:31 | I |     + error = [0.5536]
24-11-25 19:00:31 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 19:00:32 | I |       - range scale = [    1.0000]
24-11-25 19:00:32 | I |         sum  error  = [    0.2451]
24-11-25 19:00:32 | I |         best error  = [    0.2451]
24-11-25 19:00:32 | I |     + error = [0.2451]
24-11-25 19:00:33 | I |       - range scale = [    1.0000]
24-11-25 19:00:33 | I |         sum  error  = [    1.8793]
24-11-25 19:00:33 | I |         best error  = [    1.8793]
24-11-25 19:00:33 | I |     + error = [1.8793]
24-11-25 19:00:33 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 19:00:33 | I |       - range scale = [    1.0000]
24-11-25 19:00:33 | I |         sum  error  = [    0.0645]
24-11-25 19:00:33 | I |         best error  = [    0.0645]
24-11-25 19:00:33 | I |     + error = [0.0645]
24-11-25 19:00:34 | I |       - range scale = [    1.0000]
24-11-25 19:00:34 | I |         sum  error  = [    0.6139]
24-11-25 19:00:34 | I |         best error  = [    0.6139]
24-11-25 19:00:34 | I |     + error = [0.6139]
24-11-25 19:00:34 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 19:00:35 | I |       - range scale = [    1.0000]
24-11-25 19:00:35 | I |         sum  error  = [    1.0041]
24-11-25 19:00:35 | I |         best error  = [    1.0041]
24-11-25 19:00:35 | I |     + error = [1.0041]
24-11-25 19:00:36 | I |       - range scale = [    1.0000]
24-11-25 19:00:36 | I |         sum  error  = [   11.0808]
24-11-25 19:00:36 | I |         best error  = [   11.0808]
24-11-25 19:00:36 | I |     + error = [11.0808]
24-11-25 19:00:36 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 19:00:37 | I |       - range scale = [    1.0000]
24-11-25 19:00:37 | I |         sum  error  = [    1.1555]
24-11-25 19:00:37 | I |         best error  = [    1.1555]
24-11-25 19:00:37 | I |     + error = [1.1555]
24-11-25 19:00:37 | I |       - range scale = [    1.0000]
24-11-25 19:00:37 | I |         sum  error  = [   11.4303]
24-11-25 19:00:37 | I |         best error  = [   11.4303]
24-11-25 19:00:37 | I |     + error = [11.4303]
24-11-25 19:00:38 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 19:00:38 | I |       - range scale = [    1.0000]
24-11-25 19:00:38 | I |         sum  error  = [    2.0072]
24-11-25 19:00:38 | I |         best error  = [    2.0072]
24-11-25 19:00:38 | I |     + error = [2.0072]
24-11-25 19:00:39 | I |       - range scale = [    1.0000]
24-11-25 19:00:39 | I |         sum  error  = [   11.6354]
24-11-25 19:00:39 | I |         best error  = [   11.6354]
24-11-25 19:00:39 | I |     + error = [11.6354]
24-11-25 19:00:39 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 19:00:41 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 19:00:42 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 19:00:43 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 19:00:45 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 19:00:46 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 19:00:48 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 19:00:51 | I | quantizing activations for layer model.layers.0
24-11-25 19:00:51 | I | collecting info in model.layers.0
24-11-25 19:00:51 | I | collecting info in model.layers.0
24-11-25 19:00:51 | I | collecting info in model.layers.0
24-11-25 19:00:51 | I | collecting info in model.layers.0
24-11-25 19:00:51 | I | collecting calibration activations in model.layers.0
24-11-25 19:00:52 | I | collecting calibration activations in model.layers.0
24-11-25 19:00:52 | I | collecting calibration activations in model.layers.0
24-11-25 19:00:52 | I | collecting calibration activations in model.layers.0
24-11-25 19:00:54 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 19:00:54 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 19:00:54 | I | - Evaluator: gptq
24-11-25 19:00:54 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 19:00:54 | I | - Batch_size: 8
24-11-25 19:00:54 | I |   + Max_seq_length: 2048
24-11-25 19:01:35 | I |     - Results:
24-11-25 19:01:35 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 19:01:35 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 19:01:35 | I |       |wikitext |      1|word_perplexity|7.8789|  |7.8789|
24-11-25 19:01:35 | I |       |val_valid|      1|word_perplexity|9.1409|  |9.1409|
24-11-25 19:01:35 | I |       
24-11-25 19:01:35 | I | forward this layer
24-11-25 19:01:35 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/133.pt
24-11-25 19:01:35 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/133.pt
24-11-25 19:01:35 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 19:01:35 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 19:01:35 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 19:01:35 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 19:01:35 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 19:01:35 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 19:01:35 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 19:01:35 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 19:01:35 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 19:01:35 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 19:01:35 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 19:01:35 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 19:01:35 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 19:01:35 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 19:01:35 | I | [52] done with optimizer step
24-11-25 19:01:35 | I | epoch 001:     67 / 409600000 loss=0.000102796, loss_per_token=0.210527, loss_sum=6898.54, wps=153.6, ups=0, wpb=32768, bsz=64, num_updates=53, lr=0.000149998, gnorm=23.065, clip=100, loss_scale=0.0078, train_wall=213, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=14626, lmquant_ppl_result_wikitext_in_train_no_quant=7.80169, lmquant_ppl_result_val_in_train_no_quant=9.0474, lmquant_ppl_result_wikitext_in_train_with_quant=7.87892, lmquant_ppl_result_val_in_train_with_quant=9.14087
24-11-25 19:01:36 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 19:01:36 | I | in layer model.layers.0
24-11-25 19:01:36 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 19:01:36 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 19:01:36 | I | - Evaluator: gptq
24-11-25 19:01:36 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 19:01:36 | I | - Batch_size: 8
24-11-25 19:01:36 | I |   + Max_seq_length: 2048
24-11-25 19:02:14 | I |     - Results:
24-11-25 19:02:14 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 19:02:14 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 19:02:14 | I |       |wikitext |      1|word_perplexity|7.8149|  |7.8149|
24-11-25 19:02:14 | I |       |val_valid|      1|word_perplexity|9.0534|  |9.0534|
24-11-25 19:02:14 | I |       
24-11-25 19:02:14 | I | quantizing weights for layer model.layers.0
24-11-25 19:02:14 | I | collecting info in model.layers.0
24-11-25 19:02:14 | I | collecting info in model.layers.0
24-11-25 19:02:14 | I | collecting info in model.layers.0
24-11-25 19:02:14 | I | collecting info in model.layers.0
24-11-25 19:02:14 | I | collecting calibration activations in model.layers.0
24-11-25 19:02:14 | I | collecting calibration activations in model.layers.0
24-11-25 19:02:14 | I | collecting calibration activations in model.layers.0
24-11-25 19:02:15 | I | collecting calibration activations in model.layers.0
24-11-25 19:02:15 | I | - Quantizing decoder layer model.layers.0
24-11-25 19:02:15 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 19:02:16 | I |       - range scale = [    1.0000]
24-11-25 19:02:16 | I |         sum  error  = [    0.0708]
24-11-25 19:02:16 | I |         best error  = [    0.0708]
24-11-25 19:02:16 | I |     + error = [0.0708]
24-11-25 19:02:16 | I |       - range scale = [    1.0000]
24-11-25 19:02:16 | I |         sum  error  = [    0.5952]
24-11-25 19:02:16 | I |         best error  = [    0.5952]
24-11-25 19:02:16 | I |     + error = [0.5952]
24-11-25 19:02:17 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 19:02:17 | I |       - range scale = [    1.0000]
24-11-25 19:02:17 | I |         sum  error  = [    0.0450]
24-11-25 19:02:17 | I |         best error  = [    0.0450]
24-11-25 19:02:17 | I |     + error = [0.0450]
24-11-25 19:02:18 | I |       - range scale = [    1.0000]
24-11-25 19:02:18 | I |         sum  error  = [    0.6229]
24-11-25 19:02:18 | I |         best error  = [    0.6229]
24-11-25 19:02:18 | I |     + error = [0.6229]
24-11-25 19:02:18 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 19:02:19 | I |       - range scale = [    1.0000]
24-11-25 19:02:19 | I |         sum  error  = [    0.2351]
24-11-25 19:02:19 | I |         best error  = [    0.2351]
24-11-25 19:02:19 | I |     + error = [0.2351]
24-11-25 19:02:19 | I |       - range scale = [    1.0000]
24-11-25 19:02:19 | I |         sum  error  = [    1.7749]
24-11-25 19:02:19 | I |         best error  = [    1.7749]
24-11-25 19:02:19 | I |     + error = [1.7749]
24-11-25 19:02:20 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 19:02:20 | I |       - range scale = [    1.0000]
24-11-25 19:02:20 | I |         sum  error  = [    0.0664]
24-11-25 19:02:20 | I |         best error  = [    0.0664]
24-11-25 19:02:20 | I |     + error = [0.0664]
24-11-25 19:02:21 | I |       - range scale = [    1.0000]
24-11-25 19:02:21 | I |         sum  error  = [    0.6559]
24-11-25 19:02:21 | I |         best error  = [    0.6559]
24-11-25 19:02:21 | I |     + error = [0.6559]
24-11-25 19:02:21 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 19:02:22 | I |       - range scale = [    1.0000]
24-11-25 19:02:22 | I |         sum  error  = [    1.0936]
24-11-25 19:02:22 | I |         best error  = [    1.0936]
24-11-25 19:02:22 | I |     + error = [1.0936]
24-11-25 19:02:23 | I |       - range scale = [    1.0000]
24-11-25 19:02:23 | I |         sum  error  = [   12.1232]
24-11-25 19:02:23 | I |         best error  = [   12.1232]
24-11-25 19:02:23 | I |     + error = [12.1232]
24-11-25 19:02:23 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 19:02:24 | I |       - range scale = [    1.0000]
24-11-25 19:02:24 | I |         sum  error  = [    1.2665]
24-11-25 19:02:24 | I |         best error  = [    1.2665]
24-11-25 19:02:24 | I |     + error = [1.2665]
24-11-25 19:02:24 | I |       - range scale = [    1.0000]
24-11-25 19:02:24 | I |         sum  error  = [   12.5272]
24-11-25 19:02:24 | I |         best error  = [   12.5272]
24-11-25 19:02:24 | I |     + error = [12.5272]
24-11-25 19:02:25 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 19:02:25 | I |       - range scale = [    1.0000]
24-11-25 19:02:25 | I |         sum  error  = [    1.6092]
24-11-25 19:02:25 | I |         best error  = [    1.6092]
24-11-25 19:02:25 | I |     + error = [1.6092]
24-11-25 19:02:26 | I |       - range scale = [    1.0000]
24-11-25 19:02:26 | I |         sum  error  = [    8.5901]
24-11-25 19:02:26 | I |         best error  = [    8.5901]
24-11-25 19:02:26 | I |     + error = [8.5901]
24-11-25 19:02:26 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 19:02:28 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 19:02:29 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 19:02:30 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 19:02:32 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 19:02:33 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 19:02:35 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 19:02:38 | I | quantizing activations for layer model.layers.0
24-11-25 19:02:38 | I | collecting info in model.layers.0
24-11-25 19:02:38 | I | collecting info in model.layers.0
24-11-25 19:02:38 | I | collecting info in model.layers.0
24-11-25 19:02:38 | I | collecting info in model.layers.0
24-11-25 19:02:39 | I | collecting calibration activations in model.layers.0
24-11-25 19:02:39 | I | collecting calibration activations in model.layers.0
24-11-25 19:02:39 | I | collecting calibration activations in model.layers.0
24-11-25 19:02:39 | I | collecting calibration activations in model.layers.0
24-11-25 19:02:41 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 19:02:41 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 19:02:41 | I | - Evaluator: gptq
24-11-25 19:02:41 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 19:02:41 | I | - Batch_size: 8
24-11-25 19:02:41 | I |   + Max_seq_length: 2048
24-11-25 19:03:22 | I |     - Results:
24-11-25 19:03:22 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 19:03:22 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 19:03:22 | I |       |wikitext |      1|word_perplexity|7.8972|  |7.8972|
24-11-25 19:03:22 | I |       |val_valid|      1|word_perplexity|9.1124|  |9.1124|
24-11-25 19:03:22 | I |       
24-11-25 19:03:22 | I | forward this layer
24-11-25 19:03:22 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/134.pt
24-11-25 19:03:22 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/134.pt
24-11-25 19:03:23 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 19:03:23 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 19:03:23 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 19:03:23 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 19:03:23 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 19:03:23 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 19:03:23 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 19:03:23 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 19:03:23 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 19:03:23 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 19:03:23 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 19:03:23 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 19:03:23 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 19:03:23 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 19:03:23 | I | in layer model.layers.0
24-11-25 19:03:23 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 19:03:23 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 19:03:23 | I | - Evaluator: gptq
24-11-25 19:03:23 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 19:03:23 | I | - Batch_size: 8
24-11-25 19:03:23 | I |   + Max_seq_length: 2048
24-11-25 19:04:01 | I |     - Results:
24-11-25 19:04:01 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 19:04:01 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 19:04:01 | I |       |wikitext |      1|word_perplexity|7.8149|  |7.8149|
24-11-25 19:04:01 | I |       |val_valid|      1|word_perplexity|9.0534|  |9.0534|
24-11-25 19:04:01 | I |       
24-11-25 19:04:01 | I | quantizing weights for layer model.layers.0
24-11-25 19:04:01 | I | collecting info in model.layers.0
24-11-25 19:04:01 | I | collecting info in model.layers.0
24-11-25 19:04:01 | I | collecting info in model.layers.0
24-11-25 19:04:01 | I | collecting info in model.layers.0
24-11-25 19:04:01 | I | collecting calibration activations in model.layers.0
24-11-25 19:04:02 | I | collecting calibration activations in model.layers.0
24-11-25 19:04:02 | I | collecting calibration activations in model.layers.0
24-11-25 19:04:02 | I | collecting calibration activations in model.layers.0
24-11-25 19:04:02 | I | - Quantizing decoder layer model.layers.0
24-11-25 19:04:02 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 19:04:03 | I |       - range scale = [    1.0000]
24-11-25 19:04:03 | I |         sum  error  = [    0.0703]
24-11-25 19:04:03 | I |         best error  = [    0.0703]
24-11-25 19:04:03 | I |     + error = [0.0703]
24-11-25 19:04:04 | I |       - range scale = [    1.0000]
24-11-25 19:04:04 | I |         sum  error  = [    0.5919]
24-11-25 19:04:04 | I |         best error  = [    0.5919]
24-11-25 19:04:04 | I |     + error = [0.5919]
24-11-25 19:04:04 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 19:04:04 | I |       - range scale = [    1.0000]
24-11-25 19:04:04 | I |         sum  error  = [    0.0443]
24-11-25 19:04:04 | I |         best error  = [    0.0443]
24-11-25 19:04:04 | I |     + error = [0.0443]
24-11-25 19:04:05 | I |       - range scale = [    1.0000]
24-11-25 19:04:05 | I |         sum  error  = [    0.6313]
24-11-25 19:04:05 | I |         best error  = [    0.6313]
24-11-25 19:04:05 | I |     + error = [0.6313]
24-11-25 19:04:05 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 19:04:06 | I |       - range scale = [    1.0000]
24-11-25 19:04:06 | I |         sum  error  = [    0.2293]
24-11-25 19:04:06 | I |         best error  = [    0.2293]
24-11-25 19:04:06 | I |     + error = [0.2293]
24-11-25 19:04:07 | I |       - range scale = [    1.0000]
24-11-25 19:04:07 | I |         sum  error  = [    1.7566]
24-11-25 19:04:07 | I |         best error  = [    1.7566]
24-11-25 19:04:07 | I |     + error = [1.7566]
24-11-25 19:04:07 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 19:04:08 | I |       - range scale = [    1.0000]
24-11-25 19:04:08 | I |         sum  error  = [    0.0657]
24-11-25 19:04:08 | I |         best error  = [    0.0657]
24-11-25 19:04:08 | I |     + error = [0.0657]
24-11-25 19:04:08 | I |       - range scale = [    1.0000]
24-11-25 19:04:08 | I |         sum  error  = [    0.6481]
24-11-25 19:04:08 | I |         best error  = [    0.6481]
24-11-25 19:04:08 | I |     + error = [0.6481]
24-11-25 19:04:08 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 19:04:09 | I |       - range scale = [    1.0000]
24-11-25 19:04:09 | I |         sum  error  = [    1.0986]
24-11-25 19:04:09 | I |         best error  = [    1.0986]
24-11-25 19:04:09 | I |     + error = [1.0986]
24-11-25 19:04:10 | I |       - range scale = [    1.0000]
24-11-25 19:04:10 | I |         sum  error  = [   12.1677]
24-11-25 19:04:10 | I |         best error  = [   12.1677]
24-11-25 19:04:10 | I |     + error = [12.1677]
24-11-25 19:04:10 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 19:04:11 | I |       - range scale = [    1.0000]
24-11-25 19:04:11 | I |         sum  error  = [    1.2707]
24-11-25 19:04:11 | I |         best error  = [    1.2707]
24-11-25 19:04:11 | I |     + error = [1.2707]
24-11-25 19:04:12 | I |       - range scale = [    1.0000]
24-11-25 19:04:12 | I |         sum  error  = [   12.5768]
24-11-25 19:04:12 | I |         best error  = [   12.5768]
24-11-25 19:04:12 | I |     + error = [12.5768]
24-11-25 19:04:12 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 19:04:12 | I |       - range scale = [    1.0000]
24-11-25 19:04:12 | I |         sum  error  = [    1.4638]
24-11-25 19:04:12 | I |         best error  = [    1.4638]
24-11-25 19:04:12 | I |     + error = [1.4638]
24-11-25 19:04:13 | I |       - range scale = [    1.0000]
24-11-25 19:04:13 | I |         sum  error  = [    7.8212]
24-11-25 19:04:13 | I |         best error  = [    7.8212]
24-11-25 19:04:13 | I |     + error = [7.8212]
24-11-25 19:04:13 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 19:04:15 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 19:04:16 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 19:04:18 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 19:04:19 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 19:04:20 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 19:04:22 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 19:04:25 | I | quantizing activations for layer model.layers.0
24-11-25 19:04:25 | I | collecting info in model.layers.0
24-11-25 19:04:25 | I | collecting info in model.layers.0
24-11-25 19:04:25 | I | collecting info in model.layers.0
24-11-25 19:04:25 | I | collecting info in model.layers.0
24-11-25 19:04:26 | I | collecting calibration activations in model.layers.0
24-11-25 19:04:26 | I | collecting calibration activations in model.layers.0
24-11-25 19:04:26 | I | collecting calibration activations in model.layers.0
24-11-25 19:04:26 | I | collecting calibration activations in model.layers.0
24-11-25 19:04:28 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 19:04:28 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 19:04:28 | I | - Evaluator: gptq
24-11-25 19:04:28 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 19:04:28 | I | - Batch_size: 8
24-11-25 19:04:28 | I |   + Max_seq_length: 2048
24-11-25 19:05:09 | I |     - Results:
24-11-25 19:05:09 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 19:05:09 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 19:05:09 | I |       |wikitext |      1|word_perplexity|7.9080|  |7.9080|
24-11-25 19:05:09 | I |       |val_valid|      1|word_perplexity|9.1124|  |9.1124|
24-11-25 19:05:09 | I |       
24-11-25 19:05:09 | I | forward this layer
24-11-25 19:05:09 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/135.pt
24-11-25 19:05:09 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/135.pt
24-11-25 19:05:10 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 19:05:10 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 19:05:10 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 19:05:10 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 19:05:10 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 19:05:10 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 19:05:10 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 19:05:10 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 19:05:10 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 19:05:10 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 19:05:10 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 19:05:10 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 19:05:10 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 19:05:10 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 19:05:10 | I | [53] done with optimizer step
24-11-25 19:05:10 | I | epoch 001:     68 / 409600000 loss=3.37532e-05, loss_per_token=0.0691266, loss_sum=2265.14, wps=152.8, ups=0, wpb=32768, bsz=64, num_updates=54, lr=0.000149998, gnorm=10.24, clip=100, loss_scale=0.0078, train_wall=214, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=14840, lmquant_ppl_result_wikitext_in_train_no_quant=7.8149, lmquant_ppl_result_val_in_train_no_quant=9.05338, lmquant_ppl_result_wikitext_in_train_with_quant=7.90803, lmquant_ppl_result_val_in_train_with_quant=9.11237
24-11-25 19:05:10 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 19:05:10 | I | in layer model.layers.0
24-11-25 19:05:10 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 19:05:10 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 19:05:10 | I | - Evaluator: gptq
24-11-25 19:05:10 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 19:05:10 | I | - Batch_size: 8
24-11-25 19:05:10 | I |   + Max_seq_length: 2048
24-11-25 19:05:48 | I |     - Results:
24-11-25 19:05:48 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 19:05:48 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 19:05:48 | I |       |wikitext |      1|word_perplexity|7.8694|  |7.8694|
24-11-25 19:05:48 | I |       |val_valid|      1|word_perplexity|9.0980|  |9.0980|
24-11-25 19:05:48 | I |       
24-11-25 19:05:48 | I | quantizing weights for layer model.layers.0
24-11-25 19:05:48 | I | collecting info in model.layers.0
24-11-25 19:05:48 | I | collecting info in model.layers.0
24-11-25 19:05:48 | I | collecting info in model.layers.0
24-11-25 19:05:48 | I | collecting info in model.layers.0
24-11-25 19:05:49 | I | collecting calibration activations in model.layers.0
24-11-25 19:05:49 | I | collecting calibration activations in model.layers.0
24-11-25 19:05:49 | I | collecting calibration activations in model.layers.0
24-11-25 19:05:49 | I | collecting calibration activations in model.layers.0
24-11-25 19:05:49 | I | - Quantizing decoder layer model.layers.0
24-11-25 19:05:49 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 19:05:50 | I |       - range scale = [    1.0000]
24-11-25 19:05:50 | I |         sum  error  = [    0.0642]
24-11-25 19:05:50 | I |         best error  = [    0.0642]
24-11-25 19:05:50 | I |     + error = [0.0642]
24-11-25 19:05:51 | I |       - range scale = [    1.0000]
24-11-25 19:05:51 | I |         sum  error  = [    0.6287]
24-11-25 19:05:51 | I |         best error  = [    0.6287]
24-11-25 19:05:51 | I |     + error = [0.6287]
24-11-25 19:05:51 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 19:05:52 | I |       - range scale = [    1.0000]
24-11-25 19:05:52 | I |         sum  error  = [    0.0528]
24-11-25 19:05:52 | I |         best error  = [    0.0528]
24-11-25 19:05:52 | I |     + error = [0.0528]
24-11-25 19:05:52 | I |       - range scale = [    1.0000]
24-11-25 19:05:52 | I |         sum  error  = [    0.5764]
24-11-25 19:05:52 | I |         best error  = [    0.5764]
24-11-25 19:05:52 | I |     + error = [0.5764]
24-11-25 19:05:53 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 19:05:53 | I |       - range scale = [    1.0000]
24-11-25 19:05:53 | I |         sum  error  = [    0.2367]
24-11-25 19:05:53 | I |         best error  = [    0.2367]
24-11-25 19:05:53 | I |     + error = [0.2367]
24-11-25 19:05:54 | I |       - range scale = [    1.0000]
24-11-25 19:05:54 | I |         sum  error  = [    1.8235]
24-11-25 19:05:54 | I |         best error  = [    1.8235]
24-11-25 19:05:54 | I |     + error = [1.8235]
24-11-25 19:05:54 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 19:05:55 | I |       - range scale = [    1.0000]
24-11-25 19:05:55 | I |         sum  error  = [    0.0653]
24-11-25 19:05:55 | I |         best error  = [    0.0653]
24-11-25 19:05:55 | I |     + error = [0.0653]
24-11-25 19:05:56 | I |       - range scale = [    1.0000]
24-11-25 19:05:56 | I |         sum  error  = [    0.6281]
24-11-25 19:05:56 | I |         best error  = [    0.6281]
24-11-25 19:05:56 | I |     + error = [0.6281]
24-11-25 19:05:56 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 19:05:56 | I |       - range scale = [    1.0000]
24-11-25 19:05:56 | I |         sum  error  = [    1.0934]
24-11-25 19:05:56 | I |         best error  = [    1.0934]
24-11-25 19:05:56 | I |     + error = [1.0934]
24-11-25 19:05:57 | I |       - range scale = [    1.0000]
24-11-25 19:05:57 | I |         sum  error  = [   12.1157]
24-11-25 19:05:57 | I |         best error  = [   12.1157]
24-11-25 19:05:57 | I |     + error = [12.1157]
24-11-25 19:05:57 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 19:05:58 | I |       - range scale = [    1.0000]
24-11-25 19:05:58 | I |         sum  error  = [    1.2652]
24-11-25 19:05:58 | I |         best error  = [    1.2652]
24-11-25 19:05:58 | I |     + error = [1.2652]
24-11-25 19:05:59 | I |       - range scale = [    1.0000]
24-11-25 19:05:59 | I |         sum  error  = [   12.5246]
24-11-25 19:05:59 | I |         best error  = [   12.5246]
24-11-25 19:05:59 | I |     + error = [12.5246]
24-11-25 19:05:59 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 19:06:00 | I |       - range scale = [    1.0000]
24-11-25 19:06:00 | I |         sum  error  = [    3.6965]
24-11-25 19:06:00 | I |         best error  = [    3.6965]
24-11-25 19:06:00 | I |     + error = [3.6965]
24-11-25 19:06:01 | I |       - range scale = [    1.0000]
24-11-25 19:06:01 | I |         sum  error  = [   20.3291]
24-11-25 19:06:01 | I |         best error  = [   20.3291]
24-11-25 19:06:01 | I |     + error = [20.3291]
24-11-25 19:06:01 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 19:06:02 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 19:06:04 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 19:06:05 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 19:06:06 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 19:06:08 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 19:06:09 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 19:06:13 | I | quantizing activations for layer model.layers.0
24-11-25 19:06:13 | I | collecting info in model.layers.0
24-11-25 19:06:13 | I | collecting info in model.layers.0
24-11-25 19:06:13 | I | collecting info in model.layers.0
24-11-25 19:06:13 | I | collecting info in model.layers.0
24-11-25 19:06:13 | I | collecting calibration activations in model.layers.0
24-11-25 19:06:13 | I | collecting calibration activations in model.layers.0
24-11-25 19:06:13 | I | collecting calibration activations in model.layers.0
24-11-25 19:06:13 | I | collecting calibration activations in model.layers.0
24-11-25 19:06:15 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 19:06:15 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 19:06:15 | I | - Evaluator: gptq
24-11-25 19:06:15 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 19:06:15 | I | - Batch_size: 8
24-11-25 19:06:15 | I |   + Max_seq_length: 2048
24-11-25 19:06:57 | I |     - Results:
24-11-25 19:06:57 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 19:06:57 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 19:06:57 | I |       |wikitext |      1|word_perplexity|8.0826|  |8.0826|
24-11-25 19:06:57 | I |       |val_valid|      1|word_perplexity|9.2573|  |9.2573|
24-11-25 19:06:57 | I |       
24-11-25 19:06:57 | I | forward this layer
24-11-25 19:06:57 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/136.pt
24-11-25 19:06:57 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/136.pt
24-11-25 19:06:57 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 19:06:57 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 19:06:57 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 19:06:57 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 19:06:57 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 19:06:57 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 19:06:57 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 19:06:57 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 19:06:57 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 19:06:57 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 19:06:57 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 19:06:57 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 19:06:57 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 19:06:57 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 19:06:57 | I | in layer model.layers.0
24-11-25 19:06:57 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 19:06:57 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 19:06:57 | I | - Evaluator: gptq
24-11-25 19:06:57 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 19:06:57 | I | - Batch_size: 8
24-11-25 19:06:57 | I |   + Max_seq_length: 2048
24-11-25 19:07:35 | I |     - Results:
24-11-25 19:07:35 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 19:07:35 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 19:07:35 | I |       |wikitext |      1|word_perplexity|7.8694|  |7.8694|
24-11-25 19:07:35 | I |       |val_valid|      1|word_perplexity|9.0980|  |9.0980|
24-11-25 19:07:35 | I |       
24-11-25 19:07:35 | I | quantizing weights for layer model.layers.0
24-11-25 19:07:35 | I | collecting info in model.layers.0
24-11-25 19:07:35 | I | collecting info in model.layers.0
24-11-25 19:07:35 | I | collecting info in model.layers.0
24-11-25 19:07:35 | I | collecting info in model.layers.0
24-11-25 19:07:36 | I | collecting calibration activations in model.layers.0
24-11-25 19:07:36 | I | collecting calibration activations in model.layers.0
24-11-25 19:07:36 | I | collecting calibration activations in model.layers.0
24-11-25 19:07:36 | I | collecting calibration activations in model.layers.0
24-11-25 19:07:36 | I | - Quantizing decoder layer model.layers.0
24-11-25 19:07:36 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 19:07:37 | I |       - range scale = [    1.0000]
24-11-25 19:07:37 | I |         sum  error  = [    0.0623]
24-11-25 19:07:37 | I |         best error  = [    0.0623]
24-11-25 19:07:37 | I |     + error = [0.0623]
24-11-25 19:07:38 | I |       - range scale = [    1.0000]
24-11-25 19:07:38 | I |         sum  error  = [    0.6155]
24-11-25 19:07:38 | I |         best error  = [    0.6155]
24-11-25 19:07:38 | I |     + error = [0.6155]
24-11-25 19:07:38 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 19:07:39 | I |       - range scale = [    1.0000]
24-11-25 19:07:39 | I |         sum  error  = [    0.0540]
24-11-25 19:07:39 | I |         best error  = [    0.0540]
24-11-25 19:07:39 | I |     + error = [0.0540]
24-11-25 19:07:39 | I |       - range scale = [    1.0000]
24-11-25 19:07:39 | I |         sum  error  = [    0.5429]
24-11-25 19:07:39 | I |         best error  = [    0.5429]
24-11-25 19:07:39 | I |     + error = [0.5429]
24-11-25 19:07:39 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 19:07:40 | I |       - range scale = [    1.0000]
24-11-25 19:07:40 | I |         sum  error  = [    0.2381]
24-11-25 19:07:40 | I |         best error  = [    0.2381]
24-11-25 19:07:40 | I |     + error = [0.2381]
24-11-25 19:07:41 | I |       - range scale = [    1.0000]
24-11-25 19:07:41 | I |         sum  error  = [    1.8427]
24-11-25 19:07:41 | I |         best error  = [    1.8427]
24-11-25 19:07:41 | I |     + error = [1.8427]
24-11-25 19:07:41 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 19:07:42 | I |       - range scale = [    1.0000]
24-11-25 19:07:42 | I |         sum  error  = [    0.0594]
24-11-25 19:07:42 | I |         best error  = [    0.0594]
24-11-25 19:07:42 | I |     + error = [0.0594]
24-11-25 19:07:42 | I |       - range scale = [    1.0000]
24-11-25 19:07:42 | I |         sum  error  = [    0.5635]
24-11-25 19:07:42 | I |         best error  = [    0.5635]
24-11-25 19:07:42 | I |     + error = [0.5635]
24-11-25 19:07:43 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 19:07:43 | I |       - range scale = [    1.0000]
24-11-25 19:07:43 | I |         sum  error  = [    1.0579]
24-11-25 19:07:43 | I |         best error  = [    1.0579]
24-11-25 19:07:43 | I |     + error = [1.0579]
24-11-25 19:07:44 | I |       - range scale = [    1.0000]
24-11-25 19:07:44 | I |         sum  error  = [   11.7070]
24-11-25 19:07:44 | I |         best error  = [   11.7070]
24-11-25 19:07:44 | I |     + error = [11.7070]
24-11-25 19:07:44 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 19:07:45 | I |       - range scale = [    1.0000]
24-11-25 19:07:45 | I |         sum  error  = [    1.2238]
24-11-25 19:07:45 | I |         best error  = [    1.2238]
24-11-25 19:07:45 | I |     + error = [1.2238]
24-11-25 19:07:46 | I |       - range scale = [    1.0000]
24-11-25 19:07:46 | I |         sum  error  = [   12.0800]
24-11-25 19:07:46 | I |         best error  = [   12.0800]
24-11-25 19:07:46 | I |     + error = [12.0800]
24-11-25 19:07:46 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 19:07:47 | I |       - range scale = [    1.0000]
24-11-25 19:07:47 | I |         sum  error  = [    2.8650]
24-11-25 19:07:47 | I |         best error  = [    2.8650]
24-11-25 19:07:47 | I |     + error = [2.8650]
24-11-25 19:07:47 | I |       - range scale = [    1.0000]
24-11-25 19:07:47 | I |         sum  error  = [   16.0002]
24-11-25 19:07:47 | I |         best error  = [   16.0002]
24-11-25 19:07:47 | I |     + error = [16.0002]
24-11-25 19:07:48 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 19:07:49 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 19:07:50 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 19:07:52 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 19:07:53 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 19:07:55 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 19:07:56 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 19:07:59 | I | quantizing activations for layer model.layers.0
24-11-25 19:07:59 | I | collecting info in model.layers.0
24-11-25 19:07:59 | I | collecting info in model.layers.0
24-11-25 19:07:59 | I | collecting info in model.layers.0
24-11-25 19:07:59 | I | collecting info in model.layers.0
24-11-25 19:08:00 | I | collecting calibration activations in model.layers.0
24-11-25 19:08:00 | I | collecting calibration activations in model.layers.0
24-11-25 19:08:00 | I | collecting calibration activations in model.layers.0
24-11-25 19:08:00 | I | collecting calibration activations in model.layers.0
24-11-25 19:08:02 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 19:08:02 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 19:08:02 | I | - Evaluator: gptq
24-11-25 19:08:02 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 19:08:02 | I | - Batch_size: 8
24-11-25 19:08:02 | I |   + Max_seq_length: 2048
24-11-25 19:08:43 | I |     - Results:
24-11-25 19:08:43 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 19:08:43 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 19:08:43 | I |       |wikitext |      1|word_perplexity|8.1013|  |8.1013|
24-11-25 19:08:43 | I |       |val_valid|      1|word_perplexity|9.2478|  |9.2478|
24-11-25 19:08:43 | I |       
24-11-25 19:08:43 | I | forward this layer
24-11-25 19:08:43 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/137.pt
24-11-25 19:08:43 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/137.pt
24-11-25 19:08:44 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 19:08:44 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 19:08:44 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 19:08:44 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 19:08:44 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 19:08:44 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 19:08:44 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 19:08:44 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 19:08:44 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 19:08:44 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 19:08:44 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 19:08:44 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 19:08:44 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 19:08:44 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 19:08:44 | I | [54] done with optimizer step
24-11-25 19:08:44 | I | epoch 001:     69 / 409600000 loss=0.000158564, loss_per_token=0.32474, loss_sum=10641.1, wps=153.1, ups=0, wpb=32768, bsz=64, num_updates=55, lr=0.000149997, gnorm=39.147, clip=100, loss_scale=0.0078, train_wall=214, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=15054, lmquant_ppl_result_wikitext_in_train_no_quant=7.86939, lmquant_ppl_result_val_in_train_no_quant=9.09801, lmquant_ppl_result_wikitext_in_train_with_quant=8.10134, lmquant_ppl_result_val_in_train_with_quant=9.24782
24-11-25 19:08:44 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 19:08:44 | I | in layer model.layers.0
24-11-25 19:08:44 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 19:08:44 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 19:08:44 | I | - Evaluator: gptq
24-11-25 19:08:44 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 19:08:44 | I | - Batch_size: 8
24-11-25 19:08:44 | I |   + Max_seq_length: 2048
24-11-25 19:09:22 | I |     - Results:
24-11-25 19:09:22 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 19:09:22 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 19:09:22 | I |       |wikitext |      1|word_perplexity|7.9191|  |7.9191|
24-11-25 19:09:22 | I |       |val_valid|      1|word_perplexity|9.1392|  |9.1392|
24-11-25 19:09:22 | I |       
24-11-25 19:09:22 | I | quantizing weights for layer model.layers.0
24-11-25 19:09:22 | I | collecting info in model.layers.0
24-11-25 19:09:22 | I | collecting info in model.layers.0
24-11-25 19:09:22 | I | collecting info in model.layers.0
24-11-25 19:09:22 | I | collecting info in model.layers.0
24-11-25 19:09:23 | I | collecting calibration activations in model.layers.0
24-11-25 19:09:23 | I | collecting calibration activations in model.layers.0
24-11-25 19:09:23 | I | collecting calibration activations in model.layers.0
24-11-25 19:09:23 | I | collecting calibration activations in model.layers.0
24-11-25 19:09:23 | I | - Quantizing decoder layer model.layers.0
24-11-25 19:09:23 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 19:09:24 | I |       - range scale = [    1.0000]
24-11-25 19:09:24 | I |         sum  error  = [    0.0613]
24-11-25 19:09:24 | I |         best error  = [    0.0613]
24-11-25 19:09:24 | I |     + error = [0.0613]
24-11-25 19:09:25 | I |       - range scale = [    1.0000]
24-11-25 19:09:25 | I |         sum  error  = [    0.5904]
24-11-25 19:09:25 | I |         best error  = [    0.5904]
24-11-25 19:09:25 | I |     + error = [0.5904]
24-11-25 19:09:25 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 19:09:26 | I |       - range scale = [    1.0000]
24-11-25 19:09:26 | I |         sum  error  = [    0.0588]
24-11-25 19:09:26 | I |         best error  = [    0.0588]
24-11-25 19:09:26 | I |     + error = [0.0588]
24-11-25 19:09:26 | I |       - range scale = [    1.0000]
24-11-25 19:09:26 | I |         sum  error  = [    0.5979]
24-11-25 19:09:26 | I |         best error  = [    0.5979]
24-11-25 19:09:26 | I |     + error = [0.5979]
24-11-25 19:09:27 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 19:09:27 | I |       - range scale = [    1.0000]
24-11-25 19:09:27 | I |         sum  error  = [    0.2443]
24-11-25 19:09:27 | I |         best error  = [    0.2443]
24-11-25 19:09:27 | I |     + error = [0.2443]
24-11-25 19:09:28 | I |       - range scale = [    1.0000]
24-11-25 19:09:28 | I |         sum  error  = [    1.8603]
24-11-25 19:09:28 | I |         best error  = [    1.8603]
24-11-25 19:09:28 | I |     + error = [1.8603]
24-11-25 19:09:28 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 19:09:29 | I |       - range scale = [    1.0000]
24-11-25 19:09:29 | I |         sum  error  = [    0.0828]
24-11-25 19:09:29 | I |         best error  = [    0.0828]
24-11-25 19:09:29 | I |     + error = [0.0828]
24-11-25 19:09:30 | I |       - range scale = [    1.0000]
24-11-25 19:09:30 | I |         sum  error  = [    0.7917]
24-11-25 19:09:30 | I |         best error  = [    0.7917]
24-11-25 19:09:30 | I |     + error = [0.7917]
24-11-25 19:09:30 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 19:09:30 | I |       - range scale = [    1.0000]
24-11-25 19:09:30 | I |         sum  error  = [    1.1265]
24-11-25 19:09:30 | I |         best error  = [    1.1265]
24-11-25 19:09:30 | I |     + error = [1.1265]
24-11-25 19:09:31 | I |       - range scale = [    1.0000]
24-11-25 19:09:31 | I |         sum  error  = [   12.4873]
24-11-25 19:09:31 | I |         best error  = [   12.4873]
24-11-25 19:09:31 | I |     + error = [12.4873]
24-11-25 19:09:31 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 19:09:32 | I |       - range scale = [    1.0000]
24-11-25 19:09:32 | I |         sum  error  = [    1.3069]
24-11-25 19:09:32 | I |         best error  = [    1.3069]
24-11-25 19:09:32 | I |     + error = [1.3069]
24-11-25 19:09:33 | I |       - range scale = [    1.0000]
24-11-25 19:09:33 | I |         sum  error  = [   12.9172]
24-11-25 19:09:33 | I |         best error  = [   12.9172]
24-11-25 19:09:33 | I |     + error = [12.9172]
24-11-25 19:09:33 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 19:09:34 | I |       - range scale = [    1.0000]
24-11-25 19:09:34 | I |         sum  error  = [    2.3491]
24-11-25 19:09:34 | I |         best error  = [    2.3491]
24-11-25 19:09:34 | I |     + error = [2.3491]
24-11-25 19:09:35 | I |       - range scale = [    1.0000]
24-11-25 19:09:35 | I |         sum  error  = [   12.7949]
24-11-25 19:09:35 | I |         best error  = [   12.7949]
24-11-25 19:09:35 | I |     + error = [12.7949]
24-11-25 19:09:35 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 19:09:36 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 19:09:38 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 19:09:39 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 19:09:40 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 19:09:42 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 19:09:43 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 19:09:47 | I | quantizing activations for layer model.layers.0
24-11-25 19:09:47 | I | collecting info in model.layers.0
24-11-25 19:09:47 | I | collecting info in model.layers.0
24-11-25 19:09:47 | I | collecting info in model.layers.0
24-11-25 19:09:47 | I | collecting info in model.layers.0
24-11-25 19:09:47 | I | collecting calibration activations in model.layers.0
24-11-25 19:09:47 | I | collecting calibration activations in model.layers.0
24-11-25 19:09:47 | I | collecting calibration activations in model.layers.0
24-11-25 19:09:47 | I | collecting calibration activations in model.layers.0
24-11-25 19:09:49 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 19:09:49 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 19:09:49 | I | - Evaluator: gptq
24-11-25 19:09:49 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 19:09:49 | I | - Batch_size: 8
24-11-25 19:09:49 | I |   + Max_seq_length: 2048
24-11-25 19:10:31 | I |     - Results:
24-11-25 19:10:31 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 19:10:31 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 19:10:31 | I |       |wikitext |      1|word_perplexity|8.1824|  |8.1824|
24-11-25 19:10:31 | I |       |val_valid|      1|word_perplexity|9.3935|  |9.3935|
24-11-25 19:10:31 | I |       
24-11-25 19:10:31 | I | forward this layer
24-11-25 19:10:31 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/138.pt
24-11-25 19:10:31 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/138.pt
24-11-25 19:10:31 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 19:10:31 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 19:10:31 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 19:10:31 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 19:10:31 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 19:10:31 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 19:10:31 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 19:10:31 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 19:10:31 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 19:10:31 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 19:10:31 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 19:10:31 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 19:10:31 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 19:10:31 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 19:10:31 | I | in layer model.layers.0
24-11-25 19:10:31 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 19:10:31 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 19:10:31 | I | - Evaluator: gptq
24-11-25 19:10:31 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 19:10:31 | I | - Batch_size: 8
24-11-25 19:10:31 | I |   + Max_seq_length: 2048
24-11-25 19:11:09 | I |     - Results:
24-11-25 19:11:09 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 19:11:09 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 19:11:09 | I |       |wikitext |      1|word_perplexity|7.9191|  |7.9191|
24-11-25 19:11:09 | I |       |val_valid|      1|word_perplexity|9.1392|  |9.1392|
24-11-25 19:11:09 | I |       
24-11-25 19:11:09 | I | quantizing weights for layer model.layers.0
24-11-25 19:11:09 | I | collecting info in model.layers.0
24-11-25 19:11:09 | I | collecting info in model.layers.0
24-11-25 19:11:09 | I | collecting info in model.layers.0
24-11-25 19:11:09 | I | collecting info in model.layers.0
24-11-25 19:11:10 | I | collecting calibration activations in model.layers.0
24-11-25 19:11:10 | I | collecting calibration activations in model.layers.0
24-11-25 19:11:10 | I | collecting calibration activations in model.layers.0
24-11-25 19:11:10 | I | collecting calibration activations in model.layers.0
24-11-25 19:11:11 | I | - Quantizing decoder layer model.layers.0
24-11-25 19:11:11 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 19:11:11 | I |       - range scale = [    1.0000]
24-11-25 19:11:11 | I |         sum  error  = [    0.0573]
24-11-25 19:11:11 | I |         best error  = [    0.0573]
24-11-25 19:11:11 | I |     + error = [0.0573]
24-11-25 19:11:12 | I |       - range scale = [    1.0000]
24-11-25 19:11:12 | I |         sum  error  = [    0.5623]
24-11-25 19:11:12 | I |         best error  = [    0.5623]
24-11-25 19:11:12 | I |     + error = [0.5623]
24-11-25 19:11:12 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 19:11:13 | I |       - range scale = [    1.0000]
24-11-25 19:11:13 | I |         sum  error  = [    0.0610]
24-11-25 19:11:13 | I |         best error  = [    0.0610]
24-11-25 19:11:13 | I |     + error = [0.0610]
24-11-25 19:11:14 | I |       - range scale = [    1.0000]
24-11-25 19:11:14 | I |         sum  error  = [    0.5881]
24-11-25 19:11:14 | I |         best error  = [    0.5881]
24-11-25 19:11:14 | I |     + error = [0.5881]
24-11-25 19:11:14 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 19:11:15 | I |       - range scale = [    1.0000]
24-11-25 19:11:15 | I |         sum  error  = [    0.2350]
24-11-25 19:11:15 | I |         best error  = [    0.2350]
24-11-25 19:11:15 | I |     + error = [0.2350]
24-11-25 19:11:15 | I |       - range scale = [    1.0000]
24-11-25 19:11:15 | I |         sum  error  = [    1.8531]
24-11-25 19:11:15 | I |         best error  = [    1.8531]
24-11-25 19:11:15 | I |     + error = [1.8531]
24-11-25 19:11:15 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 19:11:16 | I |       - range scale = [    1.0000]
24-11-25 19:11:16 | I |         sum  error  = [    0.0637]
24-11-25 19:11:16 | I |         best error  = [    0.0637]
24-11-25 19:11:16 | I |     + error = [0.0637]
24-11-25 19:11:17 | I |       - range scale = [    1.0000]
24-11-25 19:11:17 | I |         sum  error  = [    0.6083]
24-11-25 19:11:17 | I |         best error  = [    0.6083]
24-11-25 19:11:17 | I |     + error = [0.6083]
24-11-25 19:11:17 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 19:11:18 | I |       - range scale = [    1.0000]
24-11-25 19:11:18 | I |         sum  error  = [    1.0754]
24-11-25 19:11:18 | I |         best error  = [    1.0754]
24-11-25 19:11:18 | I |     + error = [1.0754]
24-11-25 19:11:18 | I |       - range scale = [    1.0000]
24-11-25 19:11:18 | I |         sum  error  = [   11.9036]
24-11-25 19:11:18 | I |         best error  = [   11.9036]
24-11-25 19:11:18 | I |     + error = [11.9036]
24-11-25 19:11:19 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 19:11:19 | I |       - range scale = [    1.0000]
24-11-25 19:11:19 | I |         sum  error  = [    1.2455]
24-11-25 19:11:19 | I |         best error  = [    1.2455]
24-11-25 19:11:19 | I |     + error = [1.2455]
24-11-25 19:11:20 | I |       - range scale = [    1.0000]
24-11-25 19:11:20 | I |         sum  error  = [   12.3052]
24-11-25 19:11:20 | I |         best error  = [   12.3052]
24-11-25 19:11:20 | I |     + error = [12.3052]
24-11-25 19:11:20 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 19:11:21 | I |       - range scale = [    1.0000]
24-11-25 19:11:21 | I |         sum  error  = [    2.0482]
24-11-25 19:11:21 | I |         best error  = [    2.0482]
24-11-25 19:11:21 | I |     + error = [2.0482]
24-11-25 19:11:22 | I |       - range scale = [    1.0000]
24-11-25 19:11:22 | I |         sum  error  = [   11.6796]
24-11-25 19:11:22 | I |         best error  = [   11.6796]
24-11-25 19:11:22 | I |     + error = [11.6796]
24-11-25 19:11:22 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 19:11:24 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 19:11:25 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 19:11:27 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 19:11:29 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 19:11:31 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 19:11:33 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 19:11:37 | I | quantizing activations for layer model.layers.0
24-11-25 19:11:37 | I | collecting info in model.layers.0
24-11-25 19:11:37 | I | collecting info in model.layers.0
24-11-25 19:11:37 | I | collecting info in model.layers.0
24-11-25 19:11:37 | I | collecting info in model.layers.0
24-11-25 19:11:37 | I | collecting calibration activations in model.layers.0
24-11-25 19:11:37 | I | collecting calibration activations in model.layers.0
24-11-25 19:11:37 | I | collecting calibration activations in model.layers.0
24-11-25 19:11:37 | I | collecting calibration activations in model.layers.0
24-11-25 19:11:39 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 19:11:39 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 19:11:39 | I | - Evaluator: gptq
24-11-25 19:11:39 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 19:11:39 | I | - Batch_size: 8
24-11-25 19:11:39 | I |   + Max_seq_length: 2048
24-11-25 19:12:21 | I |     - Results:
24-11-25 19:12:21 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 19:12:21 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 19:12:21 | I |       |wikitext |      1|word_perplexity|8.1284|  |8.1284|
24-11-25 19:12:21 | I |       |val_valid|      1|word_perplexity|9.2971|  |9.2971|
24-11-25 19:12:21 | I |       
24-11-25 19:12:21 | I | forward this layer
24-11-25 19:12:21 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/139.pt
24-11-25 19:12:21 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/139.pt
24-11-25 19:12:21 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 19:12:21 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 19:12:21 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 19:12:21 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 19:12:21 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 19:12:21 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 19:12:21 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 19:12:21 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 19:12:21 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 19:12:21 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 19:12:21 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 19:12:21 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 19:12:21 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 19:12:21 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 19:12:21 | I | [55] done with optimizer step
24-11-25 19:12:21 | I | epoch 001:     70 / 409600000 loss=0.000234896, loss_per_token=0.481067, loss_sum=15763.6, wps=150.9, ups=0, wpb=32768, bsz=64, num_updates=56, lr=0.000149997, gnorm=55.167, clip=100, loss_scale=0.0078, train_wall=217, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=15271, lmquant_ppl_result_wikitext_in_train_no_quant=7.91909, lmquant_ppl_result_val_in_train_no_quant=9.13917, lmquant_ppl_result_wikitext_in_train_with_quant=8.1284, lmquant_ppl_result_val_in_train_with_quant=9.29709
24-11-25 19:12:21 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 19:12:21 | I | in layer model.layers.0
24-11-25 19:12:21 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 19:12:21 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 19:12:21 | I | - Evaluator: gptq
24-11-25 19:12:21 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 19:12:21 | I | - Batch_size: 8
24-11-25 19:12:21 | I |   + Max_seq_length: 2048
24-11-25 19:12:59 | I |     - Results:
24-11-25 19:12:59 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 19:12:59 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 19:12:59 | I |       |wikitext |      1|word_perplexity|7.9189|  |7.9189|
24-11-25 19:12:59 | I |       |val_valid|      1|word_perplexity|9.1473|  |9.1473|
24-11-25 19:12:59 | I |       
24-11-25 19:12:59 | I | quantizing weights for layer model.layers.0
24-11-25 19:12:59 | I | collecting info in model.layers.0
24-11-25 19:12:59 | I | collecting info in model.layers.0
24-11-25 19:12:59 | I | collecting info in model.layers.0
24-11-25 19:12:59 | I | collecting info in model.layers.0
24-11-25 19:13:00 | I | collecting calibration activations in model.layers.0
24-11-25 19:13:00 | I | collecting calibration activations in model.layers.0
24-11-25 19:13:00 | I | collecting calibration activations in model.layers.0
24-11-25 19:13:00 | I | collecting calibration activations in model.layers.0
24-11-25 19:13:01 | I | - Quantizing decoder layer model.layers.0
24-11-25 19:13:01 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 19:13:01 | I |       - range scale = [    1.0000]
24-11-25 19:13:01 | I |         sum  error  = [    0.0690]
24-11-25 19:13:01 | I |         best error  = [    0.0690]
24-11-25 19:13:01 | I |     + error = [0.0690]
24-11-25 19:13:02 | I |       - range scale = [    1.0000]
24-11-25 19:13:02 | I |         sum  error  = [    0.6303]
24-11-25 19:13:02 | I |         best error  = [    0.6303]
24-11-25 19:13:02 | I |     + error = [0.6303]
24-11-25 19:13:02 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 19:13:03 | I |       - range scale = [    1.0000]
24-11-25 19:13:03 | I |         sum  error  = [    0.0615]
24-11-25 19:13:03 | I |         best error  = [    0.0615]
24-11-25 19:13:03 | I |     + error = [0.0615]
24-11-25 19:13:04 | I |       - range scale = [    1.0000]
24-11-25 19:13:04 | I |         sum  error  = [    0.5878]
24-11-25 19:13:04 | I |         best error  = [    0.5878]
24-11-25 19:13:04 | I |     + error = [0.5878]
24-11-25 19:13:04 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 19:13:05 | I |       - range scale = [    1.0000]
24-11-25 19:13:05 | I |         sum  error  = [    0.2338]
24-11-25 19:13:05 | I |         best error  = [    0.2338]
24-11-25 19:13:05 | I |     + error = [0.2338]
24-11-25 19:13:05 | I |       - range scale = [    1.0000]
24-11-25 19:13:05 | I |         sum  error  = [    1.8371]
24-11-25 19:13:05 | I |         best error  = [    1.8371]
24-11-25 19:13:05 | I |     + error = [1.8371]
24-11-25 19:13:05 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 19:13:06 | I |       - range scale = [    1.0000]
24-11-25 19:13:06 | I |         sum  error  = [    0.0675]
24-11-25 19:13:06 | I |         best error  = [    0.0675]
24-11-25 19:13:06 | I |     + error = [0.0675]
24-11-25 19:13:07 | I |       - range scale = [    1.0000]
24-11-25 19:13:07 | I |         sum  error  = [    0.6461]
24-11-25 19:13:07 | I |         best error  = [    0.6461]
24-11-25 19:13:07 | I |     + error = [0.6461]
24-11-25 19:13:07 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 19:13:08 | I |       - range scale = [    1.0000]
24-11-25 19:13:08 | I |         sum  error  = [    1.0664]
24-11-25 19:13:08 | I |         best error  = [    1.0664]
24-11-25 19:13:08 | I |     + error = [1.0664]
24-11-25 19:13:09 | I |       - range scale = [    1.0000]
24-11-25 19:13:09 | I |         sum  error  = [   11.8129]
24-11-25 19:13:09 | I |         best error  = [   11.8129]
24-11-25 19:13:09 | I |     + error = [11.8129]
24-11-25 19:13:09 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 19:13:09 | I |       - range scale = [    1.0000]
24-11-25 19:13:09 | I |         sum  error  = [    1.2323]
24-11-25 19:13:09 | I |         best error  = [    1.2323]
24-11-25 19:13:09 | I |     + error = [1.2323]
24-11-25 19:13:10 | I |       - range scale = [    1.0000]
24-11-25 19:13:10 | I |         sum  error  = [   12.1988]
24-11-25 19:13:10 | I |         best error  = [   12.1988]
24-11-25 19:13:10 | I |     + error = [12.1988]
24-11-25 19:13:10 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 19:13:11 | I |       - range scale = [    1.0000]
24-11-25 19:13:11 | I |         sum  error  = [    2.9009]
24-11-25 19:13:11 | I |         best error  = [    2.9009]
24-11-25 19:13:11 | I |     + error = [2.9009]
24-11-25 19:13:12 | I |       - range scale = [    1.0000]
24-11-25 19:13:12 | I |         sum  error  = [   15.3244]
24-11-25 19:13:12 | I |         best error  = [   15.3244]
24-11-25 19:13:12 | I |     + error = [15.3244]
24-11-25 19:13:12 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 19:13:14 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 19:13:15 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 19:13:16 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 19:13:18 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 19:13:19 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 19:13:21 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 19:13:24 | I | quantizing activations for layer model.layers.0
24-11-25 19:13:24 | I | collecting info in model.layers.0
24-11-25 19:13:24 | I | collecting info in model.layers.0
24-11-25 19:13:24 | I | collecting info in model.layers.0
24-11-25 19:13:24 | I | collecting info in model.layers.0
24-11-25 19:13:24 | I | collecting calibration activations in model.layers.0
24-11-25 19:13:25 | I | collecting calibration activations in model.layers.0
24-11-25 19:13:25 | I | collecting calibration activations in model.layers.0
24-11-25 19:13:25 | I | collecting calibration activations in model.layers.0
24-11-25 19:13:27 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 19:13:27 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 19:13:27 | I | - Evaluator: gptq
24-11-25 19:13:27 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 19:13:27 | I | - Batch_size: 8
24-11-25 19:13:27 | I |   + Max_seq_length: 2048
24-11-25 19:14:08 | I |     - Results:
24-11-25 19:14:08 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 19:14:08 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 19:14:08 | I |       |wikitext |      1|word_perplexity|8.1083|  |8.1083|
24-11-25 19:14:08 | I |       |val_valid|      1|word_perplexity|9.3192|  |9.3192|
24-11-25 19:14:08 | I |       
24-11-25 19:14:08 | I | forward this layer
24-11-25 19:14:08 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/140.pt
24-11-25 19:14:08 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/140.pt
24-11-25 19:14:08 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 19:14:08 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 19:14:08 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 19:14:08 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 19:14:08 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 19:14:08 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 19:14:08 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 19:14:08 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 19:14:08 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 19:14:08 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 19:14:08 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 19:14:08 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 19:14:08 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 19:14:08 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 19:14:08 | I | in layer model.layers.0
24-11-25 19:14:08 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 19:14:08 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 19:14:08 | I | - Evaluator: gptq
24-11-25 19:14:08 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 19:14:08 | I | - Batch_size: 8
24-11-25 19:14:08 | I |   + Max_seq_length: 2048
24-11-25 19:14:47 | I |     - Results:
24-11-25 19:14:47 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 19:14:47 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 19:14:47 | I |       |wikitext |      1|word_perplexity|7.9189|  |7.9189|
24-11-25 19:14:47 | I |       |val_valid|      1|word_perplexity|9.1473|  |9.1473|
24-11-25 19:14:47 | I |       
24-11-25 19:14:47 | I | quantizing weights for layer model.layers.0
24-11-25 19:14:47 | I | collecting info in model.layers.0
24-11-25 19:14:47 | I | collecting info in model.layers.0
24-11-25 19:14:47 | I | collecting info in model.layers.0
24-11-25 19:14:47 | I | collecting info in model.layers.0
24-11-25 19:14:47 | I | collecting calibration activations in model.layers.0
24-11-25 19:14:47 | I | collecting calibration activations in model.layers.0
24-11-25 19:14:47 | I | collecting calibration activations in model.layers.0
24-11-25 19:14:48 | I | collecting calibration activations in model.layers.0
24-11-25 19:14:48 | I | - Quantizing decoder layer model.layers.0
24-11-25 19:14:48 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 19:14:49 | I |       - range scale = [    1.0000]
24-11-25 19:14:49 | I |         sum  error  = [    0.0675]
24-11-25 19:14:49 | I |         best error  = [    0.0675]
24-11-25 19:14:49 | I |     + error = [0.0675]
24-11-25 19:14:49 | I |       - range scale = [    1.0000]
24-11-25 19:14:49 | I |         sum  error  = [    0.6255]
24-11-25 19:14:49 | I |         best error  = [    0.6255]
24-11-25 19:14:49 | I |     + error = [0.6255]
24-11-25 19:14:49 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 19:14:50 | I |       - range scale = [    1.0000]
24-11-25 19:14:50 | I |         sum  error  = [    0.0608]
24-11-25 19:14:50 | I |         best error  = [    0.0608]
24-11-25 19:14:50 | I |     + error = [0.0608]
24-11-25 19:14:51 | I |       - range scale = [    1.0000]
24-11-25 19:14:51 | I |         sum  error  = [    0.5769]
24-11-25 19:14:51 | I |         best error  = [    0.5769]
24-11-25 19:14:51 | I |     + error = [0.5769]
24-11-25 19:14:51 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 19:14:52 | I |       - range scale = [    1.0000]
24-11-25 19:14:52 | I |         sum  error  = [    0.2410]
24-11-25 19:14:52 | I |         best error  = [    0.2410]
24-11-25 19:14:52 | I |     + error = [0.2410]
24-11-25 19:14:52 | I |       - range scale = [    1.0000]
24-11-25 19:14:52 | I |         sum  error  = [    1.8903]
24-11-25 19:14:52 | I |         best error  = [    1.8903]
24-11-25 19:14:52 | I |     + error = [1.8903]
24-11-25 19:14:53 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 19:14:53 | I |       - range scale = [    1.0000]
24-11-25 19:14:53 | I |         sum  error  = [    0.0659]
24-11-25 19:14:53 | I |         best error  = [    0.0659]
24-11-25 19:14:53 | I |     + error = [0.0659]
24-11-25 19:14:54 | I |       - range scale = [    1.0000]
24-11-25 19:14:54 | I |         sum  error  = [    0.6199]
24-11-25 19:14:54 | I |         best error  = [    0.6199]
24-11-25 19:14:54 | I |     + error = [0.6199]
24-11-25 19:14:54 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 19:14:55 | I |       - range scale = [    1.0000]
24-11-25 19:14:55 | I |         sum  error  = [    1.0648]
24-11-25 19:14:55 | I |         best error  = [    1.0648]
24-11-25 19:14:55 | I |     + error = [1.0648]
24-11-25 19:14:56 | I |       - range scale = [    1.0000]
24-11-25 19:14:56 | I |         sum  error  = [   11.7843]
24-11-25 19:14:56 | I |         best error  = [   11.7843]
24-11-25 19:14:56 | I |     + error = [11.7843]
24-11-25 19:14:56 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 19:14:57 | I |       - range scale = [    1.0000]
24-11-25 19:14:57 | I |         sum  error  = [    1.2262]
24-11-25 19:14:57 | I |         best error  = [    1.2262]
24-11-25 19:14:57 | I |     + error = [1.2262]
24-11-25 19:14:57 | I |       - range scale = [    1.0000]
24-11-25 19:14:57 | I |         sum  error  = [   12.1780]
24-11-25 19:14:57 | I |         best error  = [   12.1780]
24-11-25 19:14:57 | I |     + error = [12.1780]
24-11-25 19:14:58 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 19:14:58 | I |       - range scale = [    1.0000]
24-11-25 19:14:58 | I |         sum  error  = [    3.7462]
24-11-25 19:14:58 | I |         best error  = [    3.7462]
24-11-25 19:14:58 | I |     + error = [3.7462]
24-11-25 19:14:59 | I |       - range scale = [    1.0000]
24-11-25 19:14:59 | I |         sum  error  = [   19.6737]
24-11-25 19:14:59 | I |         best error  = [   19.6737]
24-11-25 19:14:59 | I |     + error = [19.6737]
24-11-25 19:14:59 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 19:15:01 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 19:15:02 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 19:15:03 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 19:15:05 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 19:15:06 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 19:15:08 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 19:15:11 | I | quantizing activations for layer model.layers.0
24-11-25 19:15:11 | I | collecting info in model.layers.0
24-11-25 19:15:11 | I | collecting info in model.layers.0
24-11-25 19:15:11 | I | collecting info in model.layers.0
24-11-25 19:15:11 | I | collecting info in model.layers.0
24-11-25 19:15:11 | I | collecting calibration activations in model.layers.0
24-11-25 19:15:12 | I | collecting calibration activations in model.layers.0
24-11-25 19:15:12 | I | collecting calibration activations in model.layers.0
24-11-25 19:15:12 | I | collecting calibration activations in model.layers.0
24-11-25 19:15:14 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 19:15:14 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 19:15:14 | I | - Evaluator: gptq
24-11-25 19:15:14 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 19:15:14 | I | - Batch_size: 8
24-11-25 19:15:14 | I |   + Max_seq_length: 2048
24-11-25 19:15:55 | I |     - Results:
24-11-25 19:15:55 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 19:15:55 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 19:15:55 | I |       |wikitext |      1|word_perplexity|8.1139|  |8.1139|
24-11-25 19:15:55 | I |       |val_valid|      1|word_perplexity|9.3511|  |9.3511|
24-11-25 19:15:55 | I |       
24-11-25 19:15:55 | I | forward this layer
24-11-25 19:15:55 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/141.pt
24-11-25 19:15:55 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/141.pt
24-11-25 19:15:56 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 19:15:56 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 19:15:56 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 19:15:56 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 19:15:56 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 19:15:56 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 19:15:56 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 19:15:56 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 19:15:56 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 19:15:56 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 19:15:56 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 19:15:56 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 19:15:56 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 19:15:56 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 19:15:56 | I | [56] done with optimizer step
24-11-25 19:15:56 | I | epoch 001:     71 / 409600000 loss=0.000275414, loss_per_token=0.564047, loss_sum=18482.7, wps=152.7, ups=0, wpb=32768, bsz=64, num_updates=57, lr=0.000149996, gnorm=22.258, clip=100, loss_scale=0.0078, train_wall=214, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=15486, lmquant_ppl_result_wikitext_in_train_no_quant=7.91888, lmquant_ppl_result_val_in_train_no_quant=9.14728, lmquant_ppl_result_wikitext_in_train_with_quant=8.1139, lmquant_ppl_result_val_in_train_with_quant=9.35105
24-11-25 19:15:56 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 19:15:56 | I | in layer model.layers.0
24-11-25 19:15:56 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 19:15:56 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 19:15:56 | I | - Evaluator: gptq
24-11-25 19:15:56 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 19:15:56 | I | - Batch_size: 8
24-11-25 19:15:56 | I |   + Max_seq_length: 2048
24-11-25 19:16:34 | I |     - Results:
24-11-25 19:16:34 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 19:16:34 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 19:16:34 | I |       |wikitext |      1|word_perplexity|7.8837|  |7.8837|
24-11-25 19:16:34 | I |       |val_valid|      1|word_perplexity|9.1149|  |9.1149|
24-11-25 19:16:34 | I |       
24-11-25 19:16:34 | I | quantizing weights for layer model.layers.0
24-11-25 19:16:34 | I | collecting info in model.layers.0
24-11-25 19:16:34 | I | collecting info in model.layers.0
24-11-25 19:16:34 | I | collecting info in model.layers.0
24-11-25 19:16:34 | I | collecting info in model.layers.0
24-11-25 19:16:35 | I | collecting calibration activations in model.layers.0
24-11-25 19:16:35 | I | collecting calibration activations in model.layers.0
24-11-25 19:16:35 | I | collecting calibration activations in model.layers.0
24-11-25 19:16:35 | I | collecting calibration activations in model.layers.0
24-11-25 19:16:35 | I | - Quantizing decoder layer model.layers.0
24-11-25 19:16:35 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 19:16:36 | I |       - range scale = [    1.0000]
24-11-25 19:16:36 | I |         sum  error  = [    0.0660]
24-11-25 19:16:36 | I |         best error  = [    0.0660]
24-11-25 19:16:36 | I |     + error = [0.0660]
24-11-25 19:16:37 | I |       - range scale = [    1.0000]
24-11-25 19:16:37 | I |         sum  error  = [    0.6255]
24-11-25 19:16:37 | I |         best error  = [    0.6255]
24-11-25 19:16:37 | I |     + error = [0.6255]
24-11-25 19:16:37 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 19:16:38 | I |       - range scale = [    1.0000]
24-11-25 19:16:38 | I |         sum  error  = [    0.0575]
24-11-25 19:16:38 | I |         best error  = [    0.0575]
24-11-25 19:16:38 | I |     + error = [0.0575]
24-11-25 19:16:38 | I |       - range scale = [    1.0000]
24-11-25 19:16:38 | I |         sum  error  = [    0.5485]
24-11-25 19:16:38 | I |         best error  = [    0.5485]
24-11-25 19:16:38 | I |     + error = [0.5485]
24-11-25 19:16:39 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 19:16:39 | I |       - range scale = [    1.0000]
24-11-25 19:16:39 | I |         sum  error  = [    0.2405]
24-11-25 19:16:39 | I |         best error  = [    0.2405]
24-11-25 19:16:39 | I |     + error = [0.2405]
24-11-25 19:16:40 | I |       - range scale = [    1.0000]
24-11-25 19:16:40 | I |         sum  error  = [    1.8412]
24-11-25 19:16:40 | I |         best error  = [    1.8412]
24-11-25 19:16:40 | I |     + error = [1.8412]
24-11-25 19:16:40 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 19:16:41 | I |       - range scale = [    1.0000]
24-11-25 19:16:41 | I |         sum  error  = [    0.0658]
24-11-25 19:16:41 | I |         best error  = [    0.0658]
24-11-25 19:16:41 | I |     + error = [0.0658]
24-11-25 19:16:41 | I |       - range scale = [    1.0000]
24-11-25 19:16:41 | I |         sum  error  = [    0.6229]
24-11-25 19:16:41 | I |         best error  = [    0.6229]
24-11-25 19:16:41 | I |     + error = [0.6229]
24-11-25 19:16:42 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 19:16:42 | I |       - range scale = [    1.0000]
24-11-25 19:16:42 | I |         sum  error  = [    1.0645]
24-11-25 19:16:42 | I |         best error  = [    1.0645]
24-11-25 19:16:42 | I |     + error = [1.0645]
24-11-25 19:16:43 | I |       - range scale = [    1.0000]
24-11-25 19:16:43 | I |         sum  error  = [   11.7641]
24-11-25 19:16:43 | I |         best error  = [   11.7641]
24-11-25 19:16:43 | I |     + error = [11.7641]
24-11-25 19:16:43 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 19:16:44 | I |       - range scale = [    1.0000]
24-11-25 19:16:44 | I |         sum  error  = [    1.2239]
24-11-25 19:16:44 | I |         best error  = [    1.2239]
24-11-25 19:16:44 | I |     + error = [1.2239]
24-11-25 19:16:45 | I |       - range scale = [    1.0000]
24-11-25 19:16:45 | I |         sum  error  = [   12.1630]
24-11-25 19:16:45 | I |         best error  = [   12.1630]
24-11-25 19:16:45 | I |     + error = [12.1630]
24-11-25 19:16:45 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 19:16:46 | I |       - range scale = [    1.0000]
24-11-25 19:16:46 | I |         sum  error  = [    2.7177]
24-11-25 19:16:46 | I |         best error  = [    2.7177]
24-11-25 19:16:46 | I |     + error = [2.7177]
24-11-25 19:16:46 | I |       - range scale = [    1.0000]
24-11-25 19:16:46 | I |         sum  error  = [   13.8059]
24-11-25 19:16:46 | I |         best error  = [   13.8059]
24-11-25 19:16:46 | I |     + error = [13.8059]
24-11-25 19:16:47 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 19:16:48 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 19:16:50 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 19:16:51 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 19:16:52 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 19:16:54 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 19:16:55 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 19:16:59 | I | quantizing activations for layer model.layers.0
24-11-25 19:16:59 | I | collecting info in model.layers.0
24-11-25 19:16:59 | I | collecting info in model.layers.0
24-11-25 19:16:59 | I | collecting info in model.layers.0
24-11-25 19:16:59 | I | collecting info in model.layers.0
24-11-25 19:16:59 | I | collecting calibration activations in model.layers.0
24-11-25 19:16:59 | I | collecting calibration activations in model.layers.0
24-11-25 19:16:59 | I | collecting calibration activations in model.layers.0
24-11-25 19:16:59 | I | collecting calibration activations in model.layers.0
24-11-25 19:17:01 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 19:17:01 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 19:17:01 | I | - Evaluator: gptq
24-11-25 19:17:01 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 19:17:01 | I | - Batch_size: 8
24-11-25 19:17:01 | I |   + Max_seq_length: 2048
24-11-25 19:17:43 | I |     - Results:
24-11-25 19:17:43 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 19:17:43 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 19:17:43 | I |       |wikitext |      1|word_perplexity|8.0008|  |8.0008|
24-11-25 19:17:43 | I |       |val_valid|      1|word_perplexity|9.2431|  |9.2431|
24-11-25 19:17:43 | I |       
24-11-25 19:17:43 | I | forward this layer
24-11-25 19:17:43 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/142.pt
24-11-25 19:17:43 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/142.pt
24-11-25 19:17:43 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 19:17:43 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 19:17:43 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 19:17:43 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 19:17:43 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 19:17:43 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 19:17:43 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 19:17:43 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 19:17:43 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 19:17:43 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 19:17:43 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 19:17:43 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 19:17:43 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 19:17:43 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 19:17:43 | I | in layer model.layers.0
24-11-25 19:17:43 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 19:17:43 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 19:17:43 | I | - Evaluator: gptq
24-11-25 19:17:43 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 19:17:43 | I | - Batch_size: 8
24-11-25 19:17:43 | I |   + Max_seq_length: 2048
24-11-25 19:18:21 | I |     - Results:
24-11-25 19:18:21 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 19:18:21 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 19:18:21 | I |       |wikitext |      1|word_perplexity|7.8837|  |7.8837|
24-11-25 19:18:21 | I |       |val_valid|      1|word_perplexity|9.1149|  |9.1149|
24-11-25 19:18:21 | I |       
24-11-25 19:18:21 | I | quantizing weights for layer model.layers.0
24-11-25 19:18:21 | I | collecting info in model.layers.0
24-11-25 19:18:21 | I | collecting info in model.layers.0
24-11-25 19:18:21 | I | collecting info in model.layers.0
24-11-25 19:18:21 | I | collecting info in model.layers.0
24-11-25 19:18:22 | I | collecting calibration activations in model.layers.0
24-11-25 19:18:22 | I | collecting calibration activations in model.layers.0
24-11-25 19:18:22 | I | collecting calibration activations in model.layers.0
24-11-25 19:18:22 | I | collecting calibration activations in model.layers.0
24-11-25 19:18:23 | I | - Quantizing decoder layer model.layers.0
24-11-25 19:18:23 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 19:18:23 | I |       - range scale = [    1.0000]
24-11-25 19:18:23 | I |         sum  error  = [    0.0655]
24-11-25 19:18:23 | I |         best error  = [    0.0655]
24-11-25 19:18:23 | I |     + error = [0.0655]
24-11-25 19:18:24 | I |       - range scale = [    1.0000]
24-11-25 19:18:24 | I |         sum  error  = [    0.6347]
24-11-25 19:18:24 | I |         best error  = [    0.6347]
24-11-25 19:18:24 | I |     + error = [0.6347]
24-11-25 19:18:24 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 19:18:25 | I |       - range scale = [    1.0000]
24-11-25 19:18:25 | I |         sum  error  = [    0.0644]
24-11-25 19:18:25 | I |         best error  = [    0.0644]
24-11-25 19:18:25 | I |     + error = [0.0644]
24-11-25 19:18:25 | I |       - range scale = [    1.0000]
24-11-25 19:18:25 | I |         sum  error  = [    0.5944]
24-11-25 19:18:25 | I |         best error  = [    0.5944]
24-11-25 19:18:25 | I |     + error = [0.5944]
24-11-25 19:18:26 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 19:18:26 | I |       - range scale = [    1.0000]
24-11-25 19:18:26 | I |         sum  error  = [    0.2398]
24-11-25 19:18:26 | I |         best error  = [    0.2398]
24-11-25 19:18:26 | I |     + error = [0.2398]
24-11-25 19:18:27 | I |       - range scale = [    1.0000]
24-11-25 19:18:27 | I |         sum  error  = [    1.8693]
24-11-25 19:18:27 | I |         best error  = [    1.8693]
24-11-25 19:18:27 | I |     + error = [1.8693]
24-11-25 19:18:27 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 19:18:28 | I |       - range scale = [    1.0000]
24-11-25 19:18:28 | I |         sum  error  = [    0.0699]
24-11-25 19:18:28 | I |         best error  = [    0.0699]
24-11-25 19:18:28 | I |     + error = [0.0699]
24-11-25 19:18:29 | I |       - range scale = [    1.0000]
24-11-25 19:18:29 | I |         sum  error  = [    0.6763]
24-11-25 19:18:29 | I |         best error  = [    0.6763]
24-11-25 19:18:29 | I |     + error = [0.6763]
24-11-25 19:18:29 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 19:18:29 | I |       - range scale = [    1.0000]
24-11-25 19:18:29 | I |         sum  error  = [    1.1393]
24-11-25 19:18:29 | I |         best error  = [    1.1393]
24-11-25 19:18:29 | I |     + error = [1.1393]
24-11-25 19:18:30 | I |       - range scale = [    1.0000]
24-11-25 19:18:30 | I |         sum  error  = [   12.6509]
24-11-25 19:18:30 | I |         best error  = [   12.6509]
24-11-25 19:18:30 | I |     + error = [12.6509]
24-11-25 19:18:30 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 19:18:31 | I |       - range scale = [    1.0000]
24-11-25 19:18:31 | I |         sum  error  = [    1.3172]
24-11-25 19:18:31 | I |         best error  = [    1.3172]
24-11-25 19:18:31 | I |     + error = [1.3172]
24-11-25 19:18:32 | I |       - range scale = [    1.0000]
24-11-25 19:18:32 | I |         sum  error  = [   13.0956]
24-11-25 19:18:32 | I |         best error  = [   13.0956]
24-11-25 19:18:32 | I |     + error = [13.0956]
24-11-25 19:18:32 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 19:18:33 | I |       - range scale = [    1.0000]
24-11-25 19:18:33 | I |         sum  error  = [    2.1681]
24-11-25 19:18:33 | I |         best error  = [    2.1681]
24-11-25 19:18:33 | I |     + error = [2.1681]
24-11-25 19:18:34 | I |       - range scale = [    1.0000]
24-11-25 19:18:34 | I |         sum  error  = [   10.9692]
24-11-25 19:18:34 | I |         best error  = [   10.9692]
24-11-25 19:18:34 | I |     + error = [10.9692]
24-11-25 19:18:34 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 19:18:35 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 19:18:37 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 19:18:38 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 19:18:39 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 19:18:41 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 19:18:42 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 19:18:46 | I | quantizing activations for layer model.layers.0
24-11-25 19:18:46 | I | collecting info in model.layers.0
24-11-25 19:18:46 | I | collecting info in model.layers.0
24-11-25 19:18:46 | I | collecting info in model.layers.0
24-11-25 19:18:46 | I | collecting info in model.layers.0
24-11-25 19:18:46 | I | collecting calibration activations in model.layers.0
24-11-25 19:18:46 | I | collecting calibration activations in model.layers.0
24-11-25 19:18:46 | I | collecting calibration activations in model.layers.0
24-11-25 19:18:46 | I | collecting calibration activations in model.layers.0
24-11-25 19:18:48 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 19:18:48 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 19:18:48 | I | - Evaluator: gptq
24-11-25 19:18:48 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 19:18:48 | I | - Batch_size: 8
24-11-25 19:18:48 | I |   + Max_seq_length: 2048
24-11-25 19:19:30 | I |     - Results:
24-11-25 19:19:30 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 19:19:30 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 19:19:30 | I |       |wikitext |      1|word_perplexity|8.0338|  |8.0338|
24-11-25 19:19:30 | I |       |val_valid|      1|word_perplexity|9.2298|  |9.2298|
24-11-25 19:19:30 | I |       
24-11-25 19:19:30 | I | forward this layer
24-11-25 19:19:30 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/143.pt
24-11-25 19:19:30 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/143.pt
24-11-25 19:19:30 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 19:19:30 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 19:19:30 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 19:19:30 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 19:19:30 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 19:19:30 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 19:19:30 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 19:19:30 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 19:19:30 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 19:19:30 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 19:19:30 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 19:19:30 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 19:19:30 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 19:19:30 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 19:19:30 | I | [57] done with optimizer step
24-11-25 19:19:30 | I | epoch 001:     72 / 409600000 loss=0.000222196, loss_per_token=0.455058, loss_sum=14911.3, wps=152.7, ups=0, wpb=32768, bsz=64, num_updates=58, lr=0.000149996, gnorm=22.423, clip=100, loss_scale=0.0078, train_wall=214, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=15701, lmquant_ppl_result_wikitext_in_train_no_quant=7.88368, lmquant_ppl_result_val_in_train_no_quant=9.11487, lmquant_ppl_result_wikitext_in_train_with_quant=8.0338, lmquant_ppl_result_val_in_train_with_quant=9.2298
24-11-25 19:19:30 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 19:19:30 | I | in layer model.layers.0
24-11-25 19:19:30 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 19:19:30 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 19:19:30 | I | - Evaluator: gptq
24-11-25 19:19:30 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 19:19:30 | I | - Batch_size: 8
24-11-25 19:19:30 | I |   + Max_seq_length: 2048
24-11-25 19:20:09 | I |     - Results:
24-11-25 19:20:09 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 19:20:09 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 19:20:09 | I |       |wikitext |      1|word_perplexity|7.8541|  |7.8541|
24-11-25 19:20:09 | I |       |val_valid|      1|word_perplexity|9.0959|  |9.0959|
24-11-25 19:20:09 | I |       
24-11-25 19:20:09 | I | quantizing weights for layer model.layers.0
24-11-25 19:20:09 | I | collecting info in model.layers.0
24-11-25 19:20:09 | I | collecting info in model.layers.0
24-11-25 19:20:09 | I | collecting info in model.layers.0
24-11-25 19:20:09 | I | collecting info in model.layers.0
24-11-25 19:20:09 | I | collecting calibration activations in model.layers.0
24-11-25 19:20:09 | I | collecting calibration activations in model.layers.0
24-11-25 19:20:10 | I | collecting calibration activations in model.layers.0
24-11-25 19:20:10 | I | collecting calibration activations in model.layers.0
24-11-25 19:20:10 | I | - Quantizing decoder layer model.layers.0
24-11-25 19:20:10 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 19:20:11 | I |       - range scale = [    1.0000]
24-11-25 19:20:11 | I |         sum  error  = [    0.0644]
24-11-25 19:20:11 | I |         best error  = [    0.0644]
24-11-25 19:20:11 | I |     + error = [0.0644]
24-11-25 19:20:11 | I |       - range scale = [    1.0000]
24-11-25 19:20:11 | I |         sum  error  = [    0.5924]
24-11-25 19:20:11 | I |         best error  = [    0.5924]
24-11-25 19:20:11 | I |     + error = [0.5924]
24-11-25 19:20:12 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 19:20:12 | I |       - range scale = [    1.0000]
24-11-25 19:20:12 | I |         sum  error  = [    0.0628]
24-11-25 19:20:12 | I |         best error  = [    0.0628]
24-11-25 19:20:12 | I |     + error = [0.0628]
24-11-25 19:20:13 | I |       - range scale = [    1.0000]
24-11-25 19:20:13 | I |         sum  error  = [    0.5927]
24-11-25 19:20:13 | I |         best error  = [    0.5927]
24-11-25 19:20:13 | I |     + error = [0.5927]
24-11-25 19:20:13 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 19:20:14 | I |       - range scale = [    1.0000]
24-11-25 19:20:14 | I |         sum  error  = [    0.2394]
24-11-25 19:20:14 | I |         best error  = [    0.2394]
24-11-25 19:20:14 | I |     + error = [0.2394]
24-11-25 19:20:15 | I |       - range scale = [    1.0000]
24-11-25 19:20:15 | I |         sum  error  = [    1.8782]
24-11-25 19:20:15 | I |         best error  = [    1.8782]
24-11-25 19:20:15 | I |     + error = [1.8782]
24-11-25 19:20:15 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 19:20:15 | I |       - range scale = [    1.0000]
24-11-25 19:20:15 | I |         sum  error  = [    0.0697]
24-11-25 19:20:15 | I |         best error  = [    0.0697]
24-11-25 19:20:15 | I |     + error = [0.0697]
24-11-25 19:20:16 | I |       - range scale = [    1.0000]
24-11-25 19:20:16 | I |         sum  error  = [    0.6584]
24-11-25 19:20:16 | I |         best error  = [    0.6584]
24-11-25 19:20:16 | I |     + error = [0.6584]
24-11-25 19:20:16 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 19:20:17 | I |       - range scale = [    1.0000]
24-11-25 19:20:17 | I |         sum  error  = [    1.0958]
24-11-25 19:20:17 | I |         best error  = [    1.0958]
24-11-25 19:20:17 | I |     + error = [1.0958]
24-11-25 19:20:18 | I |       - range scale = [    1.0000]
24-11-25 19:20:18 | I |         sum  error  = [   12.1474]
24-11-25 19:20:18 | I |         best error  = [   12.1474]
24-11-25 19:20:18 | I |     + error = [12.1474]
24-11-25 19:20:18 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 19:20:19 | I |       - range scale = [    1.0000]
24-11-25 19:20:19 | I |         sum  error  = [    1.2668]
24-11-25 19:20:19 | I |         best error  = [    1.2668]
24-11-25 19:20:19 | I |     + error = [1.2668]
24-11-25 19:20:19 | I |       - range scale = [    1.0000]
24-11-25 19:20:19 | I |         sum  error  = [   12.5588]
24-11-25 19:20:19 | I |         best error  = [   12.5588]
24-11-25 19:20:19 | I |     + error = [12.5588]
24-11-25 19:20:20 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 19:20:20 | I |       - range scale = [    1.0000]
24-11-25 19:20:20 | I |         sum  error  = [    2.9817]
24-11-25 19:20:20 | I |         best error  = [    2.9817]
24-11-25 19:20:20 | I |     + error = [2.9817]
24-11-25 19:20:21 | I |       - range scale = [    1.0000]
24-11-25 19:20:21 | I |         sum  error  = [   15.9017]
24-11-25 19:20:21 | I |         best error  = [   15.9017]
24-11-25 19:20:21 | I |     + error = [15.9017]
24-11-25 19:20:21 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 19:20:23 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 19:20:24 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 19:20:26 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 19:20:27 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 19:20:28 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 19:20:30 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 19:20:33 | I | quantizing activations for layer model.layers.0
24-11-25 19:20:33 | I | collecting info in model.layers.0
24-11-25 19:20:33 | I | collecting info in model.layers.0
24-11-25 19:20:33 | I | collecting info in model.layers.0
24-11-25 19:20:33 | I | collecting info in model.layers.0
24-11-25 19:20:34 | I | collecting calibration activations in model.layers.0
24-11-25 19:20:34 | I | collecting calibration activations in model.layers.0
24-11-25 19:20:34 | I | collecting calibration activations in model.layers.0
24-11-25 19:20:34 | I | collecting calibration activations in model.layers.0
24-11-25 19:20:36 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 19:20:36 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 19:20:36 | I | - Evaluator: gptq
24-11-25 19:20:36 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 19:20:36 | I | - Batch_size: 8
24-11-25 19:20:36 | I |   + Max_seq_length: 2048
24-11-25 19:21:18 | I |     - Results:
24-11-25 19:21:18 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 19:21:18 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 19:21:18 | I |       |wikitext |      1|word_perplexity|7.9690|  |7.9690|
24-11-25 19:21:18 | I |       |val_valid|      1|word_perplexity|9.1747|  |9.1747|
24-11-25 19:21:18 | I |       
24-11-25 19:21:18 | I | forward this layer
24-11-25 19:21:18 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/144.pt
24-11-25 19:21:18 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/144.pt
24-11-25 19:21:18 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 19:21:18 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 19:21:18 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 19:21:18 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 19:21:18 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 19:21:18 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 19:21:18 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 19:21:18 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 19:21:18 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 19:21:18 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 19:21:18 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 19:21:18 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 19:21:18 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 19:21:18 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 19:21:18 | I | in layer model.layers.0
24-11-25 19:21:18 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 19:21:18 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 19:21:18 | I | - Evaluator: gptq
24-11-25 19:21:18 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 19:21:18 | I | - Batch_size: 8
24-11-25 19:21:18 | I |   + Max_seq_length: 2048
24-11-25 19:21:56 | I |     - Results:
24-11-25 19:21:56 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 19:21:56 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 19:21:56 | I |       |wikitext |      1|word_perplexity|7.8541|  |7.8541|
24-11-25 19:21:56 | I |       |val_valid|      1|word_perplexity|9.0959|  |9.0959|
24-11-25 19:21:56 | I |       
24-11-25 19:21:56 | I | quantizing weights for layer model.layers.0
24-11-25 19:21:56 | I | collecting info in model.layers.0
24-11-25 19:21:56 | I | collecting info in model.layers.0
24-11-25 19:21:56 | I | collecting info in model.layers.0
24-11-25 19:21:56 | I | collecting info in model.layers.0
24-11-25 19:21:57 | I | collecting calibration activations in model.layers.0
24-11-25 19:21:57 | I | collecting calibration activations in model.layers.0
24-11-25 19:21:57 | I | collecting calibration activations in model.layers.0
24-11-25 19:21:57 | I | collecting calibration activations in model.layers.0
24-11-25 19:21:57 | I | - Quantizing decoder layer model.layers.0
24-11-25 19:21:57 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 19:21:58 | I |       - range scale = [    1.0000]
24-11-25 19:21:58 | I |         sum  error  = [    0.0665]
24-11-25 19:21:58 | I |         best error  = [    0.0665]
24-11-25 19:21:58 | I |     + error = [0.0665]
24-11-25 19:21:59 | I |       - range scale = [    1.0000]
24-11-25 19:21:59 | I |         sum  error  = [    0.6378]
24-11-25 19:21:59 | I |         best error  = [    0.6378]
24-11-25 19:21:59 | I |     + error = [0.6378]
24-11-25 19:21:59 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 19:22:00 | I |       - range scale = [    1.0000]
24-11-25 19:22:00 | I |         sum  error  = [    0.0661]
24-11-25 19:22:00 | I |         best error  = [    0.0661]
24-11-25 19:22:00 | I |     + error = [0.0661]
24-11-25 19:22:00 | I |       - range scale = [    1.0000]
24-11-25 19:22:00 | I |         sum  error  = [    0.5773]
24-11-25 19:22:00 | I |         best error  = [    0.5773]
24-11-25 19:22:00 | I |     + error = [0.5773]
24-11-25 19:22:00 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 19:22:01 | I |       - range scale = [    1.0000]
24-11-25 19:22:01 | I |         sum  error  = [    0.2398]
24-11-25 19:22:01 | I |         best error  = [    0.2398]
24-11-25 19:22:01 | I |     + error = [0.2398]
24-11-25 19:22:02 | I |       - range scale = [    1.0000]
24-11-25 19:22:02 | I |         sum  error  = [    1.8809]
24-11-25 19:22:02 | I |         best error  = [    1.8809]
24-11-25 19:22:02 | I |     + error = [1.8809]
24-11-25 19:22:02 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 19:22:03 | I |       - range scale = [    1.0000]
24-11-25 19:22:03 | I |         sum  error  = [    0.0639]
24-11-25 19:22:03 | I |         best error  = [    0.0639]
24-11-25 19:22:03 | I |     + error = [0.0639]
24-11-25 19:22:03 | I |       - range scale = [    1.0000]
24-11-25 19:22:03 | I |         sum  error  = [    0.6068]
24-11-25 19:22:03 | I |         best error  = [    0.6068]
24-11-25 19:22:03 | I |     + error = [0.6068]
24-11-25 19:22:04 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 19:22:04 | I |       - range scale = [    1.0000]
24-11-25 19:22:04 | I |         sum  error  = [    1.0552]
24-11-25 19:22:04 | I |         best error  = [    1.0552]
24-11-25 19:22:04 | I |     + error = [1.0552]
24-11-25 19:22:05 | I |       - range scale = [    1.0000]
24-11-25 19:22:05 | I |         sum  error  = [   11.6853]
24-11-25 19:22:05 | I |         best error  = [   11.6853]
24-11-25 19:22:05 | I |     + error = [11.6853]
24-11-25 19:22:05 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 19:22:06 | I |       - range scale = [    1.0000]
24-11-25 19:22:06 | I |         sum  error  = [    1.2185]
24-11-25 19:22:06 | I |         best error  = [    1.2185]
24-11-25 19:22:06 | I |     + error = [1.2185]
24-11-25 19:22:07 | I |       - range scale = [    1.0000]
24-11-25 19:22:07 | I |         sum  error  = [   12.0607]
24-11-25 19:22:07 | I |         best error  = [   12.0607]
24-11-25 19:22:07 | I |     + error = [12.0607]
24-11-25 19:22:07 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 19:22:08 | I |       - range scale = [    1.0000]
24-11-25 19:22:08 | I |         sum  error  = [    2.7432]
24-11-25 19:22:08 | I |         best error  = [    2.7432]
24-11-25 19:22:08 | I |     + error = [2.7432]
24-11-25 19:22:08 | I |       - range scale = [    1.0000]
24-11-25 19:22:08 | I |         sum  error  = [   14.6209]
24-11-25 19:22:08 | I |         best error  = [   14.6209]
24-11-25 19:22:08 | I |     + error = [14.6209]
24-11-25 19:22:09 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 19:22:10 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 19:22:11 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 19:22:13 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 19:22:14 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 19:22:16 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 19:22:17 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 19:22:20 | I | quantizing activations for layer model.layers.0
24-11-25 19:22:20 | I | collecting info in model.layers.0
24-11-25 19:22:20 | I | collecting info in model.layers.0
24-11-25 19:22:20 | I | collecting info in model.layers.0
24-11-25 19:22:20 | I | collecting info in model.layers.0
24-11-25 19:22:21 | I | collecting calibration activations in model.layers.0
24-11-25 19:22:21 | I | collecting calibration activations in model.layers.0
24-11-25 19:22:21 | I | collecting calibration activations in model.layers.0
24-11-25 19:22:21 | I | collecting calibration activations in model.layers.0
24-11-25 19:22:23 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 19:22:23 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 19:22:23 | I | - Evaluator: gptq
24-11-25 19:22:23 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 19:22:23 | I | - Batch_size: 8
24-11-25 19:22:23 | I |   + Max_seq_length: 2048
24-11-25 19:23:05 | I |     - Results:
24-11-25 19:23:05 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 19:23:05 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 19:23:05 | I |       |wikitext |      1|word_perplexity|7.9454|  |7.9454|
24-11-25 19:23:05 | I |       |val_valid|      1|word_perplexity|9.1848|  |9.1848|
24-11-25 19:23:05 | I |       
24-11-25 19:23:05 | I | forward this layer
24-11-25 19:23:05 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/145.pt
24-11-25 19:23:05 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/145.pt
24-11-25 19:23:05 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 19:23:05 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 19:23:05 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 19:23:05 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 19:23:05 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 19:23:05 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 19:23:05 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 19:23:05 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 19:23:05 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 19:23:05 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 19:23:05 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 19:23:05 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 19:23:05 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 19:23:05 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 19:23:05 | I | [58] done with optimizer step
24-11-25 19:23:05 | I | epoch 001:     73 / 409600000 loss=0.000156343, loss_per_token=0.32019, loss_sum=10492, wps=152.7, ups=0, wpb=32768, bsz=64, num_updates=59, lr=0.000149995, gnorm=34.054, clip=100, loss_scale=0.0078, train_wall=214, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=15915, lmquant_ppl_result_wikitext_in_train_no_quant=7.85414, lmquant_ppl_result_val_in_train_no_quant=9.09587, lmquant_ppl_result_wikitext_in_train_with_quant=7.94539, lmquant_ppl_result_val_in_train_with_quant=9.18475
24-11-25 19:23:05 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 19:23:05 | I | in layer model.layers.0
24-11-25 19:23:05 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 19:23:05 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 19:23:05 | I | - Evaluator: gptq
24-11-25 19:23:05 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 19:23:05 | I | - Batch_size: 8
24-11-25 19:23:05 | I |   + Max_seq_length: 2048
24-11-25 19:23:43 | I |     - Results:
24-11-25 19:23:43 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 19:23:43 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 19:23:43 | I |       |wikitext |      1|word_perplexity|7.8481|  |7.8481|
24-11-25 19:23:43 | I |       |val_valid|      1|word_perplexity|9.0927|  |9.0927|
24-11-25 19:23:43 | I |       
24-11-25 19:23:43 | I | quantizing weights for layer model.layers.0
24-11-25 19:23:43 | I | collecting info in model.layers.0
24-11-25 19:23:43 | I | collecting info in model.layers.0
24-11-25 19:23:43 | I | collecting info in model.layers.0
24-11-25 19:23:43 | I | collecting info in model.layers.0
24-11-25 19:23:44 | I | collecting calibration activations in model.layers.0
24-11-25 19:23:44 | I | collecting calibration activations in model.layers.0
24-11-25 19:23:44 | I | collecting calibration activations in model.layers.0
24-11-25 19:23:44 | I | collecting calibration activations in model.layers.0
24-11-25 19:23:45 | I | - Quantizing decoder layer model.layers.0
24-11-25 19:23:45 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 19:23:45 | I |       - range scale = [    1.0000]
24-11-25 19:23:45 | I |         sum  error  = [    0.0712]
24-11-25 19:23:45 | I |         best error  = [    0.0712]
24-11-25 19:23:45 | I |     + error = [0.0712]
24-11-25 19:23:46 | I |       - range scale = [    1.0000]
24-11-25 19:23:46 | I |         sum  error  = [    0.6623]
24-11-25 19:23:46 | I |         best error  = [    0.6623]
24-11-25 19:23:46 | I |     + error = [0.6623]
24-11-25 19:23:46 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 19:23:47 | I |       - range scale = [    1.0000]
24-11-25 19:23:47 | I |         sum  error  = [    0.0662]
24-11-25 19:23:47 | I |         best error  = [    0.0662]
24-11-25 19:23:47 | I |     + error = [0.0662]
24-11-25 19:23:48 | I |       - range scale = [    1.0000]
24-11-25 19:23:48 | I |         sum  error  = [    0.5918]
24-11-25 19:23:48 | I |         best error  = [    0.5918]
24-11-25 19:23:48 | I |     + error = [0.5918]
24-11-25 19:23:48 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 19:23:49 | I |       - range scale = [    1.0000]
24-11-25 19:23:49 | I |         sum  error  = [    0.2536]
24-11-25 19:23:49 | I |         best error  = [    0.2536]
24-11-25 19:23:49 | I |     + error = [0.2536]
24-11-25 19:23:49 | I |       - range scale = [    1.0000]
24-11-25 19:23:49 | I |         sum  error  = [    1.9570]
24-11-25 19:23:49 | I |         best error  = [    1.9570]
24-11-25 19:23:49 | I |     + error = [1.9570]
24-11-25 19:23:49 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 19:23:50 | I |       - range scale = [    1.0000]
24-11-25 19:23:50 | I |         sum  error  = [    0.0764]
24-11-25 19:23:50 | I |         best error  = [    0.0764]
24-11-25 19:23:50 | I |     + error = [0.0764]
24-11-25 19:23:51 | I |       - range scale = [    1.0000]
24-11-25 19:23:51 | I |         sum  error  = [    0.7265]
24-11-25 19:23:51 | I |         best error  = [    0.7265]
24-11-25 19:23:51 | I |     + error = [0.7265]
24-11-25 19:23:51 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 19:23:52 | I |       - range scale = [    1.0000]
24-11-25 19:23:52 | I |         sum  error  = [    1.1582]
24-11-25 19:23:52 | I |         best error  = [    1.1582]
24-11-25 19:23:52 | I |     + error = [1.1582]
24-11-25 19:23:52 | I |       - range scale = [    1.0000]
24-11-25 19:23:52 | I |         sum  error  = [   12.8173]
24-11-25 19:23:52 | I |         best error  = [   12.8173]
24-11-25 19:23:52 | I |     + error = [12.8173]
24-11-25 19:23:53 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 19:23:53 | I |       - range scale = [    1.0000]
24-11-25 19:23:53 | I |         sum  error  = [    1.3373]
24-11-25 19:23:53 | I |         best error  = [    1.3373]
24-11-25 19:23:53 | I |     + error = [1.3373]
24-11-25 19:23:54 | I |       - range scale = [    1.0000]
24-11-25 19:23:54 | I |         sum  error  = [   13.2699]
24-11-25 19:23:54 | I |         best error  = [   13.2699]
24-11-25 19:23:54 | I |     + error = [13.2699]
24-11-25 19:23:54 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 19:23:55 | I |       - range scale = [    1.0000]
24-11-25 19:23:55 | I |         sum  error  = [    2.9456]
24-11-25 19:23:55 | I |         best error  = [    2.9456]
24-11-25 19:23:55 | I |     + error = [2.9456]
24-11-25 19:23:56 | I |       - range scale = [    1.0000]
24-11-25 19:23:56 | I |         sum  error  = [   15.1415]
24-11-25 19:23:56 | I |         best error  = [   15.1415]
24-11-25 19:23:56 | I |     + error = [15.1415]
24-11-25 19:23:56 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 19:23:57 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 19:23:59 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 19:24:00 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 19:24:02 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 19:24:03 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 19:24:05 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 19:24:08 | I | quantizing activations for layer model.layers.0
24-11-25 19:24:08 | I | collecting info in model.layers.0
24-11-25 19:24:08 | I | collecting info in model.layers.0
24-11-25 19:24:08 | I | collecting info in model.layers.0
24-11-25 19:24:08 | I | collecting info in model.layers.0
24-11-25 19:24:08 | I | collecting calibration activations in model.layers.0
24-11-25 19:24:08 | I | collecting calibration activations in model.layers.0
24-11-25 19:24:09 | I | collecting calibration activations in model.layers.0
24-11-25 19:24:09 | I | collecting calibration activations in model.layers.0
24-11-25 19:24:11 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 19:24:11 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 19:24:11 | I | - Evaluator: gptq
24-11-25 19:24:11 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 19:24:11 | I | - Batch_size: 8
24-11-25 19:24:11 | I |   + Max_seq_length: 2048
24-11-25 19:24:52 | I |     - Results:
24-11-25 19:24:52 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 19:24:52 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 19:24:52 | I |       |wikitext |      1|word_perplexity|7.9325|  |7.9325|
24-11-25 19:24:52 | I |       |val_valid|      1|word_perplexity|9.1464|  |9.1464|
24-11-25 19:24:52 | I |       
24-11-25 19:24:52 | I | forward this layer
24-11-25 19:24:52 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/146.pt
24-11-25 19:24:52 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/146.pt
24-11-25 19:24:52 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 19:24:52 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 19:24:52 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 19:24:52 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 19:24:52 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 19:24:52 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 19:24:52 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 19:24:52 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 19:24:52 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 19:24:52 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 19:24:52 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 19:24:52 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 19:24:52 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 19:24:52 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 19:24:52 | I | in layer model.layers.0
24-11-25 19:24:52 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 19:24:52 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 19:24:52 | I | - Evaluator: gptq
24-11-25 19:24:52 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 19:24:52 | I | - Batch_size: 8
24-11-25 19:24:52 | I |   + Max_seq_length: 2048
24-11-25 19:25:31 | I |     - Results:
24-11-25 19:25:31 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 19:25:31 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 19:25:31 | I |       |wikitext |      1|word_perplexity|7.8481|  |7.8481|
24-11-25 19:25:31 | I |       |val_valid|      1|word_perplexity|9.0927|  |9.0927|
24-11-25 19:25:31 | I |       
24-11-25 19:25:31 | I | quantizing weights for layer model.layers.0
24-11-25 19:25:31 | I | collecting info in model.layers.0
24-11-25 19:25:31 | I | collecting info in model.layers.0
24-11-25 19:25:31 | I | collecting info in model.layers.0
24-11-25 19:25:31 | I | collecting info in model.layers.0
24-11-25 19:25:31 | I | collecting calibration activations in model.layers.0
24-11-25 19:25:31 | I | collecting calibration activations in model.layers.0
24-11-25 19:25:32 | I | collecting calibration activations in model.layers.0
24-11-25 19:25:32 | I | collecting calibration activations in model.layers.0
24-11-25 19:25:32 | I | - Quantizing decoder layer model.layers.0
24-11-25 19:25:32 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 19:25:33 | I |       - range scale = [    1.0000]
24-11-25 19:25:33 | I |         sum  error  = [    0.0614]
24-11-25 19:25:33 | I |         best error  = [    0.0614]
24-11-25 19:25:33 | I |     + error = [0.0614]
24-11-25 19:25:33 | I |       - range scale = [    1.0000]
24-11-25 19:25:33 | I |         sum  error  = [    0.5935]
24-11-25 19:25:33 | I |         best error  = [    0.5935]
24-11-25 19:25:33 | I |     + error = [0.5935]
24-11-25 19:25:34 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 19:25:34 | I |       - range scale = [    1.0000]
24-11-25 19:25:34 | I |         sum  error  = [    0.0591]
24-11-25 19:25:34 | I |         best error  = [    0.0591]
24-11-25 19:25:34 | I |     + error = [0.0591]
24-11-25 19:25:35 | I |       - range scale = [    1.0000]
24-11-25 19:25:35 | I |         sum  error  = [    0.5362]
24-11-25 19:25:35 | I |         best error  = [    0.5362]
24-11-25 19:25:35 | I |     + error = [0.5362]
24-11-25 19:25:35 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 19:25:36 | I |       - range scale = [    1.0000]
24-11-25 19:25:36 | I |         sum  error  = [    0.2319]
24-11-25 19:25:36 | I |         best error  = [    0.2319]
24-11-25 19:25:36 | I |     + error = [0.2319]
24-11-25 19:25:36 | I |       - range scale = [    1.0000]
24-11-25 19:25:36 | I |         sum  error  = [    1.8134]
24-11-25 19:25:36 | I |         best error  = [    1.8134]
24-11-25 19:25:36 | I |     + error = [1.8134]
24-11-25 19:25:37 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 19:25:37 | I |       - range scale = [    1.0000]
24-11-25 19:25:37 | I |         sum  error  = [    0.0588]
24-11-25 19:25:37 | I |         best error  = [    0.0588]
24-11-25 19:25:37 | I |     + error = [0.0588]
24-11-25 19:25:38 | I |       - range scale = [    1.0000]
24-11-25 19:25:38 | I |         sum  error  = [    0.5518]
24-11-25 19:25:38 | I |         best error  = [    0.5518]
24-11-25 19:25:38 | I |     + error = [0.5518]
24-11-25 19:25:38 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 19:25:39 | I |       - range scale = [    1.0000]
24-11-25 19:25:39 | I |         sum  error  = [    1.0609]
24-11-25 19:25:39 | I |         best error  = [    1.0609]
24-11-25 19:25:39 | I |     + error = [1.0609]
24-11-25 19:25:40 | I |       - range scale = [    1.0000]
24-11-25 19:25:40 | I |         sum  error  = [   11.7515]
24-11-25 19:25:40 | I |         best error  = [   11.7515]
24-11-25 19:25:40 | I |     + error = [11.7515]
24-11-25 19:25:40 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 19:25:41 | I |       - range scale = [    1.0000]
24-11-25 19:25:41 | I |         sum  error  = [    1.2256]
24-11-25 19:25:41 | I |         best error  = [    1.2256]
24-11-25 19:25:41 | I |     + error = [1.2256]
24-11-25 19:25:41 | I |       - range scale = [    1.0000]
24-11-25 19:25:41 | I |         sum  error  = [   12.1314]
24-11-25 19:25:41 | I |         best error  = [   12.1314]
24-11-25 19:25:41 | I |     + error = [12.1314]
24-11-25 19:25:42 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 19:25:42 | I |       - range scale = [    1.0000]
24-11-25 19:25:42 | I |         sum  error  = [    3.1017]
24-11-25 19:25:42 | I |         best error  = [    3.1017]
24-11-25 19:25:42 | I |     + error = [3.1017]
24-11-25 19:25:43 | I |       - range scale = [    1.0000]
24-11-25 19:25:43 | I |         sum  error  = [   16.7853]
24-11-25 19:25:43 | I |         best error  = [   16.7853]
24-11-25 19:25:43 | I |     + error = [16.7853]
24-11-25 19:25:43 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 19:25:45 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 19:25:46 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 19:25:47 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 19:25:49 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 19:25:50 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 19:25:52 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 19:25:55 | I | quantizing activations for layer model.layers.0
24-11-25 19:25:55 | I | collecting info in model.layers.0
24-11-25 19:25:55 | I | collecting info in model.layers.0
24-11-25 19:25:55 | I | collecting info in model.layers.0
24-11-25 19:25:55 | I | collecting info in model.layers.0
24-11-25 19:25:56 | I | collecting calibration activations in model.layers.0
24-11-25 19:25:56 | I | collecting calibration activations in model.layers.0
24-11-25 19:25:56 | I | collecting calibration activations in model.layers.0
24-11-25 19:25:56 | I | collecting calibration activations in model.layers.0
24-11-25 19:25:58 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 19:25:58 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 19:25:58 | I | - Evaluator: gptq
24-11-25 19:25:58 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 19:25:58 | I | - Batch_size: 8
24-11-25 19:25:58 | I |   + Max_seq_length: 2048
24-11-25 19:26:39 | I |     - Results:
24-11-25 19:26:39 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 19:26:39 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 19:26:39 | I |       |wikitext |      1|word_perplexity|7.9274|  |7.9274|
24-11-25 19:26:39 | I |       |val_valid|      1|word_perplexity|9.1526|  |9.1526|
24-11-25 19:26:39 | I |       
24-11-25 19:26:39 | I | forward this layer
24-11-25 19:26:39 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/147.pt
24-11-25 19:26:39 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/147.pt
24-11-25 19:26:39 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 19:26:39 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 19:26:39 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 19:26:39 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 19:26:39 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 19:26:39 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 19:26:39 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 19:26:39 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 19:26:39 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 19:26:39 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 19:26:39 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 19:26:39 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 19:26:39 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 19:26:39 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 19:26:40 | I | [59] done with optimizer step
24-11-25 19:26:40 | I | epoch 001:     74 / 409600000 loss=0.000152029, loss_per_token=0.311355, loss_sum=10202.5, wps=152.7, ups=0, wpb=32768, bsz=64, num_updates=60, lr=0.000149995, gnorm=53.814, clip=100, loss_scale=0.0078, train_wall=214, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=16130, lmquant_ppl_result_wikitext_in_train_no_quant=7.8481, lmquant_ppl_result_val_in_train_no_quant=9.0927, lmquant_ppl_result_wikitext_in_train_with_quant=7.92739, lmquant_ppl_result_val_in_train_with_quant=9.15263
24-11-25 19:26:40 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 19:26:40 | I | in layer model.layers.0
24-11-25 19:26:40 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 19:26:40 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 19:26:40 | I | - Evaluator: gptq
24-11-25 19:26:40 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 19:26:40 | I | - Batch_size: 8
24-11-25 19:26:40 | I |   + Max_seq_length: 2048
24-11-25 19:27:18 | I |     - Results:
24-11-25 19:27:18 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 19:27:18 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 19:27:18 | I |       |wikitext |      1|word_perplexity|7.8447|  |7.8447|
24-11-25 19:27:18 | I |       |val_valid|      1|word_perplexity|9.0987|  |9.0987|
24-11-25 19:27:18 | I |       
24-11-25 19:27:18 | I | quantizing weights for layer model.layers.0
24-11-25 19:27:18 | I | collecting info in model.layers.0
24-11-25 19:27:18 | I | collecting info in model.layers.0
24-11-25 19:27:18 | I | collecting info in model.layers.0
24-11-25 19:27:18 | I | collecting info in model.layers.0
24-11-25 19:27:19 | I | collecting calibration activations in model.layers.0
24-11-25 19:27:19 | I | collecting calibration activations in model.layers.0
24-11-25 19:27:19 | I | collecting calibration activations in model.layers.0
24-11-25 19:27:19 | I | collecting calibration activations in model.layers.0
24-11-25 19:27:19 | I | - Quantizing decoder layer model.layers.0
24-11-25 19:27:19 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 19:27:20 | I |       - range scale = [    1.0000]
24-11-25 19:27:20 | I |         sum  error  = [    0.0712]
24-11-25 19:27:20 | I |         best error  = [    0.0712]
24-11-25 19:27:20 | I |     + error = [0.0712]
24-11-25 19:27:21 | I |       - range scale = [    1.0000]
24-11-25 19:27:21 | I |         sum  error  = [    0.6347]
24-11-25 19:27:21 | I |         best error  = [    0.6347]
24-11-25 19:27:21 | I |     + error = [0.6347]
24-11-25 19:27:21 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 19:27:21 | I |       - range scale = [    1.0000]
24-11-25 19:27:21 | I |         sum  error  = [    0.0593]
24-11-25 19:27:21 | I |         best error  = [    0.0593]
24-11-25 19:27:21 | I |     + error = [0.0593]
24-11-25 19:27:22 | I |       - range scale = [    1.0000]
24-11-25 19:27:22 | I |         sum  error  = [    0.6026]
24-11-25 19:27:22 | I |         best error  = [    0.6026]
24-11-25 19:27:22 | I |     + error = [0.6026]
24-11-25 19:27:22 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 19:27:23 | I |       - range scale = [    1.0000]
24-11-25 19:27:23 | I |         sum  error  = [    0.2456]
24-11-25 19:27:23 | I |         best error  = [    0.2456]
24-11-25 19:27:23 | I |     + error = [0.2456]
24-11-25 19:27:24 | I |       - range scale = [    1.0000]
24-11-25 19:27:24 | I |         sum  error  = [    1.8838]
24-11-25 19:27:24 | I |         best error  = [    1.8838]
24-11-25 19:27:24 | I |     + error = [1.8838]
24-11-25 19:27:24 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 19:27:25 | I |       - range scale = [    1.0000]
24-11-25 19:27:25 | I |         sum  error  = [    0.0695]
24-11-25 19:27:25 | I |         best error  = [    0.0695]
24-11-25 19:27:25 | I |     + error = [0.0695]
24-11-25 19:27:25 | I |       - range scale = [    1.0000]
24-11-25 19:27:25 | I |         sum  error  = [    0.6732]
24-11-25 19:27:25 | I |         best error  = [    0.6732]
24-11-25 19:27:25 | I |     + error = [0.6732]
24-11-25 19:27:26 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 19:27:26 | I |       - range scale = [    1.0000]
24-11-25 19:27:26 | I |         sum  error  = [    1.1705]
24-11-25 19:27:26 | I |         best error  = [    1.1705]
24-11-25 19:27:26 | I |     + error = [1.1705]
24-11-25 19:27:27 | I |       - range scale = [    1.0000]
24-11-25 19:27:27 | I |         sum  error  = [   12.9566]
24-11-25 19:27:27 | I |         best error  = [   12.9566]
24-11-25 19:27:27 | I |     + error = [12.9566]
24-11-25 19:27:27 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 19:27:28 | I |       - range scale = [    1.0000]
24-11-25 19:27:28 | I |         sum  error  = [    1.3458]
24-11-25 19:27:28 | I |         best error  = [    1.3458]
24-11-25 19:27:28 | I |     + error = [1.3458]
24-11-25 19:27:29 | I |       - range scale = [    1.0000]
24-11-25 19:27:29 | I |         sum  error  = [   13.4274]
24-11-25 19:27:29 | I |         best error  = [   13.4274]
24-11-25 19:27:29 | I |     + error = [13.4274]
24-11-25 19:27:29 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 19:27:29 | I |       - range scale = [    1.0000]
24-11-25 19:27:29 | I |         sum  error  = [    2.1670]
24-11-25 19:27:29 | I |         best error  = [    2.1670]
24-11-25 19:27:29 | I |     + error = [2.1670]
24-11-25 19:27:30 | I |       - range scale = [    1.0000]
24-11-25 19:27:30 | I |         sum  error  = [   11.3927]
24-11-25 19:27:30 | I |         best error  = [   11.3927]
24-11-25 19:27:30 | I |     + error = [11.3927]
24-11-25 19:27:30 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 19:27:32 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 19:27:33 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 19:27:35 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 19:27:36 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 19:27:37 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 19:27:39 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 19:27:42 | I | quantizing activations for layer model.layers.0
24-11-25 19:27:42 | I | collecting info in model.layers.0
24-11-25 19:27:42 | I | collecting info in model.layers.0
24-11-25 19:27:42 | I | collecting info in model.layers.0
24-11-25 19:27:42 | I | collecting info in model.layers.0
24-11-25 19:27:43 | I | collecting calibration activations in model.layers.0
24-11-25 19:27:43 | I | collecting calibration activations in model.layers.0
24-11-25 19:27:43 | I | collecting calibration activations in model.layers.0
24-11-25 19:27:43 | I | collecting calibration activations in model.layers.0
24-11-25 19:27:45 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 19:27:45 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 19:27:45 | I | - Evaluator: gptq
24-11-25 19:27:45 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 19:27:45 | I | - Batch_size: 8
24-11-25 19:27:45 | I |   + Max_seq_length: 2048
24-11-25 19:28:26 | I |     - Results:
24-11-25 19:28:26 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 19:28:26 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 19:28:26 | I |       |wikitext |      1|word_perplexity|7.9239|  |7.9239|
24-11-25 19:28:26 | I |       |val_valid|      1|word_perplexity|9.1547|  |9.1547|
24-11-25 19:28:26 | I |       
24-11-25 19:28:26 | I | forward this layer
24-11-25 19:28:26 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/148.pt
24-11-25 19:28:26 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/148.pt
24-11-25 19:28:26 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 19:28:26 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 19:28:26 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 19:28:26 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 19:28:26 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 19:28:26 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 19:28:26 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 19:28:26 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 19:28:26 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 19:28:26 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 19:28:26 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 19:28:26 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 19:28:26 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 19:28:26 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 19:28:26 | I | in layer model.layers.0
24-11-25 19:28:26 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 19:28:26 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 19:28:26 | I | - Evaluator: gptq
24-11-25 19:28:26 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 19:28:26 | I | - Batch_size: 8
24-11-25 19:28:26 | I |   + Max_seq_length: 2048
24-11-25 19:29:05 | I |     - Results:
24-11-25 19:29:05 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 19:29:05 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 19:29:05 | I |       |wikitext |      1|word_perplexity|7.8447|  |7.8447|
24-11-25 19:29:05 | I |       |val_valid|      1|word_perplexity|9.0987|  |9.0987|
24-11-25 19:29:05 | I |       
24-11-25 19:29:05 | I | quantizing weights for layer model.layers.0
24-11-25 19:29:05 | I | collecting info in model.layers.0
24-11-25 19:29:05 | I | collecting info in model.layers.0
24-11-25 19:29:05 | I | collecting info in model.layers.0
24-11-25 19:29:05 | I | collecting info in model.layers.0
24-11-25 19:29:05 | I | collecting calibration activations in model.layers.0
24-11-25 19:29:05 | I | collecting calibration activations in model.layers.0
24-11-25 19:29:05 | I | collecting calibration activations in model.layers.0
24-11-25 19:29:06 | I | collecting calibration activations in model.layers.0
24-11-25 19:29:06 | I | - Quantizing decoder layer model.layers.0
24-11-25 19:29:06 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 19:29:07 | I |       - range scale = [    1.0000]
24-11-25 19:29:07 | I |         sum  error  = [    0.0723]
24-11-25 19:29:07 | I |         best error  = [    0.0723]
24-11-25 19:29:07 | I |     + error = [0.0723]
24-11-25 19:29:07 | I |       - range scale = [    1.0000]
24-11-25 19:29:07 | I |         sum  error  = [    0.6294]
24-11-25 19:29:07 | I |         best error  = [    0.6294]
24-11-25 19:29:07 | I |     + error = [0.6294]
24-11-25 19:29:08 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 19:29:08 | I |       - range scale = [    1.0000]
24-11-25 19:29:08 | I |         sum  error  = [    0.0605]
24-11-25 19:29:08 | I |         best error  = [    0.0605]
24-11-25 19:29:08 | I |     + error = [0.0605]
24-11-25 19:29:09 | I |       - range scale = [    1.0000]
24-11-25 19:29:09 | I |         sum  error  = [    0.6309]
24-11-25 19:29:09 | I |         best error  = [    0.6309]
24-11-25 19:29:09 | I |     + error = [0.6309]
24-11-25 19:29:09 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 19:29:10 | I |       - range scale = [    1.0000]
24-11-25 19:29:10 | I |         sum  error  = [    0.2443]
24-11-25 19:29:10 | I |         best error  = [    0.2443]
24-11-25 19:29:10 | I |     + error = [0.2443]
24-11-25 19:29:10 | I |       - range scale = [    1.0000]
24-11-25 19:29:10 | I |         sum  error  = [    1.8688]
24-11-25 19:29:10 | I |         best error  = [    1.8688]
24-11-25 19:29:10 | I |     + error = [1.8688]
24-11-25 19:29:11 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 19:29:11 | I |       - range scale = [    1.0000]
24-11-25 19:29:11 | I |         sum  error  = [    0.0726]
24-11-25 19:29:11 | I |         best error  = [    0.0726]
24-11-25 19:29:11 | I |     + error = [0.0726]
24-11-25 19:29:12 | I |       - range scale = [    1.0000]
24-11-25 19:29:12 | I |         sum  error  = [    0.7018]
24-11-25 19:29:12 | I |         best error  = [    0.7018]
24-11-25 19:29:12 | I |     + error = [0.7018]
24-11-25 19:29:12 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 19:29:13 | I |       - range scale = [    1.0000]
24-11-25 19:29:13 | I |         sum  error  = [    1.1662]
24-11-25 19:29:13 | I |         best error  = [    1.1662]
24-11-25 19:29:13 | I |     + error = [1.1662]
24-11-25 19:29:14 | I |       - range scale = [    1.0000]
24-11-25 19:29:14 | I |         sum  error  = [   12.9135]
24-11-25 19:29:14 | I |         best error  = [   12.9135]
24-11-25 19:29:14 | I |     + error = [12.9135]
24-11-25 19:29:14 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 19:29:15 | I |       - range scale = [    1.0000]
24-11-25 19:29:15 | I |         sum  error  = [    1.3396]
24-11-25 19:29:15 | I |         best error  = [    1.3396]
24-11-25 19:29:15 | I |     + error = [1.3396]
24-11-25 19:29:15 | I |       - range scale = [    1.0000]
24-11-25 19:29:15 | I |         sum  error  = [   13.3757]
24-11-25 19:29:15 | I |         best error  = [   13.3757]
24-11-25 19:29:15 | I |     + error = [13.3757]
24-11-25 19:29:16 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 19:29:16 | I |       - range scale = [    1.0000]
24-11-25 19:29:16 | I |         sum  error  = [    1.9131]
24-11-25 19:29:16 | I |         best error  = [    1.9131]
24-11-25 19:29:16 | I |     + error = [1.9131]
24-11-25 19:29:17 | I |       - range scale = [    1.0000]
24-11-25 19:29:17 | I |         sum  error  = [    9.5645]
24-11-25 19:29:17 | I |         best error  = [    9.5645]
24-11-25 19:29:17 | I |     + error = [9.5645]
24-11-25 19:29:17 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 19:29:19 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 19:29:20 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 19:29:21 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 19:29:23 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 19:29:24 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 19:29:26 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 19:29:29 | I | quantizing activations for layer model.layers.0
24-11-25 19:29:29 | I | collecting info in model.layers.0
24-11-25 19:29:29 | I | collecting info in model.layers.0
24-11-25 19:29:29 | I | collecting info in model.layers.0
24-11-25 19:29:29 | I | collecting info in model.layers.0
24-11-25 19:29:29 | I | collecting calibration activations in model.layers.0
24-11-25 19:29:29 | I | collecting calibration activations in model.layers.0
24-11-25 19:29:30 | I | collecting calibration activations in model.layers.0
24-11-25 19:29:30 | I | collecting calibration activations in model.layers.0
24-11-25 19:29:32 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 19:29:32 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 19:29:32 | I | - Evaluator: gptq
24-11-25 19:29:32 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 19:29:32 | I | - Batch_size: 8
24-11-25 19:29:32 | I |   + Max_seq_length: 2048
24-11-25 19:30:13 | I |     - Results:
24-11-25 19:30:13 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 19:30:13 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 19:30:13 | I |       |wikitext |      1|word_perplexity|7.9436|  |7.9436|
24-11-25 19:30:13 | I |       |val_valid|      1|word_perplexity|9.1440|  |9.1440|
24-11-25 19:30:13 | I |       
24-11-25 19:30:13 | I | forward this layer
24-11-25 19:30:13 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/149.pt
24-11-25 19:30:13 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/149.pt
24-11-25 19:30:13 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 19:30:13 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 19:30:13 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 19:30:13 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 19:30:13 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 19:30:13 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 19:30:13 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 19:30:13 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 19:30:13 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 19:30:13 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 19:30:13 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 19:30:13 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 19:30:13 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 19:30:13 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 19:30:13 | I | [60] done with optimizer step
24-11-25 19:30:13 | I | epoch 001:     75 / 409600000 loss=0.000233788, loss_per_token=0.478798, loss_sum=15689.3, wps=153.3, ups=0, wpb=32768, bsz=64, num_updates=61, lr=0.000149994, gnorm=82.364, clip=100, loss_scale=0.0078, train_wall=213, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=16344, lmquant_ppl_result_wikitext_in_train_no_quant=7.84474, lmquant_ppl_result_val_in_train_no_quant=9.09868, lmquant_ppl_result_wikitext_in_train_with_quant=7.94361, lmquant_ppl_result_val_in_train_with_quant=9.14399
24-11-25 19:30:13 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 19:30:13 | I | in layer model.layers.0
24-11-25 19:30:13 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 19:30:13 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 19:30:13 | I | - Evaluator: gptq
24-11-25 19:30:13 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 19:30:13 | I | - Batch_size: 8
24-11-25 19:30:13 | I |   + Max_seq_length: 2048
24-11-25 19:30:52 | I |     - Results:
24-11-25 19:30:52 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 19:30:52 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 19:30:52 | I |       |wikitext |      1|word_perplexity|7.8438|  |7.8438|
24-11-25 19:30:52 | I |       |val_valid|      1|word_perplexity|9.1097|  |9.1097|
24-11-25 19:30:52 | I |       
24-11-25 19:30:52 | I | quantizing weights for layer model.layers.0
24-11-25 19:30:52 | I | collecting info in model.layers.0
24-11-25 19:30:52 | I | collecting info in model.layers.0
24-11-25 19:30:52 | I | collecting info in model.layers.0
24-11-25 19:30:52 | I | collecting info in model.layers.0
24-11-25 19:30:52 | I | collecting calibration activations in model.layers.0
24-11-25 19:30:52 | I | collecting calibration activations in model.layers.0
24-11-25 19:30:52 | I | collecting calibration activations in model.layers.0
24-11-25 19:30:53 | I | collecting calibration activations in model.layers.0
24-11-25 19:30:53 | I | - Quantizing decoder layer model.layers.0
24-11-25 19:30:53 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 19:30:54 | I |       - range scale = [    1.0000]
24-11-25 19:30:54 | I |         sum  error  = [    0.0680]
24-11-25 19:30:54 | I |         best error  = [    0.0680]
24-11-25 19:30:54 | I |     + error = [0.0680]
24-11-25 19:30:54 | I |       - range scale = [    1.0000]
24-11-25 19:30:54 | I |         sum  error  = [    0.6487]
24-11-25 19:30:54 | I |         best error  = [    0.6487]
24-11-25 19:30:54 | I |     + error = [0.6487]
24-11-25 19:30:54 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 19:30:55 | I |       - range scale = [    1.0000]
24-11-25 19:30:55 | I |         sum  error  = [    0.0627]
24-11-25 19:30:55 | I |         best error  = [    0.0627]
24-11-25 19:30:55 | I |     + error = [0.0627]
24-11-25 19:30:56 | I |       - range scale = [    1.0000]
24-11-25 19:30:56 | I |         sum  error  = [    0.5792]
24-11-25 19:30:56 | I |         best error  = [    0.5792]
24-11-25 19:30:56 | I |     + error = [0.5792]
24-11-25 19:30:56 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 19:30:57 | I |       - range scale = [    1.0000]
24-11-25 19:30:57 | I |         sum  error  = [    0.2439]
24-11-25 19:30:57 | I |         best error  = [    0.2439]
24-11-25 19:30:57 | I |     + error = [0.2439]
24-11-25 19:30:57 | I |       - range scale = [    1.0000]
24-11-25 19:30:57 | I |         sum  error  = [    1.8722]
24-11-25 19:30:57 | I |         best error  = [    1.8722]
24-11-25 19:30:57 | I |     + error = [1.8722]
24-11-25 19:30:58 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 19:30:58 | I |       - range scale = [    1.0000]
24-11-25 19:30:58 | I |         sum  error  = [    0.0670]
24-11-25 19:30:58 | I |         best error  = [    0.0670]
24-11-25 19:30:58 | I |     + error = [0.0670]
24-11-25 19:30:59 | I |       - range scale = [    1.0000]
24-11-25 19:30:59 | I |         sum  error  = [    0.6320]
24-11-25 19:30:59 | I |         best error  = [    0.6320]
24-11-25 19:30:59 | I |     + error = [0.6320]
24-11-25 19:30:59 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 19:31:00 | I |       - range scale = [    1.0000]
24-11-25 19:31:00 | I |         sum  error  = [    1.0871]
24-11-25 19:31:00 | I |         best error  = [    1.0871]
24-11-25 19:31:00 | I |     + error = [1.0871]
24-11-25 19:31:01 | I |       - range scale = [    1.0000]
24-11-25 19:31:01 | I |         sum  error  = [   12.0191]
24-11-25 19:31:01 | I |         best error  = [   12.0191]
24-11-25 19:31:01 | I |     + error = [12.0191]
24-11-25 19:31:01 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 19:31:02 | I |       - range scale = [    1.0000]
24-11-25 19:31:02 | I |         sum  error  = [    1.2526]
24-11-25 19:31:02 | I |         best error  = [    1.2526]
24-11-25 19:31:02 | I |     + error = [1.2526]
24-11-25 19:31:02 | I |       - range scale = [    1.0000]
24-11-25 19:31:02 | I |         sum  error  = [   12.4194]
24-11-25 19:31:02 | I |         best error  = [   12.4194]
24-11-25 19:31:02 | I |     + error = [12.4194]
24-11-25 19:31:02 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 19:31:03 | I |       - range scale = [    1.0000]
24-11-25 19:31:03 | I |         sum  error  = [    3.4126]
24-11-25 19:31:03 | I |         best error  = [    3.4126]
24-11-25 19:31:03 | I |     + error = [3.4126]
24-11-25 19:31:04 | I |       - range scale = [    1.0000]
24-11-25 19:31:04 | I |         sum  error  = [   18.1924]
24-11-25 19:31:04 | I |         best error  = [   18.1924]
24-11-25 19:31:04 | I |     + error = [18.1924]
24-11-25 19:31:04 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 19:31:05 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 19:31:07 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 19:31:08 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 19:31:10 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 19:31:11 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 19:31:12 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 19:31:16 | I | quantizing activations for layer model.layers.0
24-11-25 19:31:16 | I | collecting info in model.layers.0
24-11-25 19:31:16 | I | collecting info in model.layers.0
24-11-25 19:31:16 | I | collecting info in model.layers.0
24-11-25 19:31:16 | I | collecting info in model.layers.0
24-11-25 19:31:16 | I | collecting calibration activations in model.layers.0
24-11-25 19:31:16 | I | collecting calibration activations in model.layers.0
24-11-25 19:31:16 | I | collecting calibration activations in model.layers.0
24-11-25 19:31:17 | I | collecting calibration activations in model.layers.0
24-11-25 19:31:18 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 19:31:18 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 19:31:18 | I | - Evaluator: gptq
24-11-25 19:31:18 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 19:31:18 | I | - Batch_size: 8
24-11-25 19:31:18 | I |   + Max_seq_length: 2048
24-11-25 19:32:00 | I |     - Results:
24-11-25 19:32:00 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 19:32:00 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 19:32:00 | I |       |wikitext |      1|word_perplexity|7.9354|  |7.9354|
24-11-25 19:32:00 | I |       |val_valid|      1|word_perplexity|9.1712|  |9.1712|
24-11-25 19:32:00 | I |       
24-11-25 19:32:00 | I | forward this layer
24-11-25 19:32:00 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/150.pt
24-11-25 19:32:00 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/150.pt
24-11-25 19:32:00 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 19:32:00 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 19:32:00 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 19:32:00 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 19:32:00 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 19:32:00 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 19:32:00 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 19:32:00 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 19:32:00 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 19:32:00 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 19:32:00 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 19:32:00 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 19:32:00 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 19:32:00 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 19:32:00 | I | in layer model.layers.0
24-11-25 19:32:00 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 19:32:00 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 19:32:00 | I | - Evaluator: gptq
24-11-25 19:32:00 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 19:32:00 | I | - Batch_size: 8
24-11-25 19:32:00 | I |   + Max_seq_length: 2048
24-11-25 19:32:38 | I |     - Results:
24-11-25 19:32:38 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 19:32:38 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 19:32:38 | I |       |wikitext |      1|word_perplexity|7.8438|  |7.8438|
24-11-25 19:32:38 | I |       |val_valid|      1|word_perplexity|9.1097|  |9.1097|
24-11-25 19:32:38 | I |       
24-11-25 19:32:38 | I | quantizing weights for layer model.layers.0
24-11-25 19:32:38 | I | collecting info in model.layers.0
24-11-25 19:32:38 | I | collecting info in model.layers.0
24-11-25 19:32:38 | I | collecting info in model.layers.0
24-11-25 19:32:38 | I | collecting info in model.layers.0
24-11-25 19:32:39 | I | collecting calibration activations in model.layers.0
24-11-25 19:32:39 | I | collecting calibration activations in model.layers.0
24-11-25 19:32:39 | I | collecting calibration activations in model.layers.0
24-11-25 19:32:39 | I | collecting calibration activations in model.layers.0
24-11-25 19:32:40 | I | - Quantizing decoder layer model.layers.0
24-11-25 19:32:40 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 19:32:40 | I |       - range scale = [    1.0000]
24-11-25 19:32:40 | I |         sum  error  = [    0.0599]
24-11-25 19:32:40 | I |         best error  = [    0.0599]
24-11-25 19:32:40 | I |     + error = [0.0599]
24-11-25 19:32:41 | I |       - range scale = [    1.0000]
24-11-25 19:32:41 | I |         sum  error  = [    0.5904]
24-11-25 19:32:41 | I |         best error  = [    0.5904]
24-11-25 19:32:41 | I |     + error = [0.5904]
24-11-25 19:32:41 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 19:32:42 | I |       - range scale = [    1.0000]
24-11-25 19:32:42 | I |         sum  error  = [    0.0610]
24-11-25 19:32:42 | I |         best error  = [    0.0610]
24-11-25 19:32:42 | I |     + error = [0.0610]
24-11-25 19:32:43 | I |       - range scale = [    1.0000]
24-11-25 19:32:43 | I |         sum  error  = [    0.5419]
24-11-25 19:32:43 | I |         best error  = [    0.5419]
24-11-25 19:32:43 | I |     + error = [0.5419]
24-11-25 19:32:43 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 19:32:43 | I |       - range scale = [    1.0000]
24-11-25 19:32:43 | I |         sum  error  = [    0.2402]
24-11-25 19:32:43 | I |         best error  = [    0.2402]
24-11-25 19:32:43 | I |     + error = [0.2402]
24-11-25 19:32:44 | I |       - range scale = [    1.0000]
24-11-25 19:32:44 | I |         sum  error  = [    1.8572]
24-11-25 19:32:44 | I |         best error  = [    1.8572]
24-11-25 19:32:44 | I |     + error = [1.8572]
24-11-25 19:32:44 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 19:32:45 | I |       - range scale = [    1.0000]
24-11-25 19:32:45 | I |         sum  error  = [    0.0601]
24-11-25 19:32:45 | I |         best error  = [    0.0601]
24-11-25 19:32:45 | I |     + error = [0.0601]
24-11-25 19:32:46 | I |       - range scale = [    1.0000]
24-11-25 19:32:46 | I |         sum  error  = [    0.5734]
24-11-25 19:32:46 | I |         best error  = [    0.5734]
24-11-25 19:32:46 | I |     + error = [0.5734]
24-11-25 19:32:46 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 19:32:47 | I |       - range scale = [    1.0000]
24-11-25 19:32:47 | I |         sum  error  = [    1.0428]
24-11-25 19:32:47 | I |         best error  = [    1.0428]
24-11-25 19:32:47 | I |     + error = [1.0428]
24-11-25 19:32:47 | I |       - range scale = [    1.0000]
24-11-25 19:32:47 | I |         sum  error  = [   11.5383]
24-11-25 19:32:47 | I |         best error  = [   11.5383]
24-11-25 19:32:47 | I |     + error = [11.5383]
24-11-25 19:32:48 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 19:32:48 | I |       - range scale = [    1.0000]
24-11-25 19:32:48 | I |         sum  error  = [    1.2044]
24-11-25 19:32:48 | I |         best error  = [    1.2044]
24-11-25 19:32:48 | I |     + error = [1.2044]
24-11-25 19:32:49 | I |       - range scale = [    1.0000]
24-11-25 19:32:49 | I |         sum  error  = [   11.8974]
24-11-25 19:32:49 | I |         best error  = [   11.8974]
24-11-25 19:32:49 | I |     + error = [11.8974]
24-11-25 19:32:49 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 19:32:50 | I |       - range scale = [    1.0000]
24-11-25 19:32:50 | I |         sum  error  = [    2.7031]
24-11-25 19:32:50 | I |         best error  = [    2.7031]
24-11-25 19:32:50 | I |     + error = [2.7031]
24-11-25 19:32:51 | I |       - range scale = [    1.0000]
24-11-25 19:32:51 | I |         sum  error  = [   14.6442]
24-11-25 19:32:51 | I |         best error  = [   14.6442]
24-11-25 19:32:51 | I |     + error = [14.6442]
24-11-25 19:32:51 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 19:32:52 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 19:32:54 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 19:32:55 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 19:32:56 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 19:32:58 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 19:32:59 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 19:33:03 | I | quantizing activations for layer model.layers.0
24-11-25 19:33:03 | I | collecting info in model.layers.0
24-11-25 19:33:03 | I | collecting info in model.layers.0
24-11-25 19:33:03 | I | collecting info in model.layers.0
24-11-25 19:33:03 | I | collecting info in model.layers.0
24-11-25 19:33:03 | I | collecting calibration activations in model.layers.0
24-11-25 19:33:03 | I | collecting calibration activations in model.layers.0
24-11-25 19:33:03 | I | collecting calibration activations in model.layers.0
24-11-25 19:33:03 | I | collecting calibration activations in model.layers.0
24-11-25 19:33:05 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 19:33:05 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 19:33:05 | I | - Evaluator: gptq
24-11-25 19:33:05 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 19:33:05 | I | - Batch_size: 8
24-11-25 19:33:05 | I |   + Max_seq_length: 2048
24-11-25 19:33:47 | I |     - Results:
24-11-25 19:33:47 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 19:33:47 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 19:33:47 | I |       |wikitext |      1|word_perplexity|7.9250|  |7.9250|
24-11-25 19:33:47 | I |       |val_valid|      1|word_perplexity|9.1622|  |9.1622|
24-11-25 19:33:47 | I |       
24-11-25 19:33:47 | I | forward this layer
24-11-25 19:33:47 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/151.pt
24-11-25 19:33:47 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/151.pt
24-11-25 19:33:47 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 19:33:47 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 19:33:47 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 19:33:47 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 19:33:47 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 19:33:47 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 19:33:47 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 19:33:47 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 19:33:47 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 19:33:47 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 19:33:47 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 19:33:47 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 19:33:47 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 19:33:47 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 19:33:47 | I | [61] done with optimizer step
24-11-25 19:33:47 | I | epoch 001:     76 / 409600000 loss=0.000150714, loss_per_token=0.308663, loss_sum=10114.3, wps=153.3, ups=0, wpb=32768, bsz=64, num_updates=62, lr=0.000149994, gnorm=34.871, clip=100, loss_scale=0.0078, train_wall=213, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=16557, lmquant_ppl_result_wikitext_in_train_no_quant=7.84384, lmquant_ppl_result_val_in_train_no_quant=9.10967, lmquant_ppl_result_wikitext_in_train_with_quant=7.92505, lmquant_ppl_result_val_in_train_with_quant=9.16217
24-11-25 19:33:47 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 19:33:47 | I | in layer model.layers.0
24-11-25 19:33:47 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 19:33:47 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 19:33:47 | I | - Evaluator: gptq
24-11-25 19:33:47 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 19:33:47 | I | - Batch_size: 8
24-11-25 19:33:47 | I |   + Max_seq_length: 2048
24-11-25 19:34:25 | I |     - Results:
24-11-25 19:34:25 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 19:34:25 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 19:34:25 | I |       |wikitext |      1|word_perplexity|7.8420|  |7.8420|
24-11-25 19:34:25 | I |       |val_valid|      1|word_perplexity|9.1338|  |9.1338|
24-11-25 19:34:25 | I |       
24-11-25 19:34:25 | I | quantizing weights for layer model.layers.0
24-11-25 19:34:25 | I | collecting info in model.layers.0
24-11-25 19:34:25 | I | collecting info in model.layers.0
24-11-25 19:34:25 | I | collecting info in model.layers.0
24-11-25 19:34:25 | I | collecting info in model.layers.0
24-11-25 19:34:26 | I | collecting calibration activations in model.layers.0
24-11-25 19:34:26 | I | collecting calibration activations in model.layers.0
24-11-25 19:34:26 | I | collecting calibration activations in model.layers.0
24-11-25 19:34:26 | I | collecting calibration activations in model.layers.0
24-11-25 19:34:27 | I | - Quantizing decoder layer model.layers.0
24-11-25 19:34:27 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 19:34:27 | I |       - range scale = [    1.0000]
24-11-25 19:34:27 | I |         sum  error  = [    0.0590]
24-11-25 19:34:27 | I |         best error  = [    0.0590]
24-11-25 19:34:27 | I |     + error = [0.0590]
24-11-25 19:34:28 | I |       - range scale = [    1.0000]
24-11-25 19:34:28 | I |         sum  error  = [    0.6063]
24-11-25 19:34:28 | I |         best error  = [    0.6063]
24-11-25 19:34:28 | I |     + error = [0.6063]
24-11-25 19:34:28 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 19:34:29 | I |       - range scale = [    1.0000]
24-11-25 19:34:29 | I |         sum  error  = [    0.0593]
24-11-25 19:34:29 | I |         best error  = [    0.0593]
24-11-25 19:34:29 | I |     + error = [0.0593]
24-11-25 19:34:30 | I |       - range scale = [    1.0000]
24-11-25 19:34:30 | I |         sum  error  = [    0.5289]
24-11-25 19:34:30 | I |         best error  = [    0.5289]
24-11-25 19:34:30 | I |     + error = [0.5289]
24-11-25 19:34:30 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 19:34:30 | I |       - range scale = [    1.0000]
24-11-25 19:34:30 | I |         sum  error  = [    0.2389]
24-11-25 19:34:30 | I |         best error  = [    0.2389]
24-11-25 19:34:30 | I |     + error = [0.2389]
24-11-25 19:34:31 | I |       - range scale = [    1.0000]
24-11-25 19:34:31 | I |         sum  error  = [    1.8534]
24-11-25 19:34:31 | I |         best error  = [    1.8534]
24-11-25 19:34:31 | I |     + error = [1.8534]
24-11-25 19:34:31 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 19:34:32 | I |       - range scale = [    1.0000]
24-11-25 19:34:32 | I |         sum  error  = [    0.0685]
24-11-25 19:34:32 | I |         best error  = [    0.0685]
24-11-25 19:34:32 | I |     + error = [0.0685]
24-11-25 19:34:33 | I |       - range scale = [    1.0000]
24-11-25 19:34:33 | I |         sum  error  = [    0.6555]
24-11-25 19:34:33 | I |         best error  = [    0.6555]
24-11-25 19:34:33 | I |     + error = [0.6555]
24-11-25 19:34:33 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 19:34:34 | I |       - range scale = [    1.0000]
24-11-25 19:34:34 | I |         sum  error  = [    1.1219]
24-11-25 19:34:34 | I |         best error  = [    1.1219]
24-11-25 19:34:34 | I |     + error = [1.1219]
24-11-25 19:34:34 | I |       - range scale = [    1.0000]
24-11-25 19:34:34 | I |         sum  error  = [   12.4147]
24-11-25 19:34:34 | I |         best error  = [   12.4147]
24-11-25 19:34:34 | I |     + error = [12.4147]
24-11-25 19:34:35 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 19:34:35 | I |       - range scale = [    1.0000]
24-11-25 19:34:35 | I |         sum  error  = [    1.2964]
24-11-25 19:34:35 | I |         best error  = [    1.2964]
24-11-25 19:34:35 | I |     + error = [1.2964]
24-11-25 19:34:36 | I |       - range scale = [    1.0000]
24-11-25 19:34:36 | I |         sum  error  = [   12.8405]
24-11-25 19:34:36 | I |         best error  = [   12.8405]
24-11-25 19:34:36 | I |     + error = [12.8405]
24-11-25 19:34:36 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 19:34:37 | I |       - range scale = [    1.0000]
24-11-25 19:34:37 | I |         sum  error  = [    3.2580]
24-11-25 19:34:37 | I |         best error  = [    3.2580]
24-11-25 19:34:37 | I |     + error = [3.2580]
24-11-25 19:34:38 | I |       - range scale = [    1.0000]
24-11-25 19:34:38 | I |         sum  error  = [   17.4160]
24-11-25 19:34:38 | I |         best error  = [   17.4160]
24-11-25 19:34:38 | I |     + error = [17.4160]
24-11-25 19:34:38 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 19:34:39 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 19:34:41 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 19:34:42 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 19:34:43 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 19:34:45 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 19:34:46 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 19:34:50 | I | quantizing activations for layer model.layers.0
24-11-25 19:34:50 | I | collecting info in model.layers.0
24-11-25 19:34:50 | I | collecting info in model.layers.0
24-11-25 19:34:50 | I | collecting info in model.layers.0
24-11-25 19:34:50 | I | collecting info in model.layers.0
24-11-25 19:34:50 | I | collecting calibration activations in model.layers.0
24-11-25 19:34:50 | I | collecting calibration activations in model.layers.0
24-11-25 19:34:50 | I | collecting calibration activations in model.layers.0
24-11-25 19:34:50 | I | collecting calibration activations in model.layers.0
24-11-25 19:34:52 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 19:34:52 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 19:34:52 | I | - Evaluator: gptq
24-11-25 19:34:52 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 19:34:52 | I | - Batch_size: 8
24-11-25 19:34:52 | I |   + Max_seq_length: 2048
24-11-25 19:35:34 | I |     - Results:
24-11-25 19:35:34 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 19:35:34 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 19:35:34 | I |       |wikitext |      1|word_perplexity|7.9348|  |7.9348|
24-11-25 19:35:34 | I |       |val_valid|      1|word_perplexity|9.1862|  |9.1862|
24-11-25 19:35:34 | I |       
24-11-25 19:35:34 | I | forward this layer
24-11-25 19:35:34 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/152.pt
24-11-25 19:35:34 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/152.pt
24-11-25 19:35:34 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 19:35:34 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 19:35:34 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 19:35:34 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 19:35:34 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 19:35:34 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 19:35:34 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 19:35:34 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 19:35:34 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 19:35:34 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 19:35:34 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 19:35:34 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 19:35:34 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 19:35:34 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 19:35:34 | I | in layer model.layers.0
24-11-25 19:35:34 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 19:35:34 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 19:35:34 | I | - Evaluator: gptq
24-11-25 19:35:34 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 19:35:34 | I | - Batch_size: 8
24-11-25 19:35:34 | I |   + Max_seq_length: 2048
24-11-25 19:36:12 | I |     - Results:
24-11-25 19:36:12 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 19:36:12 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 19:36:12 | I |       |wikitext |      1|word_perplexity|7.8420|  |7.8420|
24-11-25 19:36:12 | I |       |val_valid|      1|word_perplexity|9.1338|  |9.1338|
24-11-25 19:36:12 | I |       
24-11-25 19:36:12 | I | quantizing weights for layer model.layers.0
24-11-25 19:36:12 | I | collecting info in model.layers.0
24-11-25 19:36:12 | I | collecting info in model.layers.0
24-11-25 19:36:12 | I | collecting info in model.layers.0
24-11-25 19:36:12 | I | collecting info in model.layers.0
24-11-25 19:36:13 | I | collecting calibration activations in model.layers.0
24-11-25 19:36:13 | I | collecting calibration activations in model.layers.0
24-11-25 19:36:13 | I | collecting calibration activations in model.layers.0
24-11-25 19:36:13 | I | collecting calibration activations in model.layers.0
24-11-25 19:36:13 | I | - Quantizing decoder layer model.layers.0
24-11-25 19:36:13 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 19:36:14 | I |       - range scale = [    1.0000]
24-11-25 19:36:14 | I |         sum  error  = [    0.0630]
24-11-25 19:36:14 | I |         best error  = [    0.0630]
24-11-25 19:36:14 | I |     + error = [0.0630]
24-11-25 19:36:15 | I |       - range scale = [    1.0000]
24-11-25 19:36:15 | I |         sum  error  = [    0.6488]
24-11-25 19:36:15 | I |         best error  = [    0.6488]
24-11-25 19:36:15 | I |     + error = [0.6488]
24-11-25 19:36:15 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 19:36:16 | I |       - range scale = [    1.0000]
24-11-25 19:36:16 | I |         sum  error  = [    0.0652]
24-11-25 19:36:16 | I |         best error  = [    0.0652]
24-11-25 19:36:16 | I |     + error = [0.0652]
24-11-25 19:36:16 | I |       - range scale = [    1.0000]
24-11-25 19:36:16 | I |         sum  error  = [    0.5893]
24-11-25 19:36:16 | I |         best error  = [    0.5893]
24-11-25 19:36:16 | I |     + error = [0.5893]
24-11-25 19:36:17 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 19:36:17 | I |       - range scale = [    1.0000]
24-11-25 19:36:17 | I |         sum  error  = [    0.2452]
24-11-25 19:36:17 | I |         best error  = [    0.2452]
24-11-25 19:36:17 | I |     + error = [0.2452]
24-11-25 19:36:18 | I |       - range scale = [    1.0000]
24-11-25 19:36:18 | I |         sum  error  = [    1.8665]
24-11-25 19:36:18 | I |         best error  = [    1.8665]
24-11-25 19:36:18 | I |     + error = [1.8665]
24-11-25 19:36:18 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 19:36:19 | I |       - range scale = [    1.0000]
24-11-25 19:36:19 | I |         sum  error  = [    0.0655]
24-11-25 19:36:19 | I |         best error  = [    0.0655]
24-11-25 19:36:19 | I |     + error = [0.0655]
24-11-25 19:36:19 | I |       - range scale = [    1.0000]
24-11-25 19:36:19 | I |         sum  error  = [    0.6271]
24-11-25 19:36:19 | I |         best error  = [    0.6271]
24-11-25 19:36:19 | I |     + error = [0.6271]
24-11-25 19:36:20 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 19:36:20 | I |       - range scale = [    1.0000]
24-11-25 19:36:20 | I |         sum  error  = [    1.1046]
24-11-25 19:36:20 | I |         best error  = [    1.1046]
24-11-25 19:36:20 | I |     + error = [1.1046]
24-11-25 19:36:21 | I |       - range scale = [    1.0000]
24-11-25 19:36:21 | I |         sum  error  = [   12.2126]
24-11-25 19:36:21 | I |         best error  = [   12.2126]
24-11-25 19:36:21 | I |     + error = [12.2126]
24-11-25 19:36:21 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 19:36:22 | I |       - range scale = [    1.0000]
24-11-25 19:36:22 | I |         sum  error  = [    1.2772]
24-11-25 19:36:22 | I |         best error  = [    1.2772]
24-11-25 19:36:22 | I |     + error = [1.2772]
24-11-25 19:36:23 | I |       - range scale = [    1.0000]
24-11-25 19:36:23 | I |         sum  error  = [   12.6280]
24-11-25 19:36:23 | I |         best error  = [   12.6280]
24-11-25 19:36:23 | I |     + error = [12.6280]
24-11-25 19:36:23 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 19:36:24 | I |       - range scale = [    1.0000]
24-11-25 19:36:24 | I |         sum  error  = [    3.6291]
24-11-25 19:36:24 | I |         best error  = [    3.6291]
24-11-25 19:36:24 | I |     + error = [3.6291]
24-11-25 19:36:24 | I |       - range scale = [    1.0000]
24-11-25 19:36:24 | I |         sum  error  = [   18.9764]
24-11-25 19:36:24 | I |         best error  = [   18.9764]
24-11-25 19:36:24 | I |     + error = [18.9764]
24-11-25 19:36:25 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 19:36:26 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 19:36:27 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 19:36:29 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 19:36:30 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 19:36:32 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 19:36:33 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 19:36:36 | I | quantizing activations for layer model.layers.0
24-11-25 19:36:36 | I | collecting info in model.layers.0
24-11-25 19:36:36 | I | collecting info in model.layers.0
24-11-25 19:36:36 | I | collecting info in model.layers.0
24-11-25 19:36:36 | I | collecting info in model.layers.0
24-11-25 19:36:37 | I | collecting calibration activations in model.layers.0
24-11-25 19:36:37 | I | collecting calibration activations in model.layers.0
24-11-25 19:36:37 | I | collecting calibration activations in model.layers.0
24-11-25 19:36:37 | I | collecting calibration activations in model.layers.0
24-11-25 19:36:39 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 19:36:39 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 19:36:39 | I | - Evaluator: gptq
24-11-25 19:36:39 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 19:36:39 | I | - Batch_size: 8
24-11-25 19:36:39 | I |   + Max_seq_length: 2048
24-11-25 19:37:21 | I |     - Results:
24-11-25 19:37:21 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 19:37:21 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 19:37:21 | I |       |wikitext |      1|word_perplexity|7.9616|  |7.9616|
24-11-25 19:37:21 | I |       |val_valid|      1|word_perplexity|9.1905|  |9.1905|
24-11-25 19:37:21 | I |       
24-11-25 19:37:21 | I | forward this layer
24-11-25 19:37:21 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/153.pt
24-11-25 19:37:21 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/153.pt
24-11-25 19:37:21 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 19:37:21 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 19:37:21 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 19:37:21 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 19:37:21 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 19:37:21 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 19:37:21 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 19:37:21 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 19:37:21 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 19:37:21 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 19:37:21 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 19:37:21 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 19:37:21 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 19:37:21 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 19:37:21 | I | [62] done with optimizer step
24-11-25 19:37:21 | I | epoch 001:     77 / 409600000 loss=0.00010031, loss_per_token=0.205434, loss_sum=6731.66, wps=153.2, ups=0, wpb=32768, bsz=64, num_updates=63, lr=0.000149993, gnorm=14.993, clip=100, loss_scale=0.0078, train_wall=214, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=16771, lmquant_ppl_result_wikitext_in_train_no_quant=7.84201, lmquant_ppl_result_val_in_train_no_quant=9.1338, lmquant_ppl_result_wikitext_in_train_with_quant=7.96163, lmquant_ppl_result_val_in_train_with_quant=9.19054
24-11-25 19:37:21 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 19:37:21 | I | in layer model.layers.0
24-11-25 19:37:21 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 19:37:21 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 19:37:21 | I | - Evaluator: gptq
24-11-25 19:37:21 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 19:37:21 | I | - Batch_size: 8
24-11-25 19:37:21 | I |   + Max_seq_length: 2048
24-11-25 19:37:59 | I |     - Results:
24-11-25 19:37:59 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 19:37:59 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 19:37:59 | I |       |wikitext |      1|word_perplexity|7.8530|  |7.8530|
24-11-25 19:37:59 | I |       |val_valid|      1|word_perplexity|9.1992|  |9.1992|
24-11-25 19:37:59 | I |       
24-11-25 19:37:59 | I | quantizing weights for layer model.layers.0
24-11-25 19:37:59 | I | collecting info in model.layers.0
24-11-25 19:37:59 | I | collecting info in model.layers.0
24-11-25 19:37:59 | I | collecting info in model.layers.0
24-11-25 19:37:59 | I | collecting info in model.layers.0
24-11-25 19:38:00 | I | collecting calibration activations in model.layers.0
24-11-25 19:38:00 | I | collecting calibration activations in model.layers.0
24-11-25 19:38:00 | I | collecting calibration activations in model.layers.0
24-11-25 19:38:00 | I | collecting calibration activations in model.layers.0
24-11-25 19:38:01 | I | - Quantizing decoder layer model.layers.0
24-11-25 19:38:01 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 19:38:01 | I |       - range scale = [    1.0000]
24-11-25 19:38:01 | I |         sum  error  = [    0.0637]
24-11-25 19:38:01 | I |         best error  = [    0.0637]
24-11-25 19:38:01 | I |     + error = [0.0637]
24-11-25 19:38:02 | I |       - range scale = [    1.0000]
24-11-25 19:38:02 | I |         sum  error  = [    0.6265]
24-11-25 19:38:02 | I |         best error  = [    0.6265]
24-11-25 19:38:02 | I |     + error = [0.6265]
24-11-25 19:38:02 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 19:38:03 | I |       - range scale = [    1.0000]
24-11-25 19:38:03 | I |         sum  error  = [    0.0587]
24-11-25 19:38:03 | I |         best error  = [    0.0587]
24-11-25 19:38:03 | I |     + error = [0.0587]
24-11-25 19:38:04 | I |       - range scale = [    1.0000]
24-11-25 19:38:04 | I |         sum  error  = [    0.5457]
24-11-25 19:38:04 | I |         best error  = [    0.5457]
24-11-25 19:38:04 | I |     + error = [0.5457]
24-11-25 19:38:04 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 19:38:04 | I |       - range scale = [    1.0000]
24-11-25 19:38:04 | I |         sum  error  = [    0.2378]
24-11-25 19:38:04 | I |         best error  = [    0.2378]
24-11-25 19:38:04 | I |     + error = [0.2378]
24-11-25 19:38:05 | I |       - range scale = [    1.0000]
24-11-25 19:38:05 | I |         sum  error  = [    1.8731]
24-11-25 19:38:05 | I |         best error  = [    1.8731]
24-11-25 19:38:05 | I |     + error = [1.8731]
24-11-25 19:38:05 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 19:38:06 | I |       - range scale = [    1.0000]
24-11-25 19:38:06 | I |         sum  error  = [    0.0690]
24-11-25 19:38:06 | I |         best error  = [    0.0690]
24-11-25 19:38:06 | I |     + error = [0.0690]
24-11-25 19:38:07 | I |       - range scale = [    1.0000]
24-11-25 19:38:07 | I |         sum  error  = [    0.6576]
24-11-25 19:38:07 | I |         best error  = [    0.6576]
24-11-25 19:38:07 | I |     + error = [0.6576]
24-11-25 19:38:07 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 19:38:08 | I |       - range scale = [    1.0000]
24-11-25 19:38:08 | I |         sum  error  = [    1.0873]
24-11-25 19:38:08 | I |         best error  = [    1.0873]
24-11-25 19:38:08 | I |     + error = [1.0873]
24-11-25 19:38:08 | I |       - range scale = [    1.0000]
24-11-25 19:38:08 | I |         sum  error  = [   12.0192]
24-11-25 19:38:08 | I |         best error  = [   12.0192]
24-11-25 19:38:08 | I |     + error = [12.0192]
24-11-25 19:38:09 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 19:38:09 | I |       - range scale = [    1.0000]
24-11-25 19:38:09 | I |         sum  error  = [    1.2571]
24-11-25 19:38:09 | I |         best error  = [    1.2571]
24-11-25 19:38:09 | I |     + error = [1.2571]
24-11-25 19:38:10 | I |       - range scale = [    1.0000]
24-11-25 19:38:10 | I |         sum  error  = [   12.4144]
24-11-25 19:38:10 | I |         best error  = [   12.4144]
24-11-25 19:38:10 | I |     + error = [12.4144]
24-11-25 19:38:10 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 19:38:11 | I |       - range scale = [    1.0000]
24-11-25 19:38:11 | I |         sum  error  = [    3.1073]
24-11-25 19:38:11 | I |         best error  = [    3.1073]
24-11-25 19:38:11 | I |     + error = [3.1073]
24-11-25 19:38:12 | I |       - range scale = [    1.0000]
24-11-25 19:38:12 | I |         sum  error  = [   16.6397]
24-11-25 19:38:12 | I |         best error  = [   16.6397]
24-11-25 19:38:12 | I |     + error = [16.6397]
24-11-25 19:38:12 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 19:38:13 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 19:38:15 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 19:38:16 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 19:38:17 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 19:38:19 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 19:38:20 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 19:38:23 | I | quantizing activations for layer model.layers.0
24-11-25 19:38:23 | I | collecting info in model.layers.0
24-11-25 19:38:23 | I | collecting info in model.layers.0
24-11-25 19:38:23 | I | collecting info in model.layers.0
24-11-25 19:38:23 | I | collecting info in model.layers.0
24-11-25 19:38:24 | I | collecting calibration activations in model.layers.0
24-11-25 19:38:24 | I | collecting calibration activations in model.layers.0
24-11-25 19:38:24 | I | collecting calibration activations in model.layers.0
24-11-25 19:38:24 | I | collecting calibration activations in model.layers.0
24-11-25 19:38:26 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 19:38:26 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 19:38:26 | I | - Evaluator: gptq
24-11-25 19:38:26 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 19:38:26 | I | - Batch_size: 8
24-11-25 19:38:26 | I |   + Max_seq_length: 2048
24-11-25 19:39:08 | I |     - Results:
24-11-25 19:39:08 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 19:39:08 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 19:39:08 | I |       |wikitext |      1|word_perplexity|7.9511|  |7.9511|
24-11-25 19:39:08 | I |       |val_valid|      1|word_perplexity|9.2346|  |9.2346|
24-11-25 19:39:08 | I |       
24-11-25 19:39:08 | I | forward this layer
24-11-25 19:39:08 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/154.pt
24-11-25 19:39:08 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/154.pt
24-11-25 19:39:08 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 19:39:08 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 19:39:08 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 19:39:08 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 19:39:08 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 19:39:08 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 19:39:08 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 19:39:08 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 19:39:08 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 19:39:08 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 19:39:08 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 19:39:08 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 19:39:08 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 19:39:08 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 19:39:08 | I | in layer model.layers.0
24-11-25 19:39:08 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 19:39:08 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 19:39:08 | I | - Evaluator: gptq
24-11-25 19:39:08 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 19:39:08 | I | - Batch_size: 8
24-11-25 19:39:08 | I |   + Max_seq_length: 2048
24-11-25 19:39:46 | I |     - Results:
24-11-25 19:39:46 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 19:39:46 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 19:39:46 | I |       |wikitext |      1|word_perplexity|7.8530|  |7.8530|
24-11-25 19:39:46 | I |       |val_valid|      1|word_perplexity|9.1992|  |9.1992|
24-11-25 19:39:46 | I |       
24-11-25 19:39:46 | I | quantizing weights for layer model.layers.0
24-11-25 19:39:46 | I | collecting info in model.layers.0
24-11-25 19:39:46 | I | collecting info in model.layers.0
24-11-25 19:39:46 | I | collecting info in model.layers.0
24-11-25 19:39:46 | I | collecting info in model.layers.0
24-11-25 19:39:47 | I | collecting calibration activations in model.layers.0
24-11-25 19:39:47 | I | collecting calibration activations in model.layers.0
24-11-25 19:39:47 | I | collecting calibration activations in model.layers.0
24-11-25 19:39:47 | I | collecting calibration activations in model.layers.0
24-11-25 19:39:47 | I | - Quantizing decoder layer model.layers.0
24-11-25 19:39:47 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 19:39:48 | I |       - range scale = [    1.0000]
24-11-25 19:39:48 | I |         sum  error  = [    0.0627]
24-11-25 19:39:48 | I |         best error  = [    0.0627]
24-11-25 19:39:48 | I |     + error = [0.0627]
24-11-25 19:39:49 | I |       - range scale = [    1.0000]
24-11-25 19:39:49 | I |         sum  error  = [    0.6297]
24-11-25 19:39:49 | I |         best error  = [    0.6297]
24-11-25 19:39:49 | I |     + error = [0.6297]
24-11-25 19:39:49 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 19:39:50 | I |       - range scale = [    1.0000]
24-11-25 19:39:50 | I |         sum  error  = [    0.0656]
24-11-25 19:39:50 | I |         best error  = [    0.0656]
24-11-25 19:39:50 | I |     + error = [0.0656]
24-11-25 19:39:50 | I |       - range scale = [    1.0000]
24-11-25 19:39:50 | I |         sum  error  = [    0.5873]
24-11-25 19:39:50 | I |         best error  = [    0.5873]
24-11-25 19:39:50 | I |     + error = [0.5873]
24-11-25 19:39:51 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 19:39:51 | I |       - range scale = [    1.0000]
24-11-25 19:39:51 | I |         sum  error  = [    0.2391]
24-11-25 19:39:51 | I |         best error  = [    0.2391]
24-11-25 19:39:51 | I |     + error = [0.2391]
24-11-25 19:39:52 | I |       - range scale = [    1.0000]
24-11-25 19:39:52 | I |         sum  error  = [    1.8777]
24-11-25 19:39:52 | I |         best error  = [    1.8777]
24-11-25 19:39:52 | I |     + error = [1.8777]
24-11-25 19:39:52 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 19:39:53 | I |       - range scale = [    1.0000]
24-11-25 19:39:53 | I |         sum  error  = [    0.0693]
24-11-25 19:39:53 | I |         best error  = [    0.0693]
24-11-25 19:39:53 | I |     + error = [0.0693]
24-11-25 19:39:53 | I |       - range scale = [    1.0000]
24-11-25 19:39:53 | I |         sum  error  = [    0.6583]
24-11-25 19:39:53 | I |         best error  = [    0.6583]
24-11-25 19:39:53 | I |     + error = [0.6583]
24-11-25 19:39:54 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 19:39:54 | I |       - range scale = [    1.0000]
24-11-25 19:39:54 | I |         sum  error  = [    1.1608]
24-11-25 19:39:54 | I |         best error  = [    1.1608]
24-11-25 19:39:54 | I |     + error = [1.1608]
24-11-25 19:39:55 | I |       - range scale = [    1.0000]
24-11-25 19:39:55 | I |         sum  error  = [   12.8252]
24-11-25 19:39:55 | I |         best error  = [   12.8252]
24-11-25 19:39:55 | I |     + error = [12.8252]
24-11-25 19:39:55 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 19:39:56 | I |       - range scale = [    1.0000]
24-11-25 19:39:56 | I |         sum  error  = [    1.3348]
24-11-25 19:39:56 | I |         best error  = [    1.3348]
24-11-25 19:39:56 | I |     + error = [1.3348]
24-11-25 19:39:57 | I |       - range scale = [    1.0000]
24-11-25 19:39:57 | I |         sum  error  = [   13.2850]
24-11-25 19:39:57 | I |         best error  = [   13.2850]
24-11-25 19:39:57 | I |     + error = [13.2850]
24-11-25 19:39:57 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 19:39:58 | I |       - range scale = [    1.0000]
24-11-25 19:39:58 | I |         sum  error  = [    3.2610]
24-11-25 19:39:58 | I |         best error  = [    3.2610]
24-11-25 19:39:58 | I |     + error = [3.2610]
24-11-25 19:39:58 | I |       - range scale = [    1.0000]
24-11-25 19:39:58 | I |         sum  error  = [   17.0886]
24-11-25 19:39:58 | I |         best error  = [   17.0886]
24-11-25 19:39:58 | I |     + error = [17.0886]
24-11-25 19:39:59 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 19:40:00 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 19:40:01 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 19:40:03 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 19:40:04 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 19:40:06 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 19:40:07 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 19:40:10 | I | quantizing activations for layer model.layers.0
24-11-25 19:40:10 | I | collecting info in model.layers.0
24-11-25 19:40:10 | I | collecting info in model.layers.0
24-11-25 19:40:10 | I | collecting info in model.layers.0
24-11-25 19:40:11 | I | collecting info in model.layers.0
24-11-25 19:40:11 | I | collecting calibration activations in model.layers.0
24-11-25 19:40:11 | I | collecting calibration activations in model.layers.0
24-11-25 19:40:11 | I | collecting calibration activations in model.layers.0
24-11-25 19:40:11 | I | collecting calibration activations in model.layers.0
24-11-25 19:40:13 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 19:40:13 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 19:40:13 | I | - Evaluator: gptq
24-11-25 19:40:13 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 19:40:13 | I | - Batch_size: 8
24-11-25 19:40:13 | I |   + Max_seq_length: 2048
24-11-25 19:40:54 | I |     - Results:
24-11-25 19:40:54 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 19:40:54 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 19:40:54 | I |       |wikitext |      1|word_perplexity|7.9195|  |7.9195|
24-11-25 19:40:54 | I |       |val_valid|      1|word_perplexity|9.2060|  |9.2060|
24-11-25 19:40:54 | I |       
24-11-25 19:40:54 | I | forward this layer
24-11-25 19:40:54 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/155.pt
24-11-25 19:40:54 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/155.pt
24-11-25 19:40:55 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 19:40:55 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 19:40:55 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 19:40:55 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 19:40:55 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 19:40:55 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 19:40:55 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 19:40:55 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 19:40:55 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 19:40:55 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 19:40:55 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 19:40:55 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 19:40:55 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 19:40:55 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 19:40:55 | I | [63] done with optimizer step
24-11-25 19:40:55 | I | epoch 001:     78 / 409600000 loss=8.40302e-05, loss_per_token=0.172094, loss_sum=5639.17, wps=153.2, ups=0, wpb=32768, bsz=64, num_updates=64, lr=0.000149993, gnorm=34.212, clip=100, loss_scale=0.0078, train_wall=214, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=16985, lmquant_ppl_result_wikitext_in_train_no_quant=7.85304, lmquant_ppl_result_val_in_train_no_quant=9.19922, lmquant_ppl_result_wikitext_in_train_with_quant=7.91946, lmquant_ppl_result_val_in_train_with_quant=9.20597
24-11-25 19:40:55 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 19:40:55 | I | in layer model.layers.0
24-11-25 19:40:55 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 19:40:55 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 19:40:55 | I | - Evaluator: gptq
24-11-25 19:40:55 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 19:40:55 | I | - Batch_size: 8
24-11-25 19:40:55 | I |   + Max_seq_length: 2048
24-11-25 19:41:33 | I |     - Results:
24-11-25 19:41:33 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 19:41:33 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 19:41:33 | I |       |wikitext |      1|word_perplexity|7.8809|  |7.8809|
24-11-25 19:41:33 | I |       |val_valid|      1|word_perplexity|9.2666|  |9.2666|
24-11-25 19:41:33 | I |       
24-11-25 19:41:33 | I | quantizing weights for layer model.layers.0
24-11-25 19:41:33 | I | collecting info in model.layers.0
24-11-25 19:41:33 | I | collecting info in model.layers.0
24-11-25 19:41:33 | I | collecting info in model.layers.0
24-11-25 19:41:33 | I | collecting info in model.layers.0
24-11-25 19:41:34 | I | collecting calibration activations in model.layers.0
24-11-25 19:41:34 | I | collecting calibration activations in model.layers.0
24-11-25 19:41:34 | I | collecting calibration activations in model.layers.0
24-11-25 19:41:34 | I | collecting calibration activations in model.layers.0
24-11-25 19:41:34 | I | - Quantizing decoder layer model.layers.0
24-11-25 19:41:34 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 19:41:35 | I |       - range scale = [    1.0000]
24-11-25 19:41:35 | I |         sum  error  = [    0.0630]
24-11-25 19:41:35 | I |         best error  = [    0.0630]
24-11-25 19:41:35 | I |     + error = [0.0630]
24-11-25 19:41:36 | I |       - range scale = [    1.0000]
24-11-25 19:41:36 | I |         sum  error  = [    0.6074]
24-11-25 19:41:36 | I |         best error  = [    0.6074]
24-11-25 19:41:36 | I |     + error = [0.6074]
24-11-25 19:41:36 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 19:41:37 | I |       - range scale = [    1.0000]
24-11-25 19:41:37 | I |         sum  error  = [    0.0604]
24-11-25 19:41:37 | I |         best error  = [    0.0604]
24-11-25 19:41:37 | I |     + error = [0.0604]
24-11-25 19:41:37 | I |       - range scale = [    1.0000]
24-11-25 19:41:37 | I |         sum  error  = [    0.5290]
24-11-25 19:41:37 | I |         best error  = [    0.5290]
24-11-25 19:41:37 | I |     + error = [0.5290]
24-11-25 19:41:38 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 19:41:38 | I |       - range scale = [    1.0000]
24-11-25 19:41:38 | I |         sum  error  = [    0.2401]
24-11-25 19:41:38 | I |         best error  = [    0.2401]
24-11-25 19:41:38 | I |     + error = [0.2401]
24-11-25 19:41:39 | I |       - range scale = [    1.0000]
24-11-25 19:41:39 | I |         sum  error  = [    1.8790]
24-11-25 19:41:39 | I |         best error  = [    1.8790]
24-11-25 19:41:39 | I |     + error = [1.8790]
24-11-25 19:41:39 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 19:41:40 | I |       - range scale = [    1.0000]
24-11-25 19:41:40 | I |         sum  error  = [    0.0666]
24-11-25 19:41:40 | I |         best error  = [    0.0666]
24-11-25 19:41:40 | I |     + error = [0.0666]
24-11-25 19:41:41 | I |       - range scale = [    1.0000]
24-11-25 19:41:41 | I |         sum  error  = [    0.6359]
24-11-25 19:41:41 | I |         best error  = [    0.6359]
24-11-25 19:41:41 | I |     + error = [0.6359]
24-11-25 19:41:41 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 19:41:41 | I |       - range scale = [    1.0000]
24-11-25 19:41:41 | I |         sum  error  = [    1.0737]
24-11-25 19:41:41 | I |         best error  = [    1.0737]
24-11-25 19:41:41 | I |     + error = [1.0737]
24-11-25 19:41:42 | I |       - range scale = [    1.0000]
24-11-25 19:41:42 | I |         sum  error  = [   11.8775]
24-11-25 19:41:42 | I |         best error  = [   11.8775]
24-11-25 19:41:42 | I |     + error = [11.8775]
24-11-25 19:41:42 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 19:41:43 | I |       - range scale = [    1.0000]
24-11-25 19:41:43 | I |         sum  error  = [    1.2397]
24-11-25 19:41:43 | I |         best error  = [    1.2397]
24-11-25 19:41:43 | I |     + error = [1.2397]
24-11-25 19:41:44 | I |       - range scale = [    1.0000]
24-11-25 19:41:44 | I |         sum  error  = [   12.2641]
24-11-25 19:41:44 | I |         best error  = [   12.2641]
24-11-25 19:41:44 | I |     + error = [12.2641]
24-11-25 19:41:44 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 19:41:45 | I |       - range scale = [    1.0000]
24-11-25 19:41:45 | I |         sum  error  = [    2.4713]
24-11-25 19:41:45 | I |         best error  = [    2.4713]
24-11-25 19:41:45 | I |     + error = [2.4713]
24-11-25 19:41:45 | I |       - range scale = [    1.0000]
24-11-25 19:41:45 | I |         sum  error  = [   13.1580]
24-11-25 19:41:45 | I |         best error  = [   13.1580]
24-11-25 19:41:45 | I |     + error = [13.1580]
24-11-25 19:41:46 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 19:41:47 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 19:41:48 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 19:41:50 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 19:41:51 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 19:41:53 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 19:41:54 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 19:41:58 | I | quantizing activations for layer model.layers.0
24-11-25 19:41:58 | I | collecting info in model.layers.0
24-11-25 19:41:58 | I | collecting info in model.layers.0
24-11-25 19:41:58 | I | collecting info in model.layers.0
24-11-25 19:41:58 | I | collecting info in model.layers.0
24-11-25 19:41:58 | I | collecting calibration activations in model.layers.0
24-11-25 19:41:58 | I | collecting calibration activations in model.layers.0
24-11-25 19:41:58 | I | collecting calibration activations in model.layers.0
24-11-25 19:41:58 | I | collecting calibration activations in model.layers.0
24-11-25 19:42:00 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 19:42:00 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 19:42:00 | I | - Evaluator: gptq
24-11-25 19:42:00 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 19:42:00 | I | - Batch_size: 8
24-11-25 19:42:00 | I |   + Max_seq_length: 2048
24-11-25 19:42:42 | I |     - Results:
24-11-25 19:42:42 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 19:42:42 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 19:42:42 | I |       |wikitext |      1|word_perplexity|7.9815|  |7.9815|
24-11-25 19:42:42 | I |       |val_valid|      1|word_perplexity|9.2469|  |9.2469|
24-11-25 19:42:42 | I |       
24-11-25 19:42:42 | I | forward this layer
24-11-25 19:42:42 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/156.pt
24-11-25 19:42:42 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/156.pt
24-11-25 19:42:42 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 19:42:42 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 19:42:42 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 19:42:42 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 19:42:42 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 19:42:42 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 19:42:42 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 19:42:42 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 19:42:42 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 19:42:42 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 19:42:42 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 19:42:42 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 19:42:42 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 19:42:42 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 19:42:42 | I | in layer model.layers.0
24-11-25 19:42:42 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 19:42:42 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 19:42:42 | I | - Evaluator: gptq
24-11-25 19:42:42 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 19:42:42 | I | - Batch_size: 8
24-11-25 19:42:42 | I |   + Max_seq_length: 2048
24-11-25 19:43:20 | I |     - Results:
24-11-25 19:43:20 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 19:43:20 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 19:43:20 | I |       |wikitext |      1|word_perplexity|7.8809|  |7.8809|
24-11-25 19:43:20 | I |       |val_valid|      1|word_perplexity|9.2666|  |9.2666|
24-11-25 19:43:20 | I |       
24-11-25 19:43:20 | I | quantizing weights for layer model.layers.0
24-11-25 19:43:20 | I | collecting info in model.layers.0
24-11-25 19:43:20 | I | collecting info in model.layers.0
24-11-25 19:43:20 | I | collecting info in model.layers.0
24-11-25 19:43:20 | I | collecting info in model.layers.0
24-11-25 19:43:21 | I | collecting calibration activations in model.layers.0
24-11-25 19:43:21 | I | collecting calibration activations in model.layers.0
24-11-25 19:43:21 | I | collecting calibration activations in model.layers.0
24-11-25 19:43:21 | I | collecting calibration activations in model.layers.0
24-11-25 19:43:21 | I | - Quantizing decoder layer model.layers.0
24-11-25 19:43:21 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 19:43:22 | I |       - range scale = [    1.0000]
24-11-25 19:43:22 | I |         sum  error  = [    0.0708]
24-11-25 19:43:22 | I |         best error  = [    0.0708]
24-11-25 19:43:22 | I |     + error = [0.0708]
24-11-25 19:43:23 | I |       - range scale = [    1.0000]
24-11-25 19:43:23 | I |         sum  error  = [    0.6662]
24-11-25 19:43:23 | I |         best error  = [    0.6662]
24-11-25 19:43:23 | I |     + error = [0.6662]
24-11-25 19:43:23 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 19:43:24 | I |       - range scale = [    1.0000]
24-11-25 19:43:24 | I |         sum  error  = [    0.0709]
24-11-25 19:43:24 | I |         best error  = [    0.0709]
24-11-25 19:43:24 | I |     + error = [0.0709]
24-11-25 19:43:24 | I |       - range scale = [    1.0000]
24-11-25 19:43:24 | I |         sum  error  = [    0.6791]
24-11-25 19:43:24 | I |         best error  = [    0.6791]
24-11-25 19:43:24 | I |     + error = [0.6791]
24-11-25 19:43:25 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 19:43:25 | I |       - range scale = [    1.0000]
24-11-25 19:43:25 | I |         sum  error  = [    0.2442]
24-11-25 19:43:25 | I |         best error  = [    0.2442]
24-11-25 19:43:25 | I |     + error = [0.2442]
24-11-25 19:43:26 | I |       - range scale = [    1.0000]
24-11-25 19:43:26 | I |         sum  error  = [    1.9047]
24-11-25 19:43:26 | I |         best error  = [    1.9047]
24-11-25 19:43:26 | I |     + error = [1.9047]
24-11-25 19:43:26 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 19:43:27 | I |       - range scale = [    1.0000]
24-11-25 19:43:27 | I |         sum  error  = [    0.0770]
24-11-25 19:43:27 | I |         best error  = [    0.0770]
24-11-25 19:43:27 | I |     + error = [0.0770]
24-11-25 19:43:28 | I |       - range scale = [    1.0000]
24-11-25 19:43:28 | I |         sum  error  = [    0.7360]
24-11-25 19:43:28 | I |         best error  = [    0.7360]
24-11-25 19:43:28 | I |     + error = [0.7360]
24-11-25 19:43:28 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 19:43:28 | I |       - range scale = [    1.0000]
24-11-25 19:43:28 | I |         sum  error  = [    1.1369]
24-11-25 19:43:28 | I |         best error  = [    1.1369]
24-11-25 19:43:28 | I |     + error = [1.1369]
24-11-25 19:43:29 | I |       - range scale = [    1.0000]
24-11-25 19:43:29 | I |         sum  error  = [   12.5588]
24-11-25 19:43:29 | I |         best error  = [   12.5588]
24-11-25 19:43:29 | I |     + error = [12.5588]
24-11-25 19:43:29 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 19:43:30 | I |       - range scale = [    1.0000]
24-11-25 19:43:30 | I |         sum  error  = [    1.3126]
24-11-25 19:43:30 | I |         best error  = [    1.3126]
24-11-25 19:43:30 | I |     + error = [1.3126]
24-11-25 19:43:31 | I |       - range scale = [    1.0000]
24-11-25 19:43:31 | I |         sum  error  = [   12.9928]
24-11-25 19:43:31 | I |         best error  = [   12.9928]
24-11-25 19:43:31 | I |     + error = [12.9928]
24-11-25 19:43:31 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 19:43:32 | I |       - range scale = [    1.0000]
24-11-25 19:43:32 | I |         sum  error  = [    2.2482]
24-11-25 19:43:32 | I |         best error  = [    2.2482]
24-11-25 19:43:32 | I |     + error = [2.2482]
24-11-25 19:43:32 | I |       - range scale = [    1.0000]
24-11-25 19:43:32 | I |         sum  error  = [   11.8198]
24-11-25 19:43:32 | I |         best error  = [   11.8198]
24-11-25 19:43:32 | I |     + error = [11.8198]
24-11-25 19:43:33 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 19:43:34 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 19:43:35 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 19:43:37 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 19:43:38 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 19:43:40 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 19:43:41 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 19:43:44 | I | quantizing activations for layer model.layers.0
24-11-25 19:43:44 | I | collecting info in model.layers.0
24-11-25 19:43:44 | I | collecting info in model.layers.0
24-11-25 19:43:44 | I | collecting info in model.layers.0
24-11-25 19:43:44 | I | collecting info in model.layers.0
24-11-25 19:43:45 | I | collecting calibration activations in model.layers.0
24-11-25 19:43:45 | I | collecting calibration activations in model.layers.0
24-11-25 19:43:45 | I | collecting calibration activations in model.layers.0
24-11-25 19:43:45 | I | collecting calibration activations in model.layers.0
24-11-25 19:43:47 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 19:43:47 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 19:43:47 | I | - Evaluator: gptq
24-11-25 19:43:47 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 19:43:47 | I | - Batch_size: 8
24-11-25 19:43:47 | I |   + Max_seq_length: 2048
24-11-25 19:44:28 | I |     - Results:
24-11-25 19:44:28 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 19:44:28 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 19:44:28 | I |       |wikitext |      1|word_perplexity|8.0006|  |8.0006|
24-11-25 19:44:28 | I |       |val_valid|      1|word_perplexity|9.3052|  |9.3052|
24-11-25 19:44:28 | I |       
24-11-25 19:44:28 | I | forward this layer
24-11-25 19:44:28 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/157.pt
24-11-25 19:44:28 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/157.pt
24-11-25 19:44:29 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 19:44:29 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 19:44:29 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 19:44:29 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 19:44:29 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 19:44:29 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 19:44:29 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 19:44:29 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 19:44:29 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 19:44:29 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 19:44:29 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 19:44:29 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 19:44:29 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 19:44:29 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 19:44:29 | I | [64] done with optimizer step
24-11-25 19:44:29 | I | epoch 001:     79 / 409600000 loss=0.000105266, loss_per_token=0.215584, loss_sum=7064.26, wps=153.1, ups=0, wpb=32768, bsz=64, num_updates=65, lr=0.000149992, gnorm=33.664, clip=100, loss_scale=0.0078, train_wall=214, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=17199, lmquant_ppl_result_wikitext_in_train_no_quant=7.88094, lmquant_ppl_result_val_in_train_no_quant=9.26657, lmquant_ppl_result_wikitext_in_train_with_quant=8.00055, lmquant_ppl_result_val_in_train_with_quant=9.30519
24-11-25 19:44:29 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 19:44:29 | I | in layer model.layers.0
24-11-25 19:44:29 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 19:44:29 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 19:44:29 | I | - Evaluator: gptq
24-11-25 19:44:29 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 19:44:29 | I | - Batch_size: 8
24-11-25 19:44:29 | I |   + Max_seq_length: 2048
24-11-25 19:45:07 | I |     - Results:
24-11-25 19:45:07 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 19:45:07 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 19:45:07 | I |       |wikitext |      1|word_perplexity|7.8357|  |7.8357|
24-11-25 19:45:07 | I |       |val_valid|      1|word_perplexity|9.2017|  |9.2017|
24-11-25 19:45:07 | I |       
24-11-25 19:45:07 | I | quantizing weights for layer model.layers.0
24-11-25 19:45:07 | I | collecting info in model.layers.0
24-11-25 19:45:07 | I | collecting info in model.layers.0
24-11-25 19:45:07 | I | collecting info in model.layers.0
24-11-25 19:45:07 | I | collecting info in model.layers.0
24-11-25 19:45:08 | I | collecting calibration activations in model.layers.0
24-11-25 19:45:08 | I | collecting calibration activations in model.layers.0
24-11-25 19:45:08 | I | collecting calibration activations in model.layers.0
24-11-25 19:45:08 | I | collecting calibration activations in model.layers.0
24-11-25 19:45:09 | I | - Quantizing decoder layer model.layers.0
24-11-25 19:45:09 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 19:45:09 | I |       - range scale = [    1.0000]
24-11-25 19:45:09 | I |         sum  error  = [    0.0642]
24-11-25 19:45:09 | I |         best error  = [    0.0642]
24-11-25 19:45:09 | I |     + error = [0.0642]
24-11-25 19:45:10 | I |       - range scale = [    1.0000]
24-11-25 19:45:10 | I |         sum  error  = [    0.5423]
24-11-25 19:45:10 | I |         best error  = [    0.5423]
24-11-25 19:45:10 | I |     + error = [0.5423]
24-11-25 19:45:10 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 19:45:11 | I |       - range scale = [    1.0000]
24-11-25 19:45:11 | I |         sum  error  = [    0.0659]
24-11-25 19:45:11 | I |         best error  = [    0.0659]
24-11-25 19:45:11 | I |     + error = [0.0659]
24-11-25 19:45:12 | I |       - range scale = [    1.0000]
24-11-25 19:45:12 | I |         sum  error  = [    0.7204]
24-11-25 19:45:12 | I |         best error  = [    0.7204]
24-11-25 19:45:12 | I |     + error = [0.7204]
24-11-25 19:45:12 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 19:45:12 | I |       - range scale = [    1.0000]
24-11-25 19:45:12 | I |         sum  error  = [    0.2420]
24-11-25 19:45:12 | I |         best error  = [    0.2420]
24-11-25 19:45:12 | I |     + error = [0.2420]
24-11-25 19:45:13 | I |       - range scale = [    1.0000]
24-11-25 19:45:13 | I |         sum  error  = [    1.8679]
24-11-25 19:45:13 | I |         best error  = [    1.8679]
24-11-25 19:45:13 | I |     + error = [1.8679]
24-11-25 19:45:13 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 19:45:14 | I |       - range scale = [    1.0000]
24-11-25 19:45:14 | I |         sum  error  = [    0.0656]
24-11-25 19:45:14 | I |         best error  = [    0.0656]
24-11-25 19:45:14 | I |     + error = [0.0656]
24-11-25 19:45:15 | I |       - range scale = [    1.0000]
24-11-25 19:45:15 | I |         sum  error  = [    0.6314]
24-11-25 19:45:15 | I |         best error  = [    0.6314]
24-11-25 19:45:15 | I |     + error = [0.6314]
24-11-25 19:45:15 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 19:45:16 | I |       - range scale = [    1.0000]
24-11-25 19:45:16 | I |         sum  error  = [    1.0603]
24-11-25 19:45:16 | I |         best error  = [    1.0603]
24-11-25 19:45:16 | I |     + error = [1.0603]
24-11-25 19:45:16 | I |       - range scale = [    1.0000]
24-11-25 19:45:16 | I |         sum  error  = [   11.7043]
24-11-25 19:45:16 | I |         best error  = [   11.7043]
24-11-25 19:45:16 | I |     + error = [11.7043]
24-11-25 19:45:17 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 19:45:17 | I |       - range scale = [    1.0000]
24-11-25 19:45:17 | I |         sum  error  = [    1.2224]
24-11-25 19:45:17 | I |         best error  = [    1.2224]
24-11-25 19:45:17 | I |     + error = [1.2224]
24-11-25 19:45:18 | I |       - range scale = [    1.0000]
24-11-25 19:45:18 | I |         sum  error  = [   12.0793]
24-11-25 19:45:18 | I |         best error  = [   12.0793]
24-11-25 19:45:18 | I |     + error = [12.0793]
24-11-25 19:45:18 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 19:45:19 | I |       - range scale = [    1.0000]
24-11-25 19:45:19 | I |         sum  error  = [    1.7437]
24-11-25 19:45:19 | I |         best error  = [    1.7437]
24-11-25 19:45:19 | I |     + error = [1.7437]
24-11-25 19:45:20 | I |       - range scale = [    1.0000]
24-11-25 19:45:20 | I |         sum  error  = [   10.2155]
24-11-25 19:45:20 | I |         best error  = [   10.2155]
24-11-25 19:45:20 | I |     + error = [10.2155]
24-11-25 19:45:20 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 19:45:21 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 19:45:23 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 19:45:24 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 19:45:25 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 19:45:27 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 19:45:28 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 19:45:32 | I | quantizing activations for layer model.layers.0
24-11-25 19:45:32 | I | collecting info in model.layers.0
24-11-25 19:45:32 | I | collecting info in model.layers.0
24-11-25 19:45:32 | I | collecting info in model.layers.0
24-11-25 19:45:32 | I | collecting info in model.layers.0
24-11-25 19:45:32 | I | collecting calibration activations in model.layers.0
24-11-25 19:45:32 | I | collecting calibration activations in model.layers.0
24-11-25 19:45:32 | I | collecting calibration activations in model.layers.0
24-11-25 19:45:32 | I | collecting calibration activations in model.layers.0
24-11-25 19:45:34 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 19:45:34 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 19:45:34 | I | - Evaluator: gptq
24-11-25 19:45:34 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 19:45:34 | I | - Batch_size: 8
24-11-25 19:45:34 | I |   + Max_seq_length: 2048
24-11-25 19:46:16 | I |     - Results:
24-11-25 19:46:16 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 19:46:16 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 19:46:16 | I |       |wikitext |      1|word_perplexity|7.9175|  |7.9175|
24-11-25 19:46:16 | I |       |val_valid|      1|word_perplexity|9.2146|  |9.2146|
24-11-25 19:46:16 | I |       
24-11-25 19:46:16 | I | forward this layer
24-11-25 19:46:16 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/158.pt
24-11-25 19:46:16 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/158.pt
24-11-25 19:46:16 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 19:46:16 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 19:46:16 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 19:46:16 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 19:46:16 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 19:46:16 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 19:46:16 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 19:46:16 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 19:46:16 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 19:46:16 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 19:46:16 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 19:46:16 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 19:46:16 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 19:46:16 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 19:46:16 | I | in layer model.layers.0
24-11-25 19:46:16 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 19:46:16 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 19:46:16 | I | - Evaluator: gptq
24-11-25 19:46:16 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 19:46:16 | I | - Batch_size: 8
24-11-25 19:46:16 | I |   + Max_seq_length: 2048
24-11-25 19:46:54 | I |     - Results:
24-11-25 19:46:54 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 19:46:54 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 19:46:54 | I |       |wikitext |      1|word_perplexity|7.8357|  |7.8357|
24-11-25 19:46:54 | I |       |val_valid|      1|word_perplexity|9.2017|  |9.2017|
24-11-25 19:46:54 | I |       
24-11-25 19:46:54 | I | quantizing weights for layer model.layers.0
24-11-25 19:46:54 | I | collecting info in model.layers.0
24-11-25 19:46:54 | I | collecting info in model.layers.0
24-11-25 19:46:54 | I | collecting info in model.layers.0
24-11-25 19:46:54 | I | collecting info in model.layers.0
24-11-25 19:46:55 | I | collecting calibration activations in model.layers.0
24-11-25 19:46:55 | I | collecting calibration activations in model.layers.0
24-11-25 19:46:55 | I | collecting calibration activations in model.layers.0
24-11-25 19:46:55 | I | collecting calibration activations in model.layers.0
24-11-25 19:46:55 | I | - Quantizing decoder layer model.layers.0
24-11-25 19:46:55 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 19:46:56 | I |       - range scale = [    1.0000]
24-11-25 19:46:56 | I |         sum  error  = [    0.0582]
24-11-25 19:46:56 | I |         best error  = [    0.0582]
24-11-25 19:46:56 | I |     + error = [0.0582]
24-11-25 19:46:57 | I |       - range scale = [    1.0000]
24-11-25 19:46:57 | I |         sum  error  = [    0.5664]
24-11-25 19:46:57 | I |         best error  = [    0.5664]
24-11-25 19:46:57 | I |     + error = [0.5664]
24-11-25 19:46:57 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 19:46:58 | I |       - range scale = [    1.0000]
24-11-25 19:46:58 | I |         sum  error  = [    0.0653]
24-11-25 19:46:58 | I |         best error  = [    0.0653]
24-11-25 19:46:58 | I |     + error = [0.0653]
24-11-25 19:46:58 | I |       - range scale = [    1.0000]
24-11-25 19:46:58 | I |         sum  error  = [    0.6121]
24-11-25 19:46:58 | I |         best error  = [    0.6121]
24-11-25 19:46:58 | I |     + error = [0.6121]
24-11-25 19:46:59 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 19:46:59 | I |       - range scale = [    1.0000]
24-11-25 19:46:59 | I |         sum  error  = [    0.2430]
24-11-25 19:46:59 | I |         best error  = [    0.2430]
24-11-25 19:46:59 | I |     + error = [0.2430]
24-11-25 19:47:00 | I |       - range scale = [    1.0000]
24-11-25 19:47:00 | I |         sum  error  = [    1.8774]
24-11-25 19:47:00 | I |         best error  = [    1.8774]
24-11-25 19:47:00 | I |     + error = [1.8774]
24-11-25 19:47:00 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 19:47:01 | I |       - range scale = [    1.0000]
24-11-25 19:47:01 | I |         sum  error  = [    0.0642]
24-11-25 19:47:01 | I |         best error  = [    0.0642]
24-11-25 19:47:01 | I |     + error = [0.0642]
24-11-25 19:47:02 | I |       - range scale = [    1.0000]
24-11-25 19:47:02 | I |         sum  error  = [    0.6192]
24-11-25 19:47:02 | I |         best error  = [    0.6192]
24-11-25 19:47:02 | I |     + error = [0.6192]
24-11-25 19:47:02 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 19:47:02 | I |       - range scale = [    1.0000]
24-11-25 19:47:02 | I |         sum  error  = [    1.0379]
24-11-25 19:47:02 | I |         best error  = [    1.0379]
24-11-25 19:47:02 | I |     + error = [1.0379]
24-11-25 19:47:03 | I |       - range scale = [    1.0000]
24-11-25 19:47:03 | I |         sum  error  = [   11.4561]
24-11-25 19:47:03 | I |         best error  = [   11.4561]
24-11-25 19:47:03 | I |     + error = [11.4561]
24-11-25 19:47:03 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 19:47:04 | I |       - range scale = [    1.0000]
24-11-25 19:47:04 | I |         sum  error  = [    1.1948]
24-11-25 19:47:04 | I |         best error  = [    1.1948]
24-11-25 19:47:04 | I |     + error = [1.1948]
24-11-25 19:47:05 | I |       - range scale = [    1.0000]
24-11-25 19:47:05 | I |         sum  error  = [   11.8206]
24-11-25 19:47:05 | I |         best error  = [   11.8206]
24-11-25 19:47:05 | I |     + error = [11.8206]
24-11-25 19:47:05 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 19:47:06 | I |       - range scale = [    1.0000]
24-11-25 19:47:06 | I |         sum  error  = [    2.0146]
24-11-25 19:47:06 | I |         best error  = [    2.0146]
24-11-25 19:47:06 | I |     + error = [2.0146]
24-11-25 19:47:07 | I |       - range scale = [    1.0000]
24-11-25 19:47:07 | I |         sum  error  = [   11.5707]
24-11-25 19:47:07 | I |         best error  = [   11.5707]
24-11-25 19:47:07 | I |     + error = [11.5707]
24-11-25 19:47:07 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 19:47:08 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 19:47:10 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 19:47:11 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 19:47:12 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 19:47:14 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 19:47:15 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 19:47:19 | I | quantizing activations for layer model.layers.0
24-11-25 19:47:19 | I | collecting info in model.layers.0
24-11-25 19:47:19 | I | collecting info in model.layers.0
24-11-25 19:47:19 | I | collecting info in model.layers.0
24-11-25 19:47:19 | I | collecting info in model.layers.0
24-11-25 19:47:19 | I | collecting calibration activations in model.layers.0
24-11-25 19:47:19 | I | collecting calibration activations in model.layers.0
24-11-25 19:47:19 | I | collecting calibration activations in model.layers.0
24-11-25 19:47:19 | I | collecting calibration activations in model.layers.0
24-11-25 19:47:21 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 19:47:21 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 19:47:21 | I | - Evaluator: gptq
24-11-25 19:47:21 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 19:47:21 | I | - Batch_size: 8
24-11-25 19:47:21 | I |   + Max_seq_length: 2048
24-11-25 19:48:03 | I |     - Results:
24-11-25 19:48:03 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 19:48:03 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 19:48:03 | I |       |wikitext |      1|word_perplexity|7.9052|  |7.9052|
24-11-25 19:48:03 | I |       |val_valid|      1|word_perplexity|9.2327|  |9.2327|
24-11-25 19:48:03 | I |       
24-11-25 19:48:03 | I | forward this layer
24-11-25 19:48:03 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/159.pt
24-11-25 19:48:03 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/159.pt
24-11-25 19:48:03 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 19:48:03 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 19:48:03 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 19:48:03 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 19:48:03 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 19:48:03 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 19:48:03 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 19:48:03 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 19:48:03 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 19:48:03 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 19:48:03 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 19:48:03 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 19:48:03 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 19:48:03 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 19:48:03 | I | [65] done with optimizer step
24-11-25 19:48:03 | I | epoch 001:     80 / 409600000 loss=0.00010116, loss_per_token=0.207176, loss_sum=6788.74, wps=153, ups=0, wpb=32768, bsz=64, num_updates=66, lr=0.000149992, gnorm=39.639, clip=100, loss_scale=0.0078, train_wall=214, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=17413, lmquant_ppl_result_wikitext_in_train_no_quant=7.83569, lmquant_ppl_result_val_in_train_no_quant=9.20168, lmquant_ppl_result_wikitext_in_train_with_quant=7.90525, lmquant_ppl_result_val_in_train_with_quant=9.2327
24-11-25 19:48:03 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 19:48:03 | I | in layer model.layers.0
24-11-25 19:48:03 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 19:48:03 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 19:48:03 | I | - Evaluator: gptq
24-11-25 19:48:03 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 19:48:03 | I | - Batch_size: 8
24-11-25 19:48:03 | I |   + Max_seq_length: 2048
24-11-25 19:48:41 | I |     - Results:
24-11-25 19:48:41 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 19:48:41 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 19:48:41 | I |       |wikitext |      1|word_perplexity|7.7972|  |7.7972|
24-11-25 19:48:41 | I |       |val_valid|      1|word_perplexity|9.1361|  |9.1361|
24-11-25 19:48:41 | I |       
24-11-25 19:48:41 | I | quantizing weights for layer model.layers.0
24-11-25 19:48:41 | I | collecting info in model.layers.0
24-11-25 19:48:41 | I | collecting info in model.layers.0
24-11-25 19:48:41 | I | collecting info in model.layers.0
24-11-25 19:48:41 | I | collecting info in model.layers.0
24-11-25 19:48:42 | I | collecting calibration activations in model.layers.0
24-11-25 19:48:42 | I | collecting calibration activations in model.layers.0
24-11-25 19:48:42 | I | collecting calibration activations in model.layers.0
24-11-25 19:48:42 | I | collecting calibration activations in model.layers.0
24-11-25 19:48:43 | I | - Quantizing decoder layer model.layers.0
24-11-25 19:48:43 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 19:48:43 | I |       - range scale = [    1.0000]
24-11-25 19:48:43 | I |         sum  error  = [    0.0571]
24-11-25 19:48:43 | I |         best error  = [    0.0571]
24-11-25 19:48:43 | I |     + error = [0.0571]
24-11-25 19:48:44 | I |       - range scale = [    1.0000]
24-11-25 19:48:44 | I |         sum  error  = [    0.5641]
24-11-25 19:48:44 | I |         best error  = [    0.5641]
24-11-25 19:48:44 | I |     + error = [0.5641]
24-11-25 19:48:44 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 19:48:45 | I |       - range scale = [    1.0000]
24-11-25 19:48:45 | I |         sum  error  = [    0.0600]
24-11-25 19:48:45 | I |         best error  = [    0.0600]
24-11-25 19:48:45 | I |     + error = [0.0600]
24-11-25 19:48:46 | I |       - range scale = [    1.0000]
24-11-25 19:48:46 | I |         sum  error  = [    0.5097]
24-11-25 19:48:46 | I |         best error  = [    0.5097]
24-11-25 19:48:46 | I |     + error = [0.5097]
24-11-25 19:48:46 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 19:48:47 | I |       - range scale = [    1.0000]
24-11-25 19:48:47 | I |         sum  error  = [    0.2273]
24-11-25 19:48:47 | I |         best error  = [    0.2273]
24-11-25 19:48:47 | I |     + error = [0.2273]
24-11-25 19:48:47 | I |       - range scale = [    1.0000]
24-11-25 19:48:47 | I |         sum  error  = [    1.8313]
24-11-25 19:48:47 | I |         best error  = [    1.8313]
24-11-25 19:48:47 | I |     + error = [1.8313]
24-11-25 19:48:47 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 19:48:48 | I |       - range scale = [    1.0000]
24-11-25 19:48:48 | I |         sum  error  = [    0.0615]
24-11-25 19:48:48 | I |         best error  = [    0.0615]
24-11-25 19:48:48 | I |     + error = [0.0615]
24-11-25 19:48:49 | I |       - range scale = [    1.0000]
24-11-25 19:48:49 | I |         sum  error  = [    0.5852]
24-11-25 19:48:49 | I |         best error  = [    0.5852]
24-11-25 19:48:49 | I |     + error = [0.5852]
24-11-25 19:48:49 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 19:48:50 | I |       - range scale = [    1.0000]
24-11-25 19:48:50 | I |         sum  error  = [    1.0785]
24-11-25 19:48:50 | I |         best error  = [    1.0785]
24-11-25 19:48:50 | I |     + error = [1.0785]
24-11-25 19:48:50 | I |       - range scale = [    1.0000]
24-11-25 19:48:50 | I |         sum  error  = [   11.9313]
24-11-25 19:48:50 | I |         best error  = [   11.9313]
24-11-25 19:48:50 | I |     + error = [11.9313]
24-11-25 19:48:51 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 19:48:51 | I |       - range scale = [    1.0000]
24-11-25 19:48:51 | I |         sum  error  = [    1.2452]
24-11-25 19:48:51 | I |         best error  = [    1.2452]
24-11-25 19:48:51 | I |     + error = [1.2452]
24-11-25 19:48:52 | I |       - range scale = [    1.0000]
24-11-25 19:48:52 | I |         sum  error  = [   12.3138]
24-11-25 19:48:52 | I |         best error  = [   12.3138]
24-11-25 19:48:52 | I |     + error = [12.3138]
24-11-25 19:48:52 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 19:48:53 | I |       - range scale = [    1.0000]
24-11-25 19:48:53 | I |         sum  error  = [    2.5643]
24-11-25 19:48:53 | I |         best error  = [    2.5643]
24-11-25 19:48:53 | I |     + error = [2.5643]
24-11-25 19:48:54 | I |       - range scale = [    1.0000]
24-11-25 19:48:54 | I |         sum  error  = [   14.3778]
24-11-25 19:48:54 | I |         best error  = [   14.3778]
24-11-25 19:48:54 | I |     + error = [14.3778]
24-11-25 19:48:54 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 19:48:55 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 19:48:57 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 19:48:58 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 19:49:00 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 19:49:01 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 19:49:02 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 19:49:06 | I | quantizing activations for layer model.layers.0
24-11-25 19:49:06 | I | collecting info in model.layers.0
24-11-25 19:49:06 | I | collecting info in model.layers.0
24-11-25 19:49:06 | I | collecting info in model.layers.0
24-11-25 19:49:06 | I | collecting info in model.layers.0
24-11-25 19:49:06 | I | collecting calibration activations in model.layers.0
24-11-25 19:49:06 | I | collecting calibration activations in model.layers.0
24-11-25 19:49:06 | I | collecting calibration activations in model.layers.0
24-11-25 19:49:06 | I | collecting calibration activations in model.layers.0
24-11-25 19:49:08 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 19:49:08 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 19:49:08 | I | - Evaluator: gptq
24-11-25 19:49:08 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 19:49:08 | I | - Batch_size: 8
24-11-25 19:49:08 | I |   + Max_seq_length: 2048
24-11-25 19:49:50 | I |     - Results:
24-11-25 19:49:50 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 19:49:50 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 19:49:50 | I |       |wikitext |      1|word_perplexity|7.8476|  |7.8476|
24-11-25 19:49:50 | I |       |val_valid|      1|word_perplexity|9.1490|  |9.1490|
24-11-25 19:49:50 | I |       
24-11-25 19:49:50 | I | forward this layer
24-11-25 19:49:50 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/160.pt
24-11-25 19:49:50 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/160.pt
24-11-25 19:49:50 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 19:49:50 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 19:49:50 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 19:49:50 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 19:49:50 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 19:49:50 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 19:49:50 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 19:49:50 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 19:49:50 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 19:49:50 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 19:49:50 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 19:49:50 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 19:49:50 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 19:49:50 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 19:49:50 | I | in layer model.layers.0
24-11-25 19:49:50 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 19:49:50 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 19:49:50 | I | - Evaluator: gptq
24-11-25 19:49:50 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 19:49:50 | I | - Batch_size: 8
24-11-25 19:49:50 | I |   + Max_seq_length: 2048
24-11-25 19:50:28 | I |     - Results:
24-11-25 19:50:28 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 19:50:28 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 19:50:28 | I |       |wikitext |      1|word_perplexity|7.7972|  |7.7972|
24-11-25 19:50:28 | I |       |val_valid|      1|word_perplexity|9.1361|  |9.1361|
24-11-25 19:50:28 | I |       
24-11-25 19:50:28 | I | quantizing weights for layer model.layers.0
24-11-25 19:50:28 | I | collecting info in model.layers.0
24-11-25 19:50:28 | I | collecting info in model.layers.0
24-11-25 19:50:28 | I | collecting info in model.layers.0
24-11-25 19:50:28 | I | collecting info in model.layers.0
24-11-25 19:50:29 | I | collecting calibration activations in model.layers.0
24-11-25 19:50:29 | I | collecting calibration activations in model.layers.0
24-11-25 19:50:29 | I | collecting calibration activations in model.layers.0
24-11-25 19:50:29 | I | collecting calibration activations in model.layers.0
24-11-25 19:50:30 | I | - Quantizing decoder layer model.layers.0
24-11-25 19:50:30 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 19:50:30 | I |       - range scale = [    1.0000]
24-11-25 19:50:30 | I |         sum  error  = [    0.0588]
24-11-25 19:50:30 | I |         best error  = [    0.0588]
24-11-25 19:50:30 | I |     + error = [0.0588]
24-11-25 19:50:31 | I |       - range scale = [    1.0000]
24-11-25 19:50:31 | I |         sum  error  = [    0.5882]
24-11-25 19:50:31 | I |         best error  = [    0.5882]
24-11-25 19:50:31 | I |     + error = [0.5882]
24-11-25 19:50:31 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 19:50:32 | I |       - range scale = [    1.0000]
24-11-25 19:50:32 | I |         sum  error  = [    0.0640]
24-11-25 19:50:32 | I |         best error  = [    0.0640]
24-11-25 19:50:32 | I |     + error = [0.0640]
24-11-25 19:50:33 | I |       - range scale = [    1.0000]
24-11-25 19:50:33 | I |         sum  error  = [    0.5517]
24-11-25 19:50:33 | I |         best error  = [    0.5517]
24-11-25 19:50:33 | I |     + error = [0.5517]
24-11-25 19:50:33 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 19:50:33 | I |       - range scale = [    1.0000]
24-11-25 19:50:33 | I |         sum  error  = [    0.2370]
24-11-25 19:50:33 | I |         best error  = [    0.2370]
24-11-25 19:50:33 | I |     + error = [0.2370]
24-11-25 19:50:34 | I |       - range scale = [    1.0000]
24-11-25 19:50:34 | I |         sum  error  = [    1.8928]
24-11-25 19:50:34 | I |         best error  = [    1.8928]
24-11-25 19:50:34 | I |     + error = [1.8928]
24-11-25 19:50:34 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 19:50:35 | I |       - range scale = [    1.0000]
24-11-25 19:50:35 | I |         sum  error  = [    0.0645]
24-11-25 19:50:35 | I |         best error  = [    0.0645]
24-11-25 19:50:35 | I |     + error = [0.0645]
24-11-25 19:50:36 | I |       - range scale = [    1.0000]
24-11-25 19:50:36 | I |         sum  error  = [    0.6174]
24-11-25 19:50:36 | I |         best error  = [    0.6174]
24-11-25 19:50:36 | I |     + error = [0.6174]
24-11-25 19:50:36 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 19:50:37 | I |       - range scale = [    1.0000]
24-11-25 19:50:37 | I |         sum  error  = [    1.0581]
24-11-25 19:50:37 | I |         best error  = [    1.0581]
24-11-25 19:50:37 | I |     + error = [1.0581]
24-11-25 19:50:37 | I |       - range scale = [    1.0000]
24-11-25 19:50:37 | I |         sum  error  = [   11.7120]
24-11-25 19:50:37 | I |         best error  = [   11.7120]
24-11-25 19:50:37 | I |     + error = [11.7120]
24-11-25 19:50:38 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 19:50:38 | I |       - range scale = [    1.0000]
24-11-25 19:50:38 | I |         sum  error  = [    1.2262]
24-11-25 19:50:38 | I |         best error  = [    1.2262]
24-11-25 19:50:38 | I |     + error = [1.2262]
24-11-25 19:50:39 | I |       - range scale = [    1.0000]
24-11-25 19:50:39 | I |         sum  error  = [   12.0871]
24-11-25 19:50:39 | I |         best error  = [   12.0871]
24-11-25 19:50:39 | I |     + error = [12.0871]
24-11-25 19:50:39 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 19:50:40 | I |       - range scale = [    1.0000]
24-11-25 19:50:40 | I |         sum  error  = [    3.0995]
24-11-25 19:50:40 | I |         best error  = [    3.0995]
24-11-25 19:50:40 | I |     + error = [3.0995]
24-11-25 19:50:41 | I |       - range scale = [    1.0000]
24-11-25 19:50:41 | I |         sum  error  = [   16.6807]
24-11-25 19:50:41 | I |         best error  = [   16.6807]
24-11-25 19:50:41 | I |     + error = [16.6807]
24-11-25 19:50:41 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 19:50:42 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 19:50:44 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 19:50:45 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 19:50:46 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 19:50:48 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 19:50:49 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 19:50:52 | I | quantizing activations for layer model.layers.0
24-11-25 19:50:52 | I | collecting info in model.layers.0
24-11-25 19:50:52 | I | collecting info in model.layers.0
24-11-25 19:50:52 | I | collecting info in model.layers.0
24-11-25 19:50:52 | I | collecting info in model.layers.0
24-11-25 19:50:53 | I | collecting calibration activations in model.layers.0
24-11-25 19:50:53 | I | collecting calibration activations in model.layers.0
24-11-25 19:50:53 | I | collecting calibration activations in model.layers.0
24-11-25 19:50:53 | I | collecting calibration activations in model.layers.0
24-11-25 19:50:55 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 19:50:55 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 19:50:55 | I | - Evaluator: gptq
24-11-25 19:50:55 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 19:50:55 | I | - Batch_size: 8
24-11-25 19:50:55 | I |   + Max_seq_length: 2048
24-11-25 19:51:36 | I |     - Results:
24-11-25 19:51:36 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 19:51:36 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 19:51:36 | I |       |wikitext |      1|word_perplexity|7.8729|  |7.8729|
24-11-25 19:51:36 | I |       |val_valid|      1|word_perplexity|9.1594|  |9.1594|
24-11-25 19:51:36 | I |       
24-11-25 19:51:36 | I | forward this layer
24-11-25 19:51:36 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/161.pt
24-11-25 19:51:36 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/161.pt
24-11-25 19:51:37 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 19:51:37 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 19:51:37 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 19:51:37 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 19:51:37 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 19:51:37 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 19:51:37 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 19:51:37 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 19:51:37 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 19:51:37 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 19:51:37 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 19:51:37 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 19:51:37 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 19:51:37 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 19:51:37 | I | [66] done with optimizer step
24-11-25 19:51:37 | I | epoch 001:     81 / 409600000 loss=0.000129131, loss_per_token=0.26446, loss_sum=8665.84, wps=153.3, ups=0, wpb=32768, bsz=64, num_updates=67, lr=0.000149991, gnorm=35.738, clip=100, loss_scale=0.0078, train_wall=214, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=17627, lmquant_ppl_result_wikitext_in_train_no_quant=7.79717, lmquant_ppl_result_val_in_train_no_quant=9.13614, lmquant_ppl_result_wikitext_in_train_with_quant=7.87293, lmquant_ppl_result_val_in_train_with_quant=9.15942
24-11-25 19:51:37 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 19:51:37 | I | in layer model.layers.0
24-11-25 19:51:37 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 19:51:37 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 19:51:37 | I | - Evaluator: gptq
24-11-25 19:51:37 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 19:51:37 | I | - Batch_size: 8
24-11-25 19:51:37 | I |   + Max_seq_length: 2048
24-11-25 19:52:15 | I |     - Results:
24-11-25 19:52:15 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 19:52:15 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 19:52:15 | I |       |wikitext |      1|word_perplexity|7.7705|  |7.7705|
24-11-25 19:52:15 | I |       |val_valid|      1|word_perplexity|9.0961|  |9.0961|
24-11-25 19:52:15 | I |       
24-11-25 19:52:15 | I | quantizing weights for layer model.layers.0
24-11-25 19:52:15 | I | collecting info in model.layers.0
24-11-25 19:52:15 | I | collecting info in model.layers.0
24-11-25 19:52:15 | I | collecting info in model.layers.0
24-11-25 19:52:15 | I | collecting info in model.layers.0
24-11-25 19:52:16 | I | collecting calibration activations in model.layers.0
24-11-25 19:52:16 | I | collecting calibration activations in model.layers.0
24-11-25 19:52:16 | I | collecting calibration activations in model.layers.0
24-11-25 19:52:16 | I | collecting calibration activations in model.layers.0
24-11-25 19:52:16 | I | - Quantizing decoder layer model.layers.0
24-11-25 19:52:16 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 19:52:17 | I |       - range scale = [    1.0000]
24-11-25 19:52:17 | I |         sum  error  = [    0.0548]
24-11-25 19:52:17 | I |         best error  = [    0.0548]
24-11-25 19:52:17 | I |     + error = [0.0548]
24-11-25 19:52:18 | I |       - range scale = [    1.0000]
24-11-25 19:52:18 | I |         sum  error  = [    0.5519]
24-11-25 19:52:18 | I |         best error  = [    0.5519]
24-11-25 19:52:18 | I |     + error = [0.5519]
24-11-25 19:52:18 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 19:52:19 | I |       - range scale = [    1.0000]
24-11-25 19:52:19 | I |         sum  error  = [    0.0600]
24-11-25 19:52:19 | I |         best error  = [    0.0600]
24-11-25 19:52:19 | I |     + error = [0.0600]
24-11-25 19:52:19 | I |       - range scale = [    1.0000]
24-11-25 19:52:19 | I |         sum  error  = [    0.5272]
24-11-25 19:52:19 | I |         best error  = [    0.5272]
24-11-25 19:52:19 | I |     + error = [0.5272]
24-11-25 19:52:20 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 19:52:20 | I |       - range scale = [    1.0000]
24-11-25 19:52:20 | I |         sum  error  = [    0.2222]
24-11-25 19:52:20 | I |         best error  = [    0.2222]
24-11-25 19:52:20 | I |     + error = [0.2222]
24-11-25 19:52:21 | I |       - range scale = [    1.0000]
24-11-25 19:52:21 | I |         sum  error  = [    1.8420]
24-11-25 19:52:21 | I |         best error  = [    1.8420]
24-11-25 19:52:21 | I |     + error = [1.8420]
24-11-25 19:52:21 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 19:52:22 | I |       - range scale = [    1.0000]
24-11-25 19:52:22 | I |         sum  error  = [    0.0620]
24-11-25 19:52:22 | I |         best error  = [    0.0620]
24-11-25 19:52:22 | I |     + error = [0.0620]
24-11-25 19:52:23 | I |       - range scale = [    1.0000]
24-11-25 19:52:23 | I |         sum  error  = [    0.5992]
24-11-25 19:52:23 | I |         best error  = [    0.5992]
24-11-25 19:52:23 | I |     + error = [0.5992]
24-11-25 19:52:23 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 19:52:23 | I |       - range scale = [    1.0000]
24-11-25 19:52:23 | I |         sum  error  = [    1.1262]
24-11-25 19:52:23 | I |         best error  = [    1.1262]
24-11-25 19:52:23 | I |     + error = [1.1262]
24-11-25 19:52:24 | I |       - range scale = [    1.0000]
24-11-25 19:52:24 | I |         sum  error  = [   12.4572]
24-11-25 19:52:24 | I |         best error  = [   12.4572]
24-11-25 19:52:24 | I |     + error = [12.4572]
24-11-25 19:52:24 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 19:52:25 | I |       - range scale = [    1.0000]
24-11-25 19:52:25 | I |         sum  error  = [    1.3015]
24-11-25 19:52:25 | I |         best error  = [    1.3015]
24-11-25 19:52:25 | I |     + error = [1.3015]
24-11-25 19:52:26 | I |       - range scale = [    1.0000]
24-11-25 19:52:26 | I |         sum  error  = [   12.8494]
24-11-25 19:52:26 | I |         best error  = [   12.8494]
24-11-25 19:52:26 | I |     + error = [12.8494]
24-11-25 19:52:26 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 19:52:27 | I |       - range scale = [    1.0000]
24-11-25 19:52:27 | I |         sum  error  = [    1.5555]
24-11-25 19:52:27 | I |         best error  = [    1.5555]
24-11-25 19:52:27 | I |     + error = [1.5555]
24-11-25 19:52:27 | I |       - range scale = [    1.0000]
24-11-25 19:52:27 | I |         sum  error  = [    8.4486]
24-11-25 19:52:27 | I |         best error  = [    8.4486]
24-11-25 19:52:27 | I |     + error = [8.4486]
24-11-25 19:52:28 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 19:52:29 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 19:52:30 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 19:52:32 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 19:52:33 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 19:52:35 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 19:52:36 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 19:52:39 | I | quantizing activations for layer model.layers.0
24-11-25 19:52:39 | I | collecting info in model.layers.0
24-11-25 19:52:39 | I | collecting info in model.layers.0
24-11-25 19:52:39 | I | collecting info in model.layers.0
24-11-25 19:52:39 | I | collecting info in model.layers.0
24-11-25 19:52:40 | I | collecting calibration activations in model.layers.0
24-11-25 19:52:40 | I | collecting calibration activations in model.layers.0
24-11-25 19:52:40 | I | collecting calibration activations in model.layers.0
24-11-25 19:52:40 | I | collecting calibration activations in model.layers.0
24-11-25 19:52:42 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 19:52:42 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 19:52:42 | I | - Evaluator: gptq
24-11-25 19:52:42 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 19:52:42 | I | - Batch_size: 8
24-11-25 19:52:42 | I |   + Max_seq_length: 2048
24-11-25 19:53:23 | I |     - Results:
24-11-25 19:53:23 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 19:53:23 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 19:53:23 | I |       |wikitext |      1|word_perplexity|7.8338|  |7.8338|
24-11-25 19:53:23 | I |       |val_valid|      1|word_perplexity|9.1293|  |9.1293|
24-11-25 19:53:23 | I |       
24-11-25 19:53:23 | I | forward this layer
24-11-25 19:53:23 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/162.pt
24-11-25 19:53:23 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/162.pt
24-11-25 19:53:23 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 19:53:23 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 19:53:23 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 19:53:23 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 19:53:23 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 19:53:23 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 19:53:23 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 19:53:23 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 19:53:23 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 19:53:23 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 19:53:23 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 19:53:23 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 19:53:23 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 19:53:23 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 19:53:24 | I | in layer model.layers.0
24-11-25 19:53:24 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 19:53:24 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 19:53:24 | I | - Evaluator: gptq
24-11-25 19:53:24 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 19:53:24 | I | - Batch_size: 8
24-11-25 19:53:24 | I |   + Max_seq_length: 2048
24-11-25 19:54:02 | I |     - Results:
24-11-25 19:54:02 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 19:54:02 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 19:54:02 | I |       |wikitext |      1|word_perplexity|7.7705|  |7.7705|
24-11-25 19:54:02 | I |       |val_valid|      1|word_perplexity|9.0961|  |9.0961|
24-11-25 19:54:02 | I |       
24-11-25 19:54:02 | I | quantizing weights for layer model.layers.0
24-11-25 19:54:02 | I | collecting info in model.layers.0
24-11-25 19:54:02 | I | collecting info in model.layers.0
24-11-25 19:54:02 | I | collecting info in model.layers.0
24-11-25 19:54:02 | I | collecting info in model.layers.0
24-11-25 19:54:02 | I | collecting calibration activations in model.layers.0
24-11-25 19:54:02 | I | collecting calibration activations in model.layers.0
24-11-25 19:54:03 | I | collecting calibration activations in model.layers.0
24-11-25 19:54:03 | I | collecting calibration activations in model.layers.0
24-11-25 19:54:03 | I | - Quantizing decoder layer model.layers.0
24-11-25 19:54:03 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 19:54:04 | I |       - range scale = [    1.0000]
24-11-25 19:54:04 | I |         sum  error  = [    0.0592]
24-11-25 19:54:04 | I |         best error  = [    0.0592]
24-11-25 19:54:04 | I |     + error = [0.0592]
24-11-25 19:54:04 | I |       - range scale = [    1.0000]
24-11-25 19:54:04 | I |         sum  error  = [    0.6223]
24-11-25 19:54:04 | I |         best error  = [    0.6223]
24-11-25 19:54:04 | I |     + error = [0.6223]
24-11-25 19:54:05 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 19:54:05 | I |       - range scale = [    1.0000]
24-11-25 19:54:05 | I |         sum  error  = [    0.0686]
24-11-25 19:54:05 | I |         best error  = [    0.0686]
24-11-25 19:54:05 | I |     + error = [0.0686]
24-11-25 19:54:06 | I |       - range scale = [    1.0000]
24-11-25 19:54:06 | I |         sum  error  = [    0.5585]
24-11-25 19:54:06 | I |         best error  = [    0.5585]
24-11-25 19:54:06 | I |     + error = [0.5585]
24-11-25 19:54:06 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 19:54:07 | I |       - range scale = [    1.0000]
24-11-25 19:54:07 | I |         sum  error  = [    0.2325]
24-11-25 19:54:07 | I |         best error  = [    0.2325]
24-11-25 19:54:07 | I |     + error = [0.2325]
24-11-25 19:54:08 | I |       - range scale = [    1.0000]
24-11-25 19:54:08 | I |         sum  error  = [    1.8795]
24-11-25 19:54:08 | I |         best error  = [    1.8795]
24-11-25 19:54:08 | I |     + error = [1.8795]
24-11-25 19:54:08 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 19:54:08 | I |       - range scale = [    1.0000]
24-11-25 19:54:08 | I |         sum  error  = [    0.0648]
24-11-25 19:54:08 | I |         best error  = [    0.0648]
24-11-25 19:54:08 | I |     + error = [0.0648]
24-11-25 19:54:09 | I |       - range scale = [    1.0000]
24-11-25 19:54:09 | I |         sum  error  = [    0.6168]
24-11-25 19:54:09 | I |         best error  = [    0.6168]
24-11-25 19:54:09 | I |     + error = [0.6168]
24-11-25 19:54:09 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 19:54:10 | I |       - range scale = [    1.0000]
24-11-25 19:54:10 | I |         sum  error  = [    1.0661]
24-11-25 19:54:10 | I |         best error  = [    1.0661]
24-11-25 19:54:10 | I |     + error = [1.0661]
24-11-25 19:54:11 | I |       - range scale = [    1.0000]
24-11-25 19:54:11 | I |         sum  error  = [   11.7787]
24-11-25 19:54:11 | I |         best error  = [   11.7787]
24-11-25 19:54:11 | I |     + error = [11.7787]
24-11-25 19:54:11 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 19:54:12 | I |       - range scale = [    1.0000]
24-11-25 19:54:12 | I |         sum  error  = [    1.2276]
24-11-25 19:54:12 | I |         best error  = [    1.2276]
24-11-25 19:54:12 | I |     + error = [1.2276]
24-11-25 19:54:12 | I |       - range scale = [    1.0000]
24-11-25 19:54:12 | I |         sum  error  = [   12.1577]
24-11-25 19:54:12 | I |         best error  = [   12.1577]
24-11-25 19:54:12 | I |     + error = [12.1577]
24-11-25 19:54:13 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 19:54:13 | I |       - range scale = [    1.0000]
24-11-25 19:54:13 | I |         sum  error  = [    3.3344]
24-11-25 19:54:13 | I |         best error  = [    3.3344]
24-11-25 19:54:13 | I |     + error = [3.3344]
24-11-25 19:54:14 | I |       - range scale = [    1.0000]
24-11-25 19:54:14 | I |         sum  error  = [   18.1762]
24-11-25 19:54:14 | I |         best error  = [   18.1762]
24-11-25 19:54:14 | I |     + error = [18.1762]
24-11-25 19:54:14 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 19:54:16 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 19:54:17 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 19:54:18 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 19:54:20 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 19:54:21 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 19:54:23 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 19:54:26 | I | quantizing activations for layer model.layers.0
24-11-25 19:54:26 | I | collecting info in model.layers.0
24-11-25 19:54:26 | I | collecting info in model.layers.0
24-11-25 19:54:26 | I | collecting info in model.layers.0
24-11-25 19:54:26 | I | collecting info in model.layers.0
24-11-25 19:54:26 | I | collecting calibration activations in model.layers.0
24-11-25 19:54:26 | I | collecting calibration activations in model.layers.0
24-11-25 19:54:27 | I | collecting calibration activations in model.layers.0
24-11-25 19:54:27 | I | collecting calibration activations in model.layers.0
24-11-25 19:54:29 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 19:54:29 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 19:54:29 | I | - Evaluator: gptq
24-11-25 19:54:29 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 19:54:29 | I | - Batch_size: 8
24-11-25 19:54:29 | I |   + Max_seq_length: 2048
24-11-25 19:55:10 | I |     - Results:
24-11-25 19:55:10 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 19:55:10 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 19:55:10 | I |       |wikitext |      1|word_perplexity|7.8366|  |7.8366|
24-11-25 19:55:10 | I |       |val_valid|      1|word_perplexity|9.1280|  |9.1280|
24-11-25 19:55:10 | I |       
24-11-25 19:55:10 | I | forward this layer
24-11-25 19:55:10 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/163.pt
24-11-25 19:55:10 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/163.pt
24-11-25 19:55:10 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 19:55:10 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 19:55:10 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 19:55:10 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 19:55:10 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 19:55:10 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 19:55:10 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 19:55:10 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 19:55:10 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 19:55:10 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 19:55:10 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 19:55:10 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 19:55:10 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 19:55:10 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 19:55:10 | I | [67] done with optimizer step
24-11-25 19:55:10 | I | epoch 001:     82 / 409600000 loss=6.89666e-05, loss_per_token=0.141244, loss_sum=4628.27, wps=153.5, ups=0, wpb=32768, bsz=64, num_updates=68, lr=0.000149991, gnorm=20.218, clip=100, loss_scale=0.0078, train_wall=213, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=17841, lmquant_ppl_result_wikitext_in_train_no_quant=7.77051, lmquant_ppl_result_val_in_train_no_quant=9.09611, lmquant_ppl_result_wikitext_in_train_with_quant=7.83662, lmquant_ppl_result_val_in_train_with_quant=9.12801
24-11-25 19:55:11 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 19:55:11 | I | in layer model.layers.0
24-11-25 19:55:11 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 19:55:11 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 19:55:11 | I | - Evaluator: gptq
24-11-25 19:55:11 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 19:55:11 | I | - Batch_size: 8
24-11-25 19:55:11 | I |   + Max_seq_length: 2048
24-11-25 19:55:49 | I |     - Results:
24-11-25 19:55:49 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 19:55:49 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 19:55:49 | I |       |wikitext |      1|word_perplexity|7.7622|  |7.7622|
24-11-25 19:55:49 | I |       |val_valid|      1|word_perplexity|9.0875|  |9.0875|
24-11-25 19:55:49 | I |       
24-11-25 19:55:49 | I | quantizing weights for layer model.layers.0
24-11-25 19:55:49 | I | collecting info in model.layers.0
24-11-25 19:55:49 | I | collecting info in model.layers.0
24-11-25 19:55:49 | I | collecting info in model.layers.0
24-11-25 19:55:49 | I | collecting info in model.layers.0
24-11-25 19:55:49 | I | collecting calibration activations in model.layers.0
24-11-25 19:55:49 | I | collecting calibration activations in model.layers.0
24-11-25 19:55:49 | I | collecting calibration activations in model.layers.0
24-11-25 19:55:50 | I | collecting calibration activations in model.layers.0
24-11-25 19:55:50 | I | - Quantizing decoder layer model.layers.0
24-11-25 19:55:50 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 19:55:51 | I |       - range scale = [    1.0000]
24-11-25 19:55:51 | I |         sum  error  = [    0.0583]
24-11-25 19:55:51 | I |         best error  = [    0.0583]
24-11-25 19:55:51 | I |     + error = [0.0583]
24-11-25 19:55:51 | I |       - range scale = [    1.0000]
24-11-25 19:55:51 | I |         sum  error  = [    0.5966]
24-11-25 19:55:51 | I |         best error  = [    0.5966]
24-11-25 19:55:51 | I |     + error = [0.5966]
24-11-25 19:55:52 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 19:55:52 | I |       - range scale = [    1.0000]
24-11-25 19:55:52 | I |         sum  error  = [    0.0678]
24-11-25 19:55:52 | I |         best error  = [    0.0678]
24-11-25 19:55:52 | I |     + error = [0.0678]
24-11-25 19:55:53 | I |       - range scale = [    1.0000]
24-11-25 19:55:53 | I |         sum  error  = [    0.5492]
24-11-25 19:55:53 | I |         best error  = [    0.5492]
24-11-25 19:55:53 | I |     + error = [0.5492]
24-11-25 19:55:53 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 19:55:54 | I |       - range scale = [    1.0000]
24-11-25 19:55:54 | I |         sum  error  = [    0.2374]
24-11-25 19:55:54 | I |         best error  = [    0.2374]
24-11-25 19:55:54 | I |     + error = [0.2374]
24-11-25 19:55:55 | I |       - range scale = [    1.0000]
24-11-25 19:55:55 | I |         sum  error  = [    1.8712]
24-11-25 19:55:55 | I |         best error  = [    1.8712]
24-11-25 19:55:55 | I |     + error = [1.8712]
24-11-25 19:55:55 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 19:55:55 | I |       - range scale = [    1.0000]
24-11-25 19:55:55 | I |         sum  error  = [    0.0595]
24-11-25 19:55:55 | I |         best error  = [    0.0595]
24-11-25 19:55:55 | I |     + error = [0.0595]
24-11-25 19:55:56 | I |       - range scale = [    1.0000]
24-11-25 19:55:56 | I |         sum  error  = [    0.5647]
24-11-25 19:55:56 | I |         best error  = [    0.5647]
24-11-25 19:55:56 | I |     + error = [0.5647]
24-11-25 19:55:56 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 19:55:57 | I |       - range scale = [    1.0000]
24-11-25 19:55:57 | I |         sum  error  = [    1.0422]
24-11-25 19:55:57 | I |         best error  = [    1.0422]
24-11-25 19:55:57 | I |     + error = [1.0422]
24-11-25 19:55:58 | I |       - range scale = [    1.0000]
24-11-25 19:55:58 | I |         sum  error  = [   11.5313]
24-11-25 19:55:58 | I |         best error  = [   11.5313]
24-11-25 19:55:58 | I |     + error = [11.5313]
24-11-25 19:55:58 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 19:55:59 | I |       - range scale = [    1.0000]
24-11-25 19:55:59 | I |         sum  error  = [    1.2041]
24-11-25 19:55:59 | I |         best error  = [    1.2041]
24-11-25 19:55:59 | I |     + error = [1.2041]
24-11-25 19:55:59 | I |       - range scale = [    1.0000]
24-11-25 19:55:59 | I |         sum  error  = [   11.8878]
24-11-25 19:55:59 | I |         best error  = [   11.8878]
24-11-25 19:55:59 | I |     + error = [11.8878]
24-11-25 19:56:00 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 19:56:00 | I |       - range scale = [    1.0000]
24-11-25 19:56:00 | I |         sum  error  = [    3.6457]
24-11-25 19:56:00 | I |         best error  = [    3.6457]
24-11-25 19:56:00 | I |     + error = [3.6457]
24-11-25 19:56:01 | I |       - range scale = [    1.0000]
24-11-25 19:56:01 | I |         sum  error  = [   19.7379]
24-11-25 19:56:01 | I |         best error  = [   19.7379]
24-11-25 19:56:01 | I |     + error = [19.7379]
24-11-25 19:56:01 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 19:56:03 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 19:56:04 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 19:56:05 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 19:56:07 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 19:56:08 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 19:56:10 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 19:56:13 | I | quantizing activations for layer model.layers.0
24-11-25 19:56:13 | I | collecting info in model.layers.0
24-11-25 19:56:13 | I | collecting info in model.layers.0
24-11-25 19:56:13 | I | collecting info in model.layers.0
24-11-25 19:56:13 | I | collecting info in model.layers.0
24-11-25 19:56:14 | I | collecting calibration activations in model.layers.0
24-11-25 19:56:14 | I | collecting calibration activations in model.layers.0
24-11-25 19:56:14 | I | collecting calibration activations in model.layers.0
24-11-25 19:56:14 | I | collecting calibration activations in model.layers.0
24-11-25 19:56:16 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 19:56:16 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 19:56:16 | I | - Evaluator: gptq
24-11-25 19:56:16 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 19:56:16 | I | - Batch_size: 8
24-11-25 19:56:16 | I |   + Max_seq_length: 2048
24-11-25 19:56:57 | I |     - Results:
24-11-25 19:56:57 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 19:56:57 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 19:56:57 | I |       |wikitext |      1|word_perplexity|7.8294|  |7.8294|
24-11-25 19:56:57 | I |       |val_valid|      1|word_perplexity|9.1220|  |9.1220|
24-11-25 19:56:57 | I |       
24-11-25 19:56:57 | I | forward this layer
24-11-25 19:56:57 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/164.pt
24-11-25 19:56:57 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/164.pt
24-11-25 19:56:57 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 19:56:57 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 19:56:57 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 19:56:57 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 19:56:57 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 19:56:57 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 19:56:57 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 19:56:57 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 19:56:57 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 19:56:57 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 19:56:57 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 19:56:57 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 19:56:57 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 19:56:57 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 19:56:57 | I | in layer model.layers.0
24-11-25 19:56:57 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 19:56:57 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 19:56:57 | I | - Evaluator: gptq
24-11-25 19:56:57 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 19:56:57 | I | - Batch_size: 8
24-11-25 19:56:57 | I |   + Max_seq_length: 2048
24-11-25 19:57:36 | I |     - Results:
24-11-25 19:57:36 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 19:57:36 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 19:57:36 | I |       |wikitext |      1|word_perplexity|7.7622|  |7.7622|
24-11-25 19:57:36 | I |       |val_valid|      1|word_perplexity|9.0875|  |9.0875|
24-11-25 19:57:36 | I |       
24-11-25 19:57:36 | I | quantizing weights for layer model.layers.0
24-11-25 19:57:36 | I | collecting info in model.layers.0
24-11-25 19:57:36 | I | collecting info in model.layers.0
24-11-25 19:57:36 | I | collecting info in model.layers.0
24-11-25 19:57:36 | I | collecting info in model.layers.0
24-11-25 19:57:36 | I | collecting calibration activations in model.layers.0
24-11-25 19:57:36 | I | collecting calibration activations in model.layers.0
24-11-25 19:57:36 | I | collecting calibration activations in model.layers.0
24-11-25 19:57:36 | I | collecting calibration activations in model.layers.0
24-11-25 19:57:37 | I | - Quantizing decoder layer model.layers.0
24-11-25 19:57:37 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 19:57:37 | I |       - range scale = [    1.0000]
24-11-25 19:57:37 | I |         sum  error  = [    0.0582]
24-11-25 19:57:37 | I |         best error  = [    0.0582]
24-11-25 19:57:37 | I |     + error = [0.0582]
24-11-25 19:57:38 | I |       - range scale = [    1.0000]
24-11-25 19:57:38 | I |         sum  error  = [    0.6062]
24-11-25 19:57:38 | I |         best error  = [    0.6062]
24-11-25 19:57:38 | I |     + error = [0.6062]
24-11-25 19:57:38 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 19:57:39 | I |       - range scale = [    1.0000]
24-11-25 19:57:39 | I |         sum  error  = [    0.0677]
24-11-25 19:57:39 | I |         best error  = [    0.0677]
24-11-25 19:57:39 | I |     + error = [0.0677]
24-11-25 19:57:40 | I |       - range scale = [    1.0000]
24-11-25 19:57:40 | I |         sum  error  = [    0.5393]
24-11-25 19:57:40 | I |         best error  = [    0.5393]
24-11-25 19:57:40 | I |     + error = [0.5393]
24-11-25 19:57:40 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 19:57:41 | I |       - range scale = [    1.0000]
24-11-25 19:57:41 | I |         sum  error  = [    0.2370]
24-11-25 19:57:41 | I |         best error  = [    0.2370]
24-11-25 19:57:41 | I |     + error = [0.2370]
24-11-25 19:57:41 | I |       - range scale = [    1.0000]
24-11-25 19:57:41 | I |         sum  error  = [    1.8719]
24-11-25 19:57:41 | I |         best error  = [    1.8719]
24-11-25 19:57:41 | I |     + error = [1.8719]
24-11-25 19:57:41 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 19:57:42 | I |       - range scale = [    1.0000]
24-11-25 19:57:42 | I |         sum  error  = [    0.0602]
24-11-25 19:57:42 | I |         best error  = [    0.0602]
24-11-25 19:57:42 | I |     + error = [0.0602]
24-11-25 19:57:43 | I |       - range scale = [    1.0000]
24-11-25 19:57:43 | I |         sum  error  = [    0.5699]
24-11-25 19:57:43 | I |         best error  = [    0.5699]
24-11-25 19:57:43 | I |     + error = [0.5699]
24-11-25 19:57:43 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 19:57:44 | I |       - range scale = [    1.0000]
24-11-25 19:57:44 | I |         sum  error  = [    1.0337]
24-11-25 19:57:44 | I |         best error  = [    1.0337]
24-11-25 19:57:44 | I |     + error = [1.0337]
24-11-25 19:57:44 | I |       - range scale = [    1.0000]
24-11-25 19:57:44 | I |         sum  error  = [   11.4261]
24-11-25 19:57:44 | I |         best error  = [   11.4261]
24-11-25 19:57:44 | I |     + error = [11.4261]
24-11-25 19:57:45 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 19:57:45 | I |       - range scale = [    1.0000]
24-11-25 19:57:45 | I |         sum  error  = [    1.1947]
24-11-25 19:57:45 | I |         best error  = [    1.1947]
24-11-25 19:57:45 | I |     + error = [1.1947]
24-11-25 19:57:46 | I |       - range scale = [    1.0000]
24-11-25 19:57:46 | I |         sum  error  = [   11.7697]
24-11-25 19:57:46 | I |         best error  = [   11.7697]
24-11-25 19:57:46 | I |     + error = [11.7697]
24-11-25 19:57:46 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 19:57:47 | I |       - range scale = [    1.0000]
24-11-25 19:57:47 | I |         sum  error  = [    3.3456]
24-11-25 19:57:47 | I |         best error  = [    3.3456]
24-11-25 19:57:47 | I |     + error = [3.3456]
24-11-25 19:57:48 | I |       - range scale = [    1.0000]
24-11-25 19:57:48 | I |         sum  error  = [   18.5397]
24-11-25 19:57:48 | I |         best error  = [   18.5397]
24-11-25 19:57:48 | I |     + error = [18.5397]
24-11-25 19:57:48 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 19:57:49 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 19:57:51 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 19:57:52 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 19:57:53 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 19:57:55 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 19:57:56 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 19:58:00 | I | quantizing activations for layer model.layers.0
24-11-25 19:58:00 | I | collecting info in model.layers.0
24-11-25 19:58:00 | I | collecting info in model.layers.0
24-11-25 19:58:00 | I | collecting info in model.layers.0
24-11-25 19:58:00 | I | collecting info in model.layers.0
24-11-25 19:58:00 | I | collecting calibration activations in model.layers.0
24-11-25 19:58:00 | I | collecting calibration activations in model.layers.0
24-11-25 19:58:00 | I | collecting calibration activations in model.layers.0
24-11-25 19:58:00 | I | collecting calibration activations in model.layers.0
24-11-25 19:58:02 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 19:58:02 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 19:58:02 | I | - Evaluator: gptq
24-11-25 19:58:02 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 19:58:02 | I | - Batch_size: 8
24-11-25 19:58:02 | I |   + Max_seq_length: 2048
24-11-25 19:58:44 | I |     - Results:
24-11-25 19:58:44 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 19:58:44 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 19:58:44 | I |       |wikitext |      1|word_perplexity|7.8297|  |7.8297|
24-11-25 19:58:44 | I |       |val_valid|      1|word_perplexity|9.1207|  |9.1207|
24-11-25 19:58:44 | I |       
24-11-25 19:58:44 | I | forward this layer
24-11-25 19:58:44 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/165.pt
24-11-25 19:58:44 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/165.pt
24-11-25 19:58:44 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 19:58:44 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 19:58:44 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 19:58:44 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 19:58:44 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 19:58:44 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 19:58:44 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 19:58:44 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 19:58:44 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 19:58:44 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 19:58:44 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 19:58:44 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 19:58:44 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 19:58:44 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 19:58:44 | I | [68] done with optimizer step
24-11-25 19:58:44 | I | epoch 001:     83 / 409600000 loss=3.04216e-05, loss_per_token=0.0623034, loss_sum=2041.56, wps=153.4, ups=0, wpb=32768, bsz=64, num_updates=69, lr=0.00014999, gnorm=5.994, clip=100, loss_scale=0.0078, train_wall=213, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=18054, lmquant_ppl_result_wikitext_in_train_no_quant=7.76222, lmquant_ppl_result_val_in_train_no_quant=9.08751, lmquant_ppl_result_wikitext_in_train_with_quant=7.82966, lmquant_ppl_result_val_in_train_with_quant=9.12073
24-11-25 19:58:44 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 19:58:44 | I | in layer model.layers.0
24-11-25 19:58:44 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 19:58:44 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 19:58:44 | I | - Evaluator: gptq
24-11-25 19:58:44 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 19:58:44 | I | - Batch_size: 8
24-11-25 19:58:44 | I |   + Max_seq_length: 2048
24-11-25 19:59:22 | I |     - Results:
24-11-25 19:59:22 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 19:59:22 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 19:59:22 | I |       |wikitext |      1|word_perplexity|7.7590|  |7.7590|
24-11-25 19:59:22 | I |       |val_valid|      1|word_perplexity|9.0797|  |9.0797|
24-11-25 19:59:22 | I |       
24-11-25 19:59:22 | I | quantizing weights for layer model.layers.0
24-11-25 19:59:22 | I | collecting info in model.layers.0
24-11-25 19:59:22 | I | collecting info in model.layers.0
24-11-25 19:59:22 | I | collecting info in model.layers.0
24-11-25 19:59:22 | I | collecting info in model.layers.0
24-11-25 19:59:23 | I | collecting calibration activations in model.layers.0
24-11-25 19:59:23 | I | collecting calibration activations in model.layers.0
24-11-25 19:59:23 | I | collecting calibration activations in model.layers.0
24-11-25 19:59:23 | I | collecting calibration activations in model.layers.0
24-11-25 19:59:24 | I | - Quantizing decoder layer model.layers.0
24-11-25 19:59:24 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 19:59:24 | I |       - range scale = [    1.0000]
24-11-25 19:59:24 | I |         sum  error  = [    0.0580]
24-11-25 19:59:24 | I |         best error  = [    0.0580]
24-11-25 19:59:24 | I |     + error = [0.0580]
24-11-25 19:59:25 | I |       - range scale = [    1.0000]
24-11-25 19:59:25 | I |         sum  error  = [    0.6057]
24-11-25 19:59:25 | I |         best error  = [    0.6057]
24-11-25 19:59:25 | I |     + error = [0.6057]
24-11-25 19:59:25 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 19:59:26 | I |       - range scale = [    1.0000]
24-11-25 19:59:26 | I |         sum  error  = [    0.0685]
24-11-25 19:59:26 | I |         best error  = [    0.0685]
24-11-25 19:59:26 | I |     + error = [0.0685]
24-11-25 19:59:27 | I |       - range scale = [    1.0000]
24-11-25 19:59:27 | I |         sum  error  = [    0.5440]
24-11-25 19:59:27 | I |         best error  = [    0.5440]
24-11-25 19:59:27 | I |     + error = [0.5440]
24-11-25 19:59:27 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 19:59:27 | I |       - range scale = [    1.0000]
24-11-25 19:59:27 | I |         sum  error  = [    0.2402]
24-11-25 19:59:27 | I |         best error  = [    0.2402]
24-11-25 19:59:27 | I |     + error = [0.2402]
24-11-25 19:59:28 | I |       - range scale = [    1.0000]
24-11-25 19:59:28 | I |         sum  error  = [    1.8919]
24-11-25 19:59:28 | I |         best error  = [    1.8919]
24-11-25 19:59:28 | I |     + error = [1.8919]
24-11-25 19:59:28 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 19:59:29 | I |       - range scale = [    1.0000]
24-11-25 19:59:29 | I |         sum  error  = [    0.0624]
24-11-25 19:59:29 | I |         best error  = [    0.0624]
24-11-25 19:59:29 | I |     + error = [0.0624]
24-11-25 19:59:30 | I |       - range scale = [    1.0000]
24-11-25 19:59:30 | I |         sum  error  = [    0.5822]
24-11-25 19:59:30 | I |         best error  = [    0.5822]
24-11-25 19:59:30 | I |     + error = [0.5822]
24-11-25 19:59:30 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 19:59:31 | I |       - range scale = [    1.0000]
24-11-25 19:59:31 | I |         sum  error  = [    1.0523]
24-11-25 19:59:31 | I |         best error  = [    1.0523]
24-11-25 19:59:31 | I |     + error = [1.0523]
24-11-25 19:59:31 | I |       - range scale = [    1.0000]
24-11-25 19:59:31 | I |         sum  error  = [   11.6247]
24-11-25 19:59:31 | I |         best error  = [   11.6247]
24-11-25 19:59:31 | I |     + error = [11.6247]
24-11-25 19:59:32 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 19:59:32 | I |       - range scale = [    1.0000]
24-11-25 19:59:32 | I |         sum  error  = [    1.2137]
24-11-25 19:59:32 | I |         best error  = [    1.2137]
24-11-25 19:59:32 | I |     + error = [1.2137]
24-11-25 19:59:33 | I |       - range scale = [    1.0000]
24-11-25 19:59:33 | I |         sum  error  = [   11.9832]
24-11-25 19:59:33 | I |         best error  = [   11.9832]
24-11-25 19:59:33 | I |     + error = [11.9832]
24-11-25 19:59:33 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 19:59:34 | I |       - range scale = [    1.0000]
24-11-25 19:59:34 | I |         sum  error  = [    3.3794]
24-11-25 19:59:34 | I |         best error  = [    3.3794]
24-11-25 19:59:34 | I |     + error = [3.3794]
24-11-25 19:59:35 | I |       - range scale = [    1.0000]
24-11-25 19:59:35 | I |         sum  error  = [   18.2163]
24-11-25 19:59:35 | I |         best error  = [   18.2163]
24-11-25 19:59:35 | I |     + error = [18.2163]
24-11-25 19:59:35 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 19:59:36 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 19:59:38 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 19:59:39 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 19:59:40 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 19:59:42 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 19:59:44 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 19:59:48 | I | quantizing activations for layer model.layers.0
24-11-25 19:59:48 | I | collecting info in model.layers.0
24-11-25 19:59:48 | I | collecting info in model.layers.0
24-11-25 19:59:48 | I | collecting info in model.layers.0
24-11-25 19:59:48 | I | collecting info in model.layers.0
24-11-25 19:59:48 | I | collecting calibration activations in model.layers.0
24-11-25 19:59:48 | I | collecting calibration activations in model.layers.0
24-11-25 19:59:48 | I | collecting calibration activations in model.layers.0
24-11-25 19:59:49 | I | collecting calibration activations in model.layers.0
24-11-25 19:59:50 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 19:59:50 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 19:59:50 | I | - Evaluator: gptq
24-11-25 19:59:50 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 19:59:50 | I | - Batch_size: 8
24-11-25 19:59:50 | I |   + Max_seq_length: 2048
24-11-25 20:00:33 | I |     - Results:
24-11-25 20:00:33 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 20:00:33 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 20:00:33 | I |       |wikitext |      1|word_perplexity|7.8064|  |7.8064|
24-11-25 20:00:33 | I |       |val_valid|      1|word_perplexity|9.1046|  |9.1046|
24-11-25 20:00:33 | I |       
24-11-25 20:00:33 | I | forward this layer
24-11-25 20:00:33 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/166.pt
24-11-25 20:00:33 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/166.pt
24-11-25 20:00:33 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 20:00:33 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 20:00:33 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 20:00:33 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 20:00:33 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 20:00:33 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 20:00:33 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 20:00:33 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 20:00:33 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 20:00:33 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 20:00:33 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 20:00:33 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 20:00:33 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 20:00:33 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 20:00:33 | I | in layer model.layers.0
24-11-25 20:00:33 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 20:00:33 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 20:00:33 | I | - Evaluator: gptq
24-11-25 20:00:33 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 20:00:33 | I | - Batch_size: 8
24-11-25 20:00:33 | I |   + Max_seq_length: 2048
24-11-25 20:01:11 | I |     - Results:
24-11-25 20:01:11 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 20:01:11 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 20:01:11 | I |       |wikitext |      1|word_perplexity|7.7590|  |7.7590|
24-11-25 20:01:11 | I |       |val_valid|      1|word_perplexity|9.0797|  |9.0797|
24-11-25 20:01:11 | I |       
24-11-25 20:01:11 | I | quantizing weights for layer model.layers.0
24-11-25 20:01:11 | I | collecting info in model.layers.0
24-11-25 20:01:11 | I | collecting info in model.layers.0
24-11-25 20:01:11 | I | collecting info in model.layers.0
24-11-25 20:01:11 | I | collecting info in model.layers.0
24-11-25 20:01:12 | I | collecting calibration activations in model.layers.0
24-11-25 20:01:12 | I | collecting calibration activations in model.layers.0
24-11-25 20:01:12 | I | collecting calibration activations in model.layers.0
24-11-25 20:01:12 | I | collecting calibration activations in model.layers.0
24-11-25 20:01:12 | I | - Quantizing decoder layer model.layers.0
24-11-25 20:01:12 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 20:01:13 | I |       - range scale = [    1.0000]
24-11-25 20:01:13 | I |         sum  error  = [    0.0583]
24-11-25 20:01:13 | I |         best error  = [    0.0583]
24-11-25 20:01:13 | I |     + error = [0.0583]
24-11-25 20:01:14 | I |       - range scale = [    1.0000]
24-11-25 20:01:14 | I |         sum  error  = [    0.6030]
24-11-25 20:01:14 | I |         best error  = [    0.6030]
24-11-25 20:01:14 | I |     + error = [0.6030]
24-11-25 20:01:14 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 20:01:15 | I |       - range scale = [    1.0000]
24-11-25 20:01:15 | I |         sum  error  = [    0.0688]
24-11-25 20:01:15 | I |         best error  = [    0.0688]
24-11-25 20:01:15 | I |     + error = [0.0688]
24-11-25 20:01:15 | I |       - range scale = [    1.0000]
24-11-25 20:01:15 | I |         sum  error  = [    0.5451]
24-11-25 20:01:15 | I |         best error  = [    0.5451]
24-11-25 20:01:15 | I |     + error = [0.5451]
24-11-25 20:01:15 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 20:01:16 | I |       - range scale = [    1.0000]
24-11-25 20:01:16 | I |         sum  error  = [    0.2397]
24-11-25 20:01:16 | I |         best error  = [    0.2397]
24-11-25 20:01:16 | I |     + error = [0.2397]
24-11-25 20:01:17 | I |       - range scale = [    1.0000]
24-11-25 20:01:17 | I |         sum  error  = [    1.8752]
24-11-25 20:01:17 | I |         best error  = [    1.8752]
24-11-25 20:01:17 | I |     + error = [1.8752]
24-11-25 20:01:17 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 20:01:18 | I |       - range scale = [    1.0000]
24-11-25 20:01:18 | I |         sum  error  = [    0.0593]
24-11-25 20:01:18 | I |         best error  = [    0.0593]
24-11-25 20:01:18 | I |     + error = [0.0593]
24-11-25 20:01:18 | I |       - range scale = [    1.0000]
24-11-25 20:01:18 | I |         sum  error  = [    0.5539]
24-11-25 20:01:18 | I |         best error  = [    0.5539]
24-11-25 20:01:18 | I |     + error = [0.5539]
24-11-25 20:01:19 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 20:01:19 | I |       - range scale = [    1.0000]
24-11-25 20:01:19 | I |         sum  error  = [    1.0362]
24-11-25 20:01:19 | I |         best error  = [    1.0362]
24-11-25 20:01:19 | I |     + error = [1.0362]
24-11-25 20:01:20 | I |       - range scale = [    1.0000]
24-11-25 20:01:20 | I |         sum  error  = [   11.4628]
24-11-25 20:01:20 | I |         best error  = [   11.4628]
24-11-25 20:01:20 | I |     + error = [11.4628]
24-11-25 20:01:20 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 20:01:21 | I |       - range scale = [    1.0000]
24-11-25 20:01:21 | I |         sum  error  = [    1.1967]
24-11-25 20:01:21 | I |         best error  = [    1.1967]
24-11-25 20:01:21 | I |     + error = [1.1967]
24-11-25 20:01:22 | I |       - range scale = [    1.0000]
24-11-25 20:01:22 | I |         sum  error  = [   11.8025]
24-11-25 20:01:22 | I |         best error  = [   11.8025]
24-11-25 20:01:22 | I |     + error = [11.8025]
24-11-25 20:01:22 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 20:01:23 | I |       - range scale = [    1.0000]
24-11-25 20:01:23 | I |         sum  error  = [    3.3855]
24-11-25 20:01:23 | I |         best error  = [    3.3855]
24-11-25 20:01:23 | I |     + error = [3.3855]
24-11-25 20:01:23 | I |       - range scale = [    1.0000]
24-11-25 20:01:23 | I |         sum  error  = [   18.2988]
24-11-25 20:01:23 | I |         best error  = [   18.2988]
24-11-25 20:01:23 | I |     + error = [18.2988]
24-11-25 20:01:24 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 20:01:25 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 20:01:26 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 20:01:28 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 20:01:29 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 20:01:31 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 20:01:32 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 20:01:36 | I | quantizing activations for layer model.layers.0
24-11-25 20:01:36 | I | collecting info in model.layers.0
24-11-25 20:01:36 | I | collecting info in model.layers.0
24-11-25 20:01:36 | I | collecting info in model.layers.0
24-11-25 20:01:36 | I | collecting info in model.layers.0
24-11-25 20:01:37 | I | collecting calibration activations in model.layers.0
24-11-25 20:01:37 | I | collecting calibration activations in model.layers.0
24-11-25 20:01:37 | I | collecting calibration activations in model.layers.0
24-11-25 20:01:37 | I | collecting calibration activations in model.layers.0
24-11-25 20:01:39 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 20:01:39 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 20:01:39 | I | - Evaluator: gptq
24-11-25 20:01:39 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 20:01:39 | I | - Batch_size: 8
24-11-25 20:01:39 | I |   + Max_seq_length: 2048
24-11-25 20:02:21 | I |     - Results:
24-11-25 20:02:21 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 20:02:21 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 20:02:21 | I |       |wikitext |      1|word_perplexity|7.8196|  |7.8196|
24-11-25 20:02:21 | I |       |val_valid|      1|word_perplexity|9.1108|  |9.1108|
24-11-25 20:02:21 | I |       
24-11-25 20:02:21 | I | forward this layer
24-11-25 20:02:21 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/167.pt
24-11-25 20:02:21 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/167.pt
24-11-25 20:02:21 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 20:02:21 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 20:02:21 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 20:02:21 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 20:02:21 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 20:02:21 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 20:02:21 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 20:02:21 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 20:02:21 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 20:02:21 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 20:02:21 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 20:02:21 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 20:02:21 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 20:02:21 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 20:02:21 | I | [69] done with optimizer step
24-11-25 20:02:22 | I | epoch 001:     84 / 409600000 loss=5.02569e-05, loss_per_token=0.102926, loss_sum=3372.68, wps=150.6, ups=0, wpb=32768, bsz=64, num_updates=70, lr=0.00014999, gnorm=21.53, clip=100, loss_scale=0.0078, train_wall=217, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=18272, lmquant_ppl_result_wikitext_in_train_no_quant=7.75903, lmquant_ppl_result_val_in_train_no_quant=9.07971, lmquant_ppl_result_wikitext_in_train_with_quant=7.81959, lmquant_ppl_result_val_in_train_with_quant=9.11077
24-11-25 20:02:22 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 20:02:22 | I | in layer model.layers.0
24-11-25 20:02:22 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 20:02:22 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 20:02:22 | I | - Evaluator: gptq
24-11-25 20:02:22 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 20:02:22 | I | - Batch_size: 8
24-11-25 20:02:22 | I |   + Max_seq_length: 2048
24-11-25 20:03:00 | I |     - Results:
24-11-25 20:03:00 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 20:03:00 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 20:03:00 | I |       |wikitext |      1|word_perplexity|7.7586|  |7.7586|
24-11-25 20:03:00 | I |       |val_valid|      1|word_perplexity|9.0762|  |9.0762|
24-11-25 20:03:00 | I |       
24-11-25 20:03:00 | I | quantizing weights for layer model.layers.0
24-11-25 20:03:00 | I | collecting info in model.layers.0
24-11-25 20:03:00 | I | collecting info in model.layers.0
24-11-25 20:03:00 | I | collecting info in model.layers.0
24-11-25 20:03:00 | I | collecting info in model.layers.0
24-11-25 20:03:00 | I | collecting calibration activations in model.layers.0
24-11-25 20:03:01 | I | collecting calibration activations in model.layers.0
24-11-25 20:03:01 | I | collecting calibration activations in model.layers.0
24-11-25 20:03:01 | I | collecting calibration activations in model.layers.0
24-11-25 20:03:01 | I | - Quantizing decoder layer model.layers.0
24-11-25 20:03:01 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 20:03:02 | I |       - range scale = [    1.0000]
24-11-25 20:03:02 | I |         sum  error  = [    0.0592]
24-11-25 20:03:02 | I |         best error  = [    0.0592]
24-11-25 20:03:02 | I |     + error = [0.0592]
24-11-25 20:03:02 | I |       - range scale = [    1.0000]
24-11-25 20:03:02 | I |         sum  error  = [    0.6174]
24-11-25 20:03:02 | I |         best error  = [    0.6174]
24-11-25 20:03:02 | I |     + error = [0.6174]
24-11-25 20:03:03 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 20:03:03 | I |       - range scale = [    1.0000]
24-11-25 20:03:03 | I |         sum  error  = [    0.0699]
24-11-25 20:03:03 | I |         best error  = [    0.0699]
24-11-25 20:03:03 | I |     + error = [0.0699]
24-11-25 20:03:04 | I |       - range scale = [    1.0000]
24-11-25 20:03:04 | I |         sum  error  = [    0.5463]
24-11-25 20:03:04 | I |         best error  = [    0.5463]
24-11-25 20:03:04 | I |     + error = [0.5463]
24-11-25 20:03:04 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 20:03:05 | I |       - range scale = [    1.0000]
24-11-25 20:03:05 | I |         sum  error  = [    0.2336]
24-11-25 20:03:05 | I |         best error  = [    0.2336]
24-11-25 20:03:05 | I |     + error = [0.2336]
24-11-25 20:03:06 | I |       - range scale = [    1.0000]
24-11-25 20:03:06 | I |         sum  error  = [    1.8723]
24-11-25 20:03:06 | I |         best error  = [    1.8723]
24-11-25 20:03:06 | I |     + error = [1.8723]
24-11-25 20:03:06 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 20:03:06 | I |       - range scale = [    1.0000]
24-11-25 20:03:06 | I |         sum  error  = [    0.0606]
24-11-25 20:03:06 | I |         best error  = [    0.0606]
24-11-25 20:03:06 | I |     + error = [0.0606]
24-11-25 20:03:07 | I |       - range scale = [    1.0000]
24-11-25 20:03:07 | I |         sum  error  = [    0.5721]
24-11-25 20:03:07 | I |         best error  = [    0.5721]
24-11-25 20:03:07 | I |     + error = [0.5721]
24-11-25 20:03:07 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 20:03:08 | I |       - range scale = [    1.0000]
24-11-25 20:03:08 | I |         sum  error  = [    1.0458]
24-11-25 20:03:08 | I |         best error  = [    1.0458]
24-11-25 20:03:08 | I |     + error = [1.0458]
24-11-25 20:03:09 | I |       - range scale = [    1.0000]
24-11-25 20:03:09 | I |         sum  error  = [   11.5663]
24-11-25 20:03:09 | I |         best error  = [   11.5663]
24-11-25 20:03:09 | I |     + error = [11.5663]
24-11-25 20:03:09 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 20:03:10 | I |       - range scale = [    1.0000]
24-11-25 20:03:10 | I |         sum  error  = [    1.2073]
24-11-25 20:03:10 | I |         best error  = [    1.2073]
24-11-25 20:03:10 | I |     + error = [1.2073]
24-11-25 20:03:10 | I |       - range scale = [    1.0000]
24-11-25 20:03:10 | I |         sum  error  = [   11.9235]
24-11-25 20:03:10 | I |         best error  = [   11.9235]
24-11-25 20:03:10 | I |     + error = [11.9235]
24-11-25 20:03:11 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 20:03:11 | I |       - range scale = [    1.0000]
24-11-25 20:03:11 | I |         sum  error  = [    3.8069]
24-11-25 20:03:11 | I |         best error  = [    3.8069]
24-11-25 20:03:11 | I |     + error = [3.8069]
24-11-25 20:03:12 | I |       - range scale = [    1.0000]
24-11-25 20:03:12 | I |         sum  error  = [   20.2614]
24-11-25 20:03:12 | I |         best error  = [   20.2614]
24-11-25 20:03:12 | I |     + error = [20.2614]
24-11-25 20:03:12 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 20:03:14 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 20:03:15 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 20:03:16 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 20:03:18 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 20:03:19 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 20:03:20 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 20:03:24 | I | quantizing activations for layer model.layers.0
24-11-25 20:03:24 | I | collecting info in model.layers.0
24-11-25 20:03:24 | I | collecting info in model.layers.0
24-11-25 20:03:24 | I | collecting info in model.layers.0
24-11-25 20:03:24 | I | collecting info in model.layers.0
24-11-25 20:03:24 | I | collecting calibration activations in model.layers.0
24-11-25 20:03:24 | I | collecting calibration activations in model.layers.0
24-11-25 20:03:24 | I | collecting calibration activations in model.layers.0
24-11-25 20:03:25 | I | collecting calibration activations in model.layers.0
24-11-25 20:03:26 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 20:03:26 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 20:03:26 | I | - Evaluator: gptq
24-11-25 20:03:26 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 20:03:26 | I | - Batch_size: 8
24-11-25 20:03:26 | I |   + Max_seq_length: 2048
24-11-25 20:04:08 | I |     - Results:
24-11-25 20:04:08 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 20:04:08 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 20:04:08 | I |       |wikitext |      1|word_perplexity|7.8288|  |7.8288|
24-11-25 20:04:08 | I |       |val_valid|      1|word_perplexity|9.1268|  |9.1268|
24-11-25 20:04:08 | I |       
24-11-25 20:04:08 | I | forward this layer
24-11-25 20:04:08 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/168.pt
24-11-25 20:04:08 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/168.pt
24-11-25 20:04:08 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 20:04:08 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 20:04:08 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 20:04:08 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 20:04:08 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 20:04:08 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 20:04:08 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 20:04:08 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 20:04:08 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 20:04:08 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 20:04:08 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 20:04:08 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 20:04:08 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 20:04:08 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 20:04:08 | I | in layer model.layers.0
24-11-25 20:04:08 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 20:04:08 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 20:04:08 | I | - Evaluator: gptq
24-11-25 20:04:08 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 20:04:08 | I | - Batch_size: 8
24-11-25 20:04:08 | I |   + Max_seq_length: 2048
24-11-25 20:04:46 | I |     - Results:
24-11-25 20:04:46 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 20:04:46 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 20:04:46 | I |       |wikitext |      1|word_perplexity|7.7586|  |7.7586|
24-11-25 20:04:46 | I |       |val_valid|      1|word_perplexity|9.0762|  |9.0762|
24-11-25 20:04:46 | I |       
24-11-25 20:04:46 | I | quantizing weights for layer model.layers.0
24-11-25 20:04:46 | I | collecting info in model.layers.0
24-11-25 20:04:46 | I | collecting info in model.layers.0
24-11-25 20:04:46 | I | collecting info in model.layers.0
24-11-25 20:04:46 | I | collecting info in model.layers.0
24-11-25 20:04:47 | I | collecting calibration activations in model.layers.0
24-11-25 20:04:47 | I | collecting calibration activations in model.layers.0
24-11-25 20:04:47 | I | collecting calibration activations in model.layers.0
24-11-25 20:04:47 | I | collecting calibration activations in model.layers.0
24-11-25 20:04:48 | I | - Quantizing decoder layer model.layers.0
24-11-25 20:04:48 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 20:04:48 | I |       - range scale = [    1.0000]
24-11-25 20:04:48 | I |         sum  error  = [    0.0582]
24-11-25 20:04:48 | I |         best error  = [    0.0582]
24-11-25 20:04:48 | I |     + error = [0.0582]
24-11-25 20:04:49 | I |       - range scale = [    1.0000]
24-11-25 20:04:49 | I |         sum  error  = [    0.5974]
24-11-25 20:04:49 | I |         best error  = [    0.5974]
24-11-25 20:04:49 | I |     + error = [0.5974]
24-11-25 20:04:49 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 20:04:50 | I |       - range scale = [    1.0000]
24-11-25 20:04:50 | I |         sum  error  = [    0.0691]
24-11-25 20:04:50 | I |         best error  = [    0.0691]
24-11-25 20:04:50 | I |     + error = [0.0691]
24-11-25 20:04:51 | I |       - range scale = [    1.0000]
24-11-25 20:04:51 | I |         sum  error  = [    0.5405]
24-11-25 20:04:51 | I |         best error  = [    0.5405]
24-11-25 20:04:51 | I |     + error = [0.5405]
24-11-25 20:04:51 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 20:04:52 | I |       - range scale = [    1.0000]
24-11-25 20:04:52 | I |         sum  error  = [    0.2340]
24-11-25 20:04:52 | I |         best error  = [    0.2340]
24-11-25 20:04:52 | I |     + error = [0.2340]
24-11-25 20:04:52 | I |       - range scale = [    1.0000]
24-11-25 20:04:52 | I |         sum  error  = [    1.8700]
24-11-25 20:04:52 | I |         best error  = [    1.8700]
24-11-25 20:04:52 | I |     + error = [1.8700]
24-11-25 20:04:52 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 20:04:53 | I |       - range scale = [    1.0000]
24-11-25 20:04:53 | I |         sum  error  = [    0.0593]
24-11-25 20:04:53 | I |         best error  = [    0.0593]
24-11-25 20:04:53 | I |     + error = [0.0593]
24-11-25 20:04:54 | I |       - range scale = [    1.0000]
24-11-25 20:04:54 | I |         sum  error  = [    0.5658]
24-11-25 20:04:54 | I |         best error  = [    0.5658]
24-11-25 20:04:54 | I |     + error = [0.5658]
24-11-25 20:04:54 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 20:04:55 | I |       - range scale = [    1.0000]
24-11-25 20:04:55 | I |         sum  error  = [    1.0446]
24-11-25 20:04:55 | I |         best error  = [    1.0446]
24-11-25 20:04:55 | I |     + error = [1.0446]
24-11-25 20:04:55 | I |       - range scale = [    1.0000]
24-11-25 20:04:55 | I |         sum  error  = [   11.5576]
24-11-25 20:04:55 | I |         best error  = [   11.5576]
24-11-25 20:04:55 | I |     + error = [11.5576]
24-11-25 20:04:56 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 20:04:56 | I |       - range scale = [    1.0000]
24-11-25 20:04:56 | I |         sum  error  = [    1.2066]
24-11-25 20:04:56 | I |         best error  = [    1.2066]
24-11-25 20:04:56 | I |     + error = [1.2066]
24-11-25 20:04:57 | I |       - range scale = [    1.0000]
24-11-25 20:04:57 | I |         sum  error  = [   11.9067]
24-11-25 20:04:57 | I |         best error  = [   11.9067]
24-11-25 20:04:57 | I |     + error = [11.9067]
24-11-25 20:04:57 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 20:04:58 | I |       - range scale = [    1.0000]
24-11-25 20:04:58 | I |         sum  error  = [    3.7251]
24-11-25 20:04:58 | I |         best error  = [    3.7251]
24-11-25 20:04:58 | I |     + error = [3.7251]
24-11-25 20:04:59 | I |       - range scale = [    1.0000]
24-11-25 20:04:59 | I |         sum  error  = [   19.6670]
24-11-25 20:04:59 | I |         best error  = [   19.6670]
24-11-25 20:04:59 | I |     + error = [19.6670]
24-11-25 20:04:59 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 20:05:00 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 20:05:02 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 20:05:03 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 20:05:05 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 20:05:06 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 20:05:07 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 20:05:11 | I | quantizing activations for layer model.layers.0
24-11-25 20:05:11 | I | collecting info in model.layers.0
24-11-25 20:05:11 | I | collecting info in model.layers.0
24-11-25 20:05:11 | I | collecting info in model.layers.0
24-11-25 20:05:11 | I | collecting info in model.layers.0
24-11-25 20:05:11 | I | collecting calibration activations in model.layers.0
24-11-25 20:05:11 | I | collecting calibration activations in model.layers.0
24-11-25 20:05:11 | I | collecting calibration activations in model.layers.0
24-11-25 20:05:12 | I | collecting calibration activations in model.layers.0
24-11-25 20:05:13 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 20:05:13 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 20:05:13 | I | - Evaluator: gptq
24-11-25 20:05:13 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 20:05:13 | I | - Batch_size: 8
24-11-25 20:05:13 | I |   + Max_seq_length: 2048
24-11-25 20:05:55 | I |     - Results:
24-11-25 20:05:55 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 20:05:55 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 20:05:55 | I |       |wikitext |      1|word_perplexity|7.8082|  |7.8082|
24-11-25 20:05:55 | I |       |val_valid|      1|word_perplexity|9.1119|  |9.1119|
24-11-25 20:05:55 | I |       
24-11-25 20:05:55 | I | forward this layer
24-11-25 20:05:55 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/169.pt
24-11-25 20:05:55 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/169.pt
24-11-25 20:05:55 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 20:05:55 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 20:05:55 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 20:05:55 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 20:05:55 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 20:05:55 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 20:05:55 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 20:05:55 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 20:05:55 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 20:05:55 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 20:05:55 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 20:05:55 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 20:05:55 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 20:05:55 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 20:05:55 | I | [70] done with optimizer step
24-11-25 20:05:55 | I | epoch 001:     85 / 409600000 loss=7.08313e-05, loss_per_token=0.145063, loss_sum=4753.41, wps=153.3, ups=0, wpb=32768, bsz=64, num_updates=71, lr=0.000149989, gnorm=29.423, clip=100, loss_scale=0.0078, train_wall=213, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=18486, lmquant_ppl_result_wikitext_in_train_no_quant=7.75863, lmquant_ppl_result_val_in_train_no_quant=9.07617, lmquant_ppl_result_wikitext_in_train_with_quant=7.80816, lmquant_ppl_result_val_in_train_with_quant=9.11195
24-11-25 20:05:55 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 20:05:55 | I | in layer model.layers.0
24-11-25 20:05:55 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 20:05:55 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 20:05:55 | I | - Evaluator: gptq
24-11-25 20:05:55 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 20:05:55 | I | - Batch_size: 8
24-11-25 20:05:55 | I |   + Max_seq_length: 2048
24-11-25 20:06:34 | I |     - Results:
24-11-25 20:06:34 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 20:06:34 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 20:06:34 | I |       |wikitext |      1|word_perplexity|7.7572|  |7.7572|
24-11-25 20:06:34 | I |       |val_valid|      1|word_perplexity|9.0775|  |9.0775|
24-11-25 20:06:34 | I |       
24-11-25 20:06:34 | I | quantizing weights for layer model.layers.0
24-11-25 20:06:34 | I | collecting info in model.layers.0
24-11-25 20:06:34 | I | collecting info in model.layers.0
24-11-25 20:06:34 | I | collecting info in model.layers.0
24-11-25 20:06:34 | I | collecting info in model.layers.0
24-11-25 20:06:34 | I | collecting calibration activations in model.layers.0
24-11-25 20:06:34 | I | collecting calibration activations in model.layers.0
24-11-25 20:06:35 | I | collecting calibration activations in model.layers.0
24-11-25 20:06:35 | I | collecting calibration activations in model.layers.0
24-11-25 20:06:35 | I | - Quantizing decoder layer model.layers.0
24-11-25 20:06:35 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 20:06:36 | I |       - range scale = [    1.0000]
24-11-25 20:06:36 | I |         sum  error  = [    0.0595]
24-11-25 20:06:36 | I |         best error  = [    0.0595]
24-11-25 20:06:36 | I |     + error = [0.0595]
24-11-25 20:06:36 | I |       - range scale = [    1.0000]
24-11-25 20:06:36 | I |         sum  error  = [    0.6240]
24-11-25 20:06:36 | I |         best error  = [    0.6240]
24-11-25 20:06:36 | I |     + error = [0.6240]
24-11-25 20:06:36 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 20:06:37 | I |       - range scale = [    1.0000]
24-11-25 20:06:37 | I |         sum  error  = [    0.0750]
24-11-25 20:06:37 | I |         best error  = [    0.0750]
24-11-25 20:06:37 | I |     + error = [0.0750]
24-11-25 20:06:38 | I |       - range scale = [    1.0000]
24-11-25 20:06:38 | I |         sum  error  = [    0.5646]
24-11-25 20:06:38 | I |         best error  = [    0.5646]
24-11-25 20:06:38 | I |     + error = [0.5646]
24-11-25 20:06:38 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 20:06:39 | I |       - range scale = [    1.0000]
24-11-25 20:06:39 | I |         sum  error  = [    0.2395]
24-11-25 20:06:39 | I |         best error  = [    0.2395]
24-11-25 20:06:39 | I |     + error = [0.2395]
24-11-25 20:06:39 | I |       - range scale = [    1.0000]
24-11-25 20:06:39 | I |         sum  error  = [    1.8914]
24-11-25 20:06:39 | I |         best error  = [    1.8914]
24-11-25 20:06:39 | I |     + error = [1.8914]
24-11-25 20:06:40 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 20:06:40 | I |       - range scale = [    1.0000]
24-11-25 20:06:40 | I |         sum  error  = [    0.0606]
24-11-25 20:06:40 | I |         best error  = [    0.0606]
24-11-25 20:06:40 | I |     + error = [0.0606]
24-11-25 20:06:41 | I |       - range scale = [    1.0000]
24-11-25 20:06:41 | I |         sum  error  = [    0.5755]
24-11-25 20:06:41 | I |         best error  = [    0.5755]
24-11-25 20:06:41 | I |     + error = [0.5755]
24-11-25 20:06:41 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 20:06:42 | I |       - range scale = [    1.0000]
24-11-25 20:06:42 | I |         sum  error  = [    1.0465]
24-11-25 20:06:42 | I |         best error  = [    1.0465]
24-11-25 20:06:42 | I |     + error = [1.0465]
24-11-25 20:06:43 | I |       - range scale = [    1.0000]
24-11-25 20:06:43 | I |         sum  error  = [   11.5846]
24-11-25 20:06:43 | I |         best error  = [   11.5846]
24-11-25 20:06:43 | I |     + error = [11.5846]
24-11-25 20:06:43 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 20:06:43 | I |       - range scale = [    1.0000]
24-11-25 20:06:43 | I |         sum  error  = [    1.2101]
24-11-25 20:06:43 | I |         best error  = [    1.2101]
24-11-25 20:06:43 | I |     + error = [1.2101]
24-11-25 20:06:44 | I |       - range scale = [    1.0000]
24-11-25 20:06:44 | I |         sum  error  = [   11.9431]
24-11-25 20:06:44 | I |         best error  = [   11.9431]
24-11-25 20:06:44 | I |     + error = [11.9431]
24-11-25 20:06:44 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 20:06:45 | I |       - range scale = [    1.0000]
24-11-25 20:06:45 | I |         sum  error  = [    3.6005]
24-11-25 20:06:45 | I |         best error  = [    3.6005]
24-11-25 20:06:45 | I |     + error = [3.6005]
24-11-25 20:06:46 | I |       - range scale = [    1.0000]
24-11-25 20:06:46 | I |         sum  error  = [   19.2468]
24-11-25 20:06:46 | I |         best error  = [   19.2468]
24-11-25 20:06:46 | I |     + error = [19.2468]
24-11-25 20:06:46 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 20:06:47 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 20:06:49 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 20:06:50 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 20:06:52 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 20:06:53 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 20:06:54 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 20:06:58 | I | quantizing activations for layer model.layers.0
24-11-25 20:06:58 | I | collecting info in model.layers.0
24-11-25 20:06:58 | I | collecting info in model.layers.0
24-11-25 20:06:58 | I | collecting info in model.layers.0
24-11-25 20:06:58 | I | collecting info in model.layers.0
24-11-25 20:06:58 | I | collecting calibration activations in model.layers.0
24-11-25 20:06:58 | I | collecting calibration activations in model.layers.0
24-11-25 20:06:58 | I | collecting calibration activations in model.layers.0
24-11-25 20:06:58 | I | collecting calibration activations in model.layers.0
24-11-25 20:07:00 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 20:07:00 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 20:07:00 | I | - Evaluator: gptq
24-11-25 20:07:00 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 20:07:00 | I | - Batch_size: 8
24-11-25 20:07:00 | I |   + Max_seq_length: 2048
24-11-25 20:07:42 | I |     - Results:
24-11-25 20:07:42 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 20:07:42 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 20:07:42 | I |       |wikitext |      1|word_perplexity|7.8348|  |7.8348|
24-11-25 20:07:42 | I |       |val_valid|      1|word_perplexity|9.1219|  |9.1219|
24-11-25 20:07:42 | I |       
24-11-25 20:07:42 | I | forward this layer
24-11-25 20:07:42 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/170.pt
24-11-25 20:07:42 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/170.pt
24-11-25 20:07:42 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 20:07:42 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 20:07:42 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 20:07:42 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 20:07:42 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 20:07:42 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 20:07:42 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 20:07:42 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 20:07:42 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 20:07:42 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 20:07:42 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 20:07:42 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 20:07:42 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 20:07:42 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 20:07:42 | I | in layer model.layers.0
24-11-25 20:07:42 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 20:07:42 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 20:07:42 | I | - Evaluator: gptq
24-11-25 20:07:42 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 20:07:42 | I | - Batch_size: 8
24-11-25 20:07:42 | I |   + Max_seq_length: 2048
24-11-25 20:08:20 | I |     - Results:
24-11-25 20:08:20 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 20:08:20 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 20:08:20 | I |       |wikitext |      1|word_perplexity|7.7572|  |7.7572|
24-11-25 20:08:20 | I |       |val_valid|      1|word_perplexity|9.0775|  |9.0775|
24-11-25 20:08:20 | I |       
24-11-25 20:08:20 | I | quantizing weights for layer model.layers.0
24-11-25 20:08:20 | I | collecting info in model.layers.0
24-11-25 20:08:20 | I | collecting info in model.layers.0
24-11-25 20:08:20 | I | collecting info in model.layers.0
24-11-25 20:08:20 | I | collecting info in model.layers.0
24-11-25 20:08:21 | I | collecting calibration activations in model.layers.0
24-11-25 20:08:21 | I | collecting calibration activations in model.layers.0
24-11-25 20:08:21 | I | collecting calibration activations in model.layers.0
24-11-25 20:08:21 | I | collecting calibration activations in model.layers.0
24-11-25 20:08:21 | I | - Quantizing decoder layer model.layers.0
24-11-25 20:08:21 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 20:08:22 | I |       - range scale = [    1.0000]
24-11-25 20:08:22 | I |         sum  error  = [    0.0657]
24-11-25 20:08:22 | I |         best error  = [    0.0657]
24-11-25 20:08:22 | I |     + error = [0.0657]
24-11-25 20:08:23 | I |       - range scale = [    1.0000]
24-11-25 20:08:23 | I |         sum  error  = [    0.6287]
24-11-25 20:08:23 | I |         best error  = [    0.6287]
24-11-25 20:08:23 | I |     + error = [0.6287]
24-11-25 20:08:23 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 20:08:24 | I |       - range scale = [    1.0000]
24-11-25 20:08:24 | I |         sum  error  = [    0.0745]
24-11-25 20:08:24 | I |         best error  = [    0.0745]
24-11-25 20:08:24 | I |     + error = [0.0745]
24-11-25 20:08:24 | I |       - range scale = [    1.0000]
24-11-25 20:08:24 | I |         sum  error  = [    0.6165]
24-11-25 20:08:24 | I |         best error  = [    0.6165]
24-11-25 20:08:24 | I |     + error = [0.6165]
24-11-25 20:08:25 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 20:08:25 | I |       - range scale = [    1.0000]
24-11-25 20:08:25 | I |         sum  error  = [    0.2374]
24-11-25 20:08:25 | I |         best error  = [    0.2374]
24-11-25 20:08:25 | I |     + error = [0.2374]
24-11-25 20:08:26 | I |       - range scale = [    1.0000]
24-11-25 20:08:26 | I |         sum  error  = [    1.8708]
24-11-25 20:08:26 | I |         best error  = [    1.8708]
24-11-25 20:08:26 | I |     + error = [1.8708]
24-11-25 20:08:26 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 20:08:27 | I |       - range scale = [    1.0000]
24-11-25 20:08:27 | I |         sum  error  = [    0.0683]
24-11-25 20:08:27 | I |         best error  = [    0.0683]
24-11-25 20:08:27 | I |     + error = [0.0683]
24-11-25 20:08:28 | I |       - range scale = [    1.0000]
24-11-25 20:08:28 | I |         sum  error  = [    0.6601]
24-11-25 20:08:28 | I |         best error  = [    0.6601]
24-11-25 20:08:28 | I |     + error = [0.6601]
24-11-25 20:08:28 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 20:08:29 | I |       - range scale = [    1.0000]
24-11-25 20:08:29 | I |         sum  error  = [    1.1306]
24-11-25 20:08:29 | I |         best error  = [    1.1306]
24-11-25 20:08:29 | I |     + error = [1.1306]
24-11-25 20:08:29 | I |       - range scale = [    1.0000]
24-11-25 20:08:29 | I |         sum  error  = [   12.5260]
24-11-25 20:08:29 | I |         best error  = [   12.5260]
24-11-25 20:08:29 | I |     + error = [12.5260]
24-11-25 20:08:30 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 20:08:30 | I |       - range scale = [    1.0000]
24-11-25 20:08:30 | I |         sum  error  = [    1.3102]
24-11-25 20:08:30 | I |         best error  = [    1.3102]
24-11-25 20:08:30 | I |     + error = [1.3102]
24-11-25 20:08:31 | I |       - range scale = [    1.0000]
24-11-25 20:08:31 | I |         sum  error  = [   12.9593]
24-11-25 20:08:31 | I |         best error  = [   12.9593]
24-11-25 20:08:31 | I |     + error = [12.9593]
24-11-25 20:08:31 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 20:08:32 | I |       - range scale = [    1.0000]
24-11-25 20:08:32 | I |         sum  error  = [    3.0486]
24-11-25 20:08:32 | I |         best error  = [    3.0486]
24-11-25 20:08:32 | I |     + error = [3.0486]
24-11-25 20:08:33 | I |       - range scale = [    1.0000]
24-11-25 20:08:33 | I |         sum  error  = [   15.6282]
24-11-25 20:08:33 | I |         best error  = [   15.6282]
24-11-25 20:08:33 | I |     + error = [15.6282]
24-11-25 20:08:33 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 20:08:34 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 20:08:36 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 20:08:37 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 20:08:38 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 20:08:40 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 20:08:41 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 20:08:44 | I | quantizing activations for layer model.layers.0
24-11-25 20:08:44 | I | collecting info in model.layers.0
24-11-25 20:08:44 | I | collecting info in model.layers.0
24-11-25 20:08:44 | I | collecting info in model.layers.0
24-11-25 20:08:44 | I | collecting info in model.layers.0
24-11-25 20:08:45 | I | collecting calibration activations in model.layers.0
24-11-25 20:08:45 | I | collecting calibration activations in model.layers.0
24-11-25 20:08:45 | I | collecting calibration activations in model.layers.0
24-11-25 20:08:45 | I | collecting calibration activations in model.layers.0
24-11-25 20:08:47 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 20:08:47 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 20:08:47 | I | - Evaluator: gptq
24-11-25 20:08:47 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 20:08:47 | I | - Batch_size: 8
24-11-25 20:08:47 | I |   + Max_seq_length: 2048
24-11-25 20:09:28 | I |     - Results:
24-11-25 20:09:28 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 20:09:28 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 20:09:28 | I |       |wikitext |      1|word_perplexity|7.8256|  |7.8256|
24-11-25 20:09:28 | I |       |val_valid|      1|word_perplexity|9.1205|  |9.1205|
24-11-25 20:09:28 | I |       
24-11-25 20:09:28 | I | forward this layer
24-11-25 20:09:28 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/171.pt
24-11-25 20:09:28 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/171.pt
24-11-25 20:09:29 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 20:09:29 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 20:09:29 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 20:09:29 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 20:09:29 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 20:09:29 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 20:09:29 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 20:09:29 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 20:09:29 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 20:09:29 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 20:09:29 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 20:09:29 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 20:09:29 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 20:09:29 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 20:09:29 | I | [71] done with optimizer step
24-11-25 20:09:29 | I | epoch 001:     86 / 409600000 loss=0.000111744, loss_per_token=0.228851, loss_sum=7498.99, wps=153.6, ups=0, wpb=32768, bsz=64, num_updates=72, lr=0.000149989, gnorm=44.868, clip=100, loss_scale=0.0078, train_wall=213, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=18699, lmquant_ppl_result_wikitext_in_train_no_quant=7.75723, lmquant_ppl_result_val_in_train_no_quant=9.07754, lmquant_ppl_result_wikitext_in_train_with_quant=7.8256, lmquant_ppl_result_val_in_train_with_quant=9.1205
24-11-25 20:09:29 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 20:09:29 | I | in layer model.layers.0
24-11-25 20:09:29 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 20:09:29 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 20:09:29 | I | - Evaluator: gptq
24-11-25 20:09:29 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 20:09:29 | I | - Batch_size: 8
24-11-25 20:09:29 | I |   + Max_seq_length: 2048
24-11-25 20:10:07 | I |     - Results:
24-11-25 20:10:07 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 20:10:07 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 20:10:07 | I |       |wikitext |      1|word_perplexity|7.7671|  |7.7671|
24-11-25 20:10:07 | I |       |val_valid|      1|word_perplexity|9.0895|  |9.0895|
24-11-25 20:10:07 | I |       
24-11-25 20:10:07 | I | quantizing weights for layer model.layers.0
24-11-25 20:10:07 | I | collecting info in model.layers.0
24-11-25 20:10:07 | I | collecting info in model.layers.0
24-11-25 20:10:07 | I | collecting info in model.layers.0
24-11-25 20:10:07 | I | collecting info in model.layers.0
24-11-25 20:10:08 | I | collecting calibration activations in model.layers.0
24-11-25 20:10:08 | I | collecting calibration activations in model.layers.0
24-11-25 20:10:08 | I | collecting calibration activations in model.layers.0
24-11-25 20:10:08 | I | collecting calibration activations in model.layers.0
24-11-25 20:10:08 | I | - Quantizing decoder layer model.layers.0
24-11-25 20:10:08 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 20:10:09 | I |       - range scale = [    1.0000]
24-11-25 20:10:09 | I |         sum  error  = [    0.0667]
24-11-25 20:10:09 | I |         best error  = [    0.0667]
24-11-25 20:10:09 | I |     + error = [0.0667]
24-11-25 20:10:10 | I |       - range scale = [    1.0000]
24-11-25 20:10:10 | I |         sum  error  = [    0.6393]
24-11-25 20:10:10 | I |         best error  = [    0.6393]
24-11-25 20:10:10 | I |     + error = [0.6393]
24-11-25 20:10:10 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 20:10:11 | I |       - range scale = [    1.0000]
24-11-25 20:10:11 | I |         sum  error  = [    0.0760]
24-11-25 20:10:11 | I |         best error  = [    0.0760]
24-11-25 20:10:11 | I |     + error = [0.0760]
24-11-25 20:10:11 | I |       - range scale = [    1.0000]
24-11-25 20:10:11 | I |         sum  error  = [    0.5899]
24-11-25 20:10:11 | I |         best error  = [    0.5899]
24-11-25 20:10:11 | I |     + error = [0.5899]
24-11-25 20:10:12 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 20:10:12 | I |       - range scale = [    1.0000]
24-11-25 20:10:12 | I |         sum  error  = [    0.2344]
24-11-25 20:10:12 | I |         best error  = [    0.2344]
24-11-25 20:10:12 | I |     + error = [0.2344]
24-11-25 20:10:13 | I |       - range scale = [    1.0000]
24-11-25 20:10:13 | I |         sum  error  = [    1.8870]
24-11-25 20:10:13 | I |         best error  = [    1.8870]
24-11-25 20:10:13 | I |     + error = [1.8870]
24-11-25 20:10:13 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 20:10:14 | I |       - range scale = [    1.0000]
24-11-25 20:10:14 | I |         sum  error  = [    0.0673]
24-11-25 20:10:14 | I |         best error  = [    0.0673]
24-11-25 20:10:14 | I |     + error = [0.0673]
24-11-25 20:10:14 | I |       - range scale = [    1.0000]
24-11-25 20:10:14 | I |         sum  error  = [    0.6521]
24-11-25 20:10:14 | I |         best error  = [    0.6521]
24-11-25 20:10:14 | I |     + error = [0.6521]
24-11-25 20:10:15 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 20:10:15 | I |       - range scale = [    1.0000]
24-11-25 20:10:15 | I |         sum  error  = [    1.1157]
24-11-25 20:10:15 | I |         best error  = [    1.1157]
24-11-25 20:10:15 | I |     + error = [1.1157]
24-11-25 20:10:16 | I |       - range scale = [    1.0000]
24-11-25 20:10:16 | I |         sum  error  = [   12.3903]
24-11-25 20:10:16 | I |         best error  = [   12.3903]
24-11-25 20:10:16 | I |     + error = [12.3903]
24-11-25 20:10:16 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 20:10:17 | I |       - range scale = [    1.0000]
24-11-25 20:10:17 | I |         sum  error  = [    1.2986]
24-11-25 20:10:17 | I |         best error  = [    1.2986]
24-11-25 20:10:17 | I |     + error = [1.2986]
24-11-25 20:10:18 | I |       - range scale = [    1.0000]
24-11-25 20:10:18 | I |         sum  error  = [   12.8053]
24-11-25 20:10:18 | I |         best error  = [   12.8053]
24-11-25 20:10:18 | I |     + error = [12.8053]
24-11-25 20:10:18 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 20:10:19 | I |       - range scale = [    1.0000]
24-11-25 20:10:19 | I |         sum  error  = [    1.8682]
24-11-25 20:10:19 | I |         best error  = [    1.8682]
24-11-25 20:10:19 | I |     + error = [1.8682]
24-11-25 20:10:19 | I |       - range scale = [    1.0000]
24-11-25 20:10:19 | I |         sum  error  = [    9.8865]
24-11-25 20:10:19 | I |         best error  = [    9.8865]
24-11-25 20:10:19 | I |     + error = [9.8865]
24-11-25 20:10:20 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 20:10:21 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 20:10:22 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 20:10:24 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 20:10:25 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 20:10:27 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 20:10:28 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 20:10:31 | I | quantizing activations for layer model.layers.0
24-11-25 20:10:31 | I | collecting info in model.layers.0
24-11-25 20:10:31 | I | collecting info in model.layers.0
24-11-25 20:10:31 | I | collecting info in model.layers.0
24-11-25 20:10:31 | I | collecting info in model.layers.0
24-11-25 20:10:32 | I | collecting calibration activations in model.layers.0
24-11-25 20:10:32 | I | collecting calibration activations in model.layers.0
24-11-25 20:10:32 | I | collecting calibration activations in model.layers.0
24-11-25 20:10:32 | I | collecting calibration activations in model.layers.0
24-11-25 20:10:34 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 20:10:34 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 20:10:34 | I | - Evaluator: gptq
24-11-25 20:10:34 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 20:10:34 | I | - Batch_size: 8
24-11-25 20:10:34 | I |   + Max_seq_length: 2048
24-11-25 20:11:16 | I |     - Results:
24-11-25 20:11:16 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 20:11:16 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 20:11:16 | I |       |wikitext |      1|word_perplexity|7.8648|  |7.8648|
24-11-25 20:11:16 | I |       |val_valid|      1|word_perplexity|9.1390|  |9.1390|
24-11-25 20:11:16 | I |       
24-11-25 20:11:16 | I | forward this layer
24-11-25 20:11:16 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/172.pt
24-11-25 20:11:16 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/172.pt
24-11-25 20:11:16 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 20:11:16 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 20:11:16 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 20:11:16 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 20:11:16 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 20:11:16 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 20:11:16 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 20:11:16 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 20:11:16 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 20:11:16 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 20:11:16 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 20:11:16 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 20:11:16 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 20:11:16 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 20:11:16 | I | in layer model.layers.0
24-11-25 20:11:16 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 20:11:16 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 20:11:16 | I | - Evaluator: gptq
24-11-25 20:11:16 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 20:11:16 | I | - Batch_size: 8
24-11-25 20:11:16 | I |   + Max_seq_length: 2048
24-11-25 20:11:54 | I |     - Results:
24-11-25 20:11:54 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 20:11:54 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 20:11:54 | I |       |wikitext |      1|word_perplexity|7.7671|  |7.7671|
24-11-25 20:11:54 | I |       |val_valid|      1|word_perplexity|9.0895|  |9.0895|
24-11-25 20:11:54 | I |       
24-11-25 20:11:54 | I | quantizing weights for layer model.layers.0
24-11-25 20:11:54 | I | collecting info in model.layers.0
24-11-25 20:11:54 | I | collecting info in model.layers.0
24-11-25 20:11:54 | I | collecting info in model.layers.0
24-11-25 20:11:54 | I | collecting info in model.layers.0
24-11-25 20:11:55 | I | collecting calibration activations in model.layers.0
24-11-25 20:11:55 | I | collecting calibration activations in model.layers.0
24-11-25 20:11:55 | I | collecting calibration activations in model.layers.0
24-11-25 20:11:55 | I | collecting calibration activations in model.layers.0
24-11-25 20:11:55 | I | - Quantizing decoder layer model.layers.0
24-11-25 20:11:55 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 20:11:56 | I |       - range scale = [    1.0000]
24-11-25 20:11:56 | I |         sum  error  = [    0.0599]
24-11-25 20:11:56 | I |         best error  = [    0.0599]
24-11-25 20:11:56 | I |     + error = [0.0599]
24-11-25 20:11:57 | I |       - range scale = [    1.0000]
24-11-25 20:11:57 | I |         sum  error  = [    0.6049]
24-11-25 20:11:57 | I |         best error  = [    0.6049]
24-11-25 20:11:57 | I |     + error = [0.6049]
24-11-25 20:11:57 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 20:11:58 | I |       - range scale = [    1.0000]
24-11-25 20:11:58 | I |         sum  error  = [    0.0725]
24-11-25 20:11:58 | I |         best error  = [    0.0725]
24-11-25 20:11:58 | I |     + error = [0.0725]
24-11-25 20:11:58 | I |       - range scale = [    1.0000]
24-11-25 20:11:58 | I |         sum  error  = [    0.5486]
24-11-25 20:11:58 | I |         best error  = [    0.5486]
24-11-25 20:11:58 | I |     + error = [0.5486]
24-11-25 20:11:58 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 20:11:59 | I |       - range scale = [    1.0000]
24-11-25 20:11:59 | I |         sum  error  = [    0.2287]
24-11-25 20:11:59 | I |         best error  = [    0.2287]
24-11-25 20:11:59 | I |     + error = [0.2287]
24-11-25 20:12:00 | I |       - range scale = [    1.0000]
24-11-25 20:12:00 | I |         sum  error  = [    1.8571]
24-11-25 20:12:00 | I |         best error  = [    1.8571]
24-11-25 20:12:00 | I |     + error = [1.8571]
24-11-25 20:12:00 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 20:12:01 | I |       - range scale = [    1.0000]
24-11-25 20:12:01 | I |         sum  error  = [    0.0640]
24-11-25 20:12:01 | I |         best error  = [    0.0640]
24-11-25 20:12:01 | I |     + error = [0.0640]
24-11-25 20:12:01 | I |       - range scale = [    1.0000]
24-11-25 20:12:01 | I |         sum  error  = [    0.6161]
24-11-25 20:12:01 | I |         best error  = [    0.6161]
24-11-25 20:12:01 | I |     + error = [0.6161]
24-11-25 20:12:02 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 20:12:02 | I |       - range scale = [    1.0000]
24-11-25 20:12:02 | I |         sum  error  = [    1.0919]
24-11-25 20:12:02 | I |         best error  = [    1.0919]
24-11-25 20:12:02 | I |     + error = [1.0919]
24-11-25 20:12:03 | I |       - range scale = [    1.0000]
24-11-25 20:12:03 | I |         sum  error  = [   12.0875]
24-11-25 20:12:03 | I |         best error  = [   12.0875]
24-11-25 20:12:03 | I |     + error = [12.0875]
24-11-25 20:12:03 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 20:12:04 | I |       - range scale = [    1.0000]
24-11-25 20:12:04 | I |         sum  error  = [    1.2613]
24-11-25 20:12:04 | I |         best error  = [    1.2613]
24-11-25 20:12:04 | I |     + error = [1.2613]
24-11-25 20:12:05 | I |       - range scale = [    1.0000]
24-11-25 20:12:05 | I |         sum  error  = [   12.4818]
24-11-25 20:12:05 | I |         best error  = [   12.4818]
24-11-25 20:12:05 | I |     + error = [12.4818]
24-11-25 20:12:05 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 20:12:06 | I |       - range scale = [    1.0000]
24-11-25 20:12:06 | I |         sum  error  = [    3.7352]
24-11-25 20:12:06 | I |         best error  = [    3.7352]
24-11-25 20:12:06 | I |     + error = [3.7352]
24-11-25 20:12:06 | I |       - range scale = [    1.0000]
24-11-25 20:12:06 | I |         sum  error  = [   19.8679]
24-11-25 20:12:06 | I |         best error  = [   19.8679]
24-11-25 20:12:06 | I |     + error = [19.8679]
24-11-25 20:12:07 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 20:12:08 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 20:12:09 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 20:12:11 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 20:12:12 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 20:12:14 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 20:12:15 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 20:12:18 | I | quantizing activations for layer model.layers.0
24-11-25 20:12:18 | I | collecting info in model.layers.0
24-11-25 20:12:18 | I | collecting info in model.layers.0
24-11-25 20:12:18 | I | collecting info in model.layers.0
24-11-25 20:12:18 | I | collecting info in model.layers.0
24-11-25 20:12:19 | I | collecting calibration activations in model.layers.0
24-11-25 20:12:19 | I | collecting calibration activations in model.layers.0
24-11-25 20:12:19 | I | collecting calibration activations in model.layers.0
24-11-25 20:12:19 | I | collecting calibration activations in model.layers.0
24-11-25 20:12:21 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 20:12:21 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 20:12:21 | I | - Evaluator: gptq
24-11-25 20:12:21 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 20:12:21 | I | - Batch_size: 8
24-11-25 20:12:21 | I |   + Max_seq_length: 2048
24-11-25 20:13:02 | I |     - Results:
24-11-25 20:13:02 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 20:13:02 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 20:13:02 | I |       |wikitext |      1|word_perplexity|7.8366|  |7.8366|
24-11-25 20:13:02 | I |       |val_valid|      1|word_perplexity|9.1300|  |9.1300|
24-11-25 20:13:02 | I |       
24-11-25 20:13:02 | I | forward this layer
24-11-25 20:13:02 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/173.pt
24-11-25 20:13:02 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/173.pt
24-11-25 20:13:02 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 20:13:02 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 20:13:02 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 20:13:02 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 20:13:02 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 20:13:02 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 20:13:02 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 20:13:02 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 20:13:02 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 20:13:02 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 20:13:02 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 20:13:02 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 20:13:02 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 20:13:02 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 20:13:02 | I | [72] done with optimizer step
24-11-25 20:13:02 | I | epoch 001:     87 / 409600000 loss=0.000139683, loss_per_token=0.28607, loss_sum=9373.93, wps=153.2, ups=0, wpb=32768, bsz=64, num_updates=73, lr=0.000149988, gnorm=15.326, clip=100, loss_scale=0.0078, train_wall=214, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=18913, lmquant_ppl_result_wikitext_in_train_no_quant=7.76708, lmquant_ppl_result_val_in_train_no_quant=9.08955, lmquant_ppl_result_wikitext_in_train_with_quant=7.83661, lmquant_ppl_result_val_in_train_with_quant=9.13002
24-11-25 20:13:03 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 20:13:03 | I | in layer model.layers.0
24-11-25 20:13:03 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 20:13:03 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 20:13:03 | I | - Evaluator: gptq
24-11-25 20:13:03 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 20:13:03 | I | - Batch_size: 8
24-11-25 20:13:03 | I |   + Max_seq_length: 2048
24-11-25 20:13:41 | I |     - Results:
24-11-25 20:13:41 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 20:13:41 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 20:13:41 | I |       |wikitext |      1|word_perplexity|7.7840|  |7.7840|
24-11-25 20:13:41 | I |       |val_valid|      1|word_perplexity|9.1173|  |9.1173|
24-11-25 20:13:41 | I |       
24-11-25 20:13:41 | I | quantizing weights for layer model.layers.0
24-11-25 20:13:41 | I | collecting info in model.layers.0
24-11-25 20:13:41 | I | collecting info in model.layers.0
24-11-25 20:13:41 | I | collecting info in model.layers.0
24-11-25 20:13:41 | I | collecting info in model.layers.0
24-11-25 20:13:42 | I | collecting calibration activations in model.layers.0
24-11-25 20:13:42 | I | collecting calibration activations in model.layers.0
24-11-25 20:13:42 | I | collecting calibration activations in model.layers.0
24-11-25 20:13:42 | I | collecting calibration activations in model.layers.0
24-11-25 20:13:42 | I | - Quantizing decoder layer model.layers.0
24-11-25 20:13:42 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 20:13:43 | I |       - range scale = [    1.0000]
24-11-25 20:13:43 | I |         sum  error  = [    0.0580]
24-11-25 20:13:43 | I |         best error  = [    0.0580]
24-11-25 20:13:43 | I |     + error = [0.0580]
24-11-25 20:13:44 | I |       - range scale = [    1.0000]
24-11-25 20:13:44 | I |         sum  error  = [    0.5731]
24-11-25 20:13:44 | I |         best error  = [    0.5731]
24-11-25 20:13:44 | I |     + error = [0.5731]
24-11-25 20:13:44 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 20:13:44 | I |       - range scale = [    1.0000]
24-11-25 20:13:44 | I |         sum  error  = [    0.0682]
24-11-25 20:13:44 | I |         best error  = [    0.0682]
24-11-25 20:13:44 | I |     + error = [0.0682]
24-11-25 20:13:45 | I |       - range scale = [    1.0000]
24-11-25 20:13:45 | I |         sum  error  = [    0.5899]
24-11-25 20:13:45 | I |         best error  = [    0.5899]
24-11-25 20:13:45 | I |     + error = [0.5899]
24-11-25 20:13:45 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 20:13:46 | I |       - range scale = [    1.0000]
24-11-25 20:13:46 | I |         sum  error  = [    0.2234]
24-11-25 20:13:46 | I |         best error  = [    0.2234]
24-11-25 20:13:46 | I |     + error = [0.2234]
24-11-25 20:13:47 | I |       - range scale = [    1.0000]
24-11-25 20:13:47 | I |         sum  error  = [    1.8584]
24-11-25 20:13:47 | I |         best error  = [    1.8584]
24-11-25 20:13:47 | I |     + error = [1.8584]
24-11-25 20:13:47 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 20:13:48 | I |       - range scale = [    1.0000]
24-11-25 20:13:48 | I |         sum  error  = [    0.0677]
24-11-25 20:13:48 | I |         best error  = [    0.0677]
24-11-25 20:13:48 | I |     + error = [0.0677]
24-11-25 20:13:48 | I |       - range scale = [    1.0000]
24-11-25 20:13:48 | I |         sum  error  = [    0.6515]
24-11-25 20:13:48 | I |         best error  = [    0.6515]
24-11-25 20:13:48 | I |     + error = [0.6515]
24-11-25 20:13:49 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 20:13:49 | I |       - range scale = [    1.0000]
24-11-25 20:13:49 | I |         sum  error  = [    1.0948]
24-11-25 20:13:49 | I |         best error  = [    1.0948]
24-11-25 20:13:49 | I |     + error = [1.0948]
24-11-25 20:13:50 | I |       - range scale = [    1.0000]
24-11-25 20:13:50 | I |         sum  error  = [   12.1301]
24-11-25 20:13:50 | I |         best error  = [   12.1301]
24-11-25 20:13:50 | I |     + error = [12.1301]
24-11-25 20:13:50 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 20:13:51 | I |       - range scale = [    1.0000]
24-11-25 20:13:51 | I |         sum  error  = [    1.2680]
24-11-25 20:13:51 | I |         best error  = [    1.2680]
24-11-25 20:13:51 | I |     + error = [1.2680]
24-11-25 20:13:52 | I |       - range scale = [    1.0000]
24-11-25 20:13:52 | I |         sum  error  = [   12.5253]
24-11-25 20:13:52 | I |         best error  = [   12.5253]
24-11-25 20:13:52 | I |     + error = [12.5253]
24-11-25 20:13:52 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 20:13:53 | I |       - range scale = [    1.0000]
24-11-25 20:13:53 | I |         sum  error  = [    1.9874]
24-11-25 20:13:53 | I |         best error  = [    1.9874]
24-11-25 20:13:53 | I |     + error = [1.9874]
24-11-25 20:13:53 | I |       - range scale = [    1.0000]
24-11-25 20:13:53 | I |         sum  error  = [   10.6435]
24-11-25 20:13:53 | I |         best error  = [   10.6435]
24-11-25 20:13:53 | I |     + error = [10.6435]
24-11-25 20:13:54 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 20:13:55 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 20:13:56 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 20:13:58 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 20:13:59 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 20:14:00 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 20:14:02 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 20:14:05 | I | quantizing activations for layer model.layers.0
24-11-25 20:14:05 | I | collecting info in model.layers.0
24-11-25 20:14:05 | I | collecting info in model.layers.0
24-11-25 20:14:05 | I | collecting info in model.layers.0
24-11-25 20:14:05 | I | collecting info in model.layers.0
24-11-25 20:14:06 | I | collecting calibration activations in model.layers.0
24-11-25 20:14:06 | I | collecting calibration activations in model.layers.0
24-11-25 20:14:06 | I | collecting calibration activations in model.layers.0
24-11-25 20:14:06 | I | collecting calibration activations in model.layers.0
24-11-25 20:14:08 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 20:14:08 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 20:14:08 | I | - Evaluator: gptq
24-11-25 20:14:08 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 20:14:08 | I | - Batch_size: 8
24-11-25 20:14:08 | I |   + Max_seq_length: 2048
24-11-25 20:14:49 | I |     - Results:
24-11-25 20:14:49 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 20:14:49 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 20:14:49 | I |       |wikitext |      1|word_perplexity|7.8412|  |7.8412|
24-11-25 20:14:49 | I |       |val_valid|      1|word_perplexity|9.1478|  |9.1478|
24-11-25 20:14:49 | I |       
24-11-25 20:14:49 | I | forward this layer
24-11-25 20:14:49 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/174.pt
24-11-25 20:14:49 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/174.pt
24-11-25 20:14:49 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 20:14:49 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 20:14:49 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 20:14:49 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 20:14:49 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 20:14:49 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 20:14:49 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 20:14:49 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 20:14:49 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 20:14:49 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 20:14:49 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 20:14:49 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 20:14:49 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 20:14:49 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 20:14:50 | I | in layer model.layers.0
24-11-25 20:14:50 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 20:14:50 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 20:14:50 | I | - Evaluator: gptq
24-11-25 20:14:50 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 20:14:50 | I | - Batch_size: 8
24-11-25 20:14:50 | I |   + Max_seq_length: 2048
24-11-25 20:15:28 | I |     - Results:
24-11-25 20:15:28 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 20:15:28 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 20:15:28 | I |       |wikitext |      1|word_perplexity|7.7840|  |7.7840|
24-11-25 20:15:28 | I |       |val_valid|      1|word_perplexity|9.1173|  |9.1173|
24-11-25 20:15:28 | I |       
24-11-25 20:15:28 | I | quantizing weights for layer model.layers.0
24-11-25 20:15:28 | I | collecting info in model.layers.0
24-11-25 20:15:28 | I | collecting info in model.layers.0
24-11-25 20:15:28 | I | collecting info in model.layers.0
24-11-25 20:15:28 | I | collecting info in model.layers.0
24-11-25 20:15:28 | I | collecting calibration activations in model.layers.0
24-11-25 20:15:28 | I | collecting calibration activations in model.layers.0
24-11-25 20:15:28 | I | collecting calibration activations in model.layers.0
24-11-25 20:15:29 | I | collecting calibration activations in model.layers.0
24-11-25 20:15:29 | I | - Quantizing decoder layer model.layers.0
24-11-25 20:15:29 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 20:15:30 | I |       - range scale = [    1.0000]
24-11-25 20:15:30 | I |         sum  error  = [    0.0574]
24-11-25 20:15:30 | I |         best error  = [    0.0574]
24-11-25 20:15:30 | I |     + error = [0.0574]
24-11-25 20:15:30 | I |       - range scale = [    1.0000]
24-11-25 20:15:30 | I |         sum  error  = [    0.5567]
24-11-25 20:15:30 | I |         best error  = [    0.5567]
24-11-25 20:15:30 | I |     + error = [0.5567]
24-11-25 20:15:31 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 20:15:31 | I |       - range scale = [    1.0000]
24-11-25 20:15:31 | I |         sum  error  = [    0.0711]
24-11-25 20:15:31 | I |         best error  = [    0.0711]
24-11-25 20:15:31 | I |     + error = [0.0711]
24-11-25 20:15:32 | I |       - range scale = [    1.0000]
24-11-25 20:15:32 | I |         sum  error  = [    0.5515]
24-11-25 20:15:32 | I |         best error  = [    0.5515]
24-11-25 20:15:32 | I |     + error = [0.5515]
24-11-25 20:15:32 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 20:15:33 | I |       - range scale = [    1.0000]
24-11-25 20:15:33 | I |         sum  error  = [    0.2245]
24-11-25 20:15:33 | I |         best error  = [    0.2245]
24-11-25 20:15:33 | I |     + error = [0.2245]
24-11-25 20:15:33 | I |       - range scale = [    1.0000]
24-11-25 20:15:33 | I |         sum  error  = [    1.8462]
24-11-25 20:15:33 | I |         best error  = [    1.8462]
24-11-25 20:15:33 | I |     + error = [1.8462]
24-11-25 20:15:34 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 20:15:34 | I |       - range scale = [    1.0000]
24-11-25 20:15:34 | I |         sum  error  = [    0.0612]
24-11-25 20:15:34 | I |         best error  = [    0.0612]
24-11-25 20:15:34 | I |     + error = [0.0612]
24-11-25 20:15:35 | I |       - range scale = [    1.0000]
24-11-25 20:15:35 | I |         sum  error  = [    0.5918]
24-11-25 20:15:35 | I |         best error  = [    0.5918]
24-11-25 20:15:35 | I |     + error = [0.5918]
24-11-25 20:15:35 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 20:15:36 | I |       - range scale = [    1.0000]
24-11-25 20:15:36 | I |         sum  error  = [    1.0595]
24-11-25 20:15:36 | I |         best error  = [    1.0595]
24-11-25 20:15:36 | I |     + error = [1.0595]
24-11-25 20:15:37 | I |       - range scale = [    1.0000]
24-11-25 20:15:37 | I |         sum  error  = [   11.7239]
24-11-25 20:15:37 | I |         best error  = [   11.7239]
24-11-25 20:15:37 | I |     + error = [11.7239]
24-11-25 20:15:37 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 20:15:38 | I |       - range scale = [    1.0000]
24-11-25 20:15:38 | I |         sum  error  = [    1.2266]
24-11-25 20:15:38 | I |         best error  = [    1.2266]
24-11-25 20:15:38 | I |     + error = [1.2266]
24-11-25 20:15:38 | I |       - range scale = [    1.0000]
24-11-25 20:15:38 | I |         sum  error  = [   12.0944]
24-11-25 20:15:38 | I |         best error  = [   12.0944]
24-11-25 20:15:38 | I |     + error = [12.0944]
24-11-25 20:15:39 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 20:15:39 | I |       - range scale = [    1.0000]
24-11-25 20:15:39 | I |         sum  error  = [    2.3818]
24-11-25 20:15:39 | I |         best error  = [    2.3818]
24-11-25 20:15:39 | I |     + error = [2.3818]
24-11-25 20:15:40 | I |       - range scale = [    1.0000]
24-11-25 20:15:40 | I |         sum  error  = [   13.1891]
24-11-25 20:15:40 | I |         best error  = [   13.1891]
24-11-25 20:15:40 | I |     + error = [13.1891]
24-11-25 20:15:40 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 20:15:42 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 20:15:43 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 20:15:44 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 20:15:46 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 20:15:47 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 20:15:49 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 20:15:52 | I | quantizing activations for layer model.layers.0
24-11-25 20:15:52 | I | collecting info in model.layers.0
24-11-25 20:15:52 | I | collecting info in model.layers.0
24-11-25 20:15:52 | I | collecting info in model.layers.0
24-11-25 20:15:52 | I | collecting info in model.layers.0
24-11-25 20:15:53 | I | collecting calibration activations in model.layers.0
24-11-25 20:15:53 | I | collecting calibration activations in model.layers.0
24-11-25 20:15:53 | I | collecting calibration activations in model.layers.0
24-11-25 20:15:53 | I | collecting calibration activations in model.layers.0
24-11-25 20:15:55 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 20:15:55 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 20:15:55 | I | - Evaluator: gptq
24-11-25 20:15:55 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 20:15:55 | I | - Batch_size: 8
24-11-25 20:15:55 | I |   + Max_seq_length: 2048
24-11-25 20:16:36 | I |     - Results:
24-11-25 20:16:36 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 20:16:36 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 20:16:36 | I |       |wikitext |      1|word_perplexity|7.8749|  |7.8749|
24-11-25 20:16:36 | I |       |val_valid|      1|word_perplexity|9.1739|  |9.1739|
24-11-25 20:16:36 | I |       
24-11-25 20:16:36 | I | forward this layer
24-11-25 20:16:36 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/175.pt
24-11-25 20:16:36 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/175.pt
24-11-25 20:16:36 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 20:16:36 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 20:16:36 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 20:16:36 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 20:16:36 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 20:16:36 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 20:16:36 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 20:16:36 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 20:16:36 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 20:16:36 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 20:16:36 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 20:16:36 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 20:16:36 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 20:16:36 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 20:16:37 | I | [73] done with optimizer step
24-11-25 20:16:37 | I | epoch 001:     88 / 409600000 loss=8.904e-05, loss_per_token=0.182354, loss_sum=5975.37, wps=153.1, ups=0, wpb=32768, bsz=64, num_updates=74, lr=0.000149988, gnorm=23.376, clip=100, loss_scale=0.0078, train_wall=214, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=19127, lmquant_ppl_result_wikitext_in_train_no_quant=7.78395, lmquant_ppl_result_val_in_train_no_quant=9.11728, lmquant_ppl_result_wikitext_in_train_with_quant=7.87485, lmquant_ppl_result_val_in_train_with_quant=9.17391
24-11-25 20:16:37 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 20:16:37 | I | in layer model.layers.0
24-11-25 20:16:37 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 20:16:37 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 20:16:37 | I | - Evaluator: gptq
24-11-25 20:16:37 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 20:16:37 | I | - Batch_size: 8
24-11-25 20:16:37 | I |   + Max_seq_length: 2048
24-11-25 20:17:15 | I |     - Results:
24-11-25 20:17:15 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 20:17:15 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 20:17:15 | I |       |wikitext |      1|word_perplexity|7.7823|  |7.7823|
24-11-25 20:17:15 | I |       |val_valid|      1|word_perplexity|9.1267|  |9.1267|
24-11-25 20:17:15 | I |       
24-11-25 20:17:15 | I | quantizing weights for layer model.layers.0
24-11-25 20:17:15 | I | collecting info in model.layers.0
24-11-25 20:17:15 | I | collecting info in model.layers.0
24-11-25 20:17:15 | I | collecting info in model.layers.0
24-11-25 20:17:15 | I | collecting info in model.layers.0
24-11-25 20:17:16 | I | collecting calibration activations in model.layers.0
24-11-25 20:17:16 | I | collecting calibration activations in model.layers.0
24-11-25 20:17:16 | I | collecting calibration activations in model.layers.0
24-11-25 20:17:16 | I | collecting calibration activations in model.layers.0
24-11-25 20:17:16 | I | - Quantizing decoder layer model.layers.0
24-11-25 20:17:16 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 20:17:17 | I |       - range scale = [    1.0000]
24-11-25 20:17:17 | I |         sum  error  = [    0.0642]
24-11-25 20:17:17 | I |         best error  = [    0.0642]
24-11-25 20:17:17 | I |     + error = [0.0642]
24-11-25 20:17:18 | I |       - range scale = [    1.0000]
24-11-25 20:17:18 | I |         sum  error  = [    0.6058]
24-11-25 20:17:18 | I |         best error  = [    0.6058]
24-11-25 20:17:18 | I |     + error = [0.6058]
24-11-25 20:17:18 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 20:17:19 | I |       - range scale = [    1.0000]
24-11-25 20:17:19 | I |         sum  error  = [    0.0719]
24-11-25 20:17:19 | I |         best error  = [    0.0719]
24-11-25 20:17:19 | I |     + error = [0.0719]
24-11-25 20:17:19 | I |       - range scale = [    1.0000]
24-11-25 20:17:19 | I |         sum  error  = [    0.5678]
24-11-25 20:17:19 | I |         best error  = [    0.5678]
24-11-25 20:17:19 | I |     + error = [0.5678]
24-11-25 20:17:19 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 20:17:20 | I |       - range scale = [    1.0000]
24-11-25 20:17:20 | I |         sum  error  = [    0.2305]
24-11-25 20:17:20 | I |         best error  = [    0.2305]
24-11-25 20:17:20 | I |     + error = [0.2305]
24-11-25 20:17:21 | I |       - range scale = [    1.0000]
24-11-25 20:17:21 | I |         sum  error  = [    1.8925]
24-11-25 20:17:21 | I |         best error  = [    1.8925]
24-11-25 20:17:21 | I |     + error = [1.8925]
24-11-25 20:17:21 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 20:17:22 | I |       - range scale = [    1.0000]
24-11-25 20:17:22 | I |         sum  error  = [    0.0704]
24-11-25 20:17:22 | I |         best error  = [    0.0704]
24-11-25 20:17:22 | I |     + error = [0.0704]
24-11-25 20:17:22 | I |       - range scale = [    1.0000]
24-11-25 20:17:22 | I |         sum  error  = [    0.6710]
24-11-25 20:17:22 | I |         best error  = [    0.6710]
24-11-25 20:17:22 | I |     + error = [0.6710]
24-11-25 20:17:23 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 20:17:23 | I |       - range scale = [    1.0000]
24-11-25 20:17:23 | I |         sum  error  = [    1.1146]
24-11-25 20:17:23 | I |         best error  = [    1.1146]
24-11-25 20:17:23 | I |     + error = [1.1146]
24-11-25 20:17:24 | I |       - range scale = [    1.0000]
24-11-25 20:17:24 | I |         sum  error  = [   12.3348]
24-11-25 20:17:24 | I |         best error  = [   12.3348]
24-11-25 20:17:24 | I |     + error = [12.3348]
24-11-25 20:17:24 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 20:17:25 | I |       - range scale = [    1.0000]
24-11-25 20:17:25 | I |         sum  error  = [    1.2858]
24-11-25 20:17:25 | I |         best error  = [    1.2858]
24-11-25 20:17:25 | I |     + error = [1.2858]
24-11-25 20:17:26 | I |       - range scale = [    1.0000]
24-11-25 20:17:26 | I |         sum  error  = [   12.7447]
24-11-25 20:17:26 | I |         best error  = [   12.7447]
24-11-25 20:17:26 | I |     + error = [12.7447]
24-11-25 20:17:26 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 20:17:27 | I |       - range scale = [    1.0000]
24-11-25 20:17:27 | I |         sum  error  = [    3.4557]
24-11-25 20:17:27 | I |         best error  = [    3.4557]
24-11-25 20:17:27 | I |     + error = [3.4557]
24-11-25 20:17:27 | I |       - range scale = [    1.0000]
24-11-25 20:17:27 | I |         sum  error  = [   18.4455]
24-11-25 20:17:27 | I |         best error  = [   18.4455]
24-11-25 20:17:27 | I |     + error = [18.4455]
24-11-25 20:17:28 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 20:17:29 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 20:17:30 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 20:17:32 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 20:17:33 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 20:17:34 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 20:17:36 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 20:17:39 | I | quantizing activations for layer model.layers.0
24-11-25 20:17:39 | I | collecting info in model.layers.0
24-11-25 20:17:39 | I | collecting info in model.layers.0
24-11-25 20:17:39 | I | collecting info in model.layers.0
24-11-25 20:17:39 | I | collecting info in model.layers.0
24-11-25 20:17:40 | I | collecting calibration activations in model.layers.0
24-11-25 20:17:40 | I | collecting calibration activations in model.layers.0
24-11-25 20:17:40 | I | collecting calibration activations in model.layers.0
24-11-25 20:17:40 | I | collecting calibration activations in model.layers.0
24-11-25 20:17:42 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 20:17:42 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 20:17:42 | I | - Evaluator: gptq
24-11-25 20:17:42 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 20:17:42 | I | - Batch_size: 8
24-11-25 20:17:42 | I |   + Max_seq_length: 2048
24-11-25 20:18:23 | I |     - Results:
24-11-25 20:18:23 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 20:18:23 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 20:18:23 | I |       |wikitext |      1|word_perplexity|7.8360|  |7.8360|
24-11-25 20:18:23 | I |       |val_valid|      1|word_perplexity|9.1531|  |9.1531|
24-11-25 20:18:23 | I |       
24-11-25 20:18:23 | I | forward this layer
24-11-25 20:18:23 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/176.pt
24-11-25 20:18:23 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/176.pt
24-11-25 20:18:23 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 20:18:23 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 20:18:23 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 20:18:23 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 20:18:24 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 20:18:24 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 20:18:24 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 20:18:24 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 20:18:24 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 20:18:24 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 20:18:24 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 20:18:24 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 20:18:24 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 20:18:24 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 20:18:24 | I | in layer model.layers.0
24-11-25 20:18:24 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 20:18:24 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 20:18:24 | I | - Evaluator: gptq
24-11-25 20:18:24 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 20:18:24 | I | - Batch_size: 8
24-11-25 20:18:24 | I |   + Max_seq_length: 2048
24-11-25 20:19:02 | I |     - Results:
24-11-25 20:19:02 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 20:19:02 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 20:19:02 | I |       |wikitext |      1|word_perplexity|7.7823|  |7.7823|
24-11-25 20:19:02 | I |       |val_valid|      1|word_perplexity|9.1267|  |9.1267|
24-11-25 20:19:02 | I |       
24-11-25 20:19:02 | I | quantizing weights for layer model.layers.0
24-11-25 20:19:02 | I | collecting info in model.layers.0
24-11-25 20:19:02 | I | collecting info in model.layers.0
24-11-25 20:19:02 | I | collecting info in model.layers.0
24-11-25 20:19:02 | I | collecting info in model.layers.0
24-11-25 20:19:02 | I | collecting calibration activations in model.layers.0
24-11-25 20:19:03 | I | collecting calibration activations in model.layers.0
24-11-25 20:19:03 | I | collecting calibration activations in model.layers.0
24-11-25 20:19:03 | I | collecting calibration activations in model.layers.0
24-11-25 20:19:03 | I | - Quantizing decoder layer model.layers.0
24-11-25 20:19:03 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 20:19:04 | I |       - range scale = [    1.0000]
24-11-25 20:19:04 | I |         sum  error  = [    0.0553]
24-11-25 20:19:04 | I |         best error  = [    0.0553]
24-11-25 20:19:04 | I |     + error = [0.0553]
24-11-25 20:19:04 | I |       - range scale = [    1.0000]
24-11-25 20:19:04 | I |         sum  error  = [    0.5589]
24-11-25 20:19:04 | I |         best error  = [    0.5589]
24-11-25 20:19:04 | I |     + error = [0.5589]
24-11-25 20:19:05 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 20:19:05 | I |       - range scale = [    1.0000]
24-11-25 20:19:05 | I |         sum  error  = [    0.0666]
24-11-25 20:19:05 | I |         best error  = [    0.0666]
24-11-25 20:19:05 | I |     + error = [0.0666]
24-11-25 20:19:06 | I |       - range scale = [    1.0000]
24-11-25 20:19:06 | I |         sum  error  = [    0.5230]
24-11-25 20:19:06 | I |         best error  = [    0.5230]
24-11-25 20:19:06 | I |     + error = [0.5230]
24-11-25 20:19:06 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 20:19:07 | I |       - range scale = [    1.0000]
24-11-25 20:19:07 | I |         sum  error  = [    0.2271]
24-11-25 20:19:07 | I |         best error  = [    0.2271]
24-11-25 20:19:07 | I |     + error = [0.2271]
24-11-25 20:19:08 | I |       - range scale = [    1.0000]
24-11-25 20:19:08 | I |         sum  error  = [    1.8420]
24-11-25 20:19:08 | I |         best error  = [    1.8420]
24-11-25 20:19:08 | I |     + error = [1.8420]
24-11-25 20:19:08 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 20:19:08 | I |       - range scale = [    1.0000]
24-11-25 20:19:08 | I |         sum  error  = [    0.0594]
24-11-25 20:19:08 | I |         best error  = [    0.0594]
24-11-25 20:19:08 | I |     + error = [0.0594]
24-11-25 20:19:09 | I |       - range scale = [    1.0000]
24-11-25 20:19:09 | I |         sum  error  = [    0.5728]
24-11-25 20:19:09 | I |         best error  = [    0.5728]
24-11-25 20:19:09 | I |     + error = [0.5728]
24-11-25 20:19:09 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 20:19:10 | I |       - range scale = [    1.0000]
24-11-25 20:19:10 | I |         sum  error  = [    1.0495]
24-11-25 20:19:10 | I |         best error  = [    1.0495]
24-11-25 20:19:10 | I |     + error = [1.0495]
24-11-25 20:19:11 | I |       - range scale = [    1.0000]
24-11-25 20:19:11 | I |         sum  error  = [   11.6155]
24-11-25 20:19:11 | I |         best error  = [   11.6155]
24-11-25 20:19:11 | I |     + error = [11.6155]
24-11-25 20:19:11 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 20:19:12 | I |       - range scale = [    1.0000]
24-11-25 20:19:12 | I |         sum  error  = [    1.2124]
24-11-25 20:19:12 | I |         best error  = [    1.2124]
24-11-25 20:19:12 | I |     + error = [1.2124]
24-11-25 20:19:12 | I |       - range scale = [    1.0000]
24-11-25 20:19:12 | I |         sum  error  = [   11.9800]
24-11-25 20:19:12 | I |         best error  = [   11.9800]
24-11-25 20:19:12 | I |     + error = [11.9800]
24-11-25 20:19:13 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 20:19:13 | I |       - range scale = [    1.0000]
24-11-25 20:19:13 | I |         sum  error  = [    3.7564]
24-11-25 20:19:13 | I |         best error  = [    3.7564]
24-11-25 20:19:13 | I |     + error = [3.7564]
24-11-25 20:19:14 | I |       - range scale = [    1.0000]
24-11-25 20:19:14 | I |         sum  error  = [   20.2984]
24-11-25 20:19:14 | I |         best error  = [   20.2984]
24-11-25 20:19:14 | I |     + error = [20.2984]
24-11-25 20:19:14 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 20:19:16 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 20:19:17 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 20:19:19 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 20:19:20 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 20:19:21 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 20:19:23 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 20:19:26 | I | quantizing activations for layer model.layers.0
24-11-25 20:19:26 | I | collecting info in model.layers.0
24-11-25 20:19:26 | I | collecting info in model.layers.0
24-11-25 20:19:26 | I | collecting info in model.layers.0
24-11-25 20:19:26 | I | collecting info in model.layers.0
24-11-25 20:19:27 | I | collecting calibration activations in model.layers.0
24-11-25 20:19:27 | I | collecting calibration activations in model.layers.0
24-11-25 20:19:27 | I | collecting calibration activations in model.layers.0
24-11-25 20:19:27 | I | collecting calibration activations in model.layers.0
24-11-25 20:19:29 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 20:19:29 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 20:19:29 | I | - Evaluator: gptq
24-11-25 20:19:29 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 20:19:29 | I | - Batch_size: 8
24-11-25 20:19:29 | I |   + Max_seq_length: 2048
24-11-25 20:20:10 | I |     - Results:
24-11-25 20:20:10 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 20:20:10 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 20:20:10 | I |       |wikitext |      1|word_perplexity|7.8481|  |7.8481|
24-11-25 20:20:10 | I |       |val_valid|      1|word_perplexity|9.1753|  |9.1753|
24-11-25 20:20:10 | I |       
24-11-25 20:20:10 | I | forward this layer
24-11-25 20:20:10 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/177.pt
24-11-25 20:20:10 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/177.pt
24-11-25 20:20:10 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 20:20:10 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 20:20:10 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 20:20:10 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 20:20:10 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 20:20:10 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 20:20:10 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 20:20:10 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 20:20:10 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 20:20:10 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 20:20:10 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 20:20:10 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 20:20:10 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 20:20:10 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 20:20:11 | I | [74] done with optimizer step
24-11-25 20:20:11 | I | epoch 001:     89 / 409600000 loss=0.000207485, loss_per_token=0.42493, loss_sum=13924.1, wps=153.2, ups=0, wpb=32768, bsz=64, num_updates=75, lr=0.000149987, gnorm=25.123, clip=100, loss_scale=0.0078, train_wall=214, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=19341, lmquant_ppl_result_wikitext_in_train_no_quant=7.78227, lmquant_ppl_result_val_in_train_no_quant=9.12666, lmquant_ppl_result_wikitext_in_train_with_quant=7.84813, lmquant_ppl_result_val_in_train_with_quant=9.1753
24-11-25 20:20:11 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 20:20:11 | I | in layer model.layers.0
24-11-25 20:20:11 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 20:20:11 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 20:20:11 | I | - Evaluator: gptq
24-11-25 20:20:11 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 20:20:11 | I | - Batch_size: 8
24-11-25 20:20:11 | I |   + Max_seq_length: 2048
24-11-25 20:20:49 | I |     - Results:
24-11-25 20:20:49 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 20:20:49 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 20:20:49 | I |       |wikitext |      1|word_perplexity|7.7697|  |7.7697|
24-11-25 20:20:49 | I |       |val_valid|      1|word_perplexity|9.1137|  |9.1137|
24-11-25 20:20:49 | I |       
24-11-25 20:20:49 | I | quantizing weights for layer model.layers.0
24-11-25 20:20:49 | I | collecting info in model.layers.0
24-11-25 20:20:49 | I | collecting info in model.layers.0
24-11-25 20:20:49 | I | collecting info in model.layers.0
24-11-25 20:20:49 | I | collecting info in model.layers.0
24-11-25 20:20:50 | I | collecting calibration activations in model.layers.0
24-11-25 20:20:50 | I | collecting calibration activations in model.layers.0
24-11-25 20:20:50 | I | collecting calibration activations in model.layers.0
24-11-25 20:20:50 | I | collecting calibration activations in model.layers.0
24-11-25 20:20:50 | I | - Quantizing decoder layer model.layers.0
24-11-25 20:20:50 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 20:20:51 | I |       - range scale = [    1.0000]
24-11-25 20:20:51 | I |         sum  error  = [    0.0626]
24-11-25 20:20:51 | I |         best error  = [    0.0626]
24-11-25 20:20:51 | I |     + error = [0.0626]
24-11-25 20:20:52 | I |       - range scale = [    1.0000]
24-11-25 20:20:52 | I |         sum  error  = [    0.5933]
24-11-25 20:20:52 | I |         best error  = [    0.5933]
24-11-25 20:20:52 | I |     + error = [0.5933]
24-11-25 20:20:52 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 20:20:53 | I |       - range scale = [    1.0000]
24-11-25 20:20:53 | I |         sum  error  = [    0.0702]
24-11-25 20:20:53 | I |         best error  = [    0.0702]
24-11-25 20:20:53 | I |     + error = [0.0702]
24-11-25 20:20:53 | I |       - range scale = [    1.0000]
24-11-25 20:20:53 | I |         sum  error  = [    0.5608]
24-11-25 20:20:53 | I |         best error  = [    0.5608]
24-11-25 20:20:53 | I |     + error = [0.5608]
24-11-25 20:20:53 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 20:20:54 | I |       - range scale = [    1.0000]
24-11-25 20:20:54 | I |         sum  error  = [    0.2342]
24-11-25 20:20:54 | I |         best error  = [    0.2342]
24-11-25 20:20:54 | I |     + error = [0.2342]
24-11-25 20:20:55 | I |       - range scale = [    1.0000]
24-11-25 20:20:55 | I |         sum  error  = [    1.8574]
24-11-25 20:20:55 | I |         best error  = [    1.8574]
24-11-25 20:20:55 | I |     + error = [1.8574]
24-11-25 20:20:55 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 20:20:56 | I |       - range scale = [    1.0000]
24-11-25 20:20:56 | I |         sum  error  = [    0.0595]
24-11-25 20:20:56 | I |         best error  = [    0.0595]
24-11-25 20:20:56 | I |     + error = [0.0595]
24-11-25 20:20:56 | I |       - range scale = [    1.0000]
24-11-25 20:20:56 | I |         sum  error  = [    0.5684]
24-11-25 20:20:56 | I |         best error  = [    0.5684]
24-11-25 20:20:56 | I |     + error = [0.5684]
24-11-25 20:20:57 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 20:20:57 | I |       - range scale = [    1.0000]
24-11-25 20:20:57 | I |         sum  error  = [    1.0261]
24-11-25 20:20:57 | I |         best error  = [    1.0261]
24-11-25 20:20:57 | I |     + error = [1.0261]
24-11-25 20:20:58 | I |       - range scale = [    1.0000]
24-11-25 20:20:58 | I |         sum  error  = [   11.3540]
24-11-25 20:20:58 | I |         best error  = [   11.3540]
24-11-25 20:20:58 | I |     + error = [11.3540]
24-11-25 20:20:58 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 20:20:59 | I |       - range scale = [    1.0000]
24-11-25 20:20:59 | I |         sum  error  = [    1.1863]
24-11-25 20:20:59 | I |         best error  = [    1.1863]
24-11-25 20:20:59 | I |     + error = [1.1863]
24-11-25 20:21:00 | I |       - range scale = [    1.0000]
24-11-25 20:21:00 | I |         sum  error  = [   11.7076]
24-11-25 20:21:00 | I |         best error  = [   11.7076]
24-11-25 20:21:00 | I |     + error = [11.7076]
24-11-25 20:21:00 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 20:21:01 | I |       - range scale = [    1.0000]
24-11-25 20:21:01 | I |         sum  error  = [    3.5861]
24-11-25 20:21:01 | I |         best error  = [    3.5861]
24-11-25 20:21:01 | I |     + error = [3.5861]
24-11-25 20:21:01 | I |       - range scale = [    1.0000]
24-11-25 20:21:01 | I |         sum  error  = [   19.2557]
24-11-25 20:21:01 | I |         best error  = [   19.2557]
24-11-25 20:21:01 | I |     + error = [19.2557]
24-11-25 20:21:02 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 20:21:03 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 20:21:04 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 20:21:06 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 20:21:07 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 20:21:08 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 20:21:10 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 20:21:13 | I | quantizing activations for layer model.layers.0
24-11-25 20:21:13 | I | collecting info in model.layers.0
24-11-25 20:21:13 | I | collecting info in model.layers.0
24-11-25 20:21:13 | I | collecting info in model.layers.0
24-11-25 20:21:13 | I | collecting info in model.layers.0
24-11-25 20:21:14 | I | collecting calibration activations in model.layers.0
24-11-25 20:21:14 | I | collecting calibration activations in model.layers.0
24-11-25 20:21:14 | I | collecting calibration activations in model.layers.0
24-11-25 20:21:14 | I | collecting calibration activations in model.layers.0
24-11-25 20:21:16 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 20:21:16 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 20:21:16 | I | - Evaluator: gptq
24-11-25 20:21:16 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 20:21:16 | I | - Batch_size: 8
24-11-25 20:21:16 | I |   + Max_seq_length: 2048
24-11-25 20:21:57 | I |     - Results:
24-11-25 20:21:57 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 20:21:57 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 20:21:57 | I |       |wikitext |      1|word_perplexity|7.8122|  |7.8122|
24-11-25 20:21:57 | I |       |val_valid|      1|word_perplexity|9.1441|  |9.1441|
24-11-25 20:21:57 | I |       
24-11-25 20:21:57 | I | forward this layer
24-11-25 20:21:57 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/178.pt
24-11-25 20:21:57 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/178.pt
24-11-25 20:21:57 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 20:21:57 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 20:21:57 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 20:21:57 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 20:21:57 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 20:21:57 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 20:21:57 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 20:21:57 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 20:21:57 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 20:21:57 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 20:21:57 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 20:21:57 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 20:21:57 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 20:21:57 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 20:21:57 | I | in layer model.layers.0
24-11-25 20:21:57 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 20:21:57 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 20:21:57 | I | - Evaluator: gptq
24-11-25 20:21:57 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 20:21:57 | I | - Batch_size: 8
24-11-25 20:21:57 | I |   + Max_seq_length: 2048
24-11-25 20:22:36 | I |     - Results:
24-11-25 20:22:36 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 20:22:36 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 20:22:36 | I |       |wikitext |      1|word_perplexity|7.7697|  |7.7697|
24-11-25 20:22:36 | I |       |val_valid|      1|word_perplexity|9.1137|  |9.1137|
24-11-25 20:22:36 | I |       
24-11-25 20:22:36 | I | quantizing weights for layer model.layers.0
24-11-25 20:22:36 | I | collecting info in model.layers.0
24-11-25 20:22:36 | I | collecting info in model.layers.0
24-11-25 20:22:36 | I | collecting info in model.layers.0
24-11-25 20:22:36 | I | collecting info in model.layers.0
24-11-25 20:22:36 | I | collecting calibration activations in model.layers.0
24-11-25 20:22:36 | I | collecting calibration activations in model.layers.0
24-11-25 20:22:36 | I | collecting calibration activations in model.layers.0
24-11-25 20:22:37 | I | collecting calibration activations in model.layers.0
24-11-25 20:22:37 | I | - Quantizing decoder layer model.layers.0
24-11-25 20:22:37 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 20:22:38 | I |       - range scale = [    1.0000]
24-11-25 20:22:38 | I |         sum  error  = [    0.0614]
24-11-25 20:22:38 | I |         best error  = [    0.0614]
24-11-25 20:22:38 | I |     + error = [0.0614]
24-11-25 20:22:38 | I |       - range scale = [    1.0000]
24-11-25 20:22:38 | I |         sum  error  = [    0.6005]
24-11-25 20:22:38 | I |         best error  = [    0.6005]
24-11-25 20:22:38 | I |     + error = [0.6005]
24-11-25 20:22:39 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 20:22:39 | I |       - range scale = [    1.0000]
24-11-25 20:22:39 | I |         sum  error  = [    0.0673]
24-11-25 20:22:39 | I |         best error  = [    0.0673]
24-11-25 20:22:39 | I |     + error = [0.0673]
24-11-25 20:22:40 | I |       - range scale = [    1.0000]
24-11-25 20:22:40 | I |         sum  error  = [    0.5623]
24-11-25 20:22:40 | I |         best error  = [    0.5623]
24-11-25 20:22:40 | I |     + error = [0.5623]
24-11-25 20:22:40 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 20:22:41 | I |       - range scale = [    1.0000]
24-11-25 20:22:41 | I |         sum  error  = [    0.2336]
24-11-25 20:22:41 | I |         best error  = [    0.2336]
24-11-25 20:22:41 | I |     + error = [0.2336]
24-11-25 20:22:41 | I |       - range scale = [    1.0000]
24-11-25 20:22:41 | I |         sum  error  = [    1.8607]
24-11-25 20:22:41 | I |         best error  = [    1.8607]
24-11-25 20:22:41 | I |     + error = [1.8607]
24-11-25 20:22:42 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 20:22:42 | I |       - range scale = [    1.0000]
24-11-25 20:22:42 | I |         sum  error  = [    0.0645]
24-11-25 20:22:42 | I |         best error  = [    0.0645]
24-11-25 20:22:42 | I |     + error = [0.0645]
24-11-25 20:22:43 | I |       - range scale = [    1.0000]
24-11-25 20:22:43 | I |         sum  error  = [    0.6194]
24-11-25 20:22:43 | I |         best error  = [    0.6194]
24-11-25 20:22:43 | I |     + error = [0.6194]
24-11-25 20:22:43 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 20:22:44 | I |       - range scale = [    1.0000]
24-11-25 20:22:44 | I |         sum  error  = [    1.0892]
24-11-25 20:22:44 | I |         best error  = [    1.0892]
24-11-25 20:22:44 | I |     + error = [1.0892]
24-11-25 20:22:45 | I |       - range scale = [    1.0000]
24-11-25 20:22:45 | I |         sum  error  = [   12.0525]
24-11-25 20:22:45 | I |         best error  = [   12.0525]
24-11-25 20:22:45 | I |     + error = [12.0525]
24-11-25 20:22:45 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 20:22:46 | I |       - range scale = [    1.0000]
24-11-25 20:22:46 | I |         sum  error  = [    1.2588]
24-11-25 20:22:46 | I |         best error  = [    1.2588]
24-11-25 20:22:46 | I |     + error = [1.2588]
24-11-25 20:22:46 | I |       - range scale = [    1.0000]
24-11-25 20:22:46 | I |         sum  error  = [   12.4706]
24-11-25 20:22:46 | I |         best error  = [   12.4706]
24-11-25 20:22:46 | I |     + error = [12.4706]
24-11-25 20:22:47 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 20:22:47 | I |       - range scale = [    1.0000]
24-11-25 20:22:47 | I |         sum  error  = [    4.0544]
24-11-25 20:22:47 | I |         best error  = [    4.0544]
24-11-25 20:22:47 | I |     + error = [4.0544]
24-11-25 20:22:48 | I |       - range scale = [    1.0000]
24-11-25 20:22:48 | I |         sum  error  = [   20.9386]
24-11-25 20:22:48 | I |         best error  = [   20.9386]
24-11-25 20:22:48 | I |     + error = [20.9386]
24-11-25 20:22:48 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 20:22:50 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 20:22:51 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 20:22:53 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 20:22:55 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 20:22:57 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 20:22:58 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 20:23:02 | I | quantizing activations for layer model.layers.0
24-11-25 20:23:02 | I | collecting info in model.layers.0
24-11-25 20:23:02 | I | collecting info in model.layers.0
24-11-25 20:23:02 | I | collecting info in model.layers.0
24-11-25 20:23:02 | I | collecting info in model.layers.0
24-11-25 20:23:03 | I | collecting calibration activations in model.layers.0
24-11-25 20:23:03 | I | collecting calibration activations in model.layers.0
24-11-25 20:23:03 | I | collecting calibration activations in model.layers.0
24-11-25 20:23:03 | I | collecting calibration activations in model.layers.0
24-11-25 20:23:05 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 20:23:05 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 20:23:05 | I | - Evaluator: gptq
24-11-25 20:23:05 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 20:23:05 | I | - Batch_size: 8
24-11-25 20:23:05 | I |   + Max_seq_length: 2048
24-11-25 20:23:47 | I |     - Results:
24-11-25 20:23:47 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 20:23:47 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 20:23:47 | I |       |wikitext |      1|word_perplexity|7.8189|  |7.8189|
24-11-25 20:23:47 | I |       |val_valid|      1|word_perplexity|9.1625|  |9.1625|
24-11-25 20:23:47 | I |       
24-11-25 20:23:47 | I | forward this layer
24-11-25 20:23:47 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/179.pt
24-11-25 20:23:47 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/179.pt
24-11-25 20:23:47 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 20:23:47 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 20:23:47 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 20:23:47 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 20:23:47 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 20:23:47 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 20:23:47 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 20:23:47 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 20:23:47 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 20:23:47 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 20:23:47 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 20:23:47 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 20:23:47 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 20:23:47 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 20:23:47 | I | [75] done with optimizer step
24-11-25 20:23:47 | I | epoch 001:     90 / 409600000 loss=0.00016895, loss_per_token=0.346009, loss_sum=11338, wps=151, ups=0, wpb=32768, bsz=64, num_updates=76, lr=0.000149987, gnorm=51.959, clip=100, loss_scale=0.0078, train_wall=217, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=19558, lmquant_ppl_result_wikitext_in_train_no_quant=7.76973, lmquant_ppl_result_val_in_train_no_quant=9.11372, lmquant_ppl_result_wikitext_in_train_with_quant=7.81885, lmquant_ppl_result_val_in_train_with_quant=9.16254
24-11-25 20:23:48 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 20:23:48 | I | in layer model.layers.0
24-11-25 20:23:48 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 20:23:48 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 20:23:48 | I | - Evaluator: gptq
24-11-25 20:23:48 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 20:23:48 | I | - Batch_size: 8
24-11-25 20:23:48 | I |   + Max_seq_length: 2048
24-11-25 20:24:26 | I |     - Results:
24-11-25 20:24:26 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 20:24:26 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 20:24:26 | I |       |wikitext |      1|word_perplexity|7.7567|  |7.7567|
24-11-25 20:24:26 | I |       |val_valid|      1|word_perplexity|9.0820|  |9.0820|
24-11-25 20:24:26 | I |       
24-11-25 20:24:26 | I | quantizing weights for layer model.layers.0
24-11-25 20:24:26 | I | collecting info in model.layers.0
24-11-25 20:24:26 | I | collecting info in model.layers.0
24-11-25 20:24:26 | I | collecting info in model.layers.0
24-11-25 20:24:26 | I | collecting info in model.layers.0
24-11-25 20:24:26 | I | collecting calibration activations in model.layers.0
24-11-25 20:24:27 | I | collecting calibration activations in model.layers.0
24-11-25 20:24:27 | I | collecting calibration activations in model.layers.0
24-11-25 20:24:27 | I | collecting calibration activations in model.layers.0
24-11-25 20:24:27 | I | - Quantizing decoder layer model.layers.0
24-11-25 20:24:27 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 20:24:28 | I |       - range scale = [    1.0000]
24-11-25 20:24:28 | I |         sum  error  = [    0.0577]
24-11-25 20:24:28 | I |         best error  = [    0.0577]
24-11-25 20:24:28 | I |     + error = [0.0577]
24-11-25 20:24:28 | I |       - range scale = [    1.0000]
24-11-25 20:24:28 | I |         sum  error  = [    0.5529]
24-11-25 20:24:28 | I |         best error  = [    0.5529]
24-11-25 20:24:28 | I |     + error = [0.5529]
24-11-25 20:24:29 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 20:24:29 | I |       - range scale = [    1.0000]
24-11-25 20:24:29 | I |         sum  error  = [    0.0663]
24-11-25 20:24:29 | I |         best error  = [    0.0663]
24-11-25 20:24:29 | I |     + error = [0.0663]
24-11-25 20:24:30 | I |       - range scale = [    1.0000]
24-11-25 20:24:30 | I |         sum  error  = [    0.5228]
24-11-25 20:24:30 | I |         best error  = [    0.5228]
24-11-25 20:24:30 | I |     + error = [0.5228]
24-11-25 20:24:30 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 20:24:31 | I |       - range scale = [    1.0000]
24-11-25 20:24:31 | I |         sum  error  = [    0.2333]
24-11-25 20:24:31 | I |         best error  = [    0.2333]
24-11-25 20:24:31 | I |     + error = [0.2333]
24-11-25 20:24:32 | I |       - range scale = [    1.0000]
24-11-25 20:24:32 | I |         sum  error  = [    1.8523]
24-11-25 20:24:32 | I |         best error  = [    1.8523]
24-11-25 20:24:32 | I |     + error = [1.8523]
24-11-25 20:24:32 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 20:24:33 | I |       - range scale = [    1.0000]
24-11-25 20:24:33 | I |         sum  error  = [    0.0559]
24-11-25 20:24:33 | I |         best error  = [    0.0559]
24-11-25 20:24:33 | I |     + error = [0.0559]
24-11-25 20:24:33 | I |       - range scale = [    1.0000]
24-11-25 20:24:33 | I |         sum  error  = [    0.5366]
24-11-25 20:24:33 | I |         best error  = [    0.5366]
24-11-25 20:24:33 | I |     + error = [0.5366]
24-11-25 20:24:33 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 20:24:34 | I |       - range scale = [    1.0000]
24-11-25 20:24:34 | I |         sum  error  = [    1.0095]
24-11-25 20:24:34 | I |         best error  = [    1.0095]
24-11-25 20:24:34 | I |     + error = [1.0095]
24-11-25 20:24:35 | I |       - range scale = [    1.0000]
24-11-25 20:24:35 | I |         sum  error  = [   11.1839]
24-11-25 20:24:35 | I |         best error  = [   11.1839]
24-11-25 20:24:35 | I |     + error = [11.1839]
24-11-25 20:24:35 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 20:24:36 | I |       - range scale = [    1.0000]
24-11-25 20:24:36 | I |         sum  error  = [    1.1677]
24-11-25 20:24:36 | I |         best error  = [    1.1677]
24-11-25 20:24:36 | I |     + error = [1.1677]
24-11-25 20:24:37 | I |       - range scale = [    1.0000]
24-11-25 20:24:37 | I |         sum  error  = [   11.5112]
24-11-25 20:24:37 | I |         best error  = [   11.5112]
24-11-25 20:24:37 | I |     + error = [11.5112]
24-11-25 20:24:37 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 20:24:37 | I |       - range scale = [    1.0000]
24-11-25 20:24:37 | I |         sum  error  = [    2.2217]
24-11-25 20:24:37 | I |         best error  = [    2.2217]
24-11-25 20:24:37 | I |     + error = [2.2217]
24-11-25 20:24:38 | I |       - range scale = [    1.0000]
24-11-25 20:24:38 | I |         sum  error  = [   13.2239]
24-11-25 20:24:38 | I |         best error  = [   13.2239]
24-11-25 20:24:38 | I |     + error = [13.2239]
24-11-25 20:24:38 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 20:24:40 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 20:24:41 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 20:24:43 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 20:24:44 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 20:24:45 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 20:24:47 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 20:24:50 | I | quantizing activations for layer model.layers.0
24-11-25 20:24:50 | I | collecting info in model.layers.0
24-11-25 20:24:50 | I | collecting info in model.layers.0
24-11-25 20:24:50 | I | collecting info in model.layers.0
24-11-25 20:24:50 | I | collecting info in model.layers.0
24-11-25 20:24:51 | I | collecting calibration activations in model.layers.0
24-11-25 20:24:51 | I | collecting calibration activations in model.layers.0
24-11-25 20:24:51 | I | collecting calibration activations in model.layers.0
24-11-25 20:24:51 | I | collecting calibration activations in model.layers.0
24-11-25 20:24:53 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 20:24:53 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 20:24:53 | I | - Evaluator: gptq
24-11-25 20:24:53 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 20:24:53 | I | - Batch_size: 8
24-11-25 20:24:53 | I |   + Max_seq_length: 2048
24-11-25 20:25:34 | I |     - Results:
24-11-25 20:25:34 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 20:25:34 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 20:25:34 | I |       |wikitext |      1|word_perplexity|7.8035|  |7.8035|
24-11-25 20:25:34 | I |       |val_valid|      1|word_perplexity|9.1151|  |9.1151|
24-11-25 20:25:34 | I |       
24-11-25 20:25:34 | I | forward this layer
24-11-25 20:25:34 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/180.pt
24-11-25 20:25:34 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/180.pt
24-11-25 20:25:34 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 20:25:34 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 20:25:34 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 20:25:34 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 20:25:34 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 20:25:34 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 20:25:34 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 20:25:34 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 20:25:34 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 20:25:34 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 20:25:34 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 20:25:34 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 20:25:34 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 20:25:34 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 20:25:35 | I | in layer model.layers.0
24-11-25 20:25:35 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 20:25:35 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 20:25:35 | I | - Evaluator: gptq
24-11-25 20:25:35 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 20:25:35 | I | - Batch_size: 8
24-11-25 20:25:35 | I |   + Max_seq_length: 2048
24-11-25 20:26:13 | I |     - Results:
24-11-25 20:26:13 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 20:26:13 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 20:26:13 | I |       |wikitext |      1|word_perplexity|7.7567|  |7.7567|
24-11-25 20:26:13 | I |       |val_valid|      1|word_perplexity|9.0820|  |9.0820|
24-11-25 20:26:13 | I |       
24-11-25 20:26:13 | I | quantizing weights for layer model.layers.0
24-11-25 20:26:13 | I | collecting info in model.layers.0
24-11-25 20:26:13 | I | collecting info in model.layers.0
24-11-25 20:26:13 | I | collecting info in model.layers.0
24-11-25 20:26:13 | I | collecting info in model.layers.0
24-11-25 20:26:13 | I | collecting calibration activations in model.layers.0
24-11-25 20:26:13 | I | collecting calibration activations in model.layers.0
24-11-25 20:26:13 | I | collecting calibration activations in model.layers.0
24-11-25 20:26:14 | I | collecting calibration activations in model.layers.0
24-11-25 20:26:14 | I | - Quantizing decoder layer model.layers.0
24-11-25 20:26:14 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 20:26:15 | I |       - range scale = [    1.0000]
24-11-25 20:26:15 | I |         sum  error  = [    0.0570]
24-11-25 20:26:15 | I |         best error  = [    0.0570]
24-11-25 20:26:15 | I |     + error = [0.0570]
24-11-25 20:26:15 | I |       - range scale = [    1.0000]
24-11-25 20:26:15 | I |         sum  error  = [    0.5527]
24-11-25 20:26:15 | I |         best error  = [    0.5527]
24-11-25 20:26:15 | I |     + error = [0.5527]
24-11-25 20:26:15 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 20:26:16 | I |       - range scale = [    1.0000]
24-11-25 20:26:16 | I |         sum  error  = [    0.0664]
24-11-25 20:26:16 | I |         best error  = [    0.0664]
24-11-25 20:26:16 | I |     + error = [0.0664]
24-11-25 20:26:17 | I |       - range scale = [    1.0000]
24-11-25 20:26:17 | I |         sum  error  = [    0.5580]
24-11-25 20:26:17 | I |         best error  = [    0.5580]
24-11-25 20:26:17 | I |     + error = [0.5580]
24-11-25 20:26:17 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 20:26:18 | I |       - range scale = [    1.0000]
24-11-25 20:26:18 | I |         sum  error  = [    0.2286]
24-11-25 20:26:18 | I |         best error  = [    0.2286]
24-11-25 20:26:18 | I |     + error = [0.2286]
24-11-25 20:26:18 | I |       - range scale = [    1.0000]
24-11-25 20:26:18 | I |         sum  error  = [    1.8256]
24-11-25 20:26:18 | I |         best error  = [    1.8256]
24-11-25 20:26:18 | I |     + error = [1.8256]
24-11-25 20:26:19 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 20:26:19 | I |       - range scale = [    1.0000]
24-11-25 20:26:19 | I |         sum  error  = [    0.0593]
24-11-25 20:26:19 | I |         best error  = [    0.0593]
24-11-25 20:26:19 | I |     + error = [0.0593]
24-11-25 20:26:20 | I |       - range scale = [    1.0000]
24-11-25 20:26:20 | I |         sum  error  = [    0.5746]
24-11-25 20:26:20 | I |         best error  = [    0.5746]
24-11-25 20:26:20 | I |     + error = [0.5746]
24-11-25 20:26:20 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 20:26:21 | I |       - range scale = [    1.0000]
24-11-25 20:26:21 | I |         sum  error  = [    1.0553]
24-11-25 20:26:21 | I |         best error  = [    1.0553]
24-11-25 20:26:21 | I |     + error = [1.0553]
24-11-25 20:26:22 | I |       - range scale = [    1.0000]
24-11-25 20:26:22 | I |         sum  error  = [   11.6968]
24-11-25 20:26:22 | I |         best error  = [   11.6968]
24-11-25 20:26:22 | I |     + error = [11.6968]
24-11-25 20:26:22 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 20:26:23 | I |       - range scale = [    1.0000]
24-11-25 20:26:23 | I |         sum  error  = [    1.2227]
24-11-25 20:26:23 | I |         best error  = [    1.2227]
24-11-25 20:26:23 | I |     + error = [1.2227]
24-11-25 20:26:23 | I |       - range scale = [    1.0000]
24-11-25 20:26:23 | I |         sum  error  = [   12.0825]
24-11-25 20:26:23 | I |         best error  = [   12.0825]
24-11-25 20:26:23 | I |     + error = [12.0825]
24-11-25 20:26:24 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 20:26:24 | I |       - range scale = [    1.0000]
24-11-25 20:26:24 | I |         sum  error  = [    2.7938]
24-11-25 20:26:24 | I |         best error  = [    2.7938]
24-11-25 20:26:24 | I |     + error = [2.7938]
24-11-25 20:26:25 | I |       - range scale = [    1.0000]
24-11-25 20:26:25 | I |         sum  error  = [   14.7147]
24-11-25 20:26:25 | I |         best error  = [   14.7147]
24-11-25 20:26:25 | I |     + error = [14.7147]
24-11-25 20:26:25 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 20:26:27 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 20:26:28 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 20:26:29 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 20:26:31 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 20:26:32 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 20:26:34 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 20:26:37 | I | quantizing activations for layer model.layers.0
24-11-25 20:26:37 | I | collecting info in model.layers.0
24-11-25 20:26:37 | I | collecting info in model.layers.0
24-11-25 20:26:37 | I | collecting info in model.layers.0
24-11-25 20:26:37 | I | collecting info in model.layers.0
24-11-25 20:26:37 | I | collecting calibration activations in model.layers.0
24-11-25 20:26:37 | I | collecting calibration activations in model.layers.0
24-11-25 20:26:38 | I | collecting calibration activations in model.layers.0
24-11-25 20:26:38 | I | collecting calibration activations in model.layers.0
24-11-25 20:26:39 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 20:26:39 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 20:26:39 | I | - Evaluator: gptq
24-11-25 20:26:39 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 20:26:39 | I | - Batch_size: 8
24-11-25 20:26:39 | I |   + Max_seq_length: 2048
24-11-25 20:27:21 | I |     - Results:
24-11-25 20:27:21 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 20:27:21 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 20:27:21 | I |       |wikitext |      1|word_perplexity|7.8013|  |7.8013|
24-11-25 20:27:21 | I |       |val_valid|      1|word_perplexity|9.1195|  |9.1195|
24-11-25 20:27:21 | I |       
24-11-25 20:27:21 | I | forward this layer
24-11-25 20:27:21 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/181.pt
24-11-25 20:27:21 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/181.pt
24-11-25 20:27:21 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 20:27:21 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 20:27:21 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 20:27:21 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 20:27:21 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 20:27:21 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 20:27:21 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 20:27:21 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 20:27:21 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 20:27:21 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 20:27:21 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 20:27:21 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 20:27:21 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 20:27:21 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 20:27:21 | I | [76] done with optimizer step
24-11-25 20:27:21 | I | epoch 001:     91 / 409600000 loss=6.53803e-05, loss_per_token=0.133899, loss_sum=4387.6, wps=153.2, ups=0, wpb=32768, bsz=64, num_updates=77, lr=0.000149986, gnorm=18.382, clip=100, loss_scale=0.0078, train_wall=214, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=19772, lmquant_ppl_result_wikitext_in_train_no_quant=7.75667, lmquant_ppl_result_val_in_train_no_quant=9.082, lmquant_ppl_result_wikitext_in_train_with_quant=7.80133, lmquant_ppl_result_val_in_train_with_quant=9.1195
24-11-25 20:27:22 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 20:27:22 | I | in layer model.layers.0
24-11-25 20:27:22 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 20:27:22 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 20:27:22 | I | - Evaluator: gptq
24-11-25 20:27:22 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 20:27:22 | I | - Batch_size: 8
24-11-25 20:27:22 | I |   + Max_seq_length: 2048
24-11-25 20:28:00 | I |     - Results:
24-11-25 20:28:00 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 20:28:00 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 20:28:00 | I |       |wikitext |      1|word_perplexity|7.7518|  |7.7518|
24-11-25 20:28:00 | I |       |val_valid|      1|word_perplexity|9.0470|  |9.0470|
24-11-25 20:28:00 | I |       
24-11-25 20:28:00 | I | quantizing weights for layer model.layers.0
24-11-25 20:28:00 | I | collecting info in model.layers.0
24-11-25 20:28:00 | I | collecting info in model.layers.0
24-11-25 20:28:00 | I | collecting info in model.layers.0
24-11-25 20:28:00 | I | collecting info in model.layers.0
24-11-25 20:28:00 | I | collecting calibration activations in model.layers.0
24-11-25 20:28:00 | I | collecting calibration activations in model.layers.0
24-11-25 20:28:01 | I | collecting calibration activations in model.layers.0
24-11-25 20:28:01 | I | collecting calibration activations in model.layers.0
24-11-25 20:28:01 | I | - Quantizing decoder layer model.layers.0
24-11-25 20:28:01 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 20:28:02 | I |       - range scale = [    1.0000]
24-11-25 20:28:02 | I |         sum  error  = [    0.0538]
24-11-25 20:28:02 | I |         best error  = [    0.0538]
24-11-25 20:28:02 | I |     + error = [0.0538]
24-11-25 20:28:02 | I |       - range scale = [    1.0000]
24-11-25 20:28:02 | I |         sum  error  = [    0.5492]
24-11-25 20:28:02 | I |         best error  = [    0.5492]
24-11-25 20:28:02 | I |     + error = [0.5492]
24-11-25 20:28:03 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 20:28:03 | I |       - range scale = [    1.0000]
24-11-25 20:28:03 | I |         sum  error  = [    0.0665]
24-11-25 20:28:03 | I |         best error  = [    0.0665]
24-11-25 20:28:03 | I |     + error = [0.0665]
24-11-25 20:28:04 | I |       - range scale = [    1.0000]
24-11-25 20:28:04 | I |         sum  error  = [    0.5545]
24-11-25 20:28:04 | I |         best error  = [    0.5545]
24-11-25 20:28:04 | I |     + error = [0.5545]
24-11-25 20:28:04 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 20:28:05 | I |       - range scale = [    1.0000]
24-11-25 20:28:05 | I |         sum  error  = [    0.2371]
24-11-25 20:28:05 | I |         best error  = [    0.2371]
24-11-25 20:28:05 | I |     + error = [0.2371]
24-11-25 20:28:06 | I |       - range scale = [    1.0000]
24-11-25 20:28:06 | I |         sum  error  = [    1.8333]
24-11-25 20:28:06 | I |         best error  = [    1.8333]
24-11-25 20:28:06 | I |     + error = [1.8333]
24-11-25 20:28:06 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 20:28:06 | I |       - range scale = [    1.0000]
24-11-25 20:28:06 | I |         sum  error  = [    0.0622]
24-11-25 20:28:06 | I |         best error  = [    0.0622]
24-11-25 20:28:06 | I |     + error = [0.0622]
24-11-25 20:28:07 | I |       - range scale = [    1.0000]
24-11-25 20:28:07 | I |         sum  error  = [    0.5960]
24-11-25 20:28:07 | I |         best error  = [    0.5960]
24-11-25 20:28:07 | I |     + error = [0.5960]
24-11-25 20:28:07 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 20:28:08 | I |       - range scale = [    1.0000]
24-11-25 20:28:08 | I |         sum  error  = [    1.0632]
24-11-25 20:28:08 | I |         best error  = [    1.0632]
24-11-25 20:28:08 | I |     + error = [1.0632]
24-11-25 20:28:09 | I |       - range scale = [    1.0000]
24-11-25 20:28:09 | I |         sum  error  = [   11.7756]
24-11-25 20:28:09 | I |         best error  = [   11.7756]
24-11-25 20:28:09 | I |     + error = [11.7756]
24-11-25 20:28:09 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 20:28:10 | I |       - range scale = [    1.0000]
24-11-25 20:28:10 | I |         sum  error  = [    1.2283]
24-11-25 20:28:10 | I |         best error  = [    1.2283]
24-11-25 20:28:10 | I |     + error = [1.2283]
24-11-25 20:28:10 | I |       - range scale = [    1.0000]
24-11-25 20:28:10 | I |         sum  error  = [   12.1585]
24-11-25 20:28:10 | I |         best error  = [   12.1585]
24-11-25 20:28:10 | I |     + error = [12.1585]
24-11-25 20:28:11 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 20:28:11 | I |       - range scale = [    1.0000]
24-11-25 20:28:11 | I |         sum  error  = [    3.4950]
24-11-25 20:28:11 | I |         best error  = [    3.4950]
24-11-25 20:28:11 | I |     + error = [3.4950]
24-11-25 20:28:12 | I |       - range scale = [    1.0000]
24-11-25 20:28:12 | I |         sum  error  = [   18.9292]
24-11-25 20:28:12 | I |         best error  = [   18.9292]
24-11-25 20:28:12 | I |     + error = [18.9292]
24-11-25 20:28:12 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 20:28:14 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 20:28:15 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 20:28:17 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 20:28:18 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 20:28:19 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 20:28:21 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 20:28:24 | I | quantizing activations for layer model.layers.0
24-11-25 20:28:24 | I | collecting info in model.layers.0
24-11-25 20:28:24 | I | collecting info in model.layers.0
24-11-25 20:28:24 | I | collecting info in model.layers.0
24-11-25 20:28:24 | I | collecting info in model.layers.0
24-11-25 20:28:25 | I | collecting calibration activations in model.layers.0
24-11-25 20:28:25 | I | collecting calibration activations in model.layers.0
24-11-25 20:28:25 | I | collecting calibration activations in model.layers.0
24-11-25 20:28:25 | I | collecting calibration activations in model.layers.0
24-11-25 20:28:27 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 20:28:27 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 20:28:27 | I | - Evaluator: gptq
24-11-25 20:28:27 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 20:28:27 | I | - Batch_size: 8
24-11-25 20:28:27 | I |   + Max_seq_length: 2048
24-11-25 20:29:08 | I |     - Results:
24-11-25 20:29:08 | I |       |  Task   |Version|    Metric     |Value|   |Stderr|
24-11-25 20:29:08 | I |       |---------|------:|---------------|----:|---|-----:|
24-11-25 20:29:08 | I |       |wikitext |      1|word_perplexity|7.778|  | 7.778|
24-11-25 20:29:08 | I |       |val_valid|      1|word_perplexity|9.080|  | 9.080|
24-11-25 20:29:08 | I |       
24-11-25 20:29:08 | I | forward this layer
24-11-25 20:29:08 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/182.pt
24-11-25 20:29:08 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/182.pt
24-11-25 20:29:09 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 20:29:09 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 20:29:09 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 20:29:09 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 20:29:09 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 20:29:09 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 20:29:09 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 20:29:09 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 20:29:09 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 20:29:09 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 20:29:09 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 20:29:09 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 20:29:09 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 20:29:09 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 20:29:09 | I | in layer model.layers.0
24-11-25 20:29:09 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 20:29:09 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 20:29:09 | I | - Evaluator: gptq
24-11-25 20:29:09 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 20:29:09 | I | - Batch_size: 8
24-11-25 20:29:09 | I |   + Max_seq_length: 2048
24-11-25 20:29:47 | I |     - Results:
24-11-25 20:29:47 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 20:29:47 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 20:29:47 | I |       |wikitext |      1|word_perplexity|7.7518|  |7.7518|
24-11-25 20:29:47 | I |       |val_valid|      1|word_perplexity|9.0470|  |9.0470|
24-11-25 20:29:47 | I |       
24-11-25 20:29:47 | I | quantizing weights for layer model.layers.0
24-11-25 20:29:47 | I | collecting info in model.layers.0
24-11-25 20:29:47 | I | collecting info in model.layers.0
24-11-25 20:29:47 | I | collecting info in model.layers.0
24-11-25 20:29:47 | I | collecting info in model.layers.0
24-11-25 20:29:48 | I | collecting calibration activations in model.layers.0
24-11-25 20:29:48 | I | collecting calibration activations in model.layers.0
24-11-25 20:29:48 | I | collecting calibration activations in model.layers.0
24-11-25 20:29:48 | I | collecting calibration activations in model.layers.0
24-11-25 20:29:48 | I | - Quantizing decoder layer model.layers.0
24-11-25 20:29:48 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 20:29:49 | I |       - range scale = [    1.0000]
24-11-25 20:29:49 | I |         sum  error  = [    0.0621]
24-11-25 20:29:49 | I |         best error  = [    0.0621]
24-11-25 20:29:49 | I |     + error = [0.0621]
24-11-25 20:29:50 | I |       - range scale = [    1.0000]
24-11-25 20:29:50 | I |         sum  error  = [    0.6340]
24-11-25 20:29:50 | I |         best error  = [    0.6340]
24-11-25 20:29:50 | I |     + error = [0.6340]
24-11-25 20:29:50 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 20:29:51 | I |       - range scale = [    1.0000]
24-11-25 20:29:51 | I |         sum  error  = [    0.0725]
24-11-25 20:29:51 | I |         best error  = [    0.0725]
24-11-25 20:29:51 | I |     + error = [0.0725]
24-11-25 20:29:51 | I |       - range scale = [    1.0000]
24-11-25 20:29:51 | I |         sum  error  = [    0.6118]
24-11-25 20:29:51 | I |         best error  = [    0.6118]
24-11-25 20:29:51 | I |     + error = [0.6118]
24-11-25 20:29:51 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 20:29:52 | I |       - range scale = [    1.0000]
24-11-25 20:29:52 | I |         sum  error  = [    0.2482]
24-11-25 20:29:52 | I |         best error  = [    0.2482]
24-11-25 20:29:52 | I |     + error = [0.2482]
24-11-25 20:29:53 | I |       - range scale = [    1.0000]
24-11-25 20:29:53 | I |         sum  error  = [    1.9189]
24-11-25 20:29:53 | I |         best error  = [    1.9189]
24-11-25 20:29:53 | I |     + error = [1.9189]
24-11-25 20:29:53 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 20:29:54 | I |       - range scale = [    1.0000]
24-11-25 20:29:54 | I |         sum  error  = [    0.0793]
24-11-25 20:29:54 | I |         best error  = [    0.0793]
24-11-25 20:29:54 | I |     + error = [0.0793]
24-11-25 20:29:54 | I |       - range scale = [    1.0000]
24-11-25 20:29:54 | I |         sum  error  = [    0.7545]
24-11-25 20:29:54 | I |         best error  = [    0.7545]
24-11-25 20:29:54 | I |     + error = [0.7545]
24-11-25 20:29:55 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 20:29:55 | I |       - range scale = [    1.0000]
24-11-25 20:29:55 | I |         sum  error  = [    1.1044]
24-11-25 20:29:55 | I |         best error  = [    1.1044]
24-11-25 20:29:55 | I |     + error = [1.1044]
24-11-25 20:29:56 | I |       - range scale = [    1.0000]
24-11-25 20:29:56 | I |         sum  error  = [   12.2453]
24-11-25 20:29:56 | I |         best error  = [   12.2453]
24-11-25 20:29:56 | I |     + error = [12.2453]
24-11-25 20:29:56 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 20:29:57 | I |       - range scale = [    1.0000]
24-11-25 20:29:57 | I |         sum  error  = [    1.2756]
24-11-25 20:29:57 | I |         best error  = [    1.2756]
24-11-25 20:29:57 | I |     + error = [1.2756]
24-11-25 20:29:58 | I |       - range scale = [    1.0000]
24-11-25 20:29:58 | I |         sum  error  = [   12.6566]
24-11-25 20:29:58 | I |         best error  = [   12.6566]
24-11-25 20:29:58 | I |     + error = [12.6566]
24-11-25 20:29:58 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 20:29:59 | I |       - range scale = [    1.0000]
24-11-25 20:29:59 | I |         sum  error  = [    3.1382]
24-11-25 20:29:59 | I |         best error  = [    3.1382]
24-11-25 20:29:59 | I |     + error = [3.1382]
24-11-25 20:29:59 | I |       - range scale = [    1.0000]
24-11-25 20:29:59 | I |         sum  error  = [   16.2180]
24-11-25 20:29:59 | I |         best error  = [   16.2180]
24-11-25 20:29:59 | I |     + error = [16.2180]
24-11-25 20:30:00 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 20:30:01 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 20:30:02 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 20:30:04 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 20:30:05 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 20:30:07 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 20:30:08 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 20:30:11 | I | quantizing activations for layer model.layers.0
24-11-25 20:30:11 | I | collecting info in model.layers.0
24-11-25 20:30:11 | I | collecting info in model.layers.0
24-11-25 20:30:11 | I | collecting info in model.layers.0
24-11-25 20:30:11 | I | collecting info in model.layers.0
24-11-25 20:30:12 | I | collecting calibration activations in model.layers.0
24-11-25 20:30:12 | I | collecting calibration activations in model.layers.0
24-11-25 20:30:12 | I | collecting calibration activations in model.layers.0
24-11-25 20:30:12 | I | collecting calibration activations in model.layers.0
24-11-25 20:30:14 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 20:30:14 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 20:30:14 | I | - Evaluator: gptq
24-11-25 20:30:14 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 20:30:14 | I | - Batch_size: 8
24-11-25 20:30:14 | I |   + Max_seq_length: 2048
24-11-25 20:30:55 | I |     - Results:
24-11-25 20:30:55 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 20:30:55 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 20:30:55 | I |       |wikitext |      1|word_perplexity|7.7911|  |7.7911|
24-11-25 20:30:55 | I |       |val_valid|      1|word_perplexity|9.0825|  |9.0825|
24-11-25 20:30:55 | I |       
24-11-25 20:30:55 | I | forward this layer
24-11-25 20:30:55 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/183.pt
24-11-25 20:30:55 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/183.pt
24-11-25 20:30:56 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 20:30:56 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 20:30:56 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 20:30:56 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 20:30:56 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 20:30:56 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 20:30:56 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 20:30:56 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 20:30:56 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 20:30:56 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 20:30:56 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 20:30:56 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 20:30:56 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 20:30:56 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 20:30:56 | I | [77] done with optimizer step
24-11-25 20:30:56 | I | epoch 001:     92 / 409600000 loss=0.000151407, loss_per_token=0.310081, loss_sum=10160.7, wps=152.8, ups=0, wpb=32768, bsz=64, num_updates=78, lr=0.000149986, gnorm=25.827, clip=100, loss_scale=0.0078, train_wall=214, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=19986, lmquant_ppl_result_wikitext_in_train_no_quant=7.7518, lmquant_ppl_result_val_in_train_no_quant=9.04702, lmquant_ppl_result_wikitext_in_train_with_quant=7.79112, lmquant_ppl_result_val_in_train_with_quant=9.08246
24-11-25 20:30:56 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 20:30:56 | I | in layer model.layers.0
24-11-25 20:30:56 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 20:30:56 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 20:30:56 | I | - Evaluator: gptq
24-11-25 20:30:56 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 20:30:56 | I | - Batch_size: 8
24-11-25 20:30:56 | I |   + Max_seq_length: 2048
24-11-25 20:31:34 | I |     - Results:
24-11-25 20:31:34 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 20:31:34 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 20:31:34 | I |       |wikitext |      1|word_perplexity|7.7558|  |7.7558|
24-11-25 20:31:34 | I |       |val_valid|      1|word_perplexity|9.0382|  |9.0382|
24-11-25 20:31:34 | I |       
24-11-25 20:31:34 | I | quantizing weights for layer model.layers.0
24-11-25 20:31:34 | I | collecting info in model.layers.0
24-11-25 20:31:34 | I | collecting info in model.layers.0
24-11-25 20:31:34 | I | collecting info in model.layers.0
24-11-25 20:31:34 | I | collecting info in model.layers.0
24-11-25 20:31:35 | I | collecting calibration activations in model.layers.0
24-11-25 20:31:35 | I | collecting calibration activations in model.layers.0
24-11-25 20:31:35 | I | collecting calibration activations in model.layers.0
24-11-25 20:31:35 | I | collecting calibration activations in model.layers.0
24-11-25 20:31:35 | I | - Quantizing decoder layer model.layers.0
24-11-25 20:31:35 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 20:31:36 | I |       - range scale = [    1.0000]
24-11-25 20:31:36 | I |         sum  error  = [    0.0624]
24-11-25 20:31:36 | I |         best error  = [    0.0624]
24-11-25 20:31:36 | I |     + error = [0.0624]
24-11-25 20:31:37 | I |       - range scale = [    1.0000]
24-11-25 20:31:37 | I |         sum  error  = [    0.6603]
24-11-25 20:31:37 | I |         best error  = [    0.6603]
24-11-25 20:31:37 | I |     + error = [0.6603]
24-11-25 20:31:37 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 20:31:38 | I |       - range scale = [    1.0000]
24-11-25 20:31:38 | I |         sum  error  = [    0.0753]
24-11-25 20:31:38 | I |         best error  = [    0.0753]
24-11-25 20:31:38 | I |     + error = [0.0753]
24-11-25 20:31:38 | I |       - range scale = [    1.0000]
24-11-25 20:31:38 | I |         sum  error  = [    0.6180]
24-11-25 20:31:38 | I |         best error  = [    0.6180]
24-11-25 20:31:38 | I |     + error = [0.6180]
24-11-25 20:31:39 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 20:31:39 | I |       - range scale = [    1.0000]
24-11-25 20:31:39 | I |         sum  error  = [    0.2474]
24-11-25 20:31:39 | I |         best error  = [    0.2474]
24-11-25 20:31:39 | I |     + error = [0.2474]
24-11-25 20:31:40 | I |       - range scale = [    1.0000]
24-11-25 20:31:40 | I |         sum  error  = [    1.9173]
24-11-25 20:31:40 | I |         best error  = [    1.9173]
24-11-25 20:31:40 | I |     + error = [1.9173]
24-11-25 20:31:40 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 20:31:41 | I |       - range scale = [    1.0000]
24-11-25 20:31:41 | I |         sum  error  = [    0.0772]
24-11-25 20:31:41 | I |         best error  = [    0.0772]
24-11-25 20:31:41 | I |     + error = [0.0772]
24-11-25 20:31:42 | I |       - range scale = [    1.0000]
24-11-25 20:31:42 | I |         sum  error  = [    0.7317]
24-11-25 20:31:42 | I |         best error  = [    0.7317]
24-11-25 20:31:42 | I |     + error = [0.7317]
24-11-25 20:31:42 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 20:31:43 | I |       - range scale = [    1.0000]
24-11-25 20:31:43 | I |         sum  error  = [    1.1389]
24-11-25 20:31:43 | I |         best error  = [    1.1389]
24-11-25 20:31:43 | I |     + error = [1.1389]
24-11-25 20:31:43 | I |       - range scale = [    1.0000]
24-11-25 20:31:43 | I |         sum  error  = [   12.5999]
24-11-25 20:31:43 | I |         best error  = [   12.5999]
24-11-25 20:31:43 | I |     + error = [12.5999]
24-11-25 20:31:44 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 20:31:44 | I |       - range scale = [    1.0000]
24-11-25 20:31:44 | I |         sum  error  = [    1.3151]
24-11-25 20:31:44 | I |         best error  = [    1.3151]
24-11-25 20:31:44 | I |     + error = [1.3151]
24-11-25 20:31:45 | I |       - range scale = [    1.0000]
24-11-25 20:31:45 | I |         sum  error  = [   13.0489]
24-11-25 20:31:45 | I |         best error  = [   13.0489]
24-11-25 20:31:45 | I |     + error = [13.0489]
24-11-25 20:31:45 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 20:31:46 | I |       - range scale = [    1.0000]
24-11-25 20:31:46 | I |         sum  error  = [    2.7462]
24-11-25 20:31:46 | I |         best error  = [    2.7462]
24-11-25 20:31:46 | I |     + error = [2.7462]
24-11-25 20:31:47 | I |       - range scale = [    1.0000]
24-11-25 20:31:47 | I |         sum  error  = [   14.5261]
24-11-25 20:31:47 | I |         best error  = [   14.5261]
24-11-25 20:31:47 | I |     + error = [14.5261]
24-11-25 20:31:47 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 20:31:48 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 20:31:50 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 20:31:51 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 20:31:52 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 20:31:54 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 20:31:55 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 20:31:59 | I | quantizing activations for layer model.layers.0
24-11-25 20:31:59 | I | collecting info in model.layers.0
24-11-25 20:31:59 | I | collecting info in model.layers.0
24-11-25 20:31:59 | I | collecting info in model.layers.0
24-11-25 20:31:59 | I | collecting info in model.layers.0
24-11-25 20:31:59 | I | collecting calibration activations in model.layers.0
24-11-25 20:31:59 | I | collecting calibration activations in model.layers.0
24-11-25 20:31:59 | I | collecting calibration activations in model.layers.0
24-11-25 20:31:59 | I | collecting calibration activations in model.layers.0
24-11-25 20:32:01 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 20:32:01 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 20:32:01 | I | - Evaluator: gptq
24-11-25 20:32:01 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 20:32:01 | I | - Batch_size: 8
24-11-25 20:32:01 | I |   + Max_seq_length: 2048
24-11-25 20:32:43 | I |     - Results:
24-11-25 20:32:43 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 20:32:43 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 20:32:43 | I |       |wikitext |      1|word_perplexity|7.7866|  |7.7866|
24-11-25 20:32:43 | I |       |val_valid|      1|word_perplexity|9.0682|  |9.0682|
24-11-25 20:32:43 | I |       
24-11-25 20:32:43 | I | forward this layer
24-11-25 20:32:43 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/184.pt
24-11-25 20:32:43 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/184.pt
24-11-25 20:32:43 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 20:32:43 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 20:32:43 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 20:32:43 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 20:32:43 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 20:32:43 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 20:32:43 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 20:32:43 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 20:32:43 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 20:32:43 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 20:32:43 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 20:32:43 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 20:32:43 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 20:32:43 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 20:32:43 | I | in layer model.layers.0
24-11-25 20:32:43 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 20:32:43 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 20:32:43 | I | - Evaluator: gptq
24-11-25 20:32:43 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 20:32:43 | I | - Batch_size: 8
24-11-25 20:32:43 | I |   + Max_seq_length: 2048
24-11-25 20:33:21 | I |     - Results:
24-11-25 20:33:21 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 20:33:21 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 20:33:21 | I |       |wikitext |      1|word_perplexity|7.7558|  |7.7558|
24-11-25 20:33:21 | I |       |val_valid|      1|word_perplexity|9.0382|  |9.0382|
24-11-25 20:33:22 | I |       
24-11-25 20:33:22 | I | quantizing weights for layer model.layers.0
24-11-25 20:33:22 | I | collecting info in model.layers.0
24-11-25 20:33:22 | I | collecting info in model.layers.0
24-11-25 20:33:22 | I | collecting info in model.layers.0
24-11-25 20:33:22 | I | collecting info in model.layers.0
24-11-25 20:33:22 | I | collecting calibration activations in model.layers.0
24-11-25 20:33:22 | I | collecting calibration activations in model.layers.0
24-11-25 20:33:22 | I | collecting calibration activations in model.layers.0
24-11-25 20:33:22 | I | collecting calibration activations in model.layers.0
24-11-25 20:33:23 | I | - Quantizing decoder layer model.layers.0
24-11-25 20:33:23 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 20:33:23 | I |       - range scale = [    1.0000]
24-11-25 20:33:23 | I |         sum  error  = [    0.0575]
24-11-25 20:33:23 | I |         best error  = [    0.0575]
24-11-25 20:33:23 | I |     + error = [0.0575]
24-11-25 20:33:24 | I |       - range scale = [    1.0000]
24-11-25 20:33:24 | I |         sum  error  = [    0.6082]
24-11-25 20:33:24 | I |         best error  = [    0.6082]
24-11-25 20:33:24 | I |     + error = [0.6082]
24-11-25 20:33:24 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 20:33:25 | I |       - range scale = [    1.0000]
24-11-25 20:33:25 | I |         sum  error  = [    0.0727]
24-11-25 20:33:25 | I |         best error  = [    0.0727]
24-11-25 20:33:25 | I |     + error = [0.0727]
24-11-25 20:33:26 | I |       - range scale = [    1.0000]
24-11-25 20:33:26 | I |         sum  error  = [    0.5887]
24-11-25 20:33:26 | I |         best error  = [    0.5887]
24-11-25 20:33:26 | I |     + error = [0.5887]
24-11-25 20:33:26 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 20:33:27 | I |       - range scale = [    1.0000]
24-11-25 20:33:27 | I |         sum  error  = [    0.2459]
24-11-25 20:33:27 | I |         best error  = [    0.2459]
24-11-25 20:33:27 | I |     + error = [0.2459]
24-11-25 20:33:27 | I |       - range scale = [    1.0000]
24-11-25 20:33:27 | I |         sum  error  = [    1.9074]
24-11-25 20:33:27 | I |         best error  = [    1.9074]
24-11-25 20:33:27 | I |     + error = [1.9074]
24-11-25 20:33:27 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 20:33:28 | I |       - range scale = [    1.0000]
24-11-25 20:33:28 | I |         sum  error  = [    0.0704]
24-11-25 20:33:28 | I |         best error  = [    0.0704]
24-11-25 20:33:28 | I |     + error = [0.0704]
24-11-25 20:33:29 | I |       - range scale = [    1.0000]
24-11-25 20:33:29 | I |         sum  error  = [    0.6708]
24-11-25 20:33:29 | I |         best error  = [    0.6708]
24-11-25 20:33:29 | I |     + error = [0.6708]
24-11-25 20:33:29 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 20:33:30 | I |       - range scale = [    1.0000]
24-11-25 20:33:30 | I |         sum  error  = [    1.0765]
24-11-25 20:33:30 | I |         best error  = [    1.0765]
24-11-25 20:33:30 | I |     + error = [1.0765]
24-11-25 20:33:30 | I |       - range scale = [    1.0000]
24-11-25 20:33:30 | I |         sum  error  = [   11.9278]
24-11-25 20:33:30 | I |         best error  = [   11.9278]
24-11-25 20:33:30 | I |     + error = [11.9278]
24-11-25 20:33:31 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 20:33:31 | I |       - range scale = [    1.0000]
24-11-25 20:33:31 | I |         sum  error  = [    1.2444]
24-11-25 20:33:31 | I |         best error  = [    1.2444]
24-11-25 20:33:31 | I |     + error = [1.2444]
24-11-25 20:33:32 | I |       - range scale = [    1.0000]
24-11-25 20:33:32 | I |         sum  error  = [   12.3311]
24-11-25 20:33:32 | I |         best error  = [   12.3311]
24-11-25 20:33:32 | I |     + error = [12.3311]
24-11-25 20:33:32 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 20:33:33 | I |       - range scale = [    1.0000]
24-11-25 20:33:33 | I |         sum  error  = [    3.3914]
24-11-25 20:33:33 | I |         best error  = [    3.3914]
24-11-25 20:33:33 | I |     + error = [3.3914]
24-11-25 20:33:34 | I |       - range scale = [    1.0000]
24-11-25 20:33:34 | I |         sum  error  = [   18.2193]
24-11-25 20:33:34 | I |         best error  = [   18.2193]
24-11-25 20:33:34 | I |     + error = [18.2193]
24-11-25 20:33:34 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 20:33:35 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 20:33:37 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 20:33:38 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 20:33:40 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 20:33:41 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 20:33:42 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 20:33:46 | I | quantizing activations for layer model.layers.0
24-11-25 20:33:46 | I | collecting info in model.layers.0
24-11-25 20:33:46 | I | collecting info in model.layers.0
24-11-25 20:33:46 | I | collecting info in model.layers.0
24-11-25 20:33:46 | I | collecting info in model.layers.0
24-11-25 20:33:46 | I | collecting calibration activations in model.layers.0
24-11-25 20:33:46 | I | collecting calibration activations in model.layers.0
24-11-25 20:33:46 | I | collecting calibration activations in model.layers.0
24-11-25 20:33:46 | I | collecting calibration activations in model.layers.0
24-11-25 20:33:48 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 20:33:48 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 20:33:48 | I | - Evaluator: gptq
24-11-25 20:33:48 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 20:33:48 | I | - Batch_size: 8
24-11-25 20:33:48 | I |   + Max_seq_length: 2048
24-11-25 20:34:30 | I |     - Results:
24-11-25 20:34:30 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 20:34:30 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 20:34:30 | I |       |wikitext |      1|word_perplexity|7.7842|  |7.7842|
24-11-25 20:34:30 | I |       |val_valid|      1|word_perplexity|9.0709|  |9.0709|
24-11-25 20:34:30 | I |       
24-11-25 20:34:30 | I | forward this layer
24-11-25 20:34:30 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/185.pt
24-11-25 20:34:30 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/185.pt
24-11-25 20:34:30 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 20:34:30 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 20:34:30 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 20:34:30 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 20:34:30 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 20:34:30 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 20:34:30 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 20:34:30 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 20:34:30 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 20:34:30 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 20:34:30 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 20:34:30 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 20:34:30 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 20:34:30 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 20:34:30 | I | [78] done with optimizer step
24-11-25 20:34:30 | I | epoch 001:     93 / 409600000 loss=0.000268494, loss_per_token=0.549875, loss_sum=18018.3, wps=152.9, ups=0, wpb=32768, bsz=64, num_updates=79, lr=0.000149985, gnorm=57.302, clip=100, loss_scale=0.0078, train_wall=214, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=20200, lmquant_ppl_result_wikitext_in_train_no_quant=7.75577, lmquant_ppl_result_val_in_train_no_quant=9.03824, lmquant_ppl_result_wikitext_in_train_with_quant=7.78422, lmquant_ppl_result_val_in_train_with_quant=9.07088
24-11-25 20:34:30 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 20:34:30 | I | in layer model.layers.0
24-11-25 20:34:30 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 20:34:30 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 20:34:30 | I | - Evaluator: gptq
24-11-25 20:34:30 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 20:34:30 | I | - Batch_size: 8
24-11-25 20:34:30 | I |   + Max_seq_length: 2048
24-11-25 20:35:09 | I |     - Results:
24-11-25 20:35:09 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 20:35:09 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 20:35:09 | I |       |wikitext |      1|word_perplexity|7.7617|  |7.7617|
24-11-25 20:35:09 | I |       |val_valid|      1|word_perplexity|9.0382|  |9.0382|
24-11-25 20:35:09 | I |       
24-11-25 20:35:09 | I | quantizing weights for layer model.layers.0
24-11-25 20:35:09 | I | collecting info in model.layers.0
24-11-25 20:35:09 | I | collecting info in model.layers.0
24-11-25 20:35:09 | I | collecting info in model.layers.0
24-11-25 20:35:09 | I | collecting info in model.layers.0
24-11-25 20:35:09 | I | collecting calibration activations in model.layers.0
24-11-25 20:35:09 | I | collecting calibration activations in model.layers.0
24-11-25 20:35:09 | I | collecting calibration activations in model.layers.0
24-11-25 20:35:10 | I | collecting calibration activations in model.layers.0
24-11-25 20:35:10 | I | - Quantizing decoder layer model.layers.0
24-11-25 20:35:10 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 20:35:11 | I |       - range scale = [    1.0000]
24-11-25 20:35:11 | I |         sum  error  = [    0.0577]
24-11-25 20:35:11 | I |         best error  = [    0.0577]
24-11-25 20:35:11 | I |     + error = [0.0577]
24-11-25 20:35:11 | I |       - range scale = [    1.0000]
24-11-25 20:35:11 | I |         sum  error  = [    0.5905]
24-11-25 20:35:11 | I |         best error  = [    0.5905]
24-11-25 20:35:11 | I |     + error = [0.5905]
24-11-25 20:35:11 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 20:35:12 | I |       - range scale = [    1.0000]
24-11-25 20:35:12 | I |         sum  error  = [    0.0694]
24-11-25 20:35:12 | I |         best error  = [    0.0694]
24-11-25 20:35:12 | I |     + error = [0.0694]
24-11-25 20:35:13 | I |       - range scale = [    1.0000]
24-11-25 20:35:13 | I |         sum  error  = [    0.5518]
24-11-25 20:35:13 | I |         best error  = [    0.5518]
24-11-25 20:35:13 | I |     + error = [0.5518]
24-11-25 20:35:13 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 20:35:14 | I |       - range scale = [    1.0000]
24-11-25 20:35:14 | I |         sum  error  = [    0.2523]
24-11-25 20:35:14 | I |         best error  = [    0.2523]
24-11-25 20:35:14 | I |     + error = [0.2523]
24-11-25 20:35:14 | I |       - range scale = [    1.0000]
24-11-25 20:35:14 | I |         sum  error  = [    1.8635]
24-11-25 20:35:14 | I |         best error  = [    1.8635]
24-11-25 20:35:14 | I |     + error = [1.8635]
24-11-25 20:35:15 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 20:35:15 | I |       - range scale = [    1.0000]
24-11-25 20:35:15 | I |         sum  error  = [    0.0725]
24-11-25 20:35:15 | I |         best error  = [    0.0725]
24-11-25 20:35:15 | I |     + error = [0.0725]
24-11-25 20:35:16 | I |       - range scale = [    1.0000]
24-11-25 20:35:16 | I |         sum  error  = [    0.6855]
24-11-25 20:35:16 | I |         best error  = [    0.6855]
24-11-25 20:35:16 | I |     + error = [0.6855]
24-11-25 20:35:16 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 20:35:17 | I |       - range scale = [    1.0000]
24-11-25 20:35:17 | I |         sum  error  = [    1.0751]
24-11-25 20:35:17 | I |         best error  = [    1.0751]
24-11-25 20:35:17 | I |     + error = [1.0751]
24-11-25 20:35:18 | I |       - range scale = [    1.0000]
24-11-25 20:35:18 | I |         sum  error  = [   11.8601]
24-11-25 20:35:18 | I |         best error  = [   11.8601]
24-11-25 20:35:18 | I |     + error = [11.8601]
24-11-25 20:35:18 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 20:35:19 | I |       - range scale = [    1.0000]
24-11-25 20:35:19 | I |         sum  error  = [    1.2382]
24-11-25 20:35:19 | I |         best error  = [    1.2382]
24-11-25 20:35:19 | I |     + error = [1.2382]
24-11-25 20:35:19 | I |       - range scale = [    1.0000]
24-11-25 20:35:19 | I |         sum  error  = [   12.2862]
24-11-25 20:35:19 | I |         best error  = [   12.2862]
24-11-25 20:35:19 | I |     + error = [12.2862]
24-11-25 20:35:20 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 20:35:20 | I |       - range scale = [    1.0000]
24-11-25 20:35:20 | I |         sum  error  = [    3.4126]
24-11-25 20:35:20 | I |         best error  = [    3.4126]
24-11-25 20:35:20 | I |     + error = [3.4126]
24-11-25 20:35:21 | I |       - range scale = [    1.0000]
24-11-25 20:35:21 | I |         sum  error  = [   17.9445]
24-11-25 20:35:21 | I |         best error  = [   17.9445]
24-11-25 20:35:21 | I |     + error = [17.9445]
24-11-25 20:35:21 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 20:35:23 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 20:35:24 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 20:35:25 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 20:35:27 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 20:35:28 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 20:35:30 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 20:35:33 | I | quantizing activations for layer model.layers.0
24-11-25 20:35:33 | I | collecting info in model.layers.0
24-11-25 20:35:33 | I | collecting info in model.layers.0
24-11-25 20:35:33 | I | collecting info in model.layers.0
24-11-25 20:35:33 | I | collecting info in model.layers.0
24-11-25 20:35:33 | I | collecting calibration activations in model.layers.0
24-11-25 20:35:33 | I | collecting calibration activations in model.layers.0
24-11-25 20:35:34 | I | collecting calibration activations in model.layers.0
24-11-25 20:35:34 | I | collecting calibration activations in model.layers.0
24-11-25 20:35:36 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 20:35:36 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 20:35:36 | I | - Evaluator: gptq
24-11-25 20:35:36 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 20:35:36 | I | - Batch_size: 8
24-11-25 20:35:36 | I |   + Max_seq_length: 2048
24-11-25 20:36:17 | I |     - Results:
24-11-25 20:36:17 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 20:36:17 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 20:36:17 | I |       |wikitext |      1|word_perplexity|7.8028|  |7.8028|
24-11-25 20:36:17 | I |       |val_valid|      1|word_perplexity|9.0704|  |9.0704|
24-11-25 20:36:17 | I |       
24-11-25 20:36:17 | I | forward this layer
24-11-25 20:36:17 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/186.pt
24-11-25 20:36:17 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/186.pt
24-11-25 20:36:17 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 20:36:17 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 20:36:17 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 20:36:17 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 20:36:17 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 20:36:17 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 20:36:17 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 20:36:17 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 20:36:17 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 20:36:17 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 20:36:17 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 20:36:17 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 20:36:17 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 20:36:17 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 20:36:17 | I | in layer model.layers.0
24-11-25 20:36:17 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 20:36:17 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 20:36:17 | I | - Evaluator: gptq
24-11-25 20:36:17 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 20:36:17 | I | - Batch_size: 8
24-11-25 20:36:17 | I |   + Max_seq_length: 2048
24-11-25 20:36:56 | I |     - Results:
24-11-25 20:36:56 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 20:36:56 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 20:36:56 | I |       |wikitext |      1|word_perplexity|7.7617|  |7.7617|
24-11-25 20:36:56 | I |       |val_valid|      1|word_perplexity|9.0382|  |9.0382|
24-11-25 20:36:56 | I |       
24-11-25 20:36:56 | I | quantizing weights for layer model.layers.0
24-11-25 20:36:56 | I | collecting info in model.layers.0
24-11-25 20:36:56 | I | collecting info in model.layers.0
24-11-25 20:36:56 | I | collecting info in model.layers.0
24-11-25 20:36:56 | I | collecting info in model.layers.0
24-11-25 20:36:56 | I | collecting calibration activations in model.layers.0
24-11-25 20:36:56 | I | collecting calibration activations in model.layers.0
24-11-25 20:36:56 | I | collecting calibration activations in model.layers.0
24-11-25 20:36:57 | I | collecting calibration activations in model.layers.0
24-11-25 20:36:57 | I | - Quantizing decoder layer model.layers.0
24-11-25 20:36:57 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 20:36:58 | I |       - range scale = [    1.0000]
24-11-25 20:36:58 | I |         sum  error  = [    0.0558]
24-11-25 20:36:58 | I |         best error  = [    0.0558]
24-11-25 20:36:58 | I |     + error = [0.0558]
24-11-25 20:36:58 | I |       - range scale = [    1.0000]
24-11-25 20:36:58 | I |         sum  error  = [    0.5560]
24-11-25 20:36:58 | I |         best error  = [    0.5560]
24-11-25 20:36:58 | I |     + error = [0.5560]
24-11-25 20:36:58 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 20:36:59 | I |       - range scale = [    1.0000]
24-11-25 20:36:59 | I |         sum  error  = [    0.0670]
24-11-25 20:36:59 | I |         best error  = [    0.0670]
24-11-25 20:36:59 | I |     + error = [0.0670]
24-11-25 20:37:00 | I |       - range scale = [    1.0000]
24-11-25 20:37:00 | I |         sum  error  = [    0.5470]
24-11-25 20:37:00 | I |         best error  = [    0.5470]
24-11-25 20:37:00 | I |     + error = [0.5470]
24-11-25 20:37:00 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 20:37:01 | I |       - range scale = [    1.0000]
24-11-25 20:37:01 | I |         sum  error  = [    0.2477]
24-11-25 20:37:01 | I |         best error  = [    0.2477]
24-11-25 20:37:01 | I |     + error = [0.2477]
24-11-25 20:37:01 | I |       - range scale = [    1.0000]
24-11-25 20:37:01 | I |         sum  error  = [    1.8405]
24-11-25 20:37:01 | I |         best error  = [    1.8405]
24-11-25 20:37:01 | I |     + error = [1.8405]
24-11-25 20:37:02 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 20:37:02 | I |       - range scale = [    1.0000]
24-11-25 20:37:02 | I |         sum  error  = [    0.0691]
24-11-25 20:37:02 | I |         best error  = [    0.0691]
24-11-25 20:37:02 | I |     + error = [0.0691]
24-11-25 20:37:03 | I |       - range scale = [    1.0000]
24-11-25 20:37:03 | I |         sum  error  = [    0.6603]
24-11-25 20:37:03 | I |         best error  = [    0.6603]
24-11-25 20:37:03 | I |     + error = [0.6603]
24-11-25 20:37:03 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 20:37:04 | I |       - range scale = [    1.0000]
24-11-25 20:37:04 | I |         sum  error  = [    1.0641]
24-11-25 20:37:04 | I |         best error  = [    1.0641]
24-11-25 20:37:04 | I |     + error = [1.0641]
24-11-25 20:37:05 | I |       - range scale = [    1.0000]
24-11-25 20:37:05 | I |         sum  error  = [   11.7304]
24-11-25 20:37:05 | I |         best error  = [   11.7304]
24-11-25 20:37:05 | I |     + error = [11.7304]
24-11-25 20:37:05 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 20:37:06 | I |       - range scale = [    1.0000]
24-11-25 20:37:06 | I |         sum  error  = [    1.2242]
24-11-25 20:37:06 | I |         best error  = [    1.2242]
24-11-25 20:37:06 | I |     + error = [1.2242]
24-11-25 20:37:06 | I |       - range scale = [    1.0000]
24-11-25 20:37:06 | I |         sum  error  = [   12.1397]
24-11-25 20:37:06 | I |         best error  = [   12.1397]
24-11-25 20:37:06 | I |     + error = [12.1397]
24-11-25 20:37:07 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 20:37:07 | I |       - range scale = [    1.0000]
24-11-25 20:37:07 | I |         sum  error  = [    3.3041]
24-11-25 20:37:07 | I |         best error  = [    3.3041]
24-11-25 20:37:07 | I |     + error = [3.3041]
24-11-25 20:37:08 | I |       - range scale = [    1.0000]
24-11-25 20:37:08 | I |         sum  error  = [   17.7549]
24-11-25 20:37:08 | I |         best error  = [   17.7549]
24-11-25 20:37:08 | I |     + error = [17.7549]
24-11-25 20:37:08 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 20:37:10 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 20:37:11 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 20:37:12 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 20:37:14 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 20:37:15 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 20:37:17 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 20:37:20 | I | quantizing activations for layer model.layers.0
24-11-25 20:37:20 | I | collecting info in model.layers.0
24-11-25 20:37:20 | I | collecting info in model.layers.0
24-11-25 20:37:20 | I | collecting info in model.layers.0
24-11-25 20:37:20 | I | collecting info in model.layers.0
24-11-25 20:37:20 | I | collecting calibration activations in model.layers.0
24-11-25 20:37:21 | I | collecting calibration activations in model.layers.0
24-11-25 20:37:21 | I | collecting calibration activations in model.layers.0
24-11-25 20:37:21 | I | collecting calibration activations in model.layers.0
24-11-25 20:37:23 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 20:37:23 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 20:37:23 | I | - Evaluator: gptq
24-11-25 20:37:23 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 20:37:23 | I | - Batch_size: 8
24-11-25 20:37:23 | I |   + Max_seq_length: 2048
24-11-25 20:38:04 | I |     - Results:
24-11-25 20:38:04 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 20:38:04 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 20:38:04 | I |       |wikitext |      1|word_perplexity|7.7894|  |7.7894|
24-11-25 20:38:04 | I |       |val_valid|      1|word_perplexity|9.0649|  |9.0649|
24-11-25 20:38:04 | I |       
24-11-25 20:38:04 | I | forward this layer
24-11-25 20:38:04 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/187.pt
24-11-25 20:38:04 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/187.pt
24-11-25 20:38:04 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 20:38:04 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 20:38:04 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 20:38:04 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 20:38:04 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 20:38:04 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 20:38:04 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 20:38:04 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 20:38:04 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 20:38:04 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 20:38:04 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 20:38:04 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 20:38:04 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 20:38:04 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 20:38:04 | I | [79] done with optimizer step
24-11-25 20:38:04 | I | epoch 001:     94 / 409600000 loss=0.000159918, loss_per_token=0.327512, loss_sum=10731.9, wps=152.9, ups=0, wpb=32768, bsz=64, num_updates=80, lr=0.000149985, gnorm=59.264, clip=100, loss_scale=0.0078, train_wall=214, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=20415, lmquant_ppl_result_wikitext_in_train_no_quant=7.76175, lmquant_ppl_result_val_in_train_no_quant=9.03819, lmquant_ppl_result_wikitext_in_train_with_quant=7.78942, lmquant_ppl_result_val_in_train_with_quant=9.06492
24-11-25 20:38:05 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 20:38:05 | I | in layer model.layers.0
24-11-25 20:38:05 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 20:38:05 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 20:38:05 | I | - Evaluator: gptq
24-11-25 20:38:05 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 20:38:05 | I | - Batch_size: 8
24-11-25 20:38:05 | I |   + Max_seq_length: 2048
24-11-25 20:38:43 | I |     - Results:
24-11-25 20:38:43 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 20:38:43 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 20:38:43 | I |       |wikitext |      1|word_perplexity|7.7653|  |7.7653|
24-11-25 20:38:43 | I |       |val_valid|      1|word_perplexity|9.0380|  |9.0380|
24-11-25 20:38:43 | I |       
24-11-25 20:38:43 | I | quantizing weights for layer model.layers.0
24-11-25 20:38:43 | I | collecting info in model.layers.0
24-11-25 20:38:43 | I | collecting info in model.layers.0
24-11-25 20:38:43 | I | collecting info in model.layers.0
24-11-25 20:38:43 | I | collecting info in model.layers.0
24-11-25 20:38:43 | I | collecting calibration activations in model.layers.0
24-11-25 20:38:44 | I | collecting calibration activations in model.layers.0
24-11-25 20:38:44 | I | collecting calibration activations in model.layers.0
24-11-25 20:38:44 | I | collecting calibration activations in model.layers.0
24-11-25 20:38:44 | I | - Quantizing decoder layer model.layers.0
24-11-25 20:38:44 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 20:38:45 | I |       - range scale = [    1.0000]
24-11-25 20:38:45 | I |         sum  error  = [    0.0541]
24-11-25 20:38:45 | I |         best error  = [    0.0541]
24-11-25 20:38:45 | I |     + error = [0.0541]
24-11-25 20:38:45 | I |       - range scale = [    1.0000]
24-11-25 20:38:45 | I |         sum  error  = [    0.5499]
24-11-25 20:38:45 | I |         best error  = [    0.5499]
24-11-25 20:38:45 | I |     + error = [0.5499]
24-11-25 20:38:46 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 20:38:46 | I |       - range scale = [    1.0000]
24-11-25 20:38:46 | I |         sum  error  = [    0.0707]
24-11-25 20:38:46 | I |         best error  = [    0.0707]
24-11-25 20:38:46 | I |     + error = [0.0707]
24-11-25 20:38:47 | I |       - range scale = [    1.0000]
24-11-25 20:38:47 | I |         sum  error  = [    0.5414]
24-11-25 20:38:47 | I |         best error  = [    0.5414]
24-11-25 20:38:47 | I |     + error = [0.5414]
24-11-25 20:38:47 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 20:38:48 | I |       - range scale = [    1.0000]
24-11-25 20:38:48 | I |         sum  error  = [    0.2371]
24-11-25 20:38:48 | I |         best error  = [    0.2371]
24-11-25 20:38:48 | I |     + error = [0.2371]
24-11-25 20:38:49 | I |       - range scale = [    1.0000]
24-11-25 20:38:49 | I |         sum  error  = [    1.8453]
24-11-25 20:38:49 | I |         best error  = [    1.8453]
24-11-25 20:38:49 | I |     + error = [1.8453]
24-11-25 20:38:49 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 20:38:49 | I |       - range scale = [    1.0000]
24-11-25 20:38:49 | I |         sum  error  = [    0.0608]
24-11-25 20:38:49 | I |         best error  = [    0.0608]
24-11-25 20:38:49 | I |     + error = [0.0608]
24-11-25 20:38:50 | I |       - range scale = [    1.0000]
24-11-25 20:38:50 | I |         sum  error  = [    0.5893]
24-11-25 20:38:50 | I |         best error  = [    0.5893]
24-11-25 20:38:50 | I |     + error = [0.5893]
24-11-25 20:38:50 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 20:38:51 | I |       - range scale = [    1.0000]
24-11-25 20:38:51 | I |         sum  error  = [    1.0785]
24-11-25 20:38:51 | I |         best error  = [    1.0785]
24-11-25 20:38:51 | I |     + error = [1.0785]
24-11-25 20:38:52 | I |       - range scale = [    1.0000]
24-11-25 20:38:52 | I |         sum  error  = [   11.9239]
24-11-25 20:38:52 | I |         best error  = [   11.9239]
24-11-25 20:38:52 | I |     + error = [11.9239]
24-11-25 20:38:52 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 20:38:53 | I |       - range scale = [    1.0000]
24-11-25 20:38:53 | I |         sum  error  = [    1.2451]
24-11-25 20:38:53 | I |         best error  = [    1.2451]
24-11-25 20:38:53 | I |     + error = [1.2451]
24-11-25 20:38:53 | I |       - range scale = [    1.0000]
24-11-25 20:38:53 | I |         sum  error  = [   12.3087]
24-11-25 20:38:53 | I |         best error  = [   12.3087]
24-11-25 20:38:53 | I |     + error = [12.3087]
24-11-25 20:38:54 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 20:38:54 | I |       - range scale = [    1.0000]
24-11-25 20:38:54 | I |         sum  error  = [    2.1822]
24-11-25 20:38:54 | I |         best error  = [    2.1822]
24-11-25 20:38:54 | I |     + error = [2.1822]
24-11-25 20:38:55 | I |       - range scale = [    1.0000]
24-11-25 20:38:55 | I |         sum  error  = [   12.5092]
24-11-25 20:38:55 | I |         best error  = [   12.5092]
24-11-25 20:38:55 | I |     + error = [12.5092]
24-11-25 20:38:55 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 20:38:57 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 20:38:58 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 20:38:59 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 20:39:01 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 20:39:02 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 20:39:04 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 20:39:07 | I | quantizing activations for layer model.layers.0
24-11-25 20:39:07 | I | collecting info in model.layers.0
24-11-25 20:39:07 | I | collecting info in model.layers.0
24-11-25 20:39:07 | I | collecting info in model.layers.0
24-11-25 20:39:07 | I | collecting info in model.layers.0
24-11-25 20:39:07 | I | collecting calibration activations in model.layers.0
24-11-25 20:39:08 | I | collecting calibration activations in model.layers.0
24-11-25 20:39:08 | I | collecting calibration activations in model.layers.0
24-11-25 20:39:08 | I | collecting calibration activations in model.layers.0
24-11-25 20:39:10 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 20:39:10 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 20:39:10 | I | - Evaluator: gptq
24-11-25 20:39:10 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 20:39:10 | I | - Batch_size: 8
24-11-25 20:39:10 | I |   + Max_seq_length: 2048
24-11-25 20:39:51 | I |     - Results:
24-11-25 20:39:51 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 20:39:51 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 20:39:51 | I |       |wikitext |      1|word_perplexity|7.7911|  |7.7911|
24-11-25 20:39:51 | I |       |val_valid|      1|word_perplexity|9.0677|  |9.0677|
24-11-25 20:39:51 | I |       
24-11-25 20:39:51 | I | forward this layer
24-11-25 20:39:51 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/188.pt
24-11-25 20:39:51 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/188.pt
24-11-25 20:39:51 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 20:39:51 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 20:39:51 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 20:39:51 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 20:39:51 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 20:39:51 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 20:39:51 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 20:39:51 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 20:39:51 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 20:39:51 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 20:39:51 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 20:39:51 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 20:39:51 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 20:39:51 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 20:39:51 | I | in layer model.layers.0
24-11-25 20:39:51 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 20:39:52 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 20:39:52 | I | - Evaluator: gptq
24-11-25 20:39:52 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 20:39:52 | I | - Batch_size: 8
24-11-25 20:39:52 | I |   + Max_seq_length: 2048
24-11-25 20:40:30 | I |     - Results:
24-11-25 20:40:30 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 20:40:30 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 20:40:30 | I |       |wikitext |      1|word_perplexity|7.7653|  |7.7653|
24-11-25 20:40:30 | I |       |val_valid|      1|word_perplexity|9.0380|  |9.0380|
24-11-25 20:40:30 | I |       
24-11-25 20:40:30 | I | quantizing weights for layer model.layers.0
24-11-25 20:40:30 | I | collecting info in model.layers.0
24-11-25 20:40:30 | I | collecting info in model.layers.0
24-11-25 20:40:30 | I | collecting info in model.layers.0
24-11-25 20:40:30 | I | collecting info in model.layers.0
24-11-25 20:40:30 | I | collecting calibration activations in model.layers.0
24-11-25 20:40:30 | I | collecting calibration activations in model.layers.0
24-11-25 20:40:30 | I | collecting calibration activations in model.layers.0
24-11-25 20:40:31 | I | collecting calibration activations in model.layers.0
24-11-25 20:40:31 | I | - Quantizing decoder layer model.layers.0
24-11-25 20:40:31 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 20:40:32 | I |       - range scale = [    1.0000]
24-11-25 20:40:32 | I |         sum  error  = [    0.0582]
24-11-25 20:40:32 | I |         best error  = [    0.0582]
24-11-25 20:40:32 | I |     + error = [0.0582]
24-11-25 20:40:32 | I |       - range scale = [    1.0000]
24-11-25 20:40:32 | I |         sum  error  = [    0.5949]
24-11-25 20:40:32 | I |         best error  = [    0.5949]
24-11-25 20:40:32 | I |     + error = [0.5949]
24-11-25 20:40:32 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 20:40:33 | I |       - range scale = [    1.0000]
24-11-25 20:40:33 | I |         sum  error  = [    0.0723]
24-11-25 20:40:33 | I |         best error  = [    0.0723]
24-11-25 20:40:33 | I |     + error = [0.0723]
24-11-25 20:40:34 | I |       - range scale = [    1.0000]
24-11-25 20:40:34 | I |         sum  error  = [    0.5543]
24-11-25 20:40:34 | I |         best error  = [    0.5543]
24-11-25 20:40:34 | I |     + error = [0.5543]
24-11-25 20:40:34 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 20:40:35 | I |       - range scale = [    1.0000]
24-11-25 20:40:35 | I |         sum  error  = [    0.2459]
24-11-25 20:40:35 | I |         best error  = [    0.2459]
24-11-25 20:40:35 | I |     + error = [0.2459]
24-11-25 20:40:35 | I |       - range scale = [    1.0000]
24-11-25 20:40:35 | I |         sum  error  = [    1.8782]
24-11-25 20:40:35 | I |         best error  = [    1.8782]
24-11-25 20:40:35 | I |     + error = [1.8782]
24-11-25 20:40:36 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 20:40:36 | I |       - range scale = [    1.0000]
24-11-25 20:40:36 | I |         sum  error  = [    0.0657]
24-11-25 20:40:36 | I |         best error  = [    0.0657]
24-11-25 20:40:36 | I |     + error = [0.0657]
24-11-25 20:40:37 | I |       - range scale = [    1.0000]
24-11-25 20:40:37 | I |         sum  error  = [    0.6258]
24-11-25 20:40:37 | I |         best error  = [    0.6258]
24-11-25 20:40:37 | I |     + error = [0.6258]
24-11-25 20:40:37 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 20:40:38 | I |       - range scale = [    1.0000]
24-11-25 20:40:38 | I |         sum  error  = [    1.0566]
24-11-25 20:40:38 | I |         best error  = [    1.0566]
24-11-25 20:40:38 | I |     + error = [1.0566]
24-11-25 20:40:39 | I |       - range scale = [    1.0000]
24-11-25 20:40:39 | I |         sum  error  = [   11.6871]
24-11-25 20:40:39 | I |         best error  = [   11.6871]
24-11-25 20:40:39 | I |     + error = [11.6871]
24-11-25 20:40:39 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 20:40:39 | I |       - range scale = [    1.0000]
24-11-25 20:40:39 | I |         sum  error  = [    1.2189]
24-11-25 20:40:39 | I |         best error  = [    1.2189]
24-11-25 20:40:40 | I |     + error = [1.2189]
24-11-25 20:40:40 | I |       - range scale = [    1.0000]
24-11-25 20:40:40 | I |         sum  error  = [   12.0638]
24-11-25 20:40:40 | I |         best error  = [   12.0638]
24-11-25 20:40:40 | I |     + error = [12.0638]
24-11-25 20:40:40 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 20:40:41 | I |       - range scale = [    1.0000]
24-11-25 20:40:41 | I |         sum  error  = [    3.2650]
24-11-25 20:40:41 | I |         best error  = [    3.2650]
24-11-25 20:40:41 | I |     + error = [3.2650]
24-11-25 20:40:42 | I |       - range scale = [    1.0000]
24-11-25 20:40:42 | I |         sum  error  = [   17.4941]
24-11-25 20:40:42 | I |         best error  = [   17.4941]
24-11-25 20:40:42 | I |     + error = [17.4941]
24-11-25 20:40:42 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 20:40:44 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 20:40:45 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 20:40:46 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 20:40:48 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 20:40:49 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 20:40:51 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 20:40:54 | I | quantizing activations for layer model.layers.0
24-11-25 20:40:54 | I | collecting info in model.layers.0
24-11-25 20:40:54 | I | collecting info in model.layers.0
24-11-25 20:40:54 | I | collecting info in model.layers.0
24-11-25 20:40:54 | I | collecting info in model.layers.0
24-11-25 20:40:54 | I | collecting calibration activations in model.layers.0
24-11-25 20:40:55 | I | collecting calibration activations in model.layers.0
24-11-25 20:40:55 | I | collecting calibration activations in model.layers.0
24-11-25 20:40:55 | I | collecting calibration activations in model.layers.0
24-11-25 20:40:57 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 20:40:57 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 20:40:57 | I | - Evaluator: gptq
24-11-25 20:40:57 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 20:40:57 | I | - Batch_size: 8
24-11-25 20:40:57 | I |   + Max_seq_length: 2048
24-11-25 20:41:38 | I |     - Results:
24-11-25 20:41:38 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 20:41:38 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 20:41:38 | I |       |wikitext |      1|word_perplexity|7.7888|  |7.7888|
24-11-25 20:41:38 | I |       |val_valid|      1|word_perplexity|9.0648|  |9.0648|
24-11-25 20:41:38 | I |       
24-11-25 20:41:38 | I | forward this layer
24-11-25 20:41:38 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/189.pt
24-11-25 20:41:38 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/189.pt
24-11-25 20:41:38 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 20:41:38 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 20:41:38 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 20:41:38 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 20:41:38 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 20:41:38 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 20:41:38 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 20:41:38 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 20:41:38 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 20:41:38 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 20:41:38 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 20:41:38 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 20:41:38 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 20:41:38 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 20:41:38 | I | [80] done with optimizer step
24-11-25 20:41:38 | I | epoch 001:     95 / 409600000 loss=0.000178755, loss_per_token=0.366089, loss_sum=11996, wps=153.1, ups=0, wpb=32768, bsz=64, num_updates=81, lr=0.000149984, gnorm=50.089, clip=100, loss_scale=0.0078, train_wall=214, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=20629, lmquant_ppl_result_wikitext_in_train_no_quant=7.76526, lmquant_ppl_result_val_in_train_no_quant=9.03803, lmquant_ppl_result_wikitext_in_train_with_quant=7.78881, lmquant_ppl_result_val_in_train_with_quant=9.06478
24-11-25 20:41:39 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 20:41:39 | I | in layer model.layers.0
24-11-25 20:41:39 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 20:41:39 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 20:41:39 | I | - Evaluator: gptq
24-11-25 20:41:39 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 20:41:39 | I | - Batch_size: 8
24-11-25 20:41:39 | I |   + Max_seq_length: 2048
24-11-25 20:42:17 | I |     - Results:
24-11-25 20:42:17 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 20:42:17 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 20:42:17 | I |       |wikitext |      1|word_perplexity|7.7681|  |7.7681|
24-11-25 20:42:17 | I |       |val_valid|      1|word_perplexity|9.0389|  |9.0389|
24-11-25 20:42:17 | I |       
24-11-25 20:42:17 | I | quantizing weights for layer model.layers.0
24-11-25 20:42:17 | I | collecting info in model.layers.0
24-11-25 20:42:17 | I | collecting info in model.layers.0
24-11-25 20:42:17 | I | collecting info in model.layers.0
24-11-25 20:42:17 | I | collecting info in model.layers.0
24-11-25 20:42:17 | I | collecting calibration activations in model.layers.0
24-11-25 20:42:18 | I | collecting calibration activations in model.layers.0
24-11-25 20:42:18 | I | collecting calibration activations in model.layers.0
24-11-25 20:42:18 | I | collecting calibration activations in model.layers.0
24-11-25 20:42:18 | I | - Quantizing decoder layer model.layers.0
24-11-25 20:42:18 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 20:42:19 | I |       - range scale = [    1.0000]
24-11-25 20:42:19 | I |         sum  error  = [    0.0507]
24-11-25 20:42:19 | I |         best error  = [    0.0507]
24-11-25 20:42:19 | I |     + error = [0.0507]
24-11-25 20:42:19 | I |       - range scale = [    1.0000]
24-11-25 20:42:19 | I |         sum  error  = [    0.5632]
24-11-25 20:42:19 | I |         best error  = [    0.5632]
24-11-25 20:42:19 | I |     + error = [0.5632]
24-11-25 20:42:20 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 20:42:20 | I |       - range scale = [    1.0000]
24-11-25 20:42:20 | I |         sum  error  = [    0.0722]
24-11-25 20:42:20 | I |         best error  = [    0.0722]
24-11-25 20:42:20 | I |     + error = [0.0722]
24-11-25 20:42:21 | I |       - range scale = [    1.0000]
24-11-25 20:42:21 | I |         sum  error  = [    0.5502]
24-11-25 20:42:21 | I |         best error  = [    0.5502]
24-11-25 20:42:21 | I |     + error = [0.5502]
24-11-25 20:42:21 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 20:42:22 | I |       - range scale = [    1.0000]
24-11-25 20:42:22 | I |         sum  error  = [    0.2381]
24-11-25 20:42:22 | I |         best error  = [    0.2381]
24-11-25 20:42:22 | I |     + error = [0.2381]
24-11-25 20:42:23 | I |       - range scale = [    1.0000]
24-11-25 20:42:23 | I |         sum  error  = [    1.8605]
24-11-25 20:42:23 | I |         best error  = [    1.8605]
24-11-25 20:42:23 | I |     + error = [1.8605]
24-11-25 20:42:23 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 20:42:24 | I |       - range scale = [    1.0000]
24-11-25 20:42:24 | I |         sum  error  = [    0.0585]
24-11-25 20:42:24 | I |         best error  = [    0.0585]
24-11-25 20:42:24 | I |     + error = [0.0585]
24-11-25 20:42:24 | I |       - range scale = [    1.0000]
24-11-25 20:42:24 | I |         sum  error  = [    0.5645]
24-11-25 20:42:24 | I |         best error  = [    0.5645]
24-11-25 20:42:24 | I |     + error = [0.5645]
24-11-25 20:42:24 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 20:42:25 | I |       - range scale = [    1.0000]
24-11-25 20:42:25 | I |         sum  error  = [    1.0602]
24-11-25 20:42:25 | I |         best error  = [    1.0602]
24-11-25 20:42:25 | I |     + error = [1.0602]
24-11-25 20:42:26 | I |       - range scale = [    1.0000]
24-11-25 20:42:26 | I |         sum  error  = [   11.7541]
24-11-25 20:42:26 | I |         best error  = [   11.7541]
24-11-25 20:42:26 | I |     + error = [11.7541]
24-11-25 20:42:26 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 20:42:27 | I |       - range scale = [    1.0000]
24-11-25 20:42:27 | I |         sum  error  = [    1.2256]
24-11-25 20:42:27 | I |         best error  = [    1.2256]
24-11-25 20:42:27 | I |     + error = [1.2256]
24-11-25 20:42:28 | I |       - range scale = [    1.0000]
24-11-25 20:42:28 | I |         sum  error  = [   12.1238]
24-11-25 20:42:28 | I |         best error  = [   12.1238]
24-11-25 20:42:28 | I |     + error = [12.1238]
24-11-25 20:42:28 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 20:42:28 | I |       - range scale = [    1.0000]
24-11-25 20:42:28 | I |         sum  error  = [    1.9642]
24-11-25 20:42:28 | I |         best error  = [    1.9642]
24-11-25 20:42:28 | I |     + error = [1.9642]
24-11-25 20:42:29 | I |       - range scale = [    1.0000]
24-11-25 20:42:29 | I |         sum  error  = [   11.7857]
24-11-25 20:42:29 | I |         best error  = [   11.7857]
24-11-25 20:42:29 | I |     + error = [11.7857]
24-11-25 20:42:29 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 20:42:31 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 20:42:32 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 20:42:34 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 20:42:35 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 20:42:36 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 20:42:38 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 20:42:41 | I | quantizing activations for layer model.layers.0
24-11-25 20:42:41 | I | collecting info in model.layers.0
24-11-25 20:42:41 | I | collecting info in model.layers.0
24-11-25 20:42:41 | I | collecting info in model.layers.0
24-11-25 20:42:41 | I | collecting info in model.layers.0
24-11-25 20:42:41 | I | collecting calibration activations in model.layers.0
24-11-25 20:42:42 | I | collecting calibration activations in model.layers.0
24-11-25 20:42:42 | I | collecting calibration activations in model.layers.0
24-11-25 20:42:42 | I | collecting calibration activations in model.layers.0
24-11-25 20:42:44 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 20:42:44 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 20:42:44 | I | - Evaluator: gptq
24-11-25 20:42:44 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 20:42:44 | I | - Batch_size: 8
24-11-25 20:42:44 | I |   + Max_seq_length: 2048
24-11-25 20:43:25 | I |     - Results:
24-11-25 20:43:25 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 20:43:25 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 20:43:25 | I |       |wikitext |      1|word_perplexity|7.7820|  |7.7820|
24-11-25 20:43:25 | I |       |val_valid|      1|word_perplexity|9.0716|  |9.0716|
24-11-25 20:43:25 | I |       
24-11-25 20:43:25 | I | forward this layer
24-11-25 20:43:25 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/190.pt
24-11-25 20:43:25 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/190.pt
24-11-25 20:43:25 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 20:43:25 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 20:43:25 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 20:43:25 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 20:43:25 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 20:43:25 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 20:43:25 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 20:43:25 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 20:43:25 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 20:43:25 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 20:43:25 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 20:43:25 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 20:43:25 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 20:43:25 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 20:43:25 | I | in layer model.layers.0
24-11-25 20:43:25 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 20:43:25 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 20:43:25 | I | - Evaluator: gptq
24-11-25 20:43:25 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 20:43:25 | I | - Batch_size: 8
24-11-25 20:43:25 | I |   + Max_seq_length: 2048
24-11-25 20:44:04 | I |     - Results:
24-11-25 20:44:04 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 20:44:04 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 20:44:04 | I |       |wikitext |      1|word_perplexity|7.7681|  |7.7681|
24-11-25 20:44:04 | I |       |val_valid|      1|word_perplexity|9.0389|  |9.0389|
24-11-25 20:44:04 | I |       
24-11-25 20:44:04 | I | quantizing weights for layer model.layers.0
24-11-25 20:44:04 | I | collecting info in model.layers.0
24-11-25 20:44:04 | I | collecting info in model.layers.0
24-11-25 20:44:04 | I | collecting info in model.layers.0
24-11-25 20:44:04 | I | collecting info in model.layers.0
24-11-25 20:44:04 | I | collecting calibration activations in model.layers.0
24-11-25 20:44:04 | I | collecting calibration activations in model.layers.0
24-11-25 20:44:04 | I | collecting calibration activations in model.layers.0
24-11-25 20:44:05 | I | collecting calibration activations in model.layers.0
24-11-25 20:44:05 | I | - Quantizing decoder layer model.layers.0
24-11-25 20:44:05 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 20:44:06 | I |       - range scale = [    1.0000]
24-11-25 20:44:06 | I |         sum  error  = [    0.0543]
24-11-25 20:44:06 | I |         best error  = [    0.0543]
24-11-25 20:44:06 | I |     + error = [0.0543]
24-11-25 20:44:06 | I |       - range scale = [    1.0000]
24-11-25 20:44:06 | I |         sum  error  = [    0.5960]
24-11-25 20:44:06 | I |         best error  = [    0.5960]
24-11-25 20:44:06 | I |     + error = [0.5960]
24-11-25 20:44:06 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 20:44:07 | I |       - range scale = [    1.0000]
24-11-25 20:44:07 | I |         sum  error  = [    0.0694]
24-11-25 20:44:07 | I |         best error  = [    0.0694]
24-11-25 20:44:07 | I |     + error = [0.0694]
24-11-25 20:44:08 | I |       - range scale = [    1.0000]
24-11-25 20:44:08 | I |         sum  error  = [    0.5638]
24-11-25 20:44:08 | I |         best error  = [    0.5638]
24-11-25 20:44:08 | I |     + error = [0.5638]
24-11-25 20:44:08 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 20:44:09 | I |       - range scale = [    1.0000]
24-11-25 20:44:09 | I |         sum  error  = [    0.2355]
24-11-25 20:44:09 | I |         best error  = [    0.2355]
24-11-25 20:44:09 | I |     + error = [0.2355]
24-11-25 20:44:09 | I |       - range scale = [    1.0000]
24-11-25 20:44:09 | I |         sum  error  = [    1.8574]
24-11-25 20:44:09 | I |         best error  = [    1.8574]
24-11-25 20:44:09 | I |     + error = [1.8574]
24-11-25 20:44:10 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 20:44:10 | I |       - range scale = [    1.0000]
24-11-25 20:44:10 | I |         sum  error  = [    0.0617]
24-11-25 20:44:10 | I |         best error  = [    0.0617]
24-11-25 20:44:10 | I |     + error = [0.0617]
24-11-25 20:44:11 | I |       - range scale = [    1.0000]
24-11-25 20:44:11 | I |         sum  error  = [    0.6016]
24-11-25 20:44:11 | I |         best error  = [    0.6016]
24-11-25 20:44:11 | I |     + error = [0.6016]
24-11-25 20:44:11 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 20:44:12 | I |       - range scale = [    1.0000]
24-11-25 20:44:12 | I |         sum  error  = [    1.0805]
24-11-25 20:44:12 | I |         best error  = [    1.0805]
24-11-25 20:44:12 | I |     + error = [1.0805]
24-11-25 20:44:12 | I |       - range scale = [    1.0000]
24-11-25 20:44:12 | I |         sum  error  = [   11.9730]
24-11-25 20:44:12 | I |         best error  = [   11.9730]
24-11-25 20:44:12 | I |     + error = [11.9730]
24-11-25 20:44:13 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 20:44:13 | I |       - range scale = [    1.0000]
24-11-25 20:44:13 | I |         sum  error  = [    1.2469]
24-11-25 20:44:13 | I |         best error  = [    1.2469]
24-11-25 20:44:13 | I |     + error = [1.2469]
24-11-25 20:44:14 | I |       - range scale = [    1.0000]
24-11-25 20:44:14 | I |         sum  error  = [   12.3668]
24-11-25 20:44:14 | I |         best error  = [   12.3668]
24-11-25 20:44:14 | I |     + error = [12.3668]
24-11-25 20:44:14 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 20:44:15 | I |       - range scale = [    1.0000]
24-11-25 20:44:15 | I |         sum  error  = [    2.5430]
24-11-25 20:44:15 | I |         best error  = [    2.5430]
24-11-25 20:44:15 | I |     + error = [2.5430]
24-11-25 20:44:16 | I |       - range scale = [    1.0000]
24-11-25 20:44:16 | I |         sum  error  = [   14.4670]
24-11-25 20:44:16 | I |         best error  = [   14.4670]
24-11-25 20:44:16 | I |     + error = [14.4670]
24-11-25 20:44:16 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 20:44:18 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 20:44:19 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 20:44:21 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 20:44:23 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 20:44:24 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 20:44:26 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 20:44:30 | I | quantizing activations for layer model.layers.0
24-11-25 20:44:30 | I | collecting info in model.layers.0
24-11-25 20:44:30 | I | collecting info in model.layers.0
24-11-25 20:44:30 | I | collecting info in model.layers.0
24-11-25 20:44:30 | I | collecting info in model.layers.0
24-11-25 20:44:31 | I | collecting calibration activations in model.layers.0
24-11-25 20:44:31 | I | collecting calibration activations in model.layers.0
24-11-25 20:44:31 | I | collecting calibration activations in model.layers.0
24-11-25 20:44:31 | I | collecting calibration activations in model.layers.0
24-11-25 20:44:33 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 20:44:33 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 20:44:33 | I | - Evaluator: gptq
24-11-25 20:44:33 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 20:44:33 | I | - Batch_size: 8
24-11-25 20:44:33 | I |   + Max_seq_length: 2048
24-11-25 20:45:15 | I |     - Results:
24-11-25 20:45:15 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 20:45:15 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 20:45:15 | I |       |wikitext |      1|word_perplexity|7.7842|  |7.7842|
24-11-25 20:45:15 | I |       |val_valid|      1|word_perplexity|9.0667|  |9.0667|
24-11-25 20:45:15 | I |       
24-11-25 20:45:15 | I | forward this layer
24-11-25 20:45:15 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/191.pt
24-11-25 20:45:15 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/191.pt
24-11-25 20:45:15 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 20:45:15 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 20:45:15 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 20:45:15 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 20:45:15 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 20:45:15 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 20:45:15 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 20:45:15 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 20:45:15 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 20:45:15 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 20:45:15 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 20:45:15 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 20:45:15 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 20:45:15 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 20:45:15 | I | [81] done with optimizer step
24-11-25 20:45:15 | I | epoch 001:     96 / 409600000 loss=0.000118466, loss_per_token=0.242617, loss_sum=7950.09, wps=151.1, ups=0, wpb=32768, bsz=64, num_updates=82, lr=0.000149984, gnorm=40.568, clip=100, loss_scale=0.0078, train_wall=217, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=20846, lmquant_ppl_result_wikitext_in_train_no_quant=7.76812, lmquant_ppl_result_val_in_train_no_quant=9.03888, lmquant_ppl_result_wikitext_in_train_with_quant=7.7842, lmquant_ppl_result_val_in_train_with_quant=9.0667
24-11-25 20:45:16 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 20:45:16 | I | in layer model.layers.0
24-11-25 20:45:16 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 20:45:16 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 20:45:16 | I | - Evaluator: gptq
24-11-25 20:45:16 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 20:45:16 | I | - Batch_size: 8
24-11-25 20:45:16 | I |   + Max_seq_length: 2048
24-11-25 20:45:54 | I |     - Results:
24-11-25 20:45:54 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 20:45:54 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 20:45:54 | I |       |wikitext |      1|word_perplexity|7.7711|  |7.7711|
24-11-25 20:45:54 | I |       |val_valid|      1|word_perplexity|9.0408|  |9.0408|
24-11-25 20:45:54 | I |       
24-11-25 20:45:54 | I | quantizing weights for layer model.layers.0
24-11-25 20:45:54 | I | collecting info in model.layers.0
24-11-25 20:45:54 | I | collecting info in model.layers.0
24-11-25 20:45:54 | I | collecting info in model.layers.0
24-11-25 20:45:54 | I | collecting info in model.layers.0
24-11-25 20:45:54 | I | collecting calibration activations in model.layers.0
24-11-25 20:45:54 | I | collecting calibration activations in model.layers.0
24-11-25 20:45:55 | I | collecting calibration activations in model.layers.0
24-11-25 20:45:55 | I | collecting calibration activations in model.layers.0
24-11-25 20:45:55 | I | - Quantizing decoder layer model.layers.0
24-11-25 20:45:55 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 20:45:56 | I |       - range scale = [    1.0000]
24-11-25 20:45:56 | I |         sum  error  = [    0.0526]
24-11-25 20:45:56 | I |         best error  = [    0.0526]
24-11-25 20:45:56 | I |     + error = [0.0526]
24-11-25 20:45:56 | I |       - range scale = [    1.0000]
24-11-25 20:45:56 | I |         sum  error  = [    0.5614]
24-11-25 20:45:56 | I |         best error  = [    0.5614]
24-11-25 20:45:56 | I |     + error = [0.5614]
24-11-25 20:45:57 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 20:45:57 | I |       - range scale = [    1.0000]
24-11-25 20:45:57 | I |         sum  error  = [    0.0644]
24-11-25 20:45:57 | I |         best error  = [    0.0644]
24-11-25 20:45:57 | I |     + error = [0.0644]
24-11-25 20:45:58 | I |       - range scale = [    1.0000]
24-11-25 20:45:58 | I |         sum  error  = [    0.5445]
24-11-25 20:45:58 | I |         best error  = [    0.5445]
24-11-25 20:45:58 | I |     + error = [0.5445]
24-11-25 20:45:58 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 20:45:59 | I |       - range scale = [    1.0000]
24-11-25 20:45:59 | I |         sum  error  = [    0.2325]
24-11-25 20:45:59 | I |         best error  = [    0.2325]
24-11-25 20:45:59 | I |     + error = [0.2325]
24-11-25 20:46:00 | I |       - range scale = [    1.0000]
24-11-25 20:46:00 | I |         sum  error  = [    1.8186]
24-11-25 20:46:00 | I |         best error  = [    1.8186]
24-11-25 20:46:00 | I |     + error = [1.8186]
24-11-25 20:46:00 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 20:46:00 | I |       - range scale = [    1.0000]
24-11-25 20:46:00 | I |         sum  error  = [    0.0586]
24-11-25 20:46:00 | I |         best error  = [    0.0586]
24-11-25 20:46:00 | I |     + error = [0.0586]
24-11-25 20:46:01 | I |       - range scale = [    1.0000]
24-11-25 20:46:01 | I |         sum  error  = [    0.5725]
24-11-25 20:46:01 | I |         best error  = [    0.5725]
24-11-25 20:46:01 | I |     + error = [0.5725]
24-11-25 20:46:01 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 20:46:02 | I |       - range scale = [    1.0000]
24-11-25 20:46:02 | I |         sum  error  = [    1.0962]
24-11-25 20:46:02 | I |         best error  = [    1.0962]
24-11-25 20:46:02 | I |     + error = [1.0962]
24-11-25 20:46:03 | I |       - range scale = [    1.0000]
24-11-25 20:46:03 | I |         sum  error  = [   12.1402]
24-11-25 20:46:03 | I |         best error  = [   12.1402]
24-11-25 20:46:03 | I |     + error = [12.1402]
24-11-25 20:46:03 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 20:46:04 | I |       - range scale = [    1.0000]
24-11-25 20:46:04 | I |         sum  error  = [    1.2654]
24-11-25 20:46:04 | I |         best error  = [    1.2654]
24-11-25 20:46:04 | I |     + error = [1.2654]
24-11-25 20:46:04 | I |       - range scale = [    1.0000]
24-11-25 20:46:04 | I |         sum  error  = [   12.5481]
24-11-25 20:46:04 | I |         best error  = [   12.5481]
24-11-25 20:46:04 | I |     + error = [12.5481]
24-11-25 20:46:05 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 20:46:05 | I |       - range scale = [    1.0000]
24-11-25 20:46:05 | I |         sum  error  = [    3.1405]
24-11-25 20:46:05 | I |         best error  = [    3.1405]
24-11-25 20:46:05 | I |     + error = [3.1405]
24-11-25 20:46:06 | I |       - range scale = [    1.0000]
24-11-25 20:46:06 | I |         sum  error  = [   17.4003]
24-11-25 20:46:06 | I |         best error  = [   17.4003]
24-11-25 20:46:06 | I |     + error = [17.4003]
24-11-25 20:46:06 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 20:46:08 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 20:46:09 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 20:46:10 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 20:46:12 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 20:46:13 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 20:46:15 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 20:46:18 | I | quantizing activations for layer model.layers.0
24-11-25 20:46:18 | I | collecting info in model.layers.0
24-11-25 20:46:18 | I | collecting info in model.layers.0
24-11-25 20:46:18 | I | collecting info in model.layers.0
24-11-25 20:46:18 | I | collecting info in model.layers.0
24-11-25 20:46:18 | I | collecting calibration activations in model.layers.0
24-11-25 20:46:18 | I | collecting calibration activations in model.layers.0
24-11-25 20:46:19 | I | collecting calibration activations in model.layers.0
24-11-25 20:46:19 | I | collecting calibration activations in model.layers.0
24-11-25 20:46:21 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 20:46:21 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 20:46:21 | I | - Evaluator: gptq
24-11-25 20:46:21 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 20:46:21 | I | - Batch_size: 8
24-11-25 20:46:21 | I |   + Max_seq_length: 2048
24-11-25 20:47:02 | I |     - Results:
24-11-25 20:47:02 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 20:47:02 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 20:47:02 | I |       |wikitext |      1|word_perplexity|7.7937|  |7.7937|
24-11-25 20:47:02 | I |       |val_valid|      1|word_perplexity|9.0779|  |9.0779|
24-11-25 20:47:02 | I |       
24-11-25 20:47:02 | I | forward this layer
24-11-25 20:47:02 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/192.pt
24-11-25 20:47:02 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/192.pt
24-11-25 20:47:02 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 20:47:02 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 20:47:02 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 20:47:02 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 20:47:02 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 20:47:02 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 20:47:02 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 20:47:02 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 20:47:02 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 20:47:02 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 20:47:02 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 20:47:02 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 20:47:02 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 20:47:02 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 20:47:02 | I | in layer model.layers.0
24-11-25 20:47:02 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 20:47:02 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 20:47:02 | I | - Evaluator: gptq
24-11-25 20:47:02 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 20:47:02 | I | - Batch_size: 8
24-11-25 20:47:02 | I |   + Max_seq_length: 2048
24-11-25 20:47:40 | I |     - Results:
24-11-25 20:47:40 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 20:47:40 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 20:47:40 | I |       |wikitext |      1|word_perplexity|7.7711|  |7.7711|
24-11-25 20:47:40 | I |       |val_valid|      1|word_perplexity|9.0408|  |9.0408|
24-11-25 20:47:40 | I |       
24-11-25 20:47:40 | I | quantizing weights for layer model.layers.0
24-11-25 20:47:40 | I | collecting info in model.layers.0
24-11-25 20:47:40 | I | collecting info in model.layers.0
24-11-25 20:47:40 | I | collecting info in model.layers.0
24-11-25 20:47:40 | I | collecting info in model.layers.0
24-11-25 20:47:41 | I | collecting calibration activations in model.layers.0
24-11-25 20:47:41 | I | collecting calibration activations in model.layers.0
24-11-25 20:47:41 | I | collecting calibration activations in model.layers.0
24-11-25 20:47:41 | I | collecting calibration activations in model.layers.0
24-11-25 20:47:42 | I | - Quantizing decoder layer model.layers.0
24-11-25 20:47:42 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 20:47:42 | I |       - range scale = [    1.0000]
24-11-25 20:47:42 | I |         sum  error  = [    0.0551]
24-11-25 20:47:42 | I |         best error  = [    0.0551]
24-11-25 20:47:42 | I |     + error = [0.0551]
24-11-25 20:47:43 | I |       - range scale = [    1.0000]
24-11-25 20:47:43 | I |         sum  error  = [    0.5826]
24-11-25 20:47:43 | I |         best error  = [    0.5826]
24-11-25 20:47:43 | I |     + error = [0.5826]
24-11-25 20:47:43 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 20:47:44 | I |       - range scale = [    1.0000]
24-11-25 20:47:44 | I |         sum  error  = [    0.0658]
24-11-25 20:47:44 | I |         best error  = [    0.0658]
24-11-25 20:47:44 | I |     + error = [0.0658]
24-11-25 20:47:45 | I |       - range scale = [    1.0000]
24-11-25 20:47:45 | I |         sum  error  = [    0.5482]
24-11-25 20:47:45 | I |         best error  = [    0.5482]
24-11-25 20:47:45 | I |     + error = [0.5482]
24-11-25 20:47:45 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 20:47:46 | I |       - range scale = [    1.0000]
24-11-25 20:47:46 | I |         sum  error  = [    0.2395]
24-11-25 20:47:46 | I |         best error  = [    0.2395]
24-11-25 20:47:46 | I |     + error = [0.2395]
24-11-25 20:47:46 | I |       - range scale = [    1.0000]
24-11-25 20:47:46 | I |         sum  error  = [    1.8606]
24-11-25 20:47:46 | I |         best error  = [    1.8606]
24-11-25 20:47:46 | I |     + error = [1.8606]
24-11-25 20:47:46 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 20:47:47 | I |       - range scale = [    1.0000]
24-11-25 20:47:47 | I |         sum  error  = [    0.0612]
24-11-25 20:47:47 | I |         best error  = [    0.0612]
24-11-25 20:47:47 | I |     + error = [0.0612]
24-11-25 20:47:48 | I |       - range scale = [    1.0000]
24-11-25 20:47:48 | I |         sum  error  = [    0.5913]
24-11-25 20:47:48 | I |         best error  = [    0.5913]
24-11-25 20:47:48 | I |     + error = [0.5913]
24-11-25 20:47:48 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 20:47:49 | I |       - range scale = [    1.0000]
24-11-25 20:47:49 | I |         sum  error  = [    1.0607]
24-11-25 20:47:49 | I |         best error  = [    1.0607]
24-11-25 20:47:49 | I |     + error = [1.0607]
24-11-25 20:47:49 | I |       - range scale = [    1.0000]
24-11-25 20:47:49 | I |         sum  error  = [   11.7543]
24-11-25 20:47:49 | I |         best error  = [   11.7543]
24-11-25 20:47:49 | I |     + error = [11.7543]
24-11-25 20:47:50 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 20:47:50 | I |       - range scale = [    1.0000]
24-11-25 20:47:50 | I |         sum  error  = [    1.2286]
24-11-25 20:47:50 | I |         best error  = [    1.2286]
24-11-25 20:47:50 | I |     + error = [1.2286]
24-11-25 20:47:51 | I |       - range scale = [    1.0000]
24-11-25 20:47:51 | I |         sum  error  = [   12.1348]
24-11-25 20:47:51 | I |         best error  = [   12.1348]
24-11-25 20:47:51 | I |     + error = [12.1348]
24-11-25 20:47:51 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 20:47:52 | I |       - range scale = [    1.0000]
24-11-25 20:47:52 | I |         sum  error  = [    4.0674]
24-11-25 20:47:52 | I |         best error  = [    4.0674]
24-11-25 20:47:52 | I |     + error = [4.0674]
24-11-25 20:47:53 | I |       - range scale = [    1.0000]
24-11-25 20:47:53 | I |         sum  error  = [   22.2031]
24-11-25 20:47:53 | I |         best error  = [   22.2031]
24-11-25 20:47:53 | I |     + error = [22.2031]
24-11-25 20:47:53 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 20:47:54 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 20:47:56 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 20:47:57 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 20:47:58 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 20:48:00 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 20:48:01 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 20:48:05 | I | quantizing activations for layer model.layers.0
24-11-25 20:48:05 | I | collecting info in model.layers.0
24-11-25 20:48:05 | I | collecting info in model.layers.0
24-11-25 20:48:05 | I | collecting info in model.layers.0
24-11-25 20:48:05 | I | collecting info in model.layers.0
24-11-25 20:48:05 | I | collecting calibration activations in model.layers.0
24-11-25 20:48:05 | I | collecting calibration activations in model.layers.0
24-11-25 20:48:05 | I | collecting calibration activations in model.layers.0
24-11-25 20:48:05 | I | collecting calibration activations in model.layers.0
24-11-25 20:48:07 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 20:48:07 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 20:48:07 | I | - Evaluator: gptq
24-11-25 20:48:07 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 20:48:07 | I | - Batch_size: 8
24-11-25 20:48:07 | I |   + Max_seq_length: 2048
24-11-25 20:48:49 | I |     - Results:
24-11-25 20:48:49 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 20:48:49 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 20:48:49 | I |       |wikitext |      1|word_perplexity|7.7931|  |7.7931|
24-11-25 20:48:49 | I |       |val_valid|      1|word_perplexity|9.0765|  |9.0765|
24-11-25 20:48:49 | I |       
24-11-25 20:48:49 | I | forward this layer
24-11-25 20:48:49 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/193.pt
24-11-25 20:48:49 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/193.pt
24-11-25 20:48:49 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 20:48:49 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 20:48:49 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 20:48:49 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 20:48:49 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 20:48:49 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 20:48:49 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 20:48:49 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 20:48:49 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 20:48:49 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 20:48:49 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 20:48:49 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 20:48:49 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 20:48:49 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 20:48:49 | I | [82] done with optimizer step
24-11-25 20:48:49 | I | epoch 001:     97 / 409600000 loss=0.000101192, loss_per_token=0.207241, loss_sum=6790.86, wps=153.5, ups=0, wpb=32768, bsz=64, num_updates=83, lr=0.000149983, gnorm=17.671, clip=100, loss_scale=0.0078, train_wall=213, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=21059, lmquant_ppl_result_wikitext_in_train_no_quant=7.77107, lmquant_ppl_result_val_in_train_no_quant=9.04084, lmquant_ppl_result_wikitext_in_train_with_quant=7.79313, lmquant_ppl_result_val_in_train_with_quant=9.07651
24-11-25 20:48:49 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 20:48:49 | I | in layer model.layers.0
24-11-25 20:48:49 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 20:48:49 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 20:48:49 | I | - Evaluator: gptq
24-11-25 20:48:49 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 20:48:49 | I | - Batch_size: 8
24-11-25 20:48:49 | I |   + Max_seq_length: 2048
24-11-25 20:49:27 | I |     - Results:
24-11-25 20:49:27 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 20:49:27 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 20:49:27 | I |       |wikitext |      1|word_perplexity|7.7784|  |7.7784|
24-11-25 20:49:27 | I |       |val_valid|      1|word_perplexity|9.0438|  |9.0438|
24-11-25 20:49:27 | I |       
24-11-25 20:49:27 | I | quantizing weights for layer model.layers.0
24-11-25 20:49:27 | I | collecting info in model.layers.0
24-11-25 20:49:27 | I | collecting info in model.layers.0
24-11-25 20:49:27 | I | collecting info in model.layers.0
24-11-25 20:49:27 | I | collecting info in model.layers.0
24-11-25 20:49:28 | I | collecting calibration activations in model.layers.0
24-11-25 20:49:28 | I | collecting calibration activations in model.layers.0
24-11-25 20:49:28 | I | collecting calibration activations in model.layers.0
24-11-25 20:49:28 | I | collecting calibration activations in model.layers.0
24-11-25 20:49:28 | I | - Quantizing decoder layer model.layers.0
24-11-25 20:49:28 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 20:49:29 | I |       - range scale = [    1.0000]
24-11-25 20:49:29 | I |         sum  error  = [    0.0548]
24-11-25 20:49:29 | I |         best error  = [    0.0548]
24-11-25 20:49:29 | I |     + error = [0.0548]
24-11-25 20:49:30 | I |       - range scale = [    1.0000]
24-11-25 20:49:30 | I |         sum  error  = [    0.5495]
24-11-25 20:49:30 | I |         best error  = [    0.5495]
24-11-25 20:49:30 | I |     + error = [0.5495]
24-11-25 20:49:30 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 20:49:31 | I |       - range scale = [    1.0000]
24-11-25 20:49:31 | I |         sum  error  = [    0.0620]
24-11-25 20:49:31 | I |         best error  = [    0.0620]
24-11-25 20:49:31 | I |     + error = [0.0620]
24-11-25 20:49:31 | I |       - range scale = [    1.0000]
24-11-25 20:49:31 | I |         sum  error  = [    0.5297]
24-11-25 20:49:31 | I |         best error  = [    0.5297]
24-11-25 20:49:31 | I |     + error = [0.5297]
24-11-25 20:49:32 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 20:49:32 | I |       - range scale = [    1.0000]
24-11-25 20:49:32 | I |         sum  error  = [    0.2343]
24-11-25 20:49:32 | I |         best error  = [    0.2343]
24-11-25 20:49:32 | I |     + error = [0.2343]
24-11-25 20:49:33 | I |       - range scale = [    1.0000]
24-11-25 20:49:33 | I |         sum  error  = [    1.8186]
24-11-25 20:49:33 | I |         best error  = [    1.8186]
24-11-25 20:49:33 | I |     + error = [1.8186]
24-11-25 20:49:33 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 20:49:34 | I |       - range scale = [    1.0000]
24-11-25 20:49:34 | I |         sum  error  = [    0.0594]
24-11-25 20:49:34 | I |         best error  = [    0.0594]
24-11-25 20:49:34 | I |     + error = [0.0594]
24-11-25 20:49:35 | I |       - range scale = [    1.0000]
24-11-25 20:49:35 | I |         sum  error  = [    0.5696]
24-11-25 20:49:35 | I |         best error  = [    0.5696]
24-11-25 20:49:35 | I |     + error = [0.5696]
24-11-25 20:49:35 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 20:49:35 | I |       - range scale = [    1.0000]
24-11-25 20:49:35 | I |         sum  error  = [    1.0393]
24-11-25 20:49:35 | I |         best error  = [    1.0393]
24-11-25 20:49:35 | I |     + error = [1.0393]
24-11-25 20:49:36 | I |       - range scale = [    1.0000]
24-11-25 20:49:36 | I |         sum  error  = [   11.4973]
24-11-25 20:49:36 | I |         best error  = [   11.4973]
24-11-25 20:49:36 | I |     + error = [11.4973]
24-11-25 20:49:36 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 20:49:37 | I |       - range scale = [    1.0000]
24-11-25 20:49:37 | I |         sum  error  = [    1.1978]
24-11-25 20:49:37 | I |         best error  = [    1.1978]
24-11-25 20:49:37 | I |     + error = [1.1978]
24-11-25 20:49:38 | I |       - range scale = [    1.0000]
24-11-25 20:49:38 | I |         sum  error  = [   11.8501]
24-11-25 20:49:38 | I |         best error  = [   11.8501]
24-11-25 20:49:38 | I |     + error = [11.8501]
24-11-25 20:49:38 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 20:49:39 | I |       - range scale = [    1.0000]
24-11-25 20:49:39 | I |         sum  error  = [    2.6930]
24-11-25 20:49:39 | I |         best error  = [    2.6930]
24-11-25 20:49:39 | I |     + error = [2.6930]
24-11-25 20:49:40 | I |       - range scale = [    1.0000]
24-11-25 20:49:40 | I |         sum  error  = [   15.5008]
24-11-25 20:49:40 | I |         best error  = [   15.5008]
24-11-25 20:49:40 | I |     + error = [15.5008]
24-11-25 20:49:40 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 20:49:41 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 20:49:43 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 20:49:44 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 20:49:45 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 20:49:47 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 20:49:48 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 20:49:51 | I | quantizing activations for layer model.layers.0
24-11-25 20:49:51 | I | collecting info in model.layers.0
24-11-25 20:49:51 | I | collecting info in model.layers.0
24-11-25 20:49:51 | I | collecting info in model.layers.0
24-11-25 20:49:51 | I | collecting info in model.layers.0
24-11-25 20:49:52 | I | collecting calibration activations in model.layers.0
24-11-25 20:49:52 | I | collecting calibration activations in model.layers.0
24-11-25 20:49:52 | I | collecting calibration activations in model.layers.0
24-11-25 20:49:52 | I | collecting calibration activations in model.layers.0
24-11-25 20:49:54 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 20:49:54 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 20:49:54 | I | - Evaluator: gptq
24-11-25 20:49:54 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 20:49:54 | I | - Batch_size: 8
24-11-25 20:49:54 | I |   + Max_seq_length: 2048
24-11-25 20:50:35 | I |     - Results:
24-11-25 20:50:35 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 20:50:35 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 20:50:35 | I |       |wikitext |      1|word_perplexity|7.8063|  |7.8063|
24-11-25 20:50:35 | I |       |val_valid|      1|word_perplexity|9.0729|  |9.0729|
24-11-25 20:50:35 | I |       
24-11-25 20:50:35 | I | forward this layer
24-11-25 20:50:35 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/194.pt
24-11-25 20:50:35 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/194.pt
24-11-25 20:50:35 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 20:50:35 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 20:50:35 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 20:50:35 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 20:50:35 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 20:50:35 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 20:50:35 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 20:50:35 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 20:50:35 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 20:50:35 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 20:50:35 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 20:50:35 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 20:50:35 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 20:50:35 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 20:50:35 | I | in layer model.layers.0
24-11-25 20:50:35 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 20:50:35 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 20:50:35 | I | - Evaluator: gptq
24-11-25 20:50:36 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 20:50:36 | I | - Batch_size: 8
24-11-25 20:50:36 | I |   + Max_seq_length: 2048
24-11-25 20:51:14 | I |     - Results:
24-11-25 20:51:14 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 20:51:14 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 20:51:14 | I |       |wikitext |      1|word_perplexity|7.7784|  |7.7784|
24-11-25 20:51:14 | I |       |val_valid|      1|word_perplexity|9.0438|  |9.0438|
24-11-25 20:51:14 | I |       
24-11-25 20:51:14 | I | quantizing weights for layer model.layers.0
24-11-25 20:51:14 | I | collecting info in model.layers.0
24-11-25 20:51:14 | I | collecting info in model.layers.0
24-11-25 20:51:14 | I | collecting info in model.layers.0
24-11-25 20:51:14 | I | collecting info in model.layers.0
24-11-25 20:51:14 | I | collecting calibration activations in model.layers.0
24-11-25 20:51:14 | I | collecting calibration activations in model.layers.0
24-11-25 20:51:14 | I | collecting calibration activations in model.layers.0
24-11-25 20:51:14 | I | collecting calibration activations in model.layers.0
24-11-25 20:51:15 | I | - Quantizing decoder layer model.layers.0
24-11-25 20:51:15 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 20:51:15 | I |       - range scale = [    1.0000]
24-11-25 20:51:15 | I |         sum  error  = [    0.0588]
24-11-25 20:51:15 | I |         best error  = [    0.0588]
24-11-25 20:51:15 | I |     + error = [0.0588]
24-11-25 20:51:16 | I |       - range scale = [    1.0000]
24-11-25 20:51:16 | I |         sum  error  = [    0.5919]
24-11-25 20:51:16 | I |         best error  = [    0.5919]
24-11-25 20:51:16 | I |     + error = [0.5919]
24-11-25 20:51:16 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 20:51:17 | I |       - range scale = [    1.0000]
24-11-25 20:51:17 | I |         sum  error  = [    0.0640]
24-11-25 20:51:17 | I |         best error  = [    0.0640]
24-11-25 20:51:17 | I |     + error = [0.0640]
24-11-25 20:51:18 | I |       - range scale = [    1.0000]
24-11-25 20:51:18 | I |         sum  error  = [    0.5334]
24-11-25 20:51:18 | I |         best error  = [    0.5334]
24-11-25 20:51:18 | I |     + error = [0.5334]
24-11-25 20:51:18 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 20:51:19 | I |       - range scale = [    1.0000]
24-11-25 20:51:19 | I |         sum  error  = [    0.2366]
24-11-25 20:51:19 | I |         best error  = [    0.2366]
24-11-25 20:51:19 | I |     + error = [0.2366]
24-11-25 20:51:19 | I |       - range scale = [    1.0000]
24-11-25 20:51:19 | I |         sum  error  = [    1.8371]
24-11-25 20:51:19 | I |         best error  = [    1.8371]
24-11-25 20:51:19 | I |     + error = [1.8371]
24-11-25 20:51:20 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 20:51:20 | I |       - range scale = [    1.0000]
24-11-25 20:51:20 | I |         sum  error  = [    0.0603]
24-11-25 20:51:20 | I |         best error  = [    0.0603]
24-11-25 20:51:20 | I |     + error = [0.0603]
24-11-25 20:51:21 | I |       - range scale = [    1.0000]
24-11-25 20:51:21 | I |         sum  error  = [    0.5750]
24-11-25 20:51:21 | I |         best error  = [    0.5750]
24-11-25 20:51:21 | I |     + error = [0.5750]
24-11-25 20:51:21 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 20:51:22 | I |       - range scale = [    1.0000]
24-11-25 20:51:22 | I |         sum  error  = [    1.0545]
24-11-25 20:51:22 | I |         best error  = [    1.0545]
24-11-25 20:51:22 | I |     + error = [1.0545]
24-11-25 20:51:23 | I |       - range scale = [    1.0000]
24-11-25 20:51:23 | I |         sum  error  = [   11.6807]
24-11-25 20:51:23 | I |         best error  = [   11.6807]
24-11-25 20:51:23 | I |     + error = [11.6807]
24-11-25 20:51:23 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 20:51:23 | I |       - range scale = [    1.0000]
24-11-25 20:51:23 | I |         sum  error  = [    1.2207]
24-11-25 20:51:23 | I |         best error  = [    1.2207]
24-11-25 20:51:23 | I |     + error = [1.2207]
24-11-25 20:51:24 | I |       - range scale = [    1.0000]
24-11-25 20:51:24 | I |         sum  error  = [   12.0545]
24-11-25 20:51:24 | I |         best error  = [   12.0545]
24-11-25 20:51:24 | I |     + error = [12.0545]
24-11-25 20:51:24 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 20:51:25 | I |       - range scale = [    1.0000]
24-11-25 20:51:25 | I |         sum  error  = [    3.6555]
24-11-25 20:51:25 | I |         best error  = [    3.6555]
24-11-25 20:51:25 | I |     + error = [3.6555]
24-11-25 20:51:26 | I |       - range scale = [    1.0000]
24-11-25 20:51:26 | I |         sum  error  = [   20.2824]
24-11-25 20:51:26 | I |         best error  = [   20.2824]
24-11-25 20:51:26 | I |     + error = [20.2824]
24-11-25 20:51:26 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 20:51:27 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 20:51:29 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 20:51:30 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 20:51:32 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 20:51:33 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 20:51:34 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 20:51:38 | I | quantizing activations for layer model.layers.0
24-11-25 20:51:38 | I | collecting info in model.layers.0
24-11-25 20:51:38 | I | collecting info in model.layers.0
24-11-25 20:51:38 | I | collecting info in model.layers.0
24-11-25 20:51:38 | I | collecting info in model.layers.0
24-11-25 20:51:38 | I | collecting calibration activations in model.layers.0
24-11-25 20:51:38 | I | collecting calibration activations in model.layers.0
24-11-25 20:51:38 | I | collecting calibration activations in model.layers.0
24-11-25 20:51:39 | I | collecting calibration activations in model.layers.0
24-11-25 20:51:40 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 20:51:40 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 20:51:40 | I | - Evaluator: gptq
24-11-25 20:51:40 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 20:51:40 | I | - Batch_size: 8
24-11-25 20:51:40 | I |   + Max_seq_length: 2048
24-11-25 20:52:22 | I |     - Results:
24-11-25 20:52:22 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 20:52:22 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 20:52:22 | I |       |wikitext |      1|word_perplexity|7.8092|  |7.8092|
24-11-25 20:52:22 | I |       |val_valid|      1|word_perplexity|9.0800|  |9.0800|
24-11-25 20:52:22 | I |       
24-11-25 20:52:22 | I | forward this layer
24-11-25 20:52:22 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/195.pt
24-11-25 20:52:22 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/195.pt
24-11-25 20:52:22 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 20:52:22 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 20:52:22 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 20:52:22 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 20:52:22 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 20:52:22 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 20:52:22 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 20:52:22 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 20:52:22 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 20:52:22 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 20:52:22 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 20:52:22 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 20:52:22 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 20:52:22 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 20:52:22 | I | [83] done with optimizer step
24-11-25 20:52:22 | I | epoch 001:     98 / 409600000 loss=9.3097e-05, loss_per_token=0.190663, loss_sum=6247.63, wps=153.7, ups=0, wpb=32768, bsz=64, num_updates=84, lr=0.000149983, gnorm=24.969, clip=100, loss_scale=0.0078, train_wall=213, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=21272, lmquant_ppl_result_wikitext_in_train_no_quant=7.77842, lmquant_ppl_result_val_in_train_no_quant=9.04377, lmquant_ppl_result_wikitext_in_train_with_quant=7.80915, lmquant_ppl_result_val_in_train_with_quant=9.08003
24-11-25 20:52:22 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 20:52:22 | I | in layer model.layers.0
24-11-25 20:52:22 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 20:52:22 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 20:52:22 | I | - Evaluator: gptq
24-11-25 20:52:22 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 20:52:22 | I | - Batch_size: 8
24-11-25 20:52:22 | I |   + Max_seq_length: 2048
24-11-25 20:53:00 | I |     - Results:
24-11-25 20:53:00 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 20:53:00 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 20:53:00 | I |       |wikitext |      1|word_perplexity|7.7837|  |7.7837|
24-11-25 20:53:00 | I |       |val_valid|      1|word_perplexity|9.0449|  |9.0449|
24-11-25 20:53:00 | I |       
24-11-25 20:53:00 | I | quantizing weights for layer model.layers.0
24-11-25 20:53:00 | I | collecting info in model.layers.0
24-11-25 20:53:00 | I | collecting info in model.layers.0
24-11-25 20:53:00 | I | collecting info in model.layers.0
24-11-25 20:53:00 | I | collecting info in model.layers.0
24-11-25 20:53:01 | I | collecting calibration activations in model.layers.0
24-11-25 20:53:01 | I | collecting calibration activations in model.layers.0
24-11-25 20:53:01 | I | collecting calibration activations in model.layers.0
24-11-25 20:53:01 | I | collecting calibration activations in model.layers.0
24-11-25 20:53:02 | I | - Quantizing decoder layer model.layers.0
24-11-25 20:53:02 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 20:53:02 | I |       - range scale = [    1.0000]
24-11-25 20:53:02 | I |         sum  error  = [    0.0613]
24-11-25 20:53:02 | I |         best error  = [    0.0613]
24-11-25 20:53:02 | I |     + error = [0.0613]
24-11-25 20:53:03 | I |       - range scale = [    1.0000]
24-11-25 20:53:03 | I |         sum  error  = [    0.5994]
24-11-25 20:53:03 | I |         best error  = [    0.5994]
24-11-25 20:53:03 | I |     + error = [0.5994]
24-11-25 20:53:03 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 20:53:04 | I |       - range scale = [    1.0000]
24-11-25 20:53:04 | I |         sum  error  = [    0.0647]
24-11-25 20:53:04 | I |         best error  = [    0.0647]
24-11-25 20:53:04 | I |     + error = [0.0647]
24-11-25 20:53:05 | I |       - range scale = [    1.0000]
24-11-25 20:53:05 | I |         sum  error  = [    0.5537]
24-11-25 20:53:05 | I |         best error  = [    0.5537]
24-11-25 20:53:05 | I |     + error = [0.5537]
24-11-25 20:53:05 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 20:53:06 | I |       - range scale = [    1.0000]
24-11-25 20:53:06 | I |         sum  error  = [    0.2355]
24-11-25 20:53:06 | I |         best error  = [    0.2355]
24-11-25 20:53:06 | I |     + error = [0.2355]
24-11-25 20:53:06 | I |       - range scale = [    1.0000]
24-11-25 20:53:06 | I |         sum  error  = [    1.8374]
24-11-25 20:53:06 | I |         best error  = [    1.8374]
24-11-25 20:53:06 | I |     + error = [1.8374]
24-11-25 20:53:07 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 20:53:07 | I |       - range scale = [    1.0000]
24-11-25 20:53:07 | I |         sum  error  = [    0.0621]
24-11-25 20:53:07 | I |         best error  = [    0.0621]
24-11-25 20:53:07 | I |     + error = [0.0621]
24-11-25 20:53:08 | I |       - range scale = [    1.0000]
24-11-25 20:53:08 | I |         sum  error  = [    0.5930]
24-11-25 20:53:08 | I |         best error  = [    0.5930]
24-11-25 20:53:08 | I |     + error = [0.5930]
24-11-25 20:53:08 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 20:53:09 | I |       - range scale = [    1.0000]
24-11-25 20:53:09 | I |         sum  error  = [    1.0780]
24-11-25 20:53:09 | I |         best error  = [    1.0780]
24-11-25 20:53:09 | I |     + error = [1.0780]
24-11-25 20:53:10 | I |       - range scale = [    1.0000]
24-11-25 20:53:10 | I |         sum  error  = [   11.9371]
24-11-25 20:53:10 | I |         best error  = [   11.9371]
24-11-25 20:53:10 | I |     + error = [11.9371]
24-11-25 20:53:10 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 20:53:10 | I |       - range scale = [    1.0000]
24-11-25 20:53:10 | I |         sum  error  = [    1.2433]
24-11-25 20:53:10 | I |         best error  = [    1.2433]
24-11-25 20:53:10 | I |     + error = [1.2433]
24-11-25 20:53:11 | I |       - range scale = [    1.0000]
24-11-25 20:53:11 | I |         sum  error  = [   12.3251]
24-11-25 20:53:11 | I |         best error  = [   12.3251]
24-11-25 20:53:11 | I |     + error = [12.3251]
24-11-25 20:53:11 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 20:53:12 | I |       - range scale = [    1.0000]
24-11-25 20:53:12 | I |         sum  error  = [    3.1524]
24-11-25 20:53:12 | I |         best error  = [    3.1524]
24-11-25 20:53:12 | I |     + error = [3.1524]
24-11-25 20:53:13 | I |       - range scale = [    1.0000]
24-11-25 20:53:13 | I |         sum  error  = [   17.7590]
24-11-25 20:53:13 | I |         best error  = [   17.7590]
24-11-25 20:53:13 | I |     + error = [17.7590]
24-11-25 20:53:13 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 20:53:14 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 20:53:16 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 20:53:17 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 20:53:19 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 20:53:20 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 20:53:21 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 20:53:25 | I | quantizing activations for layer model.layers.0
24-11-25 20:53:25 | I | collecting info in model.layers.0
24-11-25 20:53:25 | I | collecting info in model.layers.0
24-11-25 20:53:25 | I | collecting info in model.layers.0
24-11-25 20:53:25 | I | collecting info in model.layers.0
24-11-25 20:53:25 | I | collecting calibration activations in model.layers.0
24-11-25 20:53:25 | I | collecting calibration activations in model.layers.0
24-11-25 20:53:25 | I | collecting calibration activations in model.layers.0
24-11-25 20:53:25 | I | collecting calibration activations in model.layers.0
24-11-25 20:53:27 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 20:53:27 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 20:53:27 | I | - Evaluator: gptq
24-11-25 20:53:27 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 20:53:27 | I | - Batch_size: 8
24-11-25 20:53:27 | I |   + Max_seq_length: 2048
24-11-25 20:54:09 | I |     - Results:
24-11-25 20:54:09 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 20:54:09 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 20:54:09 | I |       |wikitext |      1|word_perplexity|7.8005|  |7.8005|
24-11-25 20:54:09 | I |       |val_valid|      1|word_perplexity|9.0818|  |9.0818|
24-11-25 20:54:09 | I |       
24-11-25 20:54:09 | I | forward this layer
24-11-25 20:54:09 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/196.pt
24-11-25 20:54:09 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/196.pt
24-11-25 20:54:09 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 20:54:09 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 20:54:09 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 20:54:09 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 20:54:09 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 20:54:09 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 20:54:09 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 20:54:09 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 20:54:09 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 20:54:09 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 20:54:09 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 20:54:09 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 20:54:09 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 20:54:09 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 20:54:09 | I | in layer model.layers.0
24-11-25 20:54:09 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 20:54:09 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 20:54:09 | I | - Evaluator: gptq
24-11-25 20:54:09 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 20:54:09 | I | - Batch_size: 8
24-11-25 20:54:09 | I |   + Max_seq_length: 2048
24-11-25 20:54:47 | I |     - Results:
24-11-25 20:54:47 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 20:54:47 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 20:54:47 | I |       |wikitext |      1|word_perplexity|7.7837|  |7.7837|
24-11-25 20:54:47 | I |       |val_valid|      1|word_perplexity|9.0449|  |9.0449|
24-11-25 20:54:47 | I |       
24-11-25 20:54:47 | I | quantizing weights for layer model.layers.0
24-11-25 20:54:47 | I | collecting info in model.layers.0
24-11-25 20:54:47 | I | collecting info in model.layers.0
24-11-25 20:54:47 | I | collecting info in model.layers.0
24-11-25 20:54:47 | I | collecting info in model.layers.0
24-11-25 20:54:48 | I | collecting calibration activations in model.layers.0
24-11-25 20:54:48 | I | collecting calibration activations in model.layers.0
24-11-25 20:54:48 | I | collecting calibration activations in model.layers.0
24-11-25 20:54:48 | I | collecting calibration activations in model.layers.0
24-11-25 20:54:48 | I | - Quantizing decoder layer model.layers.0
24-11-25 20:54:48 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 20:54:49 | I |       - range scale = [    1.0000]
24-11-25 20:54:49 | I |         sum  error  = [    0.0591]
24-11-25 20:54:49 | I |         best error  = [    0.0591]
24-11-25 20:54:49 | I |     + error = [0.0591]
24-11-25 20:54:50 | I |       - range scale = [    1.0000]
24-11-25 20:54:50 | I |         sum  error  = [    0.5688]
24-11-25 20:54:50 | I |         best error  = [    0.5688]
24-11-25 20:54:50 | I |     + error = [0.5688]
24-11-25 20:54:50 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 20:54:51 | I |       - range scale = [    1.0000]
24-11-25 20:54:51 | I |         sum  error  = [    0.0637]
24-11-25 20:54:51 | I |         best error  = [    0.0637]
24-11-25 20:54:51 | I |     + error = [0.0637]
24-11-25 20:54:51 | I |       - range scale = [    1.0000]
24-11-25 20:54:51 | I |         sum  error  = [    0.5486]
24-11-25 20:54:51 | I |         best error  = [    0.5486]
24-11-25 20:54:51 | I |     + error = [0.5486]
24-11-25 20:54:52 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 20:54:52 | I |       - range scale = [    1.0000]
24-11-25 20:54:52 | I |         sum  error  = [    0.2382]
24-11-25 20:54:52 | I |         best error  = [    0.2382]
24-11-25 20:54:52 | I |     + error = [0.2382]
24-11-25 20:54:53 | I |       - range scale = [    1.0000]
24-11-25 20:54:53 | I |         sum  error  = [    1.8526]
24-11-25 20:54:53 | I |         best error  = [    1.8526]
24-11-25 20:54:53 | I |     + error = [1.8526]
24-11-25 20:54:53 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 20:54:54 | I |       - range scale = [    1.0000]
24-11-25 20:54:54 | I |         sum  error  = [    0.0694]
24-11-25 20:54:54 | I |         best error  = [    0.0694]
24-11-25 20:54:54 | I |     + error = [0.0694]
24-11-25 20:54:54 | I |       - range scale = [    1.0000]
24-11-25 20:54:54 | I |         sum  error  = [    0.6470]
24-11-25 20:54:54 | I |         best error  = [    0.6470]
24-11-25 20:54:54 | I |     + error = [0.6470]
24-11-25 20:54:55 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 20:54:55 | I |       - range scale = [    1.0000]
24-11-25 20:54:55 | I |         sum  error  = [    1.0766]
24-11-25 20:54:55 | I |         best error  = [    1.0766]
24-11-25 20:54:55 | I |     + error = [1.0766]
24-11-25 20:54:56 | I |       - range scale = [    1.0000]
24-11-25 20:54:56 | I |         sum  error  = [   11.8995]
24-11-25 20:54:56 | I |         best error  = [   11.8995]
24-11-25 20:54:56 | I |     + error = [11.8995]
24-11-25 20:54:56 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 20:54:57 | I |       - range scale = [    1.0000]
24-11-25 20:54:57 | I |         sum  error  = [    1.2421]
24-11-25 20:54:57 | I |         best error  = [    1.2421]
24-11-25 20:54:57 | I |     + error = [1.2421]
24-11-25 20:54:58 | I |       - range scale = [    1.0000]
24-11-25 20:54:58 | I |         sum  error  = [   12.3003]
24-11-25 20:54:58 | I |         best error  = [   12.3003]
24-11-25 20:54:58 | I |     + error = [12.3003]
24-11-25 20:54:58 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 20:54:59 | I |       - range scale = [    1.0000]
24-11-25 20:54:59 | I |         sum  error  = [    3.5264]
24-11-25 20:54:59 | I |         best error  = [    3.5264]
24-11-25 20:54:59 | I |     + error = [3.5264]
24-11-25 20:54:59 | I |       - range scale = [    1.0000]
24-11-25 20:54:59 | I |         sum  error  = [   19.4694]
24-11-25 20:54:59 | I |         best error  = [   19.4694]
24-11-25 20:54:59 | I |     + error = [19.4694]
24-11-25 20:55:00 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 20:55:01 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 20:55:02 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 20:55:04 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 20:55:05 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 20:55:06 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 20:55:08 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 20:55:11 | I | quantizing activations for layer model.layers.0
24-11-25 20:55:11 | I | collecting info in model.layers.0
24-11-25 20:55:11 | I | collecting info in model.layers.0
24-11-25 20:55:11 | I | collecting info in model.layers.0
24-11-25 20:55:11 | I | collecting info in model.layers.0
24-11-25 20:55:12 | I | collecting calibration activations in model.layers.0
24-11-25 20:55:12 | I | collecting calibration activations in model.layers.0
24-11-25 20:55:12 | I | collecting calibration activations in model.layers.0
24-11-25 20:55:12 | I | collecting calibration activations in model.layers.0
24-11-25 20:55:14 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 20:55:14 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 20:55:14 | I | - Evaluator: gptq
24-11-25 20:55:14 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 20:55:14 | I | - Batch_size: 8
24-11-25 20:55:14 | I |   + Max_seq_length: 2048
24-11-25 20:55:55 | I |     - Results:
24-11-25 20:55:55 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 20:55:55 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 20:55:55 | I |       |wikitext |      1|word_perplexity|7.8034|  |7.8034|
24-11-25 20:55:55 | I |       |val_valid|      1|word_perplexity|9.0802|  |9.0802|
24-11-25 20:55:55 | I |       
24-11-25 20:55:55 | I | forward this layer
24-11-25 20:55:55 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/197.pt
24-11-25 20:55:55 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/197.pt
24-11-25 20:55:55 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 20:55:55 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 20:55:55 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 20:55:55 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 20:55:55 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 20:55:55 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 20:55:55 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 20:55:55 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 20:55:55 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 20:55:55 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 20:55:55 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 20:55:55 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 20:55:55 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 20:55:55 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 20:55:55 | I | [84] done with optimizer step
24-11-25 20:55:55 | I | epoch 001:     99 / 409600000 loss=8.40587e-05, loss_per_token=0.172152, loss_sum=5641.08, wps=153.6, ups=0, wpb=32768, bsz=64, num_updates=85, lr=0.000149982, gnorm=18.028, clip=100, loss_scale=0.0078, train_wall=213, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=21486, lmquant_ppl_result_wikitext_in_train_no_quant=7.78373, lmquant_ppl_result_val_in_train_no_quant=9.04486, lmquant_ppl_result_wikitext_in_train_with_quant=7.80343, lmquant_ppl_result_val_in_train_with_quant=9.08025
24-11-25 20:55:56 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 20:55:56 | I | in layer model.layers.0
24-11-25 20:55:56 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 20:55:56 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 20:55:56 | I | - Evaluator: gptq
24-11-25 20:55:56 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 20:55:56 | I | - Batch_size: 8
24-11-25 20:55:56 | I |   + Max_seq_length: 2048
24-11-25 20:56:34 | I |     - Results:
24-11-25 20:56:34 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 20:56:34 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 20:56:34 | I |       |wikitext |      1|word_perplexity|7.7875|  |7.7875|
24-11-25 20:56:34 | I |       |val_valid|      1|word_perplexity|9.0439|  |9.0439|
24-11-25 20:56:34 | I |       
24-11-25 20:56:34 | I | quantizing weights for layer model.layers.0
24-11-25 20:56:34 | I | collecting info in model.layers.0
24-11-25 20:56:34 | I | collecting info in model.layers.0
24-11-25 20:56:34 | I | collecting info in model.layers.0
24-11-25 20:56:34 | I | collecting info in model.layers.0
24-11-25 20:56:34 | I | collecting calibration activations in model.layers.0
24-11-25 20:56:35 | I | collecting calibration activations in model.layers.0
24-11-25 20:56:35 | I | collecting calibration activations in model.layers.0
24-11-25 20:56:35 | I | collecting calibration activations in model.layers.0
24-11-25 20:56:35 | I | - Quantizing decoder layer model.layers.0
24-11-25 20:56:35 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 20:56:36 | I |       - range scale = [    1.0000]
24-11-25 20:56:36 | I |         sum  error  = [    0.0639]
24-11-25 20:56:36 | I |         best error  = [    0.0639]
24-11-25 20:56:36 | I |     + error = [0.0639]
24-11-25 20:56:36 | I |       - range scale = [    1.0000]
24-11-25 20:56:36 | I |         sum  error  = [    0.6563]
24-11-25 20:56:36 | I |         best error  = [    0.6563]
24-11-25 20:56:36 | I |     + error = [0.6563]
24-11-25 20:56:37 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 20:56:37 | I |       - range scale = [    1.0000]
24-11-25 20:56:37 | I |         sum  error  = [    0.0698]
24-11-25 20:56:37 | I |         best error  = [    0.0698]
24-11-25 20:56:37 | I |     + error = [0.0698]
24-11-25 20:56:38 | I |       - range scale = [    1.0000]
24-11-25 20:56:38 | I |         sum  error  = [    0.5967]
24-11-25 20:56:38 | I |         best error  = [    0.5967]
24-11-25 20:56:38 | I |     + error = [0.5967]
24-11-25 20:56:38 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 20:56:39 | I |       - range scale = [    1.0000]
24-11-25 20:56:39 | I |         sum  error  = [    0.2403]
24-11-25 20:56:39 | I |         best error  = [    0.2403]
24-11-25 20:56:39 | I |     + error = [0.2403]
24-11-25 20:56:40 | I |       - range scale = [    1.0000]
24-11-25 20:56:40 | I |         sum  error  = [    1.8993]
24-11-25 20:56:40 | I |         best error  = [    1.8993]
24-11-25 20:56:40 | I |     + error = [1.8993]
24-11-25 20:56:40 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 20:56:40 | I |       - range scale = [    1.0000]
24-11-25 20:56:40 | I |         sum  error  = [    0.0734]
24-11-25 20:56:40 | I |         best error  = [    0.0734]
24-11-25 20:56:40 | I |     + error = [0.0734]
24-11-25 20:56:41 | I |       - range scale = [    1.0000]
24-11-25 20:56:41 | I |         sum  error  = [    0.6951]
24-11-25 20:56:41 | I |         best error  = [    0.6951]
24-11-25 20:56:41 | I |     + error = [0.6951]
24-11-25 20:56:41 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 20:56:42 | I |       - range scale = [    1.0000]
24-11-25 20:56:42 | I |         sum  error  = [    1.1141]
24-11-25 20:56:42 | I |         best error  = [    1.1141]
24-11-25 20:56:42 | I |     + error = [1.1141]
24-11-25 20:56:43 | I |       - range scale = [    1.0000]
24-11-25 20:56:43 | I |         sum  error  = [   12.3350]
24-11-25 20:56:43 | I |         best error  = [   12.3350]
24-11-25 20:56:43 | I |     + error = [12.3350]
24-11-25 20:56:43 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 20:56:44 | I |       - range scale = [    1.0000]
24-11-25 20:56:44 | I |         sum  error  = [    1.2841]
24-11-25 20:56:44 | I |         best error  = [    1.2841]
24-11-25 20:56:44 | I |     + error = [1.2841]
24-11-25 20:56:44 | I |       - range scale = [    1.0000]
24-11-25 20:56:44 | I |         sum  error  = [   12.7564]
24-11-25 20:56:44 | I |         best error  = [   12.7564]
24-11-25 20:56:44 | I |     + error = [12.7564]
24-11-25 20:56:45 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 20:56:45 | I |       - range scale = [    1.0000]
24-11-25 20:56:45 | I |         sum  error  = [    3.3555]
24-11-25 20:56:45 | I |         best error  = [    3.3555]
24-11-25 20:56:45 | I |     + error = [3.3555]
24-11-25 20:56:46 | I |       - range scale = [    1.0000]
24-11-25 20:56:46 | I |         sum  error  = [   18.2087]
24-11-25 20:56:46 | I |         best error  = [   18.2087]
24-11-25 20:56:46 | I |     + error = [18.2087]
24-11-25 20:56:46 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 20:56:48 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 20:56:49 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 20:56:50 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 20:56:52 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 20:56:53 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 20:56:55 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 20:56:58 | I | quantizing activations for layer model.layers.0
24-11-25 20:56:58 | I | collecting info in model.layers.0
24-11-25 20:56:58 | I | collecting info in model.layers.0
24-11-25 20:56:58 | I | collecting info in model.layers.0
24-11-25 20:56:58 | I | collecting info in model.layers.0
24-11-25 20:56:58 | I | collecting calibration activations in model.layers.0
24-11-25 20:56:58 | I | collecting calibration activations in model.layers.0
24-11-25 20:56:59 | I | collecting calibration activations in model.layers.0
24-11-25 20:56:59 | I | collecting calibration activations in model.layers.0
24-11-25 20:57:01 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 20:57:01 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 20:57:01 | I | - Evaluator: gptq
24-11-25 20:57:01 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 20:57:01 | I | - Batch_size: 8
24-11-25 20:57:01 | I |   + Max_seq_length: 2048
24-11-25 20:57:42 | I |     - Results:
24-11-25 20:57:42 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 20:57:42 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 20:57:42 | I |       |wikitext |      1|word_perplexity|7.8232|  |7.8232|
24-11-25 20:57:42 | I |       |val_valid|      1|word_perplexity|9.0738|  |9.0738|
24-11-25 20:57:42 | I |       
24-11-25 20:57:42 | I | forward this layer
24-11-25 20:57:42 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/198.pt
24-11-25 20:57:42 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/198.pt
24-11-25 20:57:42 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 20:57:42 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 20:57:42 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 20:57:42 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 20:57:42 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 20:57:42 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 20:57:42 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 20:57:42 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 20:57:42 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 20:57:42 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 20:57:42 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 20:57:42 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 20:57:42 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 20:57:42 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 20:57:42 | I | in layer model.layers.0
24-11-25 20:57:42 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 20:57:42 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 20:57:42 | I | - Evaluator: gptq
24-11-25 20:57:42 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 20:57:42 | I | - Batch_size: 8
24-11-25 20:57:42 | I |   + Max_seq_length: 2048
24-11-25 20:58:20 | I |     - Results:
24-11-25 20:58:20 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 20:58:20 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 20:58:20 | I |       |wikitext |      1|word_perplexity|7.7875|  |7.7875|
24-11-25 20:58:20 | I |       |val_valid|      1|word_perplexity|9.0439|  |9.0439|
24-11-25 20:58:20 | I |       
24-11-25 20:58:20 | I | quantizing weights for layer model.layers.0
24-11-25 20:58:20 | I | collecting info in model.layers.0
24-11-25 20:58:20 | I | collecting info in model.layers.0
24-11-25 20:58:20 | I | collecting info in model.layers.0
24-11-25 20:58:20 | I | collecting info in model.layers.0
24-11-25 20:58:21 | I | collecting calibration activations in model.layers.0
24-11-25 20:58:21 | I | collecting calibration activations in model.layers.0
24-11-25 20:58:21 | I | collecting calibration activations in model.layers.0
24-11-25 20:58:21 | I | collecting calibration activations in model.layers.0
24-11-25 20:58:22 | I | - Quantizing decoder layer model.layers.0
24-11-25 20:58:22 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 20:58:22 | I |       - range scale = [    1.0000]
24-11-25 20:58:22 | I |         sum  error  = [    0.0657]
24-11-25 20:58:22 | I |         best error  = [    0.0657]
24-11-25 20:58:22 | I |     + error = [0.0657]
24-11-25 20:58:23 | I |       - range scale = [    1.0000]
24-11-25 20:58:23 | I |         sum  error  = [    0.7022]
24-11-25 20:58:23 | I |         best error  = [    0.7022]
24-11-25 20:58:23 | I |     + error = [0.7022]
24-11-25 20:58:23 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 20:58:24 | I |       - range scale = [    1.0000]
24-11-25 20:58:24 | I |         sum  error  = [    0.0737]
24-11-25 20:58:24 | I |         best error  = [    0.0737]
24-11-25 20:58:24 | I |     + error = [0.0737]
24-11-25 20:58:25 | I |       - range scale = [    1.0000]
24-11-25 20:58:25 | I |         sum  error  = [    0.6428]
24-11-25 20:58:25 | I |         best error  = [    0.6428]
24-11-25 20:58:25 | I |     + error = [0.6428]
24-11-25 20:58:25 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 20:58:25 | I |       - range scale = [    1.0000]
24-11-25 20:58:25 | I |         sum  error  = [    0.2438]
24-11-25 20:58:25 | I |         best error  = [    0.2438]
24-11-25 20:58:25 | I |     + error = [0.2438]
24-11-25 20:58:26 | I |       - range scale = [    1.0000]
24-11-25 20:58:26 | I |         sum  error  = [    1.9307]
24-11-25 20:58:26 | I |         best error  = [    1.9307]
24-11-25 20:58:26 | I |     + error = [1.9307]
24-11-25 20:58:26 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 20:58:27 | I |       - range scale = [    1.0000]
24-11-25 20:58:27 | I |         sum  error  = [    0.0808]
24-11-25 20:58:27 | I |         best error  = [    0.0808]
24-11-25 20:58:27 | I |     + error = [0.0808]
24-11-25 20:58:28 | I |       - range scale = [    1.0000]
24-11-25 20:58:28 | I |         sum  error  = [    0.7738]
24-11-25 20:58:28 | I |         best error  = [    0.7738]
24-11-25 20:58:28 | I |     + error = [0.7738]
24-11-25 20:58:28 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 20:58:29 | I |       - range scale = [    1.0000]
24-11-25 20:58:29 | I |         sum  error  = [    1.1636]
24-11-25 20:58:29 | I |         best error  = [    1.1636]
24-11-25 20:58:29 | I |     + error = [1.1636]
24-11-25 20:58:29 | I |       - range scale = [    1.0000]
24-11-25 20:58:29 | I |         sum  error  = [   12.8820]
24-11-25 20:58:29 | I |         best error  = [   12.8820]
24-11-25 20:58:29 | I |     + error = [12.8820]
24-11-25 20:58:30 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 20:58:30 | I |       - range scale = [    1.0000]
24-11-25 20:58:30 | I |         sum  error  = [    1.3423]
24-11-25 20:58:30 | I |         best error  = [    1.3423]
24-11-25 20:58:30 | I |     + error = [1.3423]
24-11-25 20:58:31 | I |       - range scale = [    1.0000]
24-11-25 20:58:31 | I |         sum  error  = [   13.3405]
24-11-25 20:58:31 | I |         best error  = [   13.3405]
24-11-25 20:58:31 | I |     + error = [13.3405]
24-11-25 20:58:31 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 20:58:32 | I |       - range scale = [    1.0000]
24-11-25 20:58:32 | I |         sum  error  = [    2.9844]
24-11-25 20:58:32 | I |         best error  = [    2.9844]
24-11-25 20:58:32 | I |     + error = [2.9844]
24-11-25 20:58:33 | I |       - range scale = [    1.0000]
24-11-25 20:58:33 | I |         sum  error  = [   15.6051]
24-11-25 20:58:33 | I |         best error  = [   15.6051]
24-11-25 20:58:33 | I |     + error = [15.6051]
24-11-25 20:58:33 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 20:58:34 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 20:58:36 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 20:58:37 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 20:58:38 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 20:58:40 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 20:58:41 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 20:58:44 | I | quantizing activations for layer model.layers.0
24-11-25 20:58:44 | I | collecting info in model.layers.0
24-11-25 20:58:44 | I | collecting info in model.layers.0
24-11-25 20:58:44 | I | collecting info in model.layers.0
24-11-25 20:58:44 | I | collecting info in model.layers.0
24-11-25 20:58:45 | I | collecting calibration activations in model.layers.0
24-11-25 20:58:45 | I | collecting calibration activations in model.layers.0
24-11-25 20:58:45 | I | collecting calibration activations in model.layers.0
24-11-25 20:58:45 | I | collecting calibration activations in model.layers.0
24-11-25 20:58:47 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 20:58:47 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 20:58:47 | I | - Evaluator: gptq
24-11-25 20:58:47 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 20:58:47 | I | - Batch_size: 8
24-11-25 20:58:47 | I |   + Max_seq_length: 2048
24-11-25 20:59:28 | I |     - Results:
24-11-25 20:59:28 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 20:59:28 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 20:59:28 | I |       |wikitext |      1|word_perplexity|7.8342|  |7.8342|
24-11-25 20:59:28 | I |       |val_valid|      1|word_perplexity|9.0790|  |9.0790|
24-11-25 20:59:28 | I |       
24-11-25 20:59:28 | I | forward this layer
24-11-25 20:59:28 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/199.pt
24-11-25 20:59:28 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/199.pt
24-11-25 20:59:29 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 20:59:29 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 20:59:29 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 20:59:29 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 20:59:29 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 20:59:29 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 20:59:29 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 20:59:29 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 20:59:29 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 20:59:29 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 20:59:29 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 20:59:29 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 20:59:29 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 20:59:29 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 20:59:29 | I | [85] done with optimizer step
24-11-25 20:59:29 | I | epoch 001:    100 / 409600000 loss=0.000193721, loss_per_token=0.39674, loss_sum=13000.4, wps=153.7, ups=0, wpb=32768, bsz=64, num_updates=86, lr=0.000149982, gnorm=60.248, clip=100, loss_scale=0.0078, train_wall=213, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=21699, lmquant_ppl_result_wikitext_in_train_no_quant=7.78749, lmquant_ppl_result_val_in_train_no_quant=9.04392, lmquant_ppl_result_wikitext_in_train_with_quant=7.83416, lmquant_ppl_result_val_in_train_with_quant=9.07898
24-11-25 20:59:29 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 20:59:29 | I | in layer model.layers.0
24-11-25 20:59:29 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 20:59:29 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 20:59:29 | I | - Evaluator: gptq
24-11-25 20:59:29 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 20:59:29 | I | - Batch_size: 8
24-11-25 20:59:29 | I |   + Max_seq_length: 2048
24-11-25 21:00:07 | I |     - Results:
24-11-25 21:00:07 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 21:00:07 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 21:00:07 | I |       |wikitext |      1|word_perplexity|7.7871|  |7.7871|
24-11-25 21:00:07 | I |       |val_valid|      1|word_perplexity|9.0384|  |9.0384|
24-11-25 21:00:07 | I |       
24-11-25 21:00:07 | I | quantizing weights for layer model.layers.0
24-11-25 21:00:07 | I | collecting info in model.layers.0
24-11-25 21:00:07 | I | collecting info in model.layers.0
24-11-25 21:00:07 | I | collecting info in model.layers.0
24-11-25 21:00:07 | I | collecting info in model.layers.0
24-11-25 21:00:08 | I | collecting calibration activations in model.layers.0
24-11-25 21:00:08 | I | collecting calibration activations in model.layers.0
24-11-25 21:00:08 | I | collecting calibration activations in model.layers.0
24-11-25 21:00:08 | I | collecting calibration activations in model.layers.0
24-11-25 21:00:08 | I | - Quantizing decoder layer model.layers.0
24-11-25 21:00:08 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 21:00:09 | I |       - range scale = [    1.0000]
24-11-25 21:00:09 | I |         sum  error  = [    0.0633]
24-11-25 21:00:09 | I |         best error  = [    0.0633]
24-11-25 21:00:09 | I |     + error = [0.0633]
24-11-25 21:00:10 | I |       - range scale = [    1.0000]
24-11-25 21:00:10 | I |         sum  error  = [    0.5885]
24-11-25 21:00:10 | I |         best error  = [    0.5885]
24-11-25 21:00:10 | I |     + error = [0.5885]
24-11-25 21:00:10 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 21:00:11 | I |       - range scale = [    1.0000]
24-11-25 21:00:11 | I |         sum  error  = [    0.0642]
24-11-25 21:00:11 | I |         best error  = [    0.0642]
24-11-25 21:00:11 | I |     + error = [0.0642]
24-11-25 21:00:11 | I |       - range scale = [    1.0000]
24-11-25 21:00:11 | I |         sum  error  = [    0.5948]
24-11-25 21:00:11 | I |         best error  = [    0.5948]
24-11-25 21:00:11 | I |     + error = [0.5948]
24-11-25 21:00:12 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 21:00:12 | I |       - range scale = [    1.0000]
24-11-25 21:00:12 | I |         sum  error  = [    0.2395]
24-11-25 21:00:12 | I |         best error  = [    0.2395]
24-11-25 21:00:12 | I |     + error = [0.2395]
24-11-25 21:00:13 | I |       - range scale = [    1.0000]
24-11-25 21:00:13 | I |         sum  error  = [    1.8488]
24-11-25 21:00:13 | I |         best error  = [    1.8488]
24-11-25 21:00:13 | I |     + error = [1.8488]
24-11-25 21:00:13 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 21:00:14 | I |       - range scale = [    1.0000]
24-11-25 21:00:14 | I |         sum  error  = [    0.0683]
24-11-25 21:00:14 | I |         best error  = [    0.0683]
24-11-25 21:00:14 | I |     + error = [0.0683]
24-11-25 21:00:14 | I |       - range scale = [    1.0000]
24-11-25 21:00:14 | I |         sum  error  = [    0.6597]
24-11-25 21:00:14 | I |         best error  = [    0.6597]
24-11-25 21:00:14 | I |     + error = [0.6597]
24-11-25 21:00:15 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 21:00:15 | I |       - range scale = [    1.0000]
24-11-25 21:00:15 | I |         sum  error  = [    1.1182]
24-11-25 21:00:15 | I |         best error  = [    1.1182]
24-11-25 21:00:15 | I |     + error = [1.1182]
24-11-25 21:00:16 | I |       - range scale = [    1.0000]
24-11-25 21:00:16 | I |         sum  error  = [   12.4000]
24-11-25 21:00:16 | I |         best error  = [   12.4000]
24-11-25 21:00:16 | I |     + error = [12.4000]
24-11-25 21:00:16 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 21:00:17 | I |       - range scale = [    1.0000]
24-11-25 21:00:17 | I |         sum  error  = [    1.2937]
24-11-25 21:00:17 | I |         best error  = [    1.2937]
24-11-25 21:00:17 | I |     + error = [1.2937]
24-11-25 21:00:18 | I |       - range scale = [    1.0000]
24-11-25 21:00:18 | I |         sum  error  = [   12.8430]
24-11-25 21:00:18 | I |         best error  = [   12.8430]
24-11-25 21:00:18 | I |     + error = [12.8430]
24-11-25 21:00:18 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 21:00:19 | I |       - range scale = [    1.0000]
24-11-25 21:00:19 | I |         sum  error  = [    2.9164]
24-11-25 21:00:19 | I |         best error  = [    2.9164]
24-11-25 21:00:19 | I |     + error = [2.9164]
24-11-25 21:00:19 | I |       - range scale = [    1.0000]
24-11-25 21:00:19 | I |         sum  error  = [   15.7066]
24-11-25 21:00:19 | I |         best error  = [   15.7066]
24-11-25 21:00:19 | I |     + error = [15.7066]
24-11-25 21:00:20 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 21:00:21 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 21:00:22 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 21:00:24 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 21:00:25 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 21:00:27 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 21:00:28 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 21:00:31 | I | quantizing activations for layer model.layers.0
24-11-25 21:00:31 | I | collecting info in model.layers.0
24-11-25 21:00:31 | I | collecting info in model.layers.0
24-11-25 21:00:31 | I | collecting info in model.layers.0
24-11-25 21:00:31 | I | collecting info in model.layers.0
24-11-25 21:00:32 | I | collecting calibration activations in model.layers.0
24-11-25 21:00:32 | I | collecting calibration activations in model.layers.0
24-11-25 21:00:32 | I | collecting calibration activations in model.layers.0
24-11-25 21:00:32 | I | collecting calibration activations in model.layers.0
24-11-25 21:00:34 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 21:00:34 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 21:00:34 | I | - Evaluator: gptq
24-11-25 21:00:34 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 21:00:34 | I | - Batch_size: 8
24-11-25 21:00:34 | I |   + Max_seq_length: 2048
24-11-25 21:01:16 | I |     - Results:
24-11-25 21:01:16 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 21:01:16 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 21:01:16 | I |       |wikitext |      1|word_perplexity|7.8158|  |7.8158|
24-11-25 21:01:16 | I |       |val_valid|      1|word_perplexity|9.0868|  |9.0868|
24-11-25 21:01:16 | I |       
24-11-25 21:01:16 | I | forward this layer
24-11-25 21:01:16 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/200.pt
24-11-25 21:01:16 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/200.pt
24-11-25 21:01:16 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 21:01:16 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 21:01:16 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 21:01:16 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 21:01:16 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 21:01:16 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 21:01:16 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 21:01:16 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 21:01:16 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 21:01:16 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 21:01:16 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 21:01:16 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 21:01:16 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 21:01:16 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 21:01:16 | I | in layer model.layers.0
24-11-25 21:01:16 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 21:01:16 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 21:01:16 | I | - Evaluator: gptq
24-11-25 21:01:16 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 21:01:16 | I | - Batch_size: 8
24-11-25 21:01:16 | I |   + Max_seq_length: 2048
24-11-25 21:01:54 | I |     - Results:
24-11-25 21:01:54 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 21:01:54 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 21:01:54 | I |       |wikitext |      1|word_perplexity|7.7871|  |7.7871|
24-11-25 21:01:54 | I |       |val_valid|      1|word_perplexity|9.0384|  |9.0384|
24-11-25 21:01:54 | I |       
24-11-25 21:01:54 | I | quantizing weights for layer model.layers.0
24-11-25 21:01:54 | I | collecting info in model.layers.0
24-11-25 21:01:54 | I | collecting info in model.layers.0
24-11-25 21:01:54 | I | collecting info in model.layers.0
24-11-25 21:01:54 | I | collecting info in model.layers.0
24-11-25 21:01:55 | I | collecting calibration activations in model.layers.0
24-11-25 21:01:55 | I | collecting calibration activations in model.layers.0
24-11-25 21:01:55 | I | collecting calibration activations in model.layers.0
24-11-25 21:01:55 | I | collecting calibration activations in model.layers.0
24-11-25 21:01:55 | I | - Quantizing decoder layer model.layers.0
24-11-25 21:01:55 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 21:01:56 | I |       - range scale = [    1.0000]
24-11-25 21:01:56 | I |         sum  error  = [    0.0619]
24-11-25 21:01:56 | I |         best error  = [    0.0619]
24-11-25 21:01:56 | I |     + error = [0.0619]
24-11-25 21:01:57 | I |       - range scale = [    1.0000]
24-11-25 21:01:57 | I |         sum  error  = [    0.5895]
24-11-25 21:01:57 | I |         best error  = [    0.5895]
24-11-25 21:01:57 | I |     + error = [0.5895]
24-11-25 21:01:57 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 21:01:58 | I |       - range scale = [    1.0000]
24-11-25 21:01:58 | I |         sum  error  = [    0.0629]
24-11-25 21:01:58 | I |         best error  = [    0.0629]
24-11-25 21:01:58 | I |     + error = [0.0629]
24-11-25 21:01:58 | I |       - range scale = [    1.0000]
24-11-25 21:01:58 | I |         sum  error  = [    0.5595]
24-11-25 21:01:58 | I |         best error  = [    0.5595]
24-11-25 21:01:58 | I |     + error = [0.5595]
24-11-25 21:01:58 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 21:01:59 | I |       - range scale = [    1.0000]
24-11-25 21:01:59 | I |         sum  error  = [    0.2375]
24-11-25 21:01:59 | I |         best error  = [    0.2375]
24-11-25 21:01:59 | I |     + error = [0.2375]
24-11-25 21:02:00 | I |       - range scale = [    1.0000]
24-11-25 21:02:00 | I |         sum  error  = [    1.8361]
24-11-25 21:02:00 | I |         best error  = [    1.8361]
24-11-25 21:02:00 | I |     + error = [1.8361]
24-11-25 21:02:00 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 21:02:01 | I |       - range scale = [    1.0000]
24-11-25 21:02:01 | I |         sum  error  = [    0.0635]
24-11-25 21:02:01 | I |         best error  = [    0.0635]
24-11-25 21:02:01 | I |     + error = [0.0635]
24-11-25 21:02:01 | I |       - range scale = [    1.0000]
24-11-25 21:02:01 | I |         sum  error  = [    0.6087]
24-11-25 21:02:01 | I |         best error  = [    0.6087]
24-11-25 21:02:01 | I |     + error = [0.6087]
24-11-25 21:02:02 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 21:02:02 | I |       - range scale = [    1.0000]
24-11-25 21:02:02 | I |         sum  error  = [    1.0835]
24-11-25 21:02:02 | I |         best error  = [    1.0835]
24-11-25 21:02:02 | I |     + error = [1.0835]
24-11-25 21:02:03 | I |       - range scale = [    1.0000]
24-11-25 21:02:03 | I |         sum  error  = [   11.9839]
24-11-25 21:02:03 | I |         best error  = [   11.9839]
24-11-25 21:02:03 | I |     + error = [11.9839]
24-11-25 21:02:03 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 21:02:04 | I |       - range scale = [    1.0000]
24-11-25 21:02:04 | I |         sum  error  = [    1.2502]
24-11-25 21:02:04 | I |         best error  = [    1.2502]
24-11-25 21:02:04 | I |     + error = [1.2502]
24-11-25 21:02:05 | I |       - range scale = [    1.0000]
24-11-25 21:02:05 | I |         sum  error  = [   12.3826]
24-11-25 21:02:05 | I |         best error  = [   12.3826]
24-11-25 21:02:05 | I |     + error = [12.3826]
24-11-25 21:02:05 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 21:02:06 | I |       - range scale = [    1.0000]
24-11-25 21:02:06 | I |         sum  error  = [    3.4278]
24-11-25 21:02:06 | I |         best error  = [    3.4278]
24-11-25 21:02:06 | I |     + error = [3.4278]
24-11-25 21:02:06 | I |       - range scale = [    1.0000]
24-11-25 21:02:06 | I |         sum  error  = [   18.5449]
24-11-25 21:02:06 | I |         best error  = [   18.5449]
24-11-25 21:02:06 | I |     + error = [18.5449]
24-11-25 21:02:07 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 21:02:08 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 21:02:09 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 21:02:11 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 21:02:12 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 21:02:13 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 21:02:15 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 21:02:19 | I | quantizing activations for layer model.layers.0
24-11-25 21:02:19 | I | collecting info in model.layers.0
24-11-25 21:02:19 | I | collecting info in model.layers.0
24-11-25 21:02:19 | I | collecting info in model.layers.0
24-11-25 21:02:19 | I | collecting info in model.layers.0
24-11-25 21:02:20 | I | collecting calibration activations in model.layers.0
24-11-25 21:02:20 | I | collecting calibration activations in model.layers.0
24-11-25 21:02:20 | I | collecting calibration activations in model.layers.0
24-11-25 21:02:20 | I | collecting calibration activations in model.layers.0
24-11-25 21:02:22 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 21:02:22 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 21:02:22 | I | - Evaluator: gptq
24-11-25 21:02:22 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 21:02:22 | I | - Batch_size: 8
24-11-25 21:02:22 | I |   + Max_seq_length: 2048
24-11-25 21:03:04 | I |     - Results:
24-11-25 21:03:04 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 21:03:04 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 21:03:04 | I |       |wikitext |      1|word_perplexity|7.8200|  |7.8200|
24-11-25 21:03:04 | I |       |val_valid|      1|word_perplexity|9.0764|  |9.0764|
24-11-25 21:03:04 | I |       
24-11-25 21:03:04 | I | forward this layer
24-11-25 21:03:04 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/201.pt
24-11-25 21:03:04 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/201.pt
24-11-25 21:03:04 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 21:03:04 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 21:03:04 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 21:03:04 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 21:03:04 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 21:03:04 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 21:03:04 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 21:03:04 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 21:03:04 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 21:03:04 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 21:03:04 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 21:03:04 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 21:03:04 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 21:03:04 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 21:03:04 | I | [86] done with optimizer step
24-11-25 21:03:04 | I | epoch 001:    101 / 409600000 loss=5.37801e-05, loss_per_token=0.110142, loss_sum=3609.12, wps=152.1, ups=0, wpb=32768, bsz=64, num_updates=87, lr=0.000149981, gnorm=11.189, clip=100, loss_scale=0.0078, train_wall=215, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=21914, lmquant_ppl_result_wikitext_in_train_no_quant=7.78709, lmquant_ppl_result_val_in_train_no_quant=9.03843, lmquant_ppl_result_wikitext_in_train_with_quant=7.81995, lmquant_ppl_result_val_in_train_with_quant=9.07636
24-11-25 21:03:04 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 21:03:04 | I | in layer model.layers.0
24-11-25 21:03:04 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 21:03:04 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 21:03:04 | I | - Evaluator: gptq
24-11-25 21:03:04 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 21:03:04 | I | - Batch_size: 8
24-11-25 21:03:04 | I |   + Max_seq_length: 2048
24-11-25 21:03:42 | I |     - Results:
24-11-25 21:03:43 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 21:03:43 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 21:03:43 | I |       |wikitext |      1|word_perplexity|7.7855|  |7.7855|
24-11-25 21:03:43 | I |       |val_valid|      1|word_perplexity|9.0322|  |9.0322|
24-11-25 21:03:43 | I |       
24-11-25 21:03:43 | I | quantizing weights for layer model.layers.0
24-11-25 21:03:43 | I | collecting info in model.layers.0
24-11-25 21:03:43 | I | collecting info in model.layers.0
24-11-25 21:03:43 | I | collecting info in model.layers.0
24-11-25 21:03:43 | I | collecting info in model.layers.0
24-11-25 21:03:43 | I | collecting calibration activations in model.layers.0
24-11-25 21:03:43 | I | collecting calibration activations in model.layers.0
24-11-25 21:03:43 | I | collecting calibration activations in model.layers.0
24-11-25 21:03:43 | I | collecting calibration activations in model.layers.0
24-11-25 21:03:44 | I | - Quantizing decoder layer model.layers.0
24-11-25 21:03:44 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 21:03:44 | I |       - range scale = [    1.0000]
24-11-25 21:03:44 | I |         sum  error  = [    0.0603]
24-11-25 21:03:44 | I |         best error  = [    0.0603]
24-11-25 21:03:44 | I |     + error = [0.0603]
24-11-25 21:03:45 | I |       - range scale = [    1.0000]
24-11-25 21:03:45 | I |         sum  error  = [    0.6019]
24-11-25 21:03:45 | I |         best error  = [    0.6019]
24-11-25 21:03:45 | I |     + error = [0.6019]
24-11-25 21:03:45 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 21:03:46 | I |       - range scale = [    1.0000]
24-11-25 21:03:46 | I |         sum  error  = [    0.0691]
24-11-25 21:03:46 | I |         best error  = [    0.0691]
24-11-25 21:03:46 | I |     + error = [0.0691]
24-11-25 21:03:47 | I |       - range scale = [    1.0000]
24-11-25 21:03:47 | I |         sum  error  = [    0.5584]
24-11-25 21:03:47 | I |         best error  = [    0.5584]
24-11-25 21:03:47 | I |     + error = [0.5584]
24-11-25 21:03:47 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 21:03:48 | I |       - range scale = [    1.0000]
24-11-25 21:03:48 | I |         sum  error  = [    0.2446]
24-11-25 21:03:48 | I |         best error  = [    0.2446]
24-11-25 21:03:48 | I |     + error = [0.2446]
24-11-25 21:03:48 | I |       - range scale = [    1.0000]
24-11-25 21:03:48 | I |         sum  error  = [    1.8443]
24-11-25 21:03:48 | I |         best error  = [    1.8443]
24-11-25 21:03:48 | I |     + error = [1.8443]
24-11-25 21:03:49 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 21:03:49 | I |       - range scale = [    1.0000]
24-11-25 21:03:49 | I |         sum  error  = [    0.0648]
24-11-25 21:03:49 | I |         best error  = [    0.0648]
24-11-25 21:03:49 | I |     + error = [0.0648]
24-11-25 21:03:50 | I |       - range scale = [    1.0000]
24-11-25 21:03:50 | I |         sum  error  = [    0.6143]
24-11-25 21:03:50 | I |         best error  = [    0.6143]
24-11-25 21:03:50 | I |     + error = [0.6143]
24-11-25 21:03:50 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 21:03:51 | I |       - range scale = [    1.0000]
24-11-25 21:03:51 | I |         sum  error  = [    1.0507]
24-11-25 21:03:51 | I |         best error  = [    1.0507]
24-11-25 21:03:51 | I |     + error = [1.0507]
24-11-25 21:03:51 | I |       - range scale = [    1.0000]
24-11-25 21:03:51 | I |         sum  error  = [   11.6326]
24-11-25 21:03:51 | I |         best error  = [   11.6326]
24-11-25 21:03:51 | I |     + error = [11.6326]
24-11-25 21:03:52 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 21:03:52 | I |       - range scale = [    1.0000]
24-11-25 21:03:52 | I |         sum  error  = [    1.2135]
24-11-25 21:03:52 | I |         best error  = [    1.2135]
24-11-25 21:03:52 | I |     + error = [1.2135]
24-11-25 21:03:53 | I |       - range scale = [    1.0000]
24-11-25 21:03:53 | I |         sum  error  = [   12.0097]
24-11-25 21:03:53 | I |         best error  = [   12.0097]
24-11-25 21:03:53 | I |     + error = [12.0097]
24-11-25 21:03:53 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 21:03:54 | I |       - range scale = [    1.0000]
24-11-25 21:03:54 | I |         sum  error  = [    3.4692]
24-11-25 21:03:54 | I |         best error  = [    3.4692]
24-11-25 21:03:54 | I |     + error = [3.4692]
24-11-25 21:03:55 | I |       - range scale = [    1.0000]
24-11-25 21:03:55 | I |         sum  error  = [   18.9275]
24-11-25 21:03:55 | I |         best error  = [   18.9275]
24-11-25 21:03:55 | I |     + error = [18.9275]
24-11-25 21:03:55 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 21:03:56 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 21:03:58 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 21:03:59 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 21:04:01 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 21:04:02 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 21:04:03 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 21:04:07 | I | quantizing activations for layer model.layers.0
24-11-25 21:04:07 | I | collecting info in model.layers.0
24-11-25 21:04:07 | I | collecting info in model.layers.0
24-11-25 21:04:07 | I | collecting info in model.layers.0
24-11-25 21:04:07 | I | collecting info in model.layers.0
24-11-25 21:04:07 | I | collecting calibration activations in model.layers.0
24-11-25 21:04:07 | I | collecting calibration activations in model.layers.0
24-11-25 21:04:07 | I | collecting calibration activations in model.layers.0
24-11-25 21:04:07 | I | collecting calibration activations in model.layers.0
24-11-25 21:04:09 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 21:04:09 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 21:04:09 | I | - Evaluator: gptq
24-11-25 21:04:09 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 21:04:09 | I | - Batch_size: 8
24-11-25 21:04:09 | I |   + Max_seq_length: 2048
24-11-25 21:04:51 | I |     - Results:
24-11-25 21:04:51 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 21:04:51 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 21:04:51 | I |       |wikitext |      1|word_perplexity|7.8112|  |7.8112|
24-11-25 21:04:51 | I |       |val_valid|      1|word_perplexity|9.0680|  |9.0680|
24-11-25 21:04:51 | I |       
24-11-25 21:04:51 | I | forward this layer
24-11-25 21:04:51 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/202.pt
24-11-25 21:04:51 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/202.pt
24-11-25 21:04:51 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 21:04:51 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 21:04:51 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 21:04:51 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 21:04:51 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 21:04:51 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 21:04:51 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 21:04:51 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 21:04:51 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 21:04:51 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 21:04:51 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 21:04:51 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 21:04:51 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 21:04:51 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 21:04:51 | I | in layer model.layers.0
24-11-25 21:04:51 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 21:04:51 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 21:04:51 | I | - Evaluator: gptq
24-11-25 21:04:51 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 21:04:51 | I | - Batch_size: 8
24-11-25 21:04:51 | I |   + Max_seq_length: 2048
24-11-25 21:05:29 | I |     - Results:
24-11-25 21:05:29 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 21:05:29 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 21:05:29 | I |       |wikitext |      1|word_perplexity|7.7855|  |7.7855|
24-11-25 21:05:29 | I |       |val_valid|      1|word_perplexity|9.0322|  |9.0322|
24-11-25 21:05:29 | I |       
24-11-25 21:05:29 | I | quantizing weights for layer model.layers.0
24-11-25 21:05:29 | I | collecting info in model.layers.0
24-11-25 21:05:29 | I | collecting info in model.layers.0
24-11-25 21:05:29 | I | collecting info in model.layers.0
24-11-25 21:05:29 | I | collecting info in model.layers.0
24-11-25 21:05:30 | I | collecting calibration activations in model.layers.0
24-11-25 21:05:30 | I | collecting calibration activations in model.layers.0
24-11-25 21:05:30 | I | collecting calibration activations in model.layers.0
24-11-25 21:05:30 | I | collecting calibration activations in model.layers.0
24-11-25 21:05:30 | I | - Quantizing decoder layer model.layers.0
24-11-25 21:05:30 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 21:05:31 | I |       - range scale = [    1.0000]
24-11-25 21:05:31 | I |         sum  error  = [    0.0608]
24-11-25 21:05:31 | I |         best error  = [    0.0608]
24-11-25 21:05:31 | I |     + error = [0.0608]
24-11-25 21:05:32 | I |       - range scale = [    1.0000]
24-11-25 21:05:32 | I |         sum  error  = [    0.6272]
24-11-25 21:05:32 | I |         best error  = [    0.6272]
24-11-25 21:05:32 | I |     + error = [0.6272]
24-11-25 21:05:32 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 21:05:33 | I |       - range scale = [    1.0000]
24-11-25 21:05:33 | I |         sum  error  = [    0.0719]
24-11-25 21:05:33 | I |         best error  = [    0.0719]
24-11-25 21:05:33 | I |     + error = [0.0719]
24-11-25 21:05:33 | I |       - range scale = [    1.0000]
24-11-25 21:05:33 | I |         sum  error  = [    0.5832]
24-11-25 21:05:33 | I |         best error  = [    0.5832]
24-11-25 21:05:33 | I |     + error = [0.5832]
24-11-25 21:05:33 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 21:05:34 | I |       - range scale = [    1.0000]
24-11-25 21:05:34 | I |         sum  error  = [    0.2433]
24-11-25 21:05:34 | I |         best error  = [    0.2433]
24-11-25 21:05:34 | I |     + error = [0.2433]
24-11-25 21:05:35 | I |       - range scale = [    1.0000]
24-11-25 21:05:35 | I |         sum  error  = [    1.8470]
24-11-25 21:05:35 | I |         best error  = [    1.8470]
24-11-25 21:05:35 | I |     + error = [1.8470]
24-11-25 21:05:35 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 21:05:36 | I |       - range scale = [    1.0000]
24-11-25 21:05:36 | I |         sum  error  = [    0.0624]
24-11-25 21:05:36 | I |         best error  = [    0.0624]
24-11-25 21:05:36 | I |     + error = [0.0624]
24-11-25 21:05:36 | I |       - range scale = [    1.0000]
24-11-25 21:05:36 | I |         sum  error  = [    0.6096]
24-11-25 21:05:36 | I |         best error  = [    0.6096]
24-11-25 21:05:36 | I |     + error = [0.6096]
24-11-25 21:05:37 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 21:05:37 | I |       - range scale = [    1.0000]
24-11-25 21:05:37 | I |         sum  error  = [    1.0653]
24-11-25 21:05:37 | I |         best error  = [    1.0653]
24-11-25 21:05:37 | I |     + error = [1.0653]
24-11-25 21:05:38 | I |       - range scale = [    1.0000]
24-11-25 21:05:38 | I |         sum  error  = [   11.8193]
24-11-25 21:05:38 | I |         best error  = [   11.8193]
24-11-25 21:05:38 | I |     + error = [11.8193]
24-11-25 21:05:38 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 21:05:39 | I |       - range scale = [    1.0000]
24-11-25 21:05:39 | I |         sum  error  = [    1.2339]
24-11-25 21:05:39 | I |         best error  = [    1.2339]
24-11-25 21:05:39 | I |     + error = [1.2339]
24-11-25 21:05:40 | I |       - range scale = [    1.0000]
24-11-25 21:05:40 | I |         sum  error  = [   12.1950]
24-11-25 21:05:40 | I |         best error  = [   12.1950]
24-11-25 21:05:40 | I |     + error = [12.1950]
24-11-25 21:05:40 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 21:05:40 | I |       - range scale = [    1.0000]
24-11-25 21:05:40 | I |         sum  error  = [    3.1242]
24-11-25 21:05:40 | I |         best error  = [    3.1242]
24-11-25 21:05:40 | I |     + error = [3.1242]
24-11-25 21:05:41 | I |       - range scale = [    1.0000]
24-11-25 21:05:41 | I |         sum  error  = [   17.1182]
24-11-25 21:05:41 | I |         best error  = [   17.1182]
24-11-25 21:05:41 | I |     + error = [17.1182]
24-11-25 21:05:41 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 21:05:43 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 21:05:44 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 21:05:45 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 21:05:47 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 21:05:48 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 21:05:50 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 21:05:53 | I | quantizing activations for layer model.layers.0
24-11-25 21:05:53 | I | collecting info in model.layers.0
24-11-25 21:05:53 | I | collecting info in model.layers.0
24-11-25 21:05:53 | I | collecting info in model.layers.0
24-11-25 21:05:53 | I | collecting info in model.layers.0
24-11-25 21:05:53 | I | collecting calibration activations in model.layers.0
24-11-25 21:05:54 | I | collecting calibration activations in model.layers.0
24-11-25 21:05:54 | I | collecting calibration activations in model.layers.0
24-11-25 21:05:54 | I | collecting calibration activations in model.layers.0
24-11-25 21:05:56 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 21:05:56 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 21:05:56 | I | - Evaluator: gptq
24-11-25 21:05:56 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 21:05:56 | I | - Batch_size: 8
24-11-25 21:05:56 | I |   + Max_seq_length: 2048
24-11-25 21:06:37 | I |     - Results:
24-11-25 21:06:37 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 21:06:37 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 21:06:37 | I |       |wikitext |      1|word_perplexity|7.8066|  |7.8066|
24-11-25 21:06:37 | I |       |val_valid|      1|word_perplexity|9.0731|  |9.0731|
24-11-25 21:06:37 | I |       
24-11-25 21:06:37 | I | forward this layer
24-11-25 21:06:37 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/203.pt
24-11-25 21:06:37 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/203.pt
24-11-25 21:06:37 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 21:06:37 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 21:06:37 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 21:06:37 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 21:06:37 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 21:06:37 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 21:06:37 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 21:06:37 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 21:06:37 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 21:06:37 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 21:06:37 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 21:06:37 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 21:06:37 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 21:06:37 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 21:06:37 | I | [87] done with optimizer step
24-11-25 21:06:37 | I | epoch 001:    102 / 409600000 loss=6.81961e-05, loss_per_token=0.139666, loss_sum=4576.56, wps=153.7, ups=0, wpb=32768, bsz=64, num_updates=88, lr=0.000149981, gnorm=17.426, clip=100, loss_scale=0.0078, train_wall=213, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=22128, lmquant_ppl_result_wikitext_in_train_no_quant=7.78548, lmquant_ppl_result_val_in_train_no_quant=9.03223, lmquant_ppl_result_wikitext_in_train_with_quant=7.80664, lmquant_ppl_result_val_in_train_with_quant=9.07307
24-11-25 21:06:37 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 21:06:37 | I | in layer model.layers.0
24-11-25 21:06:37 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 21:06:37 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 21:06:37 | I | - Evaluator: gptq
24-11-25 21:06:37 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 21:06:37 | I | - Batch_size: 8
24-11-25 21:06:37 | I |   + Max_seq_length: 2048
24-11-25 21:07:16 | I |     - Results:
24-11-25 21:07:16 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 21:07:16 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 21:07:16 | I |       |wikitext |      1|word_perplexity|7.7847|  |7.7847|
24-11-25 21:07:16 | I |       |val_valid|      1|word_perplexity|9.0317|  |9.0317|
24-11-25 21:07:16 | I |       
24-11-25 21:07:16 | I | quantizing weights for layer model.layers.0
24-11-25 21:07:16 | I | collecting info in model.layers.0
24-11-25 21:07:16 | I | collecting calibration activations in model.layers.0
24-11-25 21:07:16 | I | - Quantizing decoder layer model.layers.0
24-11-25 21:07:16 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 21:07:17 | I |       - range scale = [    1.0000]
24-11-25 21:07:17 | I |         sum  error  = [    0.0228]
24-11-25 21:07:17 | I |         best error  = [    0.0228]
24-11-25 21:07:17 | I |     + error = [0.0228]
24-11-25 21:07:18 | I |       - range scale = [    1.0000]
24-11-25 21:07:18 | I |         sum  error  = [    0.2273]
24-11-25 21:07:18 | I |         best error  = [    0.2273]
24-11-25 21:07:18 | I |     + error = [0.2273]
24-11-25 21:07:18 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 21:07:19 | I |       - range scale = [    1.0000]
24-11-25 21:07:19 | I |         sum  error  = [    0.0255]
24-11-25 21:07:19 | I |         best error  = [    0.0255]
24-11-25 21:07:19 | I |     + error = [0.0255]
24-11-25 21:07:19 | I |       - range scale = [    1.0000]
24-11-25 21:07:19 | I |         sum  error  = [    0.2062]
24-11-25 21:07:19 | I |         best error  = [    0.2062]
24-11-25 21:07:19 | I |     + error = [0.2062]
24-11-25 21:07:20 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 21:07:20 | I |       - range scale = [    1.0000]
24-11-25 21:07:20 | I |         sum  error  = [    0.2352]
24-11-25 21:07:20 | I |         best error  = [    0.2352]
24-11-25 21:07:20 | I |     + error = [0.2352]
24-11-25 21:07:21 | I |       - range scale = [    1.0000]
24-11-25 21:07:21 | I |         sum  error  = [    1.8235]
24-11-25 21:07:21 | I |         best error  = [    1.8235]
24-11-25 21:07:21 | I |     + error = [1.8235]
24-11-25 21:07:21 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 21:07:22 | I |       - range scale = [    1.0000]
24-11-25 21:07:22 | I |         sum  error  = [    0.0675]
24-11-25 21:07:22 | I |         best error  = [    0.0675]
24-11-25 21:07:22 | I |     + error = [0.0675]
24-11-25 21:07:22 | I |       - range scale = [    1.0000]
24-11-25 21:07:22 | I |         sum  error  = [    0.6442]
24-11-25 21:07:22 | I |         best error  = [    0.6442]
24-11-25 21:07:22 | I |     + error = [0.6442]
24-11-25 21:07:23 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 21:07:23 | I |       - range scale = [    1.0000]
24-11-25 21:07:23 | I |         sum  error  = [    1.0775]
24-11-25 21:07:23 | I |         best error  = [    1.0775]
24-11-25 21:07:23 | I |     + error = [1.0775]
24-11-25 21:07:24 | I |       - range scale = [    1.0000]
24-11-25 21:07:24 | I |         sum  error  = [   11.9592]
24-11-25 21:07:24 | I |         best error  = [   11.9592]
24-11-25 21:07:24 | I |     + error = [11.9592]
24-11-25 21:07:24 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 21:07:25 | I |       - range scale = [    1.0000]
24-11-25 21:07:25 | I |         sum  error  = [    1.2458]
24-11-25 21:07:25 | I |         best error  = [    1.2458]
24-11-25 21:07:25 | I |     + error = [1.2458]
24-11-25 21:07:26 | I |       - range scale = [    1.0000]
24-11-25 21:07:26 | I |         sum  error  = [   12.3516]
24-11-25 21:07:26 | I |         best error  = [   12.3516]
24-11-25 21:07:26 | I |     + error = [12.3516]
24-11-25 21:07:26 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 21:07:27 | I |       - range scale = [    1.0000]
24-11-25 21:07:27 | I |         sum  error  = [    2.2562]
24-11-25 21:07:27 | I |         best error  = [    2.2562]
24-11-25 21:07:27 | I |     + error = [2.2562]
24-11-25 21:07:27 | I |       - range scale = [    1.0000]
24-11-25 21:07:27 | I |         sum  error  = [   12.1280]
24-11-25 21:07:27 | I |         best error  = [   12.1280]
24-11-25 21:07:27 | I |     + error = [12.1280]
24-11-25 21:07:28 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 21:07:29 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 21:07:30 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 21:07:32 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 21:07:33 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 21:07:34 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 21:07:36 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 21:07:39 | I | quantizing activations for layer model.layers.0
24-11-25 21:07:39 | I | collecting info in model.layers.0
24-11-25 21:07:39 | I | collecting calibration activations in model.layers.0
24-11-25 21:07:41 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 21:07:41 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 21:07:41 | I | - Evaluator: gptq
24-11-25 21:07:41 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 21:07:41 | I | - Batch_size: 8
24-11-25 21:07:41 | I |   + Max_seq_length: 2048
24-11-25 21:08:23 | I |     - Results:
24-11-25 21:08:23 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 21:08:23 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 21:08:23 | I |       |wikitext |      1|word_perplexity|7.8441|  |7.8441|
24-11-25 21:08:23 | I |       |val_valid|      1|word_perplexity|9.0674|  |9.0674|
24-11-25 21:08:23 | I |       
24-11-25 21:08:23 | I | forward this layer
24-11-25 21:08:23 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/204.pt
24-11-25 21:08:23 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/204.pt
24-11-25 21:08:23 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 21:08:23 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 21:08:23 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 21:08:23 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 21:08:23 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 21:08:23 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 21:08:23 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 21:08:23 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 21:08:23 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 21:08:23 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 21:08:23 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 21:08:23 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 21:08:23 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 21:08:23 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 21:08:23 | I | [88] done with optimizer step
24-11-25 21:08:23 | I | epoch 001:    103 / 409600000 loss=3.39447e-05, loss_per_token=0.0695187, loss_sum=142.374, wps=19.4, ups=0.01, wpb=2048, bsz=4, num_updates=89, lr=0.00014998, gnorm=16.071, clip=100, loss_scale=0.0078, train_wall=105, cuda_gb_allocated=5.9, cuda_gb_reserved=13.7, cuda_gb_free=17.8, wall=22233, lmquant_ppl_result_wikitext_in_train_no_quant=7.78472, lmquant_ppl_result_val_in_train_no_quant=9.03173, lmquant_ppl_result_wikitext_in_train_with_quant=7.8441, lmquant_ppl_result_val_in_train_with_quant=9.06738
24-11-25 21:08:23 | I | end of epoch 1 (average epoch stats below)
24-11-25 21:08:23 | I | epoch 001 | loss 0.000489706 | loss_per_token 1.00292 | loss_sum 32517.5 | wps 150.4 | ups 0 | wpb 32422.8 | bsz 63.3 | num_updates 89 | lr 0.00014998 | gnorm 61.848 | clip 100 | loss_scale 0.0078 | train_wall 21956 | cuda_gb_allocated 5.9 | cuda_gb_reserved 13.7 | cuda_gb_free 17.8 | wall 22233
24-11-25 21:08:23 | I | begin training epoch 1
24-11-25 21:08:23 | I | Start iterating over samples
24-11-25 21:08:23 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 21:08:23 | I | in layer model.layers.0
24-11-25 21:08:23 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 21:08:23 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 21:08:23 | I | - Evaluator: gptq
24-11-25 21:08:23 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 21:08:23 | I | - Batch_size: 8
24-11-25 21:08:23 | I |   + Max_seq_length: 2048
24-11-25 21:09:01 | I |     - Results:
24-11-25 21:09:01 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 21:09:01 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 21:09:01 | I |       |wikitext |      1|word_perplexity|7.7823|  |7.7823|
24-11-25 21:09:01 | I |       |val_valid|      1|word_perplexity|9.0284|  |9.0284|
24-11-25 21:09:01 | I |       
24-11-25 21:09:01 | I | quantizing weights for layer model.layers.0
24-11-25 21:09:01 | I | collecting info in model.layers.0
24-11-25 21:09:01 | I | collecting info in model.layers.0
24-11-25 21:09:01 | I | collecting info in model.layers.0
24-11-25 21:09:01 | I | collecting info in model.layers.0
24-11-25 21:09:02 | I | collecting calibration activations in model.layers.0
24-11-25 21:09:02 | I | collecting calibration activations in model.layers.0
24-11-25 21:09:02 | I | collecting calibration activations in model.layers.0
24-11-25 21:09:02 | I | collecting calibration activations in model.layers.0
24-11-25 21:09:02 | I | - Quantizing decoder layer model.layers.0
24-11-25 21:09:02 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 21:09:03 | I |       - range scale = [    1.0000]
24-11-25 21:09:03 | I |         sum  error  = [    0.0547]
24-11-25 21:09:03 | I |         best error  = [    0.0547]
24-11-25 21:09:03 | I |     + error = [0.0547]
24-11-25 21:09:04 | I |       - range scale = [    1.0000]
24-11-25 21:09:04 | I |         sum  error  = [    0.5788]
24-11-25 21:09:04 | I |         best error  = [    0.5788]
24-11-25 21:09:04 | I |     + error = [0.5788]
24-11-25 21:09:04 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 21:09:05 | I |       - range scale = [    1.0000]
24-11-25 21:09:05 | I |         sum  error  = [    0.0722]
24-11-25 21:09:05 | I |         best error  = [    0.0722]
24-11-25 21:09:05 | I |     + error = [0.0722]
24-11-25 21:09:05 | I |       - range scale = [    1.0000]
24-11-25 21:09:05 | I |         sum  error  = [    0.5802]
24-11-25 21:09:05 | I |         best error  = [    0.5802]
24-11-25 21:09:05 | I |     + error = [0.5802]
24-11-25 21:09:06 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 21:09:06 | I |       - range scale = [    1.0000]
24-11-25 21:09:06 | I |         sum  error  = [    0.2474]
24-11-25 21:09:06 | I |         best error  = [    0.2474]
24-11-25 21:09:06 | I |     + error = [0.2474]
24-11-25 21:09:07 | I |       - range scale = [    1.0000]
24-11-25 21:09:07 | I |         sum  error  = [    1.8855]
24-11-25 21:09:07 | I |         best error  = [    1.8855]
24-11-25 21:09:07 | I |     + error = [1.8855]
24-11-25 21:09:07 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 21:09:08 | I |       - range scale = [    1.0000]
24-11-25 21:09:08 | I |         sum  error  = [    0.0603]
24-11-25 21:09:08 | I |         best error  = [    0.0603]
24-11-25 21:09:08 | I |     + error = [0.0603]
24-11-25 21:09:08 | I |       - range scale = [    1.0000]
24-11-25 21:09:08 | I |         sum  error  = [    0.5805]
24-11-25 21:09:08 | I |         best error  = [    0.5805]
24-11-25 21:09:08 | I |     + error = [0.5805]
24-11-25 21:09:09 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 21:09:09 | I |       - range scale = [    1.0000]
24-11-25 21:09:09 | I |         sum  error  = [    1.0438]
24-11-25 21:09:09 | I |         best error  = [    1.0438]
24-11-25 21:09:09 | I |     + error = [1.0438]
24-11-25 21:09:10 | I |       - range scale = [    1.0000]
24-11-25 21:09:10 | I |         sum  error  = [   11.5756]
24-11-25 21:09:10 | I |         best error  = [   11.5756]
24-11-25 21:09:10 | I |     + error = [11.5756]
24-11-25 21:09:10 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 21:09:11 | I |       - range scale = [    1.0000]
24-11-25 21:09:11 | I |         sum  error  = [    1.2067]
24-11-25 21:09:11 | I |         best error  = [    1.2067]
24-11-25 21:09:11 | I |     + error = [1.2067]
24-11-25 21:09:12 | I |       - range scale = [    1.0000]
24-11-25 21:09:12 | I |         sum  error  = [   11.9320]
24-11-25 21:09:12 | I |         best error  = [   11.9320]
24-11-25 21:09:12 | I |     + error = [11.9320]
24-11-25 21:09:12 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 21:09:13 | I |       - range scale = [    1.0000]
24-11-25 21:09:13 | I |         sum  error  = [    2.2351]
24-11-25 21:09:13 | I |         best error  = [    2.2351]
24-11-25 21:09:13 | I |     + error = [2.2351]
24-11-25 21:09:13 | I |       - range scale = [    1.0000]
24-11-25 21:09:13 | I |         sum  error  = [   12.5472]
24-11-25 21:09:13 | I |         best error  = [   12.5472]
24-11-25 21:09:13 | I |     + error = [12.5472]
24-11-25 21:09:14 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 21:09:15 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 21:09:16 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 21:09:18 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 21:09:19 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 21:09:20 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 21:09:22 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 21:09:25 | I | quantizing activations for layer model.layers.0
24-11-25 21:09:25 | I | collecting info in model.layers.0
24-11-25 21:09:25 | I | collecting info in model.layers.0
24-11-25 21:09:25 | I | collecting info in model.layers.0
24-11-25 21:09:25 | I | collecting info in model.layers.0
24-11-25 21:09:26 | I | collecting calibration activations in model.layers.0
24-11-25 21:09:26 | I | collecting calibration activations in model.layers.0
24-11-25 21:09:26 | I | collecting calibration activations in model.layers.0
24-11-25 21:09:26 | I | collecting calibration activations in model.layers.0
24-11-25 21:09:28 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 21:09:28 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 21:09:28 | I | - Evaluator: gptq
24-11-25 21:09:28 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 21:09:28 | I | - Batch_size: 8
24-11-25 21:09:28 | I |   + Max_seq_length: 2048
24-11-25 21:10:09 | I |     - Results:
24-11-25 21:10:09 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 21:10:09 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 21:10:09 | I |       |wikitext |      1|word_perplexity|7.8062|  |7.8062|
24-11-25 21:10:09 | I |       |val_valid|      1|word_perplexity|9.0581|  |9.0581|
24-11-25 21:10:09 | I |       
24-11-25 21:10:09 | I | forward this layer
24-11-25 21:10:09 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/00.pt
24-11-25 21:10:09 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/00.pt
24-11-25 21:10:09 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 21:10:09 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 21:10:09 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 21:10:09 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 21:10:09 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 21:10:09 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 21:10:09 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 21:10:09 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 21:10:09 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 21:10:09 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 21:10:09 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 21:10:09 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 21:10:09 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 21:10:09 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 21:10:09 | I | in layer model.layers.0
24-11-25 21:10:09 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 21:10:09 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 21:10:09 | I | - Evaluator: gptq
24-11-25 21:10:09 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 21:10:09 | I | - Batch_size: 8
24-11-25 21:10:09 | I |   + Max_seq_length: 2048
24-11-25 21:10:48 | I |     - Results:
24-11-25 21:10:48 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 21:10:48 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 21:10:48 | I |       |wikitext |      1|word_perplexity|7.7823|  |7.7823|
24-11-25 21:10:48 | I |       |val_valid|      1|word_perplexity|9.0284|  |9.0284|
24-11-25 21:10:48 | I |       
24-11-25 21:10:48 | I | quantizing weights for layer model.layers.0
24-11-25 21:10:48 | I | collecting info in model.layers.0
24-11-25 21:10:48 | I | collecting info in model.layers.0
24-11-25 21:10:48 | I | collecting info in model.layers.0
24-11-25 21:10:48 | I | collecting info in model.layers.0
24-11-25 21:10:48 | I | collecting calibration activations in model.layers.0
24-11-25 21:10:48 | I | collecting calibration activations in model.layers.0
24-11-25 21:10:48 | I | collecting calibration activations in model.layers.0
24-11-25 21:10:48 | I | collecting calibration activations in model.layers.0
24-11-25 21:10:49 | I | - Quantizing decoder layer model.layers.0
24-11-25 21:10:49 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 21:10:49 | I |       - range scale = [    1.0000]
24-11-25 21:10:49 | I |         sum  error  = [    0.0568]
24-11-25 21:10:49 | I |         best error  = [    0.0568]
24-11-25 21:10:49 | I |     + error = [0.0568]
24-11-25 21:10:50 | I |       - range scale = [    1.0000]
24-11-25 21:10:50 | I |         sum  error  = [    0.6049]
24-11-25 21:10:50 | I |         best error  = [    0.6049]
24-11-25 21:10:50 | I |     + error = [0.6049]
24-11-25 21:10:50 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 21:10:51 | I |       - range scale = [    1.0000]
24-11-25 21:10:51 | I |         sum  error  = [    0.0739]
24-11-25 21:10:51 | I |         best error  = [    0.0739]
24-11-25 21:10:51 | I |     + error = [0.0739]
24-11-25 21:10:52 | I |       - range scale = [    1.0000]
24-11-25 21:10:52 | I |         sum  error  = [    0.5898]
24-11-25 21:10:52 | I |         best error  = [    0.5898]
24-11-25 21:10:52 | I |     + error = [0.5898]
24-11-25 21:10:52 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 21:10:52 | I |       - range scale = [    1.0000]
24-11-25 21:10:52 | I |         sum  error  = [    0.2473]
24-11-25 21:10:52 | I |         best error  = [    0.2473]
24-11-25 21:10:53 | I |     + error = [0.2473]
24-11-25 21:10:53 | I |       - range scale = [    1.0000]
24-11-25 21:10:53 | I |         sum  error  = [    1.8892]
24-11-25 21:10:53 | I |         best error  = [    1.8892]
24-11-25 21:10:53 | I |     + error = [1.8892]
24-11-25 21:10:53 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 21:10:54 | I |       - range scale = [    1.0000]
24-11-25 21:10:54 | I |         sum  error  = [    0.0638]
24-11-25 21:10:54 | I |         best error  = [    0.0638]
24-11-25 21:10:54 | I |     + error = [0.0638]
24-11-25 21:10:55 | I |       - range scale = [    1.0000]
24-11-25 21:10:55 | I |         sum  error  = [    0.5994]
24-11-25 21:10:55 | I |         best error  = [    0.5994]
24-11-25 21:10:55 | I |     + error = [0.5994]
24-11-25 21:10:55 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 21:10:56 | I |       - range scale = [    1.0000]
24-11-25 21:10:56 | I |         sum  error  = [    1.0405]
24-11-25 21:10:56 | I |         best error  = [    1.0405]
24-11-25 21:10:56 | I |     + error = [1.0405]
24-11-25 21:10:56 | I |       - range scale = [    1.0000]
24-11-25 21:10:56 | I |         sum  error  = [   11.5513]
24-11-25 21:10:56 | I |         best error  = [   11.5513]
24-11-25 21:10:56 | I |     + error = [11.5513]
24-11-25 21:10:56 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 21:10:57 | I |       - range scale = [    1.0000]
24-11-25 21:10:57 | I |         sum  error  = [    1.2046]
24-11-25 21:10:57 | I |         best error  = [    1.2046]
24-11-25 21:10:57 | I |     + error = [1.2046]
24-11-25 21:10:58 | I |       - range scale = [    1.0000]
24-11-25 21:10:58 | I |         sum  error  = [   11.9118]
24-11-25 21:10:58 | I |         best error  = [   11.9118]
24-11-25 21:10:58 | I |     + error = [11.9118]
24-11-25 21:10:58 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 21:10:59 | I |       - range scale = [    1.0000]
24-11-25 21:10:59 | I |         sum  error  = [    3.3163]
24-11-25 21:10:59 | I |         best error  = [    3.3163]
24-11-25 21:10:59 | I |     + error = [3.3163]
24-11-25 21:11:00 | I |       - range scale = [    1.0000]
24-11-25 21:11:00 | I |         sum  error  = [   17.9703]
24-11-25 21:11:00 | I |         best error  = [   17.9703]
24-11-25 21:11:00 | I |     + error = [17.9703]
24-11-25 21:11:00 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 21:11:01 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 21:11:02 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 21:11:04 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 21:11:05 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 21:11:07 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 21:11:08 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 21:11:11 | I | quantizing activations for layer model.layers.0
24-11-25 21:11:11 | I | collecting info in model.layers.0
24-11-25 21:11:11 | I | collecting info in model.layers.0
24-11-25 21:11:11 | I | collecting info in model.layers.0
24-11-25 21:11:11 | I | collecting info in model.layers.0
24-11-25 21:11:12 | I | collecting calibration activations in model.layers.0
24-11-25 21:11:12 | I | collecting calibration activations in model.layers.0
24-11-25 21:11:12 | I | collecting calibration activations in model.layers.0
24-11-25 21:11:12 | I | collecting calibration activations in model.layers.0
24-11-25 21:11:14 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 21:11:14 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 21:11:14 | I | - Evaluator: gptq
24-11-25 21:11:14 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 21:11:14 | I | - Batch_size: 8
24-11-25 21:11:14 | I |   + Max_seq_length: 2048
24-11-25 21:11:55 | I |     - Results:
24-11-25 21:11:55 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 21:11:55 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 21:11:55 | I |       |wikitext |      1|word_perplexity|7.8215|  |7.8215|
24-11-25 21:11:55 | I |       |val_valid|      1|word_perplexity|9.0627|  |9.0627|
24-11-25 21:11:55 | I |       
24-11-25 21:11:55 | I | forward this layer
24-11-25 21:11:55 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/01.pt
24-11-25 21:11:55 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/01.pt
24-11-25 21:11:56 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 21:11:56 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 21:11:56 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 21:11:56 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 21:11:56 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 21:11:56 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 21:11:56 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 21:11:56 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 21:11:56 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 21:11:56 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 21:11:56 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 21:11:56 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 21:11:56 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 21:11:56 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 21:11:56 | I | [89] done with optimizer step
24-11-25 21:11:56 | I | epoch 001:      1 / 409600000 loss=0.000108009, loss_per_token=0.221202, loss_sum=7248.34, wps=153.9, ups=0, wpb=32768, bsz=64, num_updates=90, lr=0.00014998, gnorm=31.721, clip=100, loss_scale=0.0078, train_wall=213, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=22446, lmquant_ppl_result_wikitext_in_train_no_quant=7.78227, lmquant_ppl_result_val_in_train_no_quant=9.02837, lmquant_ppl_result_wikitext_in_train_with_quant=7.82149, lmquant_ppl_result_val_in_train_with_quant=9.06267
24-11-25 21:11:56 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 21:11:56 | I | in layer model.layers.0
24-11-25 21:11:56 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 21:11:56 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 21:11:56 | I | - Evaluator: gptq
24-11-25 21:11:56 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 21:11:56 | I | - Batch_size: 8
24-11-25 21:11:56 | I |   + Max_seq_length: 2048
24-11-25 21:12:34 | I |     - Results:
24-11-25 21:12:34 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 21:12:34 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 21:12:34 | I |       |wikitext |      1|word_perplexity|7.7815|  |7.7815|
24-11-25 21:12:34 | I |       |val_valid|      1|word_perplexity|9.0288|  |9.0288|
24-11-25 21:12:34 | I |       
24-11-25 21:12:34 | I | quantizing weights for layer model.layers.0
24-11-25 21:12:34 | I | collecting info in model.layers.0
24-11-25 21:12:34 | I | collecting info in model.layers.0
24-11-25 21:12:34 | I | collecting info in model.layers.0
24-11-25 21:12:34 | I | collecting info in model.layers.0
24-11-25 21:12:35 | I | collecting calibration activations in model.layers.0
24-11-25 21:12:35 | I | collecting calibration activations in model.layers.0
24-11-25 21:12:35 | I | collecting calibration activations in model.layers.0
24-11-25 21:12:35 | I | collecting calibration activations in model.layers.0
24-11-25 21:12:35 | I | - Quantizing decoder layer model.layers.0
24-11-25 21:12:35 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 21:12:36 | I |       - range scale = [    1.0000]
24-11-25 21:12:36 | I |         sum  error  = [    0.0595]
24-11-25 21:12:36 | I |         best error  = [    0.0595]
24-11-25 21:12:36 | I |     + error = [0.0595]
24-11-25 21:12:37 | I |       - range scale = [    1.0000]
24-11-25 21:12:37 | I |         sum  error  = [    0.6047]
24-11-25 21:12:37 | I |         best error  = [    0.6047]
24-11-25 21:12:37 | I |     + error = [0.6047]
24-11-25 21:12:37 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 21:12:38 | I |       - range scale = [    1.0000]
24-11-25 21:12:38 | I |         sum  error  = [    0.0714]
24-11-25 21:12:38 | I |         best error  = [    0.0714]
24-11-25 21:12:38 | I |     + error = [0.0714]
24-11-25 21:12:38 | I |       - range scale = [    1.0000]
24-11-25 21:12:38 | I |         sum  error  = [    0.5855]
24-11-25 21:12:38 | I |         best error  = [    0.5855]
24-11-25 21:12:38 | I |     + error = [0.5855]
24-11-25 21:12:39 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 21:12:39 | I |       - range scale = [    1.0000]
24-11-25 21:12:39 | I |         sum  error  = [    0.2495]
24-11-25 21:12:39 | I |         best error  = [    0.2495]
24-11-25 21:12:39 | I |     + error = [0.2495]
24-11-25 21:12:40 | I |       - range scale = [    1.0000]
24-11-25 21:12:40 | I |         sum  error  = [    1.8962]
24-11-25 21:12:40 | I |         best error  = [    1.8962]
24-11-25 21:12:40 | I |     + error = [1.8962]
24-11-25 21:12:40 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 21:12:41 | I |       - range scale = [    1.0000]
24-11-25 21:12:41 | I |         sum  error  = [    0.0623]
24-11-25 21:12:41 | I |         best error  = [    0.0623]
24-11-25 21:12:41 | I |     + error = [0.0623]
24-11-25 21:12:41 | I |       - range scale = [    1.0000]
24-11-25 21:12:41 | I |         sum  error  = [    0.5894]
24-11-25 21:12:41 | I |         best error  = [    0.5894]
24-11-25 21:12:41 | I |     + error = [0.5894]
24-11-25 21:12:42 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 21:12:42 | I |       - range scale = [    1.0000]
24-11-25 21:12:42 | I |         sum  error  = [    1.0329]
24-11-25 21:12:42 | I |         best error  = [    1.0329]
24-11-25 21:12:42 | I |     + error = [1.0329]
24-11-25 21:12:43 | I |       - range scale = [    1.0000]
24-11-25 21:12:43 | I |         sum  error  = [   11.4678]
24-11-25 21:12:43 | I |         best error  = [   11.4678]
24-11-25 21:12:43 | I |     + error = [11.4678]
24-11-25 21:12:43 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 21:12:44 | I |       - range scale = [    1.0000]
24-11-25 21:12:44 | I |         sum  error  = [    1.1945]
24-11-25 21:12:44 | I |         best error  = [    1.1945]
24-11-25 21:12:44 | I |     + error = [1.1945]
24-11-25 21:12:45 | I |       - range scale = [    1.0000]
24-11-25 21:12:45 | I |         sum  error  = [   11.8269]
24-11-25 21:12:45 | I |         best error  = [   11.8269]
24-11-25 21:12:45 | I |     + error = [11.8269]
24-11-25 21:12:45 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 21:12:46 | I |       - range scale = [    1.0000]
24-11-25 21:12:46 | I |         sum  error  = [    3.3068]
24-11-25 21:12:46 | I |         best error  = [    3.3068]
24-11-25 21:12:46 | I |     + error = [3.3068]
24-11-25 21:12:46 | I |       - range scale = [    1.0000]
24-11-25 21:12:46 | I |         sum  error  = [   18.5069]
24-11-25 21:12:46 | I |         best error  = [   18.5069]
24-11-25 21:12:46 | I |     + error = [18.5069]
24-11-25 21:12:47 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 21:12:48 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 21:12:49 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 21:12:51 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 21:12:52 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 21:12:54 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 21:12:55 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 21:12:58 | I | quantizing activations for layer model.layers.0
24-11-25 21:12:58 | I | collecting info in model.layers.0
24-11-25 21:12:58 | I | collecting info in model.layers.0
24-11-25 21:12:58 | I | collecting info in model.layers.0
24-11-25 21:12:58 | I | collecting info in model.layers.0
24-11-25 21:12:59 | I | collecting calibration activations in model.layers.0
24-11-25 21:12:59 | I | collecting calibration activations in model.layers.0
24-11-25 21:12:59 | I | collecting calibration activations in model.layers.0
24-11-25 21:12:59 | I | collecting calibration activations in model.layers.0
24-11-25 21:13:01 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 21:13:01 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 21:13:01 | I | - Evaluator: gptq
24-11-25 21:13:01 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 21:13:01 | I | - Batch_size: 8
24-11-25 21:13:01 | I |   + Max_seq_length: 2048
24-11-25 21:13:42 | I |     - Results:
24-11-25 21:13:42 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 21:13:42 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 21:13:42 | I |       |wikitext |      1|word_perplexity|7.8098|  |7.8098|
24-11-25 21:13:42 | I |       |val_valid|      1|word_perplexity|9.0593|  |9.0593|
24-11-25 21:13:42 | I |       
24-11-25 21:13:42 | I | forward this layer
24-11-25 21:13:42 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/02.pt
24-11-25 21:13:42 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/02.pt
24-11-25 21:13:43 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 21:13:43 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 21:13:43 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 21:13:43 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 21:13:43 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 21:13:43 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 21:13:43 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 21:13:43 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 21:13:43 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 21:13:43 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 21:13:43 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 21:13:43 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 21:13:43 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 21:13:43 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 21:13:43 | I | in layer model.layers.0
24-11-25 21:13:43 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 21:13:43 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 21:13:43 | I | - Evaluator: gptq
24-11-25 21:13:43 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 21:13:43 | I | - Batch_size: 8
24-11-25 21:13:43 | I |   + Max_seq_length: 2048
24-11-25 21:14:21 | I |     - Results:
24-11-25 21:14:21 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 21:14:21 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 21:14:21 | I |       |wikitext |      1|word_perplexity|7.7815|  |7.7815|
24-11-25 21:14:21 | I |       |val_valid|      1|word_perplexity|9.0288|  |9.0288|
24-11-25 21:14:21 | I |       
24-11-25 21:14:21 | I | quantizing weights for layer model.layers.0
24-11-25 21:14:21 | I | collecting info in model.layers.0
24-11-25 21:14:21 | I | collecting info in model.layers.0
24-11-25 21:14:21 | I | collecting info in model.layers.0
24-11-25 21:14:21 | I | collecting info in model.layers.0
24-11-25 21:14:21 | I | collecting calibration activations in model.layers.0
24-11-25 21:14:22 | I | collecting calibration activations in model.layers.0
24-11-25 21:14:22 | I | collecting calibration activations in model.layers.0
24-11-25 21:14:22 | I | collecting calibration activations in model.layers.0
24-11-25 21:14:22 | I | - Quantizing decoder layer model.layers.0
24-11-25 21:14:22 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 21:14:23 | I |       - range scale = [    1.0000]
24-11-25 21:14:23 | I |         sum  error  = [    0.0590]
24-11-25 21:14:23 | I |         best error  = [    0.0590]
24-11-25 21:14:23 | I |     + error = [0.0590]
24-11-25 21:14:23 | I |       - range scale = [    1.0000]
24-11-25 21:14:23 | I |         sum  error  = [    0.5991]
24-11-25 21:14:23 | I |         best error  = [    0.5991]
24-11-25 21:14:23 | I |     + error = [0.5991]
24-11-25 21:14:24 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 21:14:24 | I |       - range scale = [    1.0000]
24-11-25 21:14:24 | I |         sum  error  = [    0.0708]
24-11-25 21:14:24 | I |         best error  = [    0.0708]
24-11-25 21:14:24 | I |     + error = [0.0708]
24-11-25 21:14:25 | I |       - range scale = [    1.0000]
24-11-25 21:14:25 | I |         sum  error  = [    0.5830]
24-11-25 21:14:25 | I |         best error  = [    0.5830]
24-11-25 21:14:25 | I |     + error = [0.5830]
24-11-25 21:14:25 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 21:14:26 | I |       - range scale = [    1.0000]
24-11-25 21:14:26 | I |         sum  error  = [    0.2465]
24-11-25 21:14:26 | I |         best error  = [    0.2465]
24-11-25 21:14:26 | I |     + error = [0.2465]
24-11-25 21:14:27 | I |       - range scale = [    1.0000]
24-11-25 21:14:27 | I |         sum  error  = [    1.8734]
24-11-25 21:14:27 | I |         best error  = [    1.8734]
24-11-25 21:14:27 | I |     + error = [1.8734]
24-11-25 21:14:27 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 21:14:27 | I |       - range scale = [    1.0000]
24-11-25 21:14:27 | I |         sum  error  = [    0.0585]
24-11-25 21:14:27 | I |         best error  = [    0.0585]
24-11-25 21:14:27 | I |     + error = [0.0585]
24-11-25 21:14:28 | I |       - range scale = [    1.0000]
24-11-25 21:14:28 | I |         sum  error  = [    0.5570]
24-11-25 21:14:28 | I |         best error  = [    0.5570]
24-11-25 21:14:28 | I |     + error = [0.5570]
24-11-25 21:14:28 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 21:14:29 | I |       - range scale = [    1.0000]
24-11-25 21:14:29 | I |         sum  error  = [    1.0369]
24-11-25 21:14:29 | I |         best error  = [    1.0369]
24-11-25 21:14:29 | I |     + error = [1.0369]
24-11-25 21:14:30 | I |       - range scale = [    1.0000]
24-11-25 21:14:30 | I |         sum  error  = [   11.5083]
24-11-25 21:14:30 | I |         best error  = [   11.5083]
24-11-25 21:14:30 | I |     + error = [11.5083]
24-11-25 21:14:30 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 21:14:31 | I |       - range scale = [    1.0000]
24-11-25 21:14:31 | I |         sum  error  = [    1.2007]
24-11-25 21:14:31 | I |         best error  = [    1.2007]
24-11-25 21:14:31 | I |     + error = [1.2007]
24-11-25 21:14:31 | I |       - range scale = [    1.0000]
24-11-25 21:14:31 | I |         sum  error  = [   11.8519]
24-11-25 21:14:31 | I |         best error  = [   11.8519]
24-11-25 21:14:31 | I |     + error = [11.8519]
24-11-25 21:14:32 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 21:14:32 | I |       - range scale = [    1.0000]
24-11-25 21:14:32 | I |         sum  error  = [    2.7777]
24-11-25 21:14:32 | I |         best error  = [    2.7777]
24-11-25 21:14:32 | I |     + error = [2.7777]
24-11-25 21:14:33 | I |       - range scale = [    1.0000]
24-11-25 21:14:33 | I |         sum  error  = [   16.0374]
24-11-25 21:14:33 | I |         best error  = [   16.0374]
24-11-25 21:14:33 | I |     + error = [16.0374]
24-11-25 21:14:33 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 21:14:35 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 21:14:36 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 21:14:37 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 21:14:39 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 21:14:40 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 21:14:42 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 21:14:45 | I | quantizing activations for layer model.layers.0
24-11-25 21:14:45 | I | collecting info in model.layers.0
24-11-25 21:14:45 | I | collecting info in model.layers.0
24-11-25 21:14:45 | I | collecting info in model.layers.0
24-11-25 21:14:45 | I | collecting info in model.layers.0
24-11-25 21:14:45 | I | collecting calibration activations in model.layers.0
24-11-25 21:14:45 | I | collecting calibration activations in model.layers.0
24-11-25 21:14:46 | I | collecting calibration activations in model.layers.0
24-11-25 21:14:46 | I | collecting calibration activations in model.layers.0
24-11-25 21:14:47 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 21:14:47 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 21:14:47 | I | - Evaluator: gptq
24-11-25 21:14:48 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 21:14:48 | I | - Batch_size: 8
24-11-25 21:14:48 | I |   + Max_seq_length: 2048
24-11-25 21:15:29 | I |     - Results:
24-11-25 21:15:29 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 21:15:29 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 21:15:29 | I |       |wikitext |      1|word_perplexity|7.8087|  |7.8087|
24-11-25 21:15:29 | I |       |val_valid|      1|word_perplexity|9.0668|  |9.0668|
24-11-25 21:15:29 | I |       
24-11-25 21:15:29 | I | forward this layer
24-11-25 21:15:29 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/03.pt
24-11-25 21:15:29 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/03.pt
24-11-25 21:15:29 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 21:15:29 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 21:15:29 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 21:15:29 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 21:15:29 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 21:15:29 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 21:15:29 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 21:15:29 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 21:15:29 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 21:15:29 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 21:15:29 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 21:15:29 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 21:15:29 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 21:15:29 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 21:15:29 | I | [90] done with optimizer step
24-11-25 21:15:29 | I | epoch 001:      2 / 409600000 loss=6.08551e-05, loss_per_token=0.124631, loss_sum=4083.92, wps=153.4, ups=0, wpb=32768, bsz=64, num_updates=91, lr=0.000149979, gnorm=17.946, clip=100, loss_scale=0.0078, train_wall=213, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=22660, lmquant_ppl_result_wikitext_in_train_no_quant=7.78152, lmquant_ppl_result_val_in_train_no_quant=9.02882, lmquant_ppl_result_wikitext_in_train_with_quant=7.80873, lmquant_ppl_result_val_in_train_with_quant=9.06678
24-11-25 21:15:29 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 21:15:29 | I | in layer model.layers.0
24-11-25 21:15:29 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 21:15:29 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 21:15:29 | I | - Evaluator: gptq
24-11-25 21:15:29 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 21:15:29 | I | - Batch_size: 8
24-11-25 21:15:29 | I |   + Max_seq_length: 2048
24-11-25 21:16:08 | I |     - Results:
24-11-25 21:16:08 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 21:16:08 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 21:16:08 | I |       |wikitext |      1|word_perplexity|7.7839|  |7.7839|
24-11-25 21:16:08 | I |       |val_valid|      1|word_perplexity|9.0323|  |9.0323|
24-11-25 21:16:08 | I |       
24-11-25 21:16:08 | I | quantizing weights for layer model.layers.0
24-11-25 21:16:08 | I | collecting info in model.layers.0
24-11-25 21:16:08 | I | collecting info in model.layers.0
24-11-25 21:16:08 | I | collecting info in model.layers.0
24-11-25 21:16:08 | I | collecting info in model.layers.0
24-11-25 21:16:08 | I | collecting calibration activations in model.layers.0
24-11-25 21:16:08 | I | collecting calibration activations in model.layers.0
24-11-25 21:16:08 | I | collecting calibration activations in model.layers.0
24-11-25 21:16:08 | I | collecting calibration activations in model.layers.0
24-11-25 21:16:09 | I | - Quantizing decoder layer model.layers.0
24-11-25 21:16:09 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 21:16:10 | I |       - range scale = [    1.0000]
24-11-25 21:16:10 | I |         sum  error  = [    0.0568]
24-11-25 21:16:10 | I |         best error  = [    0.0568]
24-11-25 21:16:10 | I |     + error = [0.0568]
24-11-25 21:16:10 | I |       - range scale = [    1.0000]
24-11-25 21:16:10 | I |         sum  error  = [    0.5952]
24-11-25 21:16:10 | I |         best error  = [    0.5952]
24-11-25 21:16:10 | I |     + error = [0.5952]
24-11-25 21:16:10 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 21:16:11 | I |       - range scale = [    1.0000]
24-11-25 21:16:11 | I |         sum  error  = [    0.0691]
24-11-25 21:16:11 | I |         best error  = [    0.0691]
24-11-25 21:16:11 | I |     + error = [0.0691]
24-11-25 21:16:12 | I |       - range scale = [    1.0000]
24-11-25 21:16:12 | I |         sum  error  = [    0.5776]
24-11-25 21:16:12 | I |         best error  = [    0.5776]
24-11-25 21:16:12 | I |     + error = [0.5776]
24-11-25 21:16:12 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 21:16:13 | I |       - range scale = [    1.0000]
24-11-25 21:16:13 | I |         sum  error  = [    0.2445]
24-11-25 21:16:13 | I |         best error  = [    0.2445]
24-11-25 21:16:13 | I |     + error = [0.2445]
24-11-25 21:16:13 | I |       - range scale = [    1.0000]
24-11-25 21:16:13 | I |         sum  error  = [    1.8680]
24-11-25 21:16:13 | I |         best error  = [    1.8680]
24-11-25 21:16:13 | I |     + error = [1.8680]
24-11-25 21:16:14 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 21:16:14 | I |       - range scale = [    1.0000]
24-11-25 21:16:14 | I |         sum  error  = [    0.0589]
24-11-25 21:16:14 | I |         best error  = [    0.0589]
24-11-25 21:16:14 | I |     + error = [0.0589]
24-11-25 21:16:15 | I |       - range scale = [    1.0000]
24-11-25 21:16:15 | I |         sum  error  = [    0.5551]
24-11-25 21:16:15 | I |         best error  = [    0.5551]
24-11-25 21:16:15 | I |     + error = [0.5551]
24-11-25 21:16:15 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 21:16:16 | I |       - range scale = [    1.0000]
24-11-25 21:16:16 | I |         sum  error  = [    1.0141]
24-11-25 21:16:16 | I |         best error  = [    1.0141]
24-11-25 21:16:16 | I |     + error = [1.0141]
24-11-25 21:16:17 | I |       - range scale = [    1.0000]
24-11-25 21:16:17 | I |         sum  error  = [   11.2412]
24-11-25 21:16:17 | I |         best error  = [   11.2412]
24-11-25 21:16:17 | I |     + error = [11.2412]
24-11-25 21:16:17 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 21:16:17 | I |       - range scale = [    1.0000]
24-11-25 21:16:17 | I |         sum  error  = [    1.1730]
24-11-25 21:16:17 | I |         best error  = [    1.1730]
24-11-25 21:16:17 | I |     + error = [1.1730]
24-11-25 21:16:18 | I |       - range scale = [    1.0000]
24-11-25 21:16:18 | I |         sum  error  = [   11.5661]
24-11-25 21:16:18 | I |         best error  = [   11.5661]
24-11-25 21:16:18 | I |     + error = [11.5661]
24-11-25 21:16:18 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 21:16:19 | I |       - range scale = [    1.0000]
24-11-25 21:16:19 | I |         sum  error  = [    2.0687]
24-11-25 21:16:19 | I |         best error  = [    2.0687]
24-11-25 21:16:19 | I |     + error = [2.0687]
24-11-25 21:16:20 | I |       - range scale = [    1.0000]
24-11-25 21:16:20 | I |         sum  error  = [   12.8148]
24-11-25 21:16:20 | I |         best error  = [   12.8148]
24-11-25 21:16:20 | I |     + error = [12.8148]
24-11-25 21:16:20 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 21:16:21 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 21:16:23 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 21:16:24 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 21:16:26 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 21:16:27 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 21:16:28 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 21:16:32 | I | quantizing activations for layer model.layers.0
24-11-25 21:16:32 | I | collecting info in model.layers.0
24-11-25 21:16:32 | I | collecting info in model.layers.0
24-11-25 21:16:32 | I | collecting info in model.layers.0
24-11-25 21:16:32 | I | collecting info in model.layers.0
24-11-25 21:16:32 | I | collecting calibration activations in model.layers.0
24-11-25 21:16:32 | I | collecting calibration activations in model.layers.0
24-11-25 21:16:32 | I | collecting calibration activations in model.layers.0
24-11-25 21:16:32 | I | collecting calibration activations in model.layers.0
24-11-25 21:16:34 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 21:16:34 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 21:16:34 | I | - Evaluator: gptq
24-11-25 21:16:34 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 21:16:34 | I | - Batch_size: 8
24-11-25 21:16:34 | I |   + Max_seq_length: 2048
24-11-25 21:17:16 | I |     - Results:
24-11-25 21:17:16 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 21:17:16 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 21:17:16 | I |       |wikitext |      1|word_perplexity|7.8056|  |7.8056|
24-11-25 21:17:16 | I |       |val_valid|      1|word_perplexity|9.0634|  |9.0634|
24-11-25 21:17:16 | I |       
24-11-25 21:17:16 | I | forward this layer
24-11-25 21:17:16 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/04.pt
24-11-25 21:17:16 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/04.pt
24-11-25 21:17:16 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 21:17:16 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 21:17:16 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 21:17:16 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 21:17:16 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 21:17:16 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 21:17:16 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 21:17:16 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 21:17:16 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 21:17:16 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 21:17:16 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 21:17:16 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 21:17:16 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 21:17:16 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 21:17:16 | I | in layer model.layers.0
24-11-25 21:17:16 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 21:17:16 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 21:17:16 | I | - Evaluator: gptq
24-11-25 21:17:16 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 21:17:16 | I | - Batch_size: 8
24-11-25 21:17:16 | I |   + Max_seq_length: 2048
24-11-25 21:17:54 | I |     - Results:
24-11-25 21:17:54 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 21:17:54 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 21:17:54 | I |       |wikitext |      1|word_perplexity|7.7839|  |7.7839|
24-11-25 21:17:54 | I |       |val_valid|      1|word_perplexity|9.0323|  |9.0323|
24-11-25 21:17:54 | I |       
24-11-25 21:17:54 | I | quantizing weights for layer model.layers.0
24-11-25 21:17:54 | I | collecting info in model.layers.0
24-11-25 21:17:54 | I | collecting info in model.layers.0
24-11-25 21:17:54 | I | collecting info in model.layers.0
24-11-25 21:17:54 | I | collecting info in model.layers.0
24-11-25 21:17:55 | I | collecting calibration activations in model.layers.0
24-11-25 21:17:55 | I | collecting calibration activations in model.layers.0
24-11-25 21:17:55 | I | collecting calibration activations in model.layers.0
24-11-25 21:17:55 | I | collecting calibration activations in model.layers.0
24-11-25 21:17:55 | I | - Quantizing decoder layer model.layers.0
24-11-25 21:17:55 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 21:17:56 | I |       - range scale = [    1.0000]
24-11-25 21:17:56 | I |         sum  error  = [    0.0581]
24-11-25 21:17:56 | I |         best error  = [    0.0581]
24-11-25 21:17:56 | I |     + error = [0.0581]
24-11-25 21:17:57 | I |       - range scale = [    1.0000]
24-11-25 21:17:57 | I |         sum  error  = [    0.6062]
24-11-25 21:17:57 | I |         best error  = [    0.6062]
24-11-25 21:17:57 | I |     + error = [0.6062]
24-11-25 21:17:57 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 21:17:58 | I |       - range scale = [    1.0000]
24-11-25 21:17:58 | I |         sum  error  = [    0.0694]
24-11-25 21:17:58 | I |         best error  = [    0.0694]
24-11-25 21:17:58 | I |     + error = [0.0694]
24-11-25 21:17:58 | I |       - range scale = [    1.0000]
24-11-25 21:17:58 | I |         sum  error  = [    0.5704]
24-11-25 21:17:58 | I |         best error  = [    0.5704]
24-11-25 21:17:58 | I |     + error = [0.5704]
24-11-25 21:17:59 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 21:17:59 | I |       - range scale = [    1.0000]
24-11-25 21:17:59 | I |         sum  error  = [    0.2480]
24-11-25 21:17:59 | I |         best error  = [    0.2480]
24-11-25 21:17:59 | I |     + error = [0.2480]
24-11-25 21:18:00 | I |       - range scale = [    1.0000]
24-11-25 21:18:00 | I |         sum  error  = [    1.8823]
24-11-25 21:18:00 | I |         best error  = [    1.8823]
24-11-25 21:18:00 | I |     + error = [1.8823]
24-11-25 21:18:00 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 21:18:01 | I |       - range scale = [    1.0000]
24-11-25 21:18:01 | I |         sum  error  = [    0.0612]
24-11-25 21:18:01 | I |         best error  = [    0.0612]
24-11-25 21:18:01 | I |     + error = [0.0612]
24-11-25 21:18:01 | I |       - range scale = [    1.0000]
24-11-25 21:18:01 | I |         sum  error  = [    0.5822]
24-11-25 21:18:01 | I |         best error  = [    0.5822]
24-11-25 21:18:01 | I |     + error = [0.5822]
24-11-25 21:18:02 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 21:18:02 | I |       - range scale = [    1.0000]
24-11-25 21:18:02 | I |         sum  error  = [    1.0377]
24-11-25 21:18:02 | I |         best error  = [    1.0377]
24-11-25 21:18:02 | I |     + error = [1.0377]
24-11-25 21:18:03 | I |       - range scale = [    1.0000]
24-11-25 21:18:03 | I |         sum  error  = [   11.5105]
24-11-25 21:18:03 | I |         best error  = [   11.5105]
24-11-25 21:18:03 | I |     + error = [11.5105]
24-11-25 21:18:03 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 21:18:04 | I |       - range scale = [    1.0000]
24-11-25 21:18:04 | I |         sum  error  = [    1.2001]
24-11-25 21:18:04 | I |         best error  = [    1.2001]
24-11-25 21:18:04 | I |     + error = [1.2001]
24-11-25 21:18:05 | I |       - range scale = [    1.0000]
24-11-25 21:18:05 | I |         sum  error  = [   11.8544]
24-11-25 21:18:05 | I |         best error  = [   11.8544]
24-11-25 21:18:05 | I |     + error = [11.8544]
24-11-25 21:18:05 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 21:18:06 | I |       - range scale = [    1.0000]
24-11-25 21:18:06 | I |         sum  error  = [    2.4000]
24-11-25 21:18:06 | I |         best error  = [    2.4000]
24-11-25 21:18:06 | I |     + error = [2.4000]
24-11-25 21:18:06 | I |       - range scale = [    1.0000]
24-11-25 21:18:06 | I |         sum  error  = [   13.7111]
24-11-25 21:18:06 | I |         best error  = [   13.7111]
24-11-25 21:18:06 | I |     + error = [13.7111]
24-11-25 21:18:07 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 21:18:08 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 21:18:09 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 21:18:11 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 21:18:12 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 21:18:14 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 21:18:15 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 21:18:18 | I | quantizing activations for layer model.layers.0
24-11-25 21:18:18 | I | collecting info in model.layers.0
24-11-25 21:18:18 | I | collecting info in model.layers.0
24-11-25 21:18:18 | I | collecting info in model.layers.0
24-11-25 21:18:18 | I | collecting info in model.layers.0
24-11-25 21:18:19 | I | collecting calibration activations in model.layers.0
24-11-25 21:18:19 | I | collecting calibration activations in model.layers.0
24-11-25 21:18:19 | I | collecting calibration activations in model.layers.0
24-11-25 21:18:19 | I | collecting calibration activations in model.layers.0
24-11-25 21:18:21 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 21:18:21 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 21:18:21 | I | - Evaluator: gptq
24-11-25 21:18:21 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 21:18:21 | I | - Batch_size: 8
24-11-25 21:18:21 | I |   + Max_seq_length: 2048
24-11-25 21:19:02 | I |     - Results:
24-11-25 21:19:02 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 21:19:02 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 21:19:02 | I |       |wikitext |      1|word_perplexity|7.8088|  |7.8088|
24-11-25 21:19:02 | I |       |val_valid|      1|word_perplexity|9.0747|  |9.0747|
24-11-25 21:19:02 | I |       
24-11-25 21:19:02 | I | forward this layer
24-11-25 21:19:02 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/05.pt
24-11-25 21:19:02 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/05.pt
24-11-25 21:19:03 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 21:19:03 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 21:19:03 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 21:19:03 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 21:19:03 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 21:19:03 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 21:19:03 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 21:19:03 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 21:19:03 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 21:19:03 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 21:19:03 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 21:19:03 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 21:19:03 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 21:19:03 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 21:19:03 | I | [91] done with optimizer step
24-11-25 21:19:03 | I | epoch 001:      3 / 409600000 loss=4.12369e-05, loss_per_token=0.0844532, loss_sum=2767.36, wps=153.5, ups=0, wpb=32768, bsz=64, num_updates=92, lr=0.000149979, gnorm=8.822, clip=100, loss_scale=0.0078, train_wall=213, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=22873, lmquant_ppl_result_wikitext_in_train_no_quant=7.78393, lmquant_ppl_result_val_in_train_no_quant=9.03233, lmquant_ppl_result_wikitext_in_train_with_quant=7.80881, lmquant_ppl_result_val_in_train_with_quant=9.07472
24-11-25 21:19:03 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 21:19:03 | I | in layer model.layers.0
24-11-25 21:19:03 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 21:19:03 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 21:19:03 | I | - Evaluator: gptq
24-11-25 21:19:03 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 21:19:03 | I | - Batch_size: 8
24-11-25 21:19:03 | I |   + Max_seq_length: 2048
24-11-25 21:19:41 | I |     - Results:
24-11-25 21:19:41 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 21:19:41 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 21:19:41 | I |       |wikitext |      1|word_perplexity|7.7893|  |7.7893|
24-11-25 21:19:41 | I |       |val_valid|      1|word_perplexity|9.0423|  |9.0423|
24-11-25 21:19:41 | I |       
24-11-25 21:19:41 | I | quantizing weights for layer model.layers.0
24-11-25 21:19:41 | I | collecting info in model.layers.0
24-11-25 21:19:41 | I | collecting info in model.layers.0
24-11-25 21:19:41 | I | collecting info in model.layers.0
24-11-25 21:19:41 | I | collecting info in model.layers.0
24-11-25 21:19:42 | I | collecting calibration activations in model.layers.0
24-11-25 21:19:42 | I | collecting calibration activations in model.layers.0
24-11-25 21:19:42 | I | collecting calibration activations in model.layers.0
24-11-25 21:19:42 | I | collecting calibration activations in model.layers.0
24-11-25 21:19:42 | I | - Quantizing decoder layer model.layers.0
24-11-25 21:19:42 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 21:19:43 | I |       - range scale = [    1.0000]
24-11-25 21:19:43 | I |         sum  error  = [    0.0571]
24-11-25 21:19:43 | I |         best error  = [    0.0571]
24-11-25 21:19:43 | I |     + error = [0.0571]
24-11-25 21:19:44 | I |       - range scale = [    1.0000]
24-11-25 21:19:44 | I |         sum  error  = [    0.6213]
24-11-25 21:19:44 | I |         best error  = [    0.6213]
24-11-25 21:19:44 | I |     + error = [0.6213]
24-11-25 21:19:44 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 21:19:45 | I |       - range scale = [    1.0000]
24-11-25 21:19:45 | I |         sum  error  = [    0.0600]
24-11-25 21:19:45 | I |         best error  = [    0.0600]
24-11-25 21:19:45 | I |     + error = [0.0600]
24-11-25 21:19:45 | I |       - range scale = [    1.0000]
24-11-25 21:19:45 | I |         sum  error  = [    0.5928]
24-11-25 21:19:45 | I |         best error  = [    0.5928]
24-11-25 21:19:45 | I |     + error = [0.5928]
24-11-25 21:19:45 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 21:19:46 | I |       - range scale = [    1.0000]
24-11-25 21:19:46 | I |         sum  error  = [    0.2500]
24-11-25 21:19:46 | I |         best error  = [    0.2500]
24-11-25 21:19:46 | I |     + error = [0.2500]
24-11-25 21:19:47 | I |       - range scale = [    1.0000]
24-11-25 21:19:47 | I |         sum  error  = [    1.8938]
24-11-25 21:19:47 | I |         best error  = [    1.8938]
24-11-25 21:19:47 | I |     + error = [1.8938]
24-11-25 21:19:47 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 21:19:48 | I |       - range scale = [    1.0000]
24-11-25 21:19:48 | I |         sum  error  = [    0.0632]
24-11-25 21:19:48 | I |         best error  = [    0.0632]
24-11-25 21:19:48 | I |     + error = [0.0632]
24-11-25 21:19:48 | I |       - range scale = [    1.0000]
24-11-25 21:19:48 | I |         sum  error  = [    0.6011]
24-11-25 21:19:48 | I |         best error  = [    0.6011]
24-11-25 21:19:48 | I |     + error = [0.6011]
24-11-25 21:19:49 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 21:19:49 | I |       - range scale = [    1.0000]
24-11-25 21:19:49 | I |         sum  error  = [    1.0276]
24-11-25 21:19:49 | I |         best error  = [    1.0276]
24-11-25 21:19:49 | I |     + error = [1.0276]
24-11-25 21:19:50 | I |       - range scale = [    1.0000]
24-11-25 21:19:50 | I |         sum  error  = [   11.3860]
24-11-25 21:19:50 | I |         best error  = [   11.3860]
24-11-25 21:19:50 | I |     + error = [11.3860]
24-11-25 21:19:50 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 21:19:51 | I |       - range scale = [    1.0000]
24-11-25 21:19:51 | I |         sum  error  = [    1.1899]
24-11-25 21:19:51 | I |         best error  = [    1.1899]
24-11-25 21:19:51 | I |     + error = [1.1899]
24-11-25 21:19:52 | I |       - range scale = [    1.0000]
24-11-25 21:19:52 | I |         sum  error  = [   11.7322]
24-11-25 21:19:52 | I |         best error  = [   11.7322]
24-11-25 21:19:52 | I |     + error = [11.7322]
24-11-25 21:19:52 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 21:19:52 | I |       - range scale = [    1.0000]
24-11-25 21:19:53 | I |         sum  error  = [    3.1245]
24-11-25 21:19:53 | I |         best error  = [    3.1245]
24-11-25 21:19:53 | I |     + error = [3.1245]
24-11-25 21:19:53 | I |       - range scale = [    1.0000]
24-11-25 21:19:53 | I |         sum  error  = [   17.7840]
24-11-25 21:19:53 | I |         best error  = [   17.7840]
24-11-25 21:19:53 | I |     + error = [17.7840]
24-11-25 21:19:53 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 21:19:55 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 21:19:56 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 21:19:58 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 21:19:59 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 21:20:00 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 21:20:02 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 21:20:05 | I | quantizing activations for layer model.layers.0
24-11-25 21:20:05 | I | collecting info in model.layers.0
24-11-25 21:20:05 | I | collecting info in model.layers.0
24-11-25 21:20:05 | I | collecting info in model.layers.0
24-11-25 21:20:05 | I | collecting info in model.layers.0
24-11-25 21:20:05 | I | collecting calibration activations in model.layers.0
24-11-25 21:20:06 | I | collecting calibration activations in model.layers.0
24-11-25 21:20:06 | I | collecting calibration activations in model.layers.0
24-11-25 21:20:06 | I | collecting calibration activations in model.layers.0
24-11-25 21:20:08 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 21:20:08 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 21:20:08 | I | - Evaluator: gptq
24-11-25 21:20:08 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 21:20:08 | I | - Batch_size: 8
24-11-25 21:20:08 | I |   + Max_seq_length: 2048
24-11-25 21:20:49 | I |     - Results:
24-11-25 21:20:49 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 21:20:49 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 21:20:49 | I |       |wikitext |      1|word_perplexity|7.8318|  |7.8318|
24-11-25 21:20:49 | I |       |val_valid|      1|word_perplexity|9.0777|  |9.0777|
24-11-25 21:20:49 | I |       
24-11-25 21:20:49 | I | forward this layer
24-11-25 21:20:49 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/06.pt
24-11-25 21:20:49 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/06.pt
24-11-25 21:20:49 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 21:20:49 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 21:20:49 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 21:20:49 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 21:20:49 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 21:20:49 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 21:20:49 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 21:20:49 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 21:20:49 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 21:20:49 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 21:20:49 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 21:20:49 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 21:20:49 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 21:20:49 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 21:20:49 | I | in layer model.layers.0
24-11-25 21:20:49 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 21:20:49 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 21:20:49 | I | - Evaluator: gptq
24-11-25 21:20:49 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 21:20:49 | I | - Batch_size: 8
24-11-25 21:20:49 | I |   + Max_seq_length: 2048
24-11-25 21:21:27 | I |     - Results:
24-11-25 21:21:27 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 21:21:27 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 21:21:27 | I |       |wikitext |      1|word_perplexity|7.7893|  |7.7893|
24-11-25 21:21:27 | I |       |val_valid|      1|word_perplexity|9.0423|  |9.0423|
24-11-25 21:21:27 | I |       
24-11-25 21:21:27 | I | quantizing weights for layer model.layers.0
24-11-25 21:21:27 | I | collecting info in model.layers.0
24-11-25 21:21:27 | I | collecting info in model.layers.0
24-11-25 21:21:27 | I | collecting info in model.layers.0
24-11-25 21:21:27 | I | collecting info in model.layers.0
24-11-25 21:21:28 | I | collecting calibration activations in model.layers.0
24-11-25 21:21:28 | I | collecting calibration activations in model.layers.0
24-11-25 21:21:28 | I | collecting calibration activations in model.layers.0
24-11-25 21:21:28 | I | collecting calibration activations in model.layers.0
24-11-25 21:21:29 | I | - Quantizing decoder layer model.layers.0
24-11-25 21:21:29 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 21:21:29 | I |       - range scale = [    1.0000]
24-11-25 21:21:29 | I |         sum  error  = [    0.0562]
24-11-25 21:21:29 | I |         best error  = [    0.0562]
24-11-25 21:21:29 | I |     + error = [0.0562]
24-11-25 21:21:30 | I |       - range scale = [    1.0000]
24-11-25 21:21:30 | I |         sum  error  = [    0.6027]
24-11-25 21:21:30 | I |         best error  = [    0.6027]
24-11-25 21:21:30 | I |     + error = [0.6027]
24-11-25 21:21:30 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 21:21:31 | I |       - range scale = [    1.0000]
24-11-25 21:21:31 | I |         sum  error  = [    0.0573]
24-11-25 21:21:31 | I |         best error  = [    0.0573]
24-11-25 21:21:31 | I |     + error = [0.0573]
24-11-25 21:21:32 | I |       - range scale = [    1.0000]
24-11-25 21:21:32 | I |         sum  error  = [    0.5744]
24-11-25 21:21:32 | I |         best error  = [    0.5744]
24-11-25 21:21:32 | I |     + error = [0.5744]
24-11-25 21:21:32 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 21:21:32 | I |       - range scale = [    1.0000]
24-11-25 21:21:32 | I |         sum  error  = [    0.2436]
24-11-25 21:21:32 | I |         best error  = [    0.2436]
24-11-25 21:21:32 | I |     + error = [0.2436]
24-11-25 21:21:33 | I |       - range scale = [    1.0000]
24-11-25 21:21:33 | I |         sum  error  = [    1.8622]
24-11-25 21:21:33 | I |         best error  = [    1.8622]
24-11-25 21:21:33 | I |     + error = [1.8622]
24-11-25 21:21:33 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 21:21:34 | I |       - range scale = [    1.0000]
24-11-25 21:21:34 | I |         sum  error  = [    0.0664]
24-11-25 21:21:34 | I |         best error  = [    0.0664]
24-11-25 21:21:34 | I |     + error = [0.0664]
24-11-25 21:21:35 | I |       - range scale = [    1.0000]
24-11-25 21:21:35 | I |         sum  error  = [    0.6328]
24-11-25 21:21:35 | I |         best error  = [    0.6328]
24-11-25 21:21:35 | I |     + error = [0.6328]
24-11-25 21:21:35 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 21:21:36 | I |       - range scale = [    1.0000]
24-11-25 21:21:36 | I |         sum  error  = [    1.0825]
24-11-25 21:21:36 | I |         best error  = [    1.0825]
24-11-25 21:21:36 | I |     + error = [1.0825]
24-11-25 21:21:36 | I |       - range scale = [    1.0000]
24-11-25 21:21:36 | I |         sum  error  = [   11.9848]
24-11-25 21:21:36 | I |         best error  = [   11.9848]
24-11-25 21:21:36 | I |     + error = [11.9848]
24-11-25 21:21:37 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 21:21:37 | I |       - range scale = [    1.0000]
24-11-25 21:21:37 | I |         sum  error  = [    1.2532]
24-11-25 21:21:37 | I |         best error  = [    1.2532]
24-11-25 21:21:37 | I |     + error = [1.2532]
24-11-25 21:21:38 | I |       - range scale = [    1.0000]
24-11-25 21:21:38 | I |         sum  error  = [   12.3696]
24-11-25 21:21:38 | I |         best error  = [   12.3696]
24-11-25 21:21:38 | I |     + error = [12.3696]
24-11-25 21:21:38 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 21:21:39 | I |       - range scale = [    1.0000]
24-11-25 21:21:39 | I |         sum  error  = [    2.7551]
24-11-25 21:21:39 | I |         best error  = [    2.7551]
24-11-25 21:21:39 | I |     + error = [2.7551]
24-11-25 21:21:40 | I |       - range scale = [    1.0000]
24-11-25 21:21:40 | I |         sum  error  = [   15.5413]
24-11-25 21:21:40 | I |         best error  = [   15.5413]
24-11-25 21:21:40 | I |     + error = [15.5413]
24-11-25 21:21:40 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 21:21:41 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 21:21:43 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 21:21:44 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 21:21:45 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 21:21:47 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 21:21:48 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 21:21:51 | I | quantizing activations for layer model.layers.0
24-11-25 21:21:51 | I | collecting info in model.layers.0
24-11-25 21:21:51 | I | collecting info in model.layers.0
24-11-25 21:21:51 | I | collecting info in model.layers.0
24-11-25 21:21:51 | I | collecting info in model.layers.0
24-11-25 21:21:52 | I | collecting calibration activations in model.layers.0
24-11-25 21:21:52 | I | collecting calibration activations in model.layers.0
24-11-25 21:21:52 | I | collecting calibration activations in model.layers.0
24-11-25 21:21:52 | I | collecting calibration activations in model.layers.0
24-11-25 21:21:54 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 21:21:54 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 21:21:54 | I | - Evaluator: gptq
24-11-25 21:21:54 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 21:21:54 | I | - Batch_size: 8
24-11-25 21:21:54 | I |   + Max_seq_length: 2048
24-11-25 21:22:35 | I |     - Results:
24-11-25 21:22:35 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 21:22:35 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 21:22:35 | I |       |wikitext |      1|word_perplexity|7.8312|  |7.8312|
24-11-25 21:22:35 | I |       |val_valid|      1|word_perplexity|9.0888|  |9.0888|
24-11-25 21:22:35 | I |       
24-11-25 21:22:35 | I | forward this layer
24-11-25 21:22:35 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/07.pt
24-11-25 21:22:35 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/07.pt
24-11-25 21:22:36 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 21:22:36 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 21:22:36 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 21:22:36 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 21:22:36 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 21:22:36 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 21:22:36 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 21:22:36 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 21:22:36 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 21:22:36 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 21:22:36 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 21:22:36 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 21:22:36 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 21:22:36 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 21:22:36 | I | [92] done with optimizer step
24-11-25 21:22:36 | I | epoch 001:      4 / 409600000 loss=7.22562e-05, loss_per_token=0.147981, loss_sum=4849.03, wps=153.8, ups=0, wpb=32768, bsz=64, num_updates=93, lr=0.000149978, gnorm=16.331, clip=100, loss_scale=0.0078, train_wall=213, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=23086, lmquant_ppl_result_wikitext_in_train_no_quant=7.78933, lmquant_ppl_result_val_in_train_no_quant=9.04229, lmquant_ppl_result_wikitext_in_train_with_quant=7.83117, lmquant_ppl_result_val_in_train_with_quant=9.08875
24-11-25 21:22:36 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 21:22:36 | I | in layer model.layers.0
24-11-25 21:22:36 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 21:22:36 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 21:22:36 | I | - Evaluator: gptq
24-11-25 21:22:36 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 21:22:36 | I | - Batch_size: 8
24-11-25 21:22:36 | I |   + Max_seq_length: 2048
24-11-25 21:23:14 | I |     - Results:
24-11-25 21:23:14 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 21:23:14 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 21:23:14 | I |       |wikitext |      1|word_perplexity|7.8112|  |7.8112|
24-11-25 21:23:14 | I |       |val_valid|      1|word_perplexity|9.0806|  |9.0806|
24-11-25 21:23:14 | I |       
24-11-25 21:23:14 | I | quantizing weights for layer model.layers.0
24-11-25 21:23:14 | I | collecting info in model.layers.0
24-11-25 21:23:14 | I | collecting info in model.layers.0
24-11-25 21:23:14 | I | collecting info in model.layers.0
24-11-25 21:23:14 | I | collecting info in model.layers.0
24-11-25 21:23:15 | I | collecting calibration activations in model.layers.0
24-11-25 21:23:15 | I | collecting calibration activations in model.layers.0
24-11-25 21:23:15 | I | collecting calibration activations in model.layers.0
24-11-25 21:23:15 | I | collecting calibration activations in model.layers.0
24-11-25 21:23:15 | I | - Quantizing decoder layer model.layers.0
24-11-25 21:23:15 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 21:23:16 | I |       - range scale = [    1.0000]
24-11-25 21:23:16 | I |         sum  error  = [    0.0606]
24-11-25 21:23:16 | I |         best error  = [    0.0606]
24-11-25 21:23:16 | I |     + error = [0.0606]
24-11-25 21:23:17 | I |       - range scale = [    1.0000]
24-11-25 21:23:17 | I |         sum  error  = [    0.6100]
24-11-25 21:23:17 | I |         best error  = [    0.6100]
24-11-25 21:23:17 | I |     + error = [0.6100]
24-11-25 21:23:17 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 21:23:17 | I |       - range scale = [    1.0000]
24-11-25 21:23:17 | I |         sum  error  = [    0.0571]
24-11-25 21:23:17 | I |         best error  = [    0.0571]
24-11-25 21:23:17 | I |     + error = [0.0571]
24-11-25 21:23:18 | I |       - range scale = [    1.0000]
24-11-25 21:23:18 | I |         sum  error  = [    0.5576]
24-11-25 21:23:18 | I |         best error  = [    0.5576]
24-11-25 21:23:18 | I |     + error = [0.5576]
24-11-25 21:23:18 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 21:23:19 | I |       - range scale = [    1.0000]
24-11-25 21:23:19 | I |         sum  error  = [    0.2404]
24-11-25 21:23:19 | I |         best error  = [    0.2404]
24-11-25 21:23:19 | I |     + error = [0.2404]
24-11-25 21:23:20 | I |       - range scale = [    1.0000]
24-11-25 21:23:20 | I |         sum  error  = [    1.8357]
24-11-25 21:23:20 | I |         best error  = [    1.8357]
24-11-25 21:23:20 | I |     + error = [1.8357]
24-11-25 21:23:20 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 21:23:21 | I |       - range scale = [    1.0000]
24-11-25 21:23:21 | I |         sum  error  = [    0.0638]
24-11-25 21:23:21 | I |         best error  = [    0.0638]
24-11-25 21:23:21 | I |     + error = [0.0638]
24-11-25 21:23:21 | I |       - range scale = [    1.0000]
24-11-25 21:23:21 | I |         sum  error  = [    0.6038]
24-11-25 21:23:21 | I |         best error  = [    0.6038]
24-11-25 21:23:21 | I |     + error = [0.6038]
24-11-25 21:23:21 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 21:23:22 | I |       - range scale = [    1.0000]
24-11-25 21:23:22 | I |         sum  error  = [    1.0642]
24-11-25 21:23:22 | I |         best error  = [    1.0642]
24-11-25 21:23:22 | I |     + error = [1.0642]
24-11-25 21:23:23 | I |       - range scale = [    1.0000]
24-11-25 21:23:23 | I |         sum  error  = [   11.8063]
24-11-25 21:23:23 | I |         best error  = [   11.8063]
24-11-25 21:23:23 | I |     + error = [11.8063]
24-11-25 21:23:23 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 21:23:24 | I |       - range scale = [    1.0000]
24-11-25 21:23:24 | I |         sum  error  = [    1.2349]
24-11-25 21:23:24 | I |         best error  = [    1.2349]
24-11-25 21:23:24 | I |     + error = [1.2349]
24-11-25 21:23:25 | I |       - range scale = [    1.0000]
24-11-25 21:23:25 | I |         sum  error  = [   12.1845]
24-11-25 21:23:25 | I |         best error  = [   12.1845]
24-11-25 21:23:25 | I |     + error = [12.1845]
24-11-25 21:23:25 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 21:23:25 | I |       - range scale = [    1.0000]
24-11-25 21:23:25 | I |         sum  error  = [    4.0133]
24-11-25 21:23:25 | I |         best error  = [    4.0133]
24-11-25 21:23:25 | I |     + error = [4.0133]
24-11-25 21:23:26 | I |       - range scale = [    1.0000]
24-11-25 21:23:26 | I |         sum  error  = [   22.4129]
24-11-25 21:23:26 | I |         best error  = [   22.4129]
24-11-25 21:23:26 | I |     + error = [22.4129]
24-11-25 21:23:26 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 21:23:28 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 21:23:29 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 21:23:31 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 21:23:32 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 21:23:33 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 21:23:35 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 21:23:38 | I | quantizing activations for layer model.layers.0
24-11-25 21:23:38 | I | collecting info in model.layers.0
24-11-25 21:23:38 | I | collecting info in model.layers.0
24-11-25 21:23:38 | I | collecting info in model.layers.0
24-11-25 21:23:38 | I | collecting info in model.layers.0
24-11-25 21:23:38 | I | collecting calibration activations in model.layers.0
24-11-25 21:23:38 | I | collecting calibration activations in model.layers.0
24-11-25 21:23:39 | I | collecting calibration activations in model.layers.0
24-11-25 21:23:39 | I | collecting calibration activations in model.layers.0
24-11-25 21:23:40 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 21:23:41 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 21:23:41 | I | - Evaluator: gptq
24-11-25 21:23:41 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 21:23:41 | I | - Batch_size: 8
24-11-25 21:23:41 | I |   + Max_seq_length: 2048
24-11-25 21:24:22 | I |     - Results:
24-11-25 21:24:22 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 21:24:22 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 21:24:22 | I |       |wikitext |      1|word_perplexity|7.8737|  |7.8737|
24-11-25 21:24:22 | I |       |val_valid|      1|word_perplexity|9.1520|  |9.1520|
24-11-25 21:24:22 | I |       
24-11-25 21:24:22 | I | forward this layer
24-11-25 21:24:22 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/08.pt
24-11-25 21:24:22 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/08.pt
24-11-25 21:24:22 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 21:24:22 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 21:24:22 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 21:24:22 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 21:24:22 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 21:24:22 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 21:24:22 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 21:24:22 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 21:24:22 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 21:24:22 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 21:24:22 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 21:24:22 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 21:24:22 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 21:24:22 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 21:24:22 | I | in layer model.layers.0
24-11-25 21:24:22 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 21:24:22 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 21:24:22 | I | - Evaluator: gptq
24-11-25 21:24:22 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 21:24:22 | I | - Batch_size: 8
24-11-25 21:24:22 | I |   + Max_seq_length: 2048
24-11-25 21:25:00 | I |     - Results:
24-11-25 21:25:00 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 21:25:00 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 21:25:00 | I |       |wikitext |      1|word_perplexity|7.8112|  |7.8112|
24-11-25 21:25:00 | I |       |val_valid|      1|word_perplexity|9.0806|  |9.0806|
24-11-25 21:25:00 | I |       
24-11-25 21:25:00 | I | quantizing weights for layer model.layers.0
24-11-25 21:25:00 | I | collecting info in model.layers.0
24-11-25 21:25:00 | I | collecting info in model.layers.0
24-11-25 21:25:00 | I | collecting info in model.layers.0
24-11-25 21:25:00 | I | collecting info in model.layers.0
24-11-25 21:25:01 | I | collecting calibration activations in model.layers.0
24-11-25 21:25:01 | I | collecting calibration activations in model.layers.0
24-11-25 21:25:01 | I | collecting calibration activations in model.layers.0
24-11-25 21:25:01 | I | collecting calibration activations in model.layers.0
24-11-25 21:25:01 | I | - Quantizing decoder layer model.layers.0
24-11-25 21:25:01 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 21:25:02 | I |       - range scale = [    1.0000]
24-11-25 21:25:02 | I |         sum  error  = [    0.0584]
24-11-25 21:25:02 | I |         best error  = [    0.0584]
24-11-25 21:25:02 | I |     + error = [0.0584]
24-11-25 21:25:03 | I |       - range scale = [    1.0000]
24-11-25 21:25:03 | I |         sum  error  = [    0.5840]
24-11-25 21:25:03 | I |         best error  = [    0.5840]
24-11-25 21:25:03 | I |     + error = [0.5840]
24-11-25 21:25:03 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 21:25:04 | I |       - range scale = [    1.0000]
24-11-25 21:25:04 | I |         sum  error  = [    0.0574]
24-11-25 21:25:04 | I |         best error  = [    0.0574]
24-11-25 21:25:04 | I |     + error = [0.0574]
24-11-25 21:25:04 | I |       - range scale = [    1.0000]
24-11-25 21:25:04 | I |         sum  error  = [    0.5705]
24-11-25 21:25:04 | I |         best error  = [    0.5705]
24-11-25 21:25:04 | I |     + error = [0.5705]
24-11-25 21:25:05 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 21:25:05 | I |       - range scale = [    1.0000]
24-11-25 21:25:05 | I |         sum  error  = [    0.2368]
24-11-25 21:25:05 | I |         best error  = [    0.2368]
24-11-25 21:25:05 | I |     + error = [0.2368]
24-11-25 21:25:06 | I |       - range scale = [    1.0000]
24-11-25 21:25:06 | I |         sum  error  = [    1.8132]
24-11-25 21:25:06 | I |         best error  = [    1.8132]
24-11-25 21:25:06 | I |     + error = [1.8132]
24-11-25 21:25:06 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 21:25:07 | I |       - range scale = [    1.0000]
24-11-25 21:25:07 | I |         sum  error  = [    0.0697]
24-11-25 21:25:07 | I |         best error  = [    0.0697]
24-11-25 21:25:07 | I |     + error = [0.0697]
24-11-25 21:25:07 | I |       - range scale = [    1.0000]
24-11-25 21:25:07 | I |         sum  error  = [    0.6408]
24-11-25 21:25:07 | I |         best error  = [    0.6408]
24-11-25 21:25:07 | I |     + error = [0.6408]
24-11-25 21:25:08 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 21:25:08 | I |       - range scale = [    1.0000]
24-11-25 21:25:08 | I |         sum  error  = [    1.0801]
24-11-25 21:25:08 | I |         best error  = [    1.0801]
24-11-25 21:25:08 | I |     + error = [1.0801]
24-11-25 21:25:09 | I |       - range scale = [    1.0000]
24-11-25 21:25:09 | I |         sum  error  = [   11.9390]
24-11-25 21:25:09 | I |         best error  = [   11.9390]
24-11-25 21:25:09 | I |     + error = [11.9390]
24-11-25 21:25:09 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 21:25:10 | I |       - range scale = [    1.0000]
24-11-25 21:25:10 | I |         sum  error  = [    1.2496]
24-11-25 21:25:10 | I |         best error  = [    1.2496]
24-11-25 21:25:10 | I |     + error = [1.2496]
24-11-25 21:25:11 | I |       - range scale = [    1.0000]
24-11-25 21:25:11 | I |         sum  error  = [   12.3489]
24-11-25 21:25:11 | I |         best error  = [   12.3489]
24-11-25 21:25:11 | I |     + error = [12.3489]
24-11-25 21:25:11 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 21:25:12 | I |       - range scale = [    1.0000]
24-11-25 21:25:12 | I |         sum  error  = [    4.0034]
24-11-25 21:25:12 | I |         best error  = [    4.0034]
24-11-25 21:25:12 | I |     + error = [4.0034]
24-11-25 21:25:12 | I |       - range scale = [    1.0000]
24-11-25 21:25:12 | I |         sum  error  = [   22.3823]
24-11-25 21:25:12 | I |         best error  = [   22.3823]
24-11-25 21:25:12 | I |     + error = [22.3823]
24-11-25 21:25:13 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 21:25:14 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 21:25:15 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 21:25:17 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 21:25:18 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 21:25:19 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 21:25:21 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 21:25:24 | I | quantizing activations for layer model.layers.0
24-11-25 21:25:24 | I | collecting info in model.layers.0
24-11-25 21:25:24 | I | collecting info in model.layers.0
24-11-25 21:25:24 | I | collecting info in model.layers.0
24-11-25 21:25:24 | I | collecting info in model.layers.0
24-11-25 21:25:25 | I | collecting calibration activations in model.layers.0
24-11-25 21:25:25 | I | collecting calibration activations in model.layers.0
24-11-25 21:25:25 | I | collecting calibration activations in model.layers.0
24-11-25 21:25:25 | I | collecting calibration activations in model.layers.0
24-11-25 21:25:27 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 21:25:27 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 21:25:27 | I | - Evaluator: gptq
24-11-25 21:25:27 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 21:25:27 | I | - Batch_size: 8
24-11-25 21:25:27 | I |   + Max_seq_length: 2048
24-11-25 21:26:08 | I |     - Results:
24-11-25 21:26:08 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 21:26:08 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 21:26:08 | I |       |wikitext |      1|word_perplexity|7.8675|  |7.8675|
24-11-25 21:26:08 | I |       |val_valid|      1|word_perplexity|9.1322|  |9.1322|
24-11-25 21:26:08 | I |       
24-11-25 21:26:08 | I | forward this layer
24-11-25 21:26:08 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/09.pt
24-11-25 21:26:08 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/09.pt
24-11-25 21:26:08 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 21:26:08 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 21:26:08 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 21:26:08 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 21:26:08 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 21:26:08 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 21:26:08 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 21:26:08 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 21:26:08 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 21:26:08 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 21:26:08 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 21:26:08 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 21:26:08 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 21:26:08 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 21:26:08 | I | [93] done with optimizer step
24-11-25 21:26:08 | I | epoch 001:      5 / 409600000 loss=8.78767e-05, loss_per_token=0.179972, loss_sum=5897.31, wps=154, ups=0, wpb=32768, bsz=64, num_updates=94, lr=0.000149978, gnorm=11.919, clip=100, loss_scale=0.0078, train_wall=213, cuda_gb_allocated=12.3, cuda_gb_reserved=13.9, cuda_gb_free=11.4, wall=23299, lmquant_ppl_result_wikitext_in_train_no_quant=7.81122, lmquant_ppl_result_val_in_train_no_quant=9.08063, lmquant_ppl_result_wikitext_in_train_with_quant=7.86751, lmquant_ppl_result_val_in_train_with_quant=9.1322
24-11-25 21:26:09 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 21:26:09 | I | in layer model.layers.0
24-11-25 21:26:09 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 21:26:09 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 21:26:09 | I | - Evaluator: gptq
24-11-25 21:26:09 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 21:26:09 | I | - Batch_size: 8
24-11-25 21:26:09 | I |   + Max_seq_length: 2048
24-11-25 21:26:47 | I |     - Results:
24-11-25 21:26:47 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 21:26:47 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 21:26:47 | I |       |wikitext |      1|word_perplexity|7.8330|  |7.8330|
24-11-25 21:26:47 | I |       |val_valid|      1|word_perplexity|9.1295|  |9.1295|
24-11-25 21:26:47 | I |       
24-11-25 21:26:47 | I | quantizing weights for layer model.layers.0
24-11-25 21:26:47 | I | collecting info in model.layers.0
24-11-25 21:26:47 | I | collecting info in model.layers.0
24-11-25 21:26:47 | I | collecting info in model.layers.0
24-11-25 21:26:47 | I | collecting info in model.layers.0
24-11-25 21:26:47 | I | collecting calibration activations in model.layers.0
24-11-25 21:26:47 | I | collecting calibration activations in model.layers.0
24-11-25 21:26:47 | I | collecting calibration activations in model.layers.0
24-11-25 21:26:48 | I | collecting calibration activations in model.layers.0
24-11-25 21:26:48 | I | - Quantizing decoder layer model.layers.0
24-11-25 21:26:48 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 21:26:49 | I |       - range scale = [    1.0000]
24-11-25 21:26:49 | I |         sum  error  = [    0.0614]
24-11-25 21:26:49 | I |         best error  = [    0.0614]
24-11-25 21:26:49 | I |     + error = [0.0614]
24-11-25 21:26:49 | I |       - range scale = [    1.0000]
24-11-25 21:26:49 | I |         sum  error  = [    0.5769]
24-11-25 21:26:49 | I |         best error  = [    0.5769]
24-11-25 21:26:49 | I |     + error = [0.5769]
24-11-25 21:26:49 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 21:26:50 | I |       - range scale = [    1.0000]
24-11-25 21:26:50 | I |         sum  error  = [    0.0594]
24-11-25 21:26:50 | I |         best error  = [    0.0594]
24-11-25 21:26:50 | I |     + error = [0.0594]
24-11-25 21:26:51 | I |       - range scale = [    1.0000]
24-11-25 21:26:51 | I |         sum  error  = [    0.5487]
24-11-25 21:26:51 | I |         best error  = [    0.5487]
24-11-25 21:26:51 | I |     + error = [0.5487]
24-11-25 21:26:51 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 21:26:52 | I |       - range scale = [    1.0000]
24-11-25 21:26:52 | I |         sum  error  = [    0.2390]
24-11-25 21:26:52 | I |         best error  = [    0.2390]
24-11-25 21:26:52 | I |     + error = [0.2390]
24-11-25 21:26:52 | I |       - range scale = [    1.0000]
24-11-25 21:26:52 | I |         sum  error  = [    1.8133]
24-11-25 21:26:52 | I |         best error  = [    1.8133]
24-11-25 21:26:52 | I |     + error = [1.8133]
24-11-25 21:26:53 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 21:26:53 | I |       - range scale = [    1.0000]
24-11-25 21:26:53 | I |         sum  error  = [    0.0599]
24-11-25 21:26:53 | I |         best error  = [    0.0599]
24-11-25 21:26:53 | I |     + error = [0.0599]
24-11-25 21:26:54 | I |       - range scale = [    1.0000]
24-11-25 21:26:54 | I |         sum  error  = [    0.5751]
24-11-25 21:26:54 | I |         best error  = [    0.5751]
24-11-25 21:26:54 | I |     + error = [0.5751]
24-11-25 21:26:54 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 21:26:55 | I |       - range scale = [    1.0000]
24-11-25 21:26:55 | I |         sum  error  = [    1.0702]
24-11-25 21:26:55 | I |         best error  = [    1.0702]
24-11-25 21:26:55 | I |     + error = [1.0702]
24-11-25 21:26:56 | I |       - range scale = [    1.0000]
24-11-25 21:26:56 | I |         sum  error  = [   11.8642]
24-11-25 21:26:56 | I |         best error  = [   11.8642]
24-11-25 21:26:56 | I |     + error = [11.8642]
24-11-25 21:26:56 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 21:26:57 | I |       - range scale = [    1.0000]
24-11-25 21:26:57 | I |         sum  error  = [    1.2410]
24-11-25 21:26:57 | I |         best error  = [    1.2410]
24-11-25 21:26:57 | I |     + error = [1.2410]
24-11-25 21:26:57 | I |       - range scale = [    1.0000]
24-11-25 21:26:57 | I |         sum  error  = [   12.2587]
24-11-25 21:26:57 | I |         best error  = [   12.2587]
24-11-25 21:26:57 | I |     + error = [12.2587]
24-11-25 21:26:58 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 21:26:58 | I |       - range scale = [    1.0000]
24-11-25 21:26:58 | I |         sum  error  = [    2.8854]
24-11-25 21:26:58 | I |         best error  = [    2.8854]
24-11-25 21:26:58 | I |     + error = [2.8854]
24-11-25 21:26:59 | I |       - range scale = [    1.0000]
24-11-25 21:26:59 | I |         sum  error  = [   16.3349]
24-11-25 21:26:59 | I |         best error  = [   16.3349]
24-11-25 21:26:59 | I |     + error = [16.3349]
24-11-25 21:26:59 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 21:27:01 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 21:27:02 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 21:27:03 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 21:27:05 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 21:27:06 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 21:27:08 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 21:27:11 | I | quantizing activations for layer model.layers.0
24-11-25 21:27:11 | I | collecting info in model.layers.0
24-11-25 21:27:11 | I | collecting info in model.layers.0
24-11-25 21:27:11 | I | collecting info in model.layers.0
24-11-25 21:27:11 | I | collecting info in model.layers.0
24-11-25 21:27:12 | I | collecting calibration activations in model.layers.0
24-11-25 21:27:12 | I | collecting calibration activations in model.layers.0
24-11-25 21:27:12 | I | collecting calibration activations in model.layers.0
24-11-25 21:27:12 | I | collecting calibration activations in model.layers.0
24-11-25 21:27:14 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 21:27:14 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 21:27:14 | I | - Evaluator: gptq
24-11-25 21:27:14 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 21:27:14 | I | - Batch_size: 8
24-11-25 21:27:14 | I |   + Max_seq_length: 2048
24-11-25 21:27:56 | I |     - Results:
24-11-25 21:27:56 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 21:27:56 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 21:27:56 | I |       |wikitext |      1|word_perplexity|7.8821|  |7.8821|
24-11-25 21:27:56 | I |       |val_valid|      1|word_perplexity|9.1820|  |9.1820|
24-11-25 21:27:56 | I |       
24-11-25 21:27:56 | I | forward this layer
24-11-25 21:27:56 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/10.pt
24-11-25 21:27:56 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/10.pt
24-11-25 21:27:56 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 21:27:56 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 21:27:56 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 21:27:56 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 21:27:56 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 21:27:56 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 21:27:56 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 21:27:56 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 21:27:56 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 21:27:56 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 21:27:56 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 21:27:56 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 21:27:56 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 21:27:56 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 21:27:56 | I | in layer model.layers.0
24-11-25 21:27:56 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 21:27:56 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 21:27:56 | I | - Evaluator: gptq
24-11-25 21:27:56 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 21:27:56 | I | - Batch_size: 8
24-11-25 21:27:56 | I |   + Max_seq_length: 2048
24-11-25 21:28:34 | I |     - Results:
24-11-25 21:28:34 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 21:28:34 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 21:28:34 | I |       |wikitext |      1|word_perplexity|7.8330|  |7.8330|
24-11-25 21:28:34 | I |       |val_valid|      1|word_perplexity|9.1295|  |9.1295|
24-11-25 21:28:34 | I |       
24-11-25 21:28:34 | I | quantizing weights for layer model.layers.0
24-11-25 21:28:34 | I | collecting info in model.layers.0
24-11-25 21:28:34 | I | collecting info in model.layers.0
24-11-25 21:28:34 | I | collecting info in model.layers.0
24-11-25 21:28:34 | I | collecting info in model.layers.0
24-11-25 21:28:35 | I | collecting calibration activations in model.layers.0
24-11-25 21:28:35 | I | collecting calibration activations in model.layers.0
24-11-25 21:28:35 | I | collecting calibration activations in model.layers.0
24-11-25 21:28:35 | I | collecting calibration activations in model.layers.0
24-11-25 21:28:36 | I | - Quantizing decoder layer model.layers.0
24-11-25 21:28:36 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 21:28:36 | I |       - range scale = [    1.0000]
24-11-25 21:28:36 | I |         sum  error  = [    0.0629]
24-11-25 21:28:36 | I |         best error  = [    0.0629]
24-11-25 21:28:36 | I |     + error = [0.0629]
24-11-25 21:28:37 | I |       - range scale = [    1.0000]
24-11-25 21:28:37 | I |         sum  error  = [    0.6100]
24-11-25 21:28:37 | I |         best error  = [    0.6100]
24-11-25 21:28:37 | I |     + error = [0.6100]
24-11-25 21:28:37 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 21:28:38 | I |       - range scale = [    1.0000]
24-11-25 21:28:38 | I |         sum  error  = [    0.0610]
24-11-25 21:28:38 | I |         best error  = [    0.0610]
24-11-25 21:28:38 | I |     + error = [0.0610]
24-11-25 21:28:38 | I |       - range scale = [    1.0000]
24-11-25 21:28:38 | I |         sum  error  = [    0.5867]
24-11-25 21:28:38 | I |         best error  = [    0.5867]
24-11-25 21:28:38 | I |     + error = [0.5867]
24-11-25 21:28:39 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 21:28:39 | I |       - range scale = [    1.0000]
24-11-25 21:28:39 | I |         sum  error  = [    0.2466]
24-11-25 21:28:39 | I |         best error  = [    0.2466]
24-11-25 21:28:39 | I |     + error = [0.2466]
24-11-25 21:28:40 | I |       - range scale = [    1.0000]
24-11-25 21:28:40 | I |         sum  error  = [    1.8795]
24-11-25 21:28:40 | I |         best error  = [    1.8795]
24-11-25 21:28:40 | I |     + error = [1.8795]
24-11-25 21:28:40 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 21:28:41 | I |       - range scale = [    1.0000]
24-11-25 21:28:41 | I |         sum  error  = [    0.0612]
24-11-25 21:28:41 | I |         best error  = [    0.0612]
24-11-25 21:28:41 | I |     + error = [0.0612]
24-11-25 21:28:42 | I |       - range scale = [    1.0000]
24-11-25 21:28:42 | I |         sum  error  = [    0.5863]
24-11-25 21:28:42 | I |         best error  = [    0.5863]
24-11-25 21:28:42 | I |     + error = [0.5863]
24-11-25 21:28:42 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 21:28:42 | I |       - range scale = [    1.0000]
24-11-25 21:28:42 | I |         sum  error  = [    1.0509]
24-11-25 21:28:42 | I |         best error  = [    1.0509]
24-11-25 21:28:42 | I |     + error = [1.0509]
24-11-25 21:28:43 | I |       - range scale = [    1.0000]
24-11-25 21:28:43 | I |         sum  error  = [   11.6542]
24-11-25 21:28:43 | I |         best error  = [   11.6542]
24-11-25 21:28:43 | I |     + error = [11.6542]
24-11-25 21:28:43 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 21:28:44 | I |       - range scale = [    1.0000]
24-11-25 21:28:44 | I |         sum  error  = [    1.2185]
24-11-25 21:28:44 | I |         best error  = [    1.2185]
24-11-25 21:28:44 | I |     + error = [1.2185]
24-11-25 21:28:45 | I |       - range scale = [    1.0000]
24-11-25 21:28:45 | I |         sum  error  = [   12.0233]
24-11-25 21:28:45 | I |         best error  = [   12.0233]
24-11-25 21:28:45 | I |     + error = [12.0233]
24-11-25 21:28:45 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 21:28:46 | I |       - range scale = [    1.0000]
24-11-25 21:28:46 | I |         sum  error  = [    3.4357]
24-11-25 21:28:46 | I |         best error  = [    3.4357]
24-11-25 21:28:46 | I |     + error = [3.4357]
24-11-25 21:28:46 | I |       - range scale = [    1.0000]
24-11-25 21:28:46 | I |         sum  error  = [   19.2007]
24-11-25 21:28:46 | I |         best error  = [   19.2007]
24-11-25 21:28:46 | I |     + error = [19.2007]
24-11-25 21:28:47 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 21:28:48 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 21:28:50 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 21:28:52 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 21:28:53 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 21:28:55 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 21:28:57 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 21:29:01 | I | quantizing activations for layer model.layers.0
24-11-25 21:29:01 | I | collecting info in model.layers.0
24-11-25 21:29:01 | I | collecting info in model.layers.0
24-11-25 21:29:01 | I | collecting info in model.layers.0
24-11-25 21:29:01 | I | collecting info in model.layers.0
24-11-25 21:29:01 | I | collecting calibration activations in model.layers.0
24-11-25 21:29:01 | I | collecting calibration activations in model.layers.0
24-11-25 21:29:01 | I | collecting calibration activations in model.layers.0
24-11-25 21:29:02 | I | collecting calibration activations in model.layers.0
24-11-25 21:29:03 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 21:29:03 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 21:29:03 | I | - Evaluator: gptq
24-11-25 21:29:03 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 21:29:03 | I | - Batch_size: 8
24-11-25 21:29:03 | I |   + Max_seq_length: 2048
24-11-25 21:29:45 | I |     - Results:
24-11-25 21:29:45 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 21:29:45 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 21:29:45 | I |       |wikitext |      1|word_perplexity|7.9801|  |7.9801|
24-11-25 21:29:45 | I |       |val_valid|      1|word_perplexity|9.1804|  |9.1804|
24-11-25 21:29:45 | I |       
24-11-25 21:29:45 | I | forward this layer
24-11-25 21:29:45 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/11.pt
24-11-25 21:29:45 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/11.pt
24-11-25 21:29:46 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 21:29:46 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 21:29:46 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 21:29:46 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 21:29:46 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 21:29:46 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 21:29:46 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 21:29:46 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 21:29:46 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 21:29:46 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 21:29:46 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 21:29:46 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 21:29:46 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 21:29:46 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 21:29:46 | I | [94] done with optimizer step
24-11-25 21:29:46 | I | epoch 001:      6 / 409600000 loss=0.000124184, loss_per_token=0.25433, loss_sum=8333.88, wps=150.8, ups=0, wpb=32768, bsz=64, num_updates=95, lr=0.000149977, gnorm=61.559, clip=100, loss_scale=0.0078, train_wall=217, cuda_gb_allocated=12.3, cuda_gb_reserved=13.9, cuda_gb_free=11.4, wall=23516, lmquant_ppl_result_wikitext_in_train_no_quant=7.83303, lmquant_ppl_result_val_in_train_no_quant=9.12945, lmquant_ppl_result_wikitext_in_train_with_quant=7.98008, lmquant_ppl_result_val_in_train_with_quant=9.18039
24-11-25 21:29:46 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 21:29:46 | I | in layer model.layers.0
24-11-25 21:29:46 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 21:29:46 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 21:29:46 | I | - Evaluator: gptq
24-11-25 21:29:46 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 21:29:46 | I | - Batch_size: 8
24-11-25 21:29:46 | I |   + Max_seq_length: 2048
24-11-25 21:30:24 | I |     - Results:
24-11-25 21:30:24 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 21:30:24 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 21:30:24 | I |       |wikitext |      1|word_perplexity|7.8361|  |7.8361|
24-11-25 21:30:24 | I |       |val_valid|      1|word_perplexity|9.1226|  |9.1226|
24-11-25 21:30:24 | I |       
24-11-25 21:30:24 | I | quantizing weights for layer model.layers.0
24-11-25 21:30:24 | I | collecting info in model.layers.0
24-11-25 21:30:24 | I | collecting info in model.layers.0
24-11-25 21:30:24 | I | collecting info in model.layers.0
24-11-25 21:30:24 | I | collecting info in model.layers.0
24-11-25 21:30:25 | I | collecting calibration activations in model.layers.0
24-11-25 21:30:25 | I | collecting calibration activations in model.layers.0
24-11-25 21:30:25 | I | collecting calibration activations in model.layers.0
24-11-25 21:30:25 | I | collecting calibration activations in model.layers.0
24-11-25 21:30:25 | I | - Quantizing decoder layer model.layers.0
24-11-25 21:30:25 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 21:30:26 | I |       - range scale = [    1.0000]
24-11-25 21:30:26 | I |         sum  error  = [    0.0645]
24-11-25 21:30:26 | I |         best error  = [    0.0645]
24-11-25 21:30:26 | I |     + error = [0.0645]
24-11-25 21:30:27 | I |       - range scale = [    1.0000]
24-11-25 21:30:27 | I |         sum  error  = [    0.6264]
24-11-25 21:30:27 | I |         best error  = [    0.6264]
24-11-25 21:30:27 | I |     + error = [0.6264]
24-11-25 21:30:27 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 21:30:28 | I |       - range scale = [    1.0000]
24-11-25 21:30:28 | I |         sum  error  = [    0.0579]
24-11-25 21:30:28 | I |         best error  = [    0.0579]
24-11-25 21:30:28 | I |     + error = [0.0579]
24-11-25 21:30:28 | I |       - range scale = [    1.0000]
24-11-25 21:30:28 | I |         sum  error  = [    0.5877]
24-11-25 21:30:28 | I |         best error  = [    0.5877]
24-11-25 21:30:28 | I |     + error = [0.5877]
24-11-25 21:30:28 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 21:30:29 | I |       - range scale = [    1.0000]
24-11-25 21:30:29 | I |         sum  error  = [    0.2399]
24-11-25 21:30:29 | I |         best error  = [    0.2399]
24-11-25 21:30:29 | I |     + error = [0.2399]
24-11-25 21:30:30 | I |       - range scale = [    1.0000]
24-11-25 21:30:30 | I |         sum  error  = [    1.8562]
24-11-25 21:30:30 | I |         best error  = [    1.8562]
24-11-25 21:30:30 | I |     + error = [1.8562]
24-11-25 21:30:30 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 21:30:31 | I |       - range scale = [    1.0000]
24-11-25 21:30:31 | I |         sum  error  = [    0.0655]
24-11-25 21:30:31 | I |         best error  = [    0.0655]
24-11-25 21:30:31 | I |     + error = [0.0655]
24-11-25 21:30:31 | I |       - range scale = [    1.0000]
24-11-25 21:30:31 | I |         sum  error  = [    0.6281]
24-11-25 21:30:31 | I |         best error  = [    0.6281]
24-11-25 21:30:31 | I |     + error = [0.6281]
24-11-25 21:30:32 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 21:30:32 | I |       - range scale = [    1.0000]
24-11-25 21:30:32 | I |         sum  error  = [    1.0800]
24-11-25 21:30:32 | I |         best error  = [    1.0800]
24-11-25 21:30:32 | I |     + error = [1.0800]
24-11-25 21:30:33 | I |       - range scale = [    1.0000]
24-11-25 21:30:33 | I |         sum  error  = [   11.9712]
24-11-25 21:30:33 | I |         best error  = [   11.9712]
24-11-25 21:30:33 | I |     + error = [11.9712]
24-11-25 21:30:33 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 21:30:34 | I |       - range scale = [    1.0000]
24-11-25 21:30:34 | I |         sum  error  = [    1.2521]
24-11-25 21:30:34 | I |         best error  = [    1.2521]
24-11-25 21:30:34 | I |     + error = [1.2521]
24-11-25 21:30:35 | I |       - range scale = [    1.0000]
24-11-25 21:30:35 | I |         sum  error  = [   12.3693]
24-11-25 21:30:35 | I |         best error  = [   12.3693]
24-11-25 21:30:35 | I |     + error = [12.3693]
24-11-25 21:30:35 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 21:30:36 | I |       - range scale = [    1.0000]
24-11-25 21:30:36 | I |         sum  error  = [    2.9968]
24-11-25 21:30:36 | I |         best error  = [    2.9968]
24-11-25 21:30:36 | I |     + error = [2.9968]
24-11-25 21:30:36 | I |       - range scale = [    1.0000]
24-11-25 21:30:36 | I |         sum  error  = [   16.8474]
24-11-25 21:30:36 | I |         best error  = [   16.8474]
24-11-25 21:30:36 | I |     + error = [16.8474]
24-11-25 21:30:37 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 21:30:38 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 21:30:39 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 21:30:41 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 21:30:42 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 21:30:43 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 21:30:45 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 21:30:48 | I | quantizing activations for layer model.layers.0
24-11-25 21:30:48 | I | collecting info in model.layers.0
24-11-25 21:30:48 | I | collecting info in model.layers.0
24-11-25 21:30:48 | I | collecting info in model.layers.0
24-11-25 21:30:48 | I | collecting info in model.layers.0
24-11-25 21:30:49 | I | collecting calibration activations in model.layers.0
24-11-25 21:30:49 | I | collecting calibration activations in model.layers.0
24-11-25 21:30:49 | I | collecting calibration activations in model.layers.0
24-11-25 21:30:49 | I | collecting calibration activations in model.layers.0
24-11-25 21:30:51 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 21:30:51 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 21:30:51 | I | - Evaluator: gptq
24-11-25 21:30:51 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 21:30:51 | I | - Batch_size: 8
24-11-25 21:30:51 | I |   + Max_seq_length: 2048
24-11-25 21:31:32 | I |     - Results:
24-11-25 21:31:32 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 21:31:32 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 21:31:32 | I |       |wikitext |      1|word_perplexity|7.8626|  |7.8626|
24-11-25 21:31:32 | I |       |val_valid|      1|word_perplexity|9.1794|  |9.1794|
24-11-25 21:31:32 | I |       
24-11-25 21:31:32 | I | forward this layer
24-11-25 21:31:32 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/12.pt
24-11-25 21:31:32 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/12.pt
24-11-25 21:31:32 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 21:31:32 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 21:31:32 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 21:31:32 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 21:31:32 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 21:31:32 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 21:31:32 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 21:31:32 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 21:31:32 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 21:31:32 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 21:31:32 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 21:31:32 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 21:31:32 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 21:31:32 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 21:31:32 | I | in layer model.layers.0
24-11-25 21:31:32 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 21:31:32 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 21:31:32 | I | - Evaluator: gptq
24-11-25 21:31:32 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 21:31:32 | I | - Batch_size: 8
24-11-25 21:31:32 | I |   + Max_seq_length: 2048
24-11-25 21:32:11 | I |     - Results:
24-11-25 21:32:11 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 21:32:11 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 21:32:11 | I |       |wikitext |      1|word_perplexity|7.8361|  |7.8361|
24-11-25 21:32:11 | I |       |val_valid|      1|word_perplexity|9.1226|  |9.1226|
24-11-25 21:32:11 | I |       
24-11-25 21:32:11 | I | quantizing weights for layer model.layers.0
24-11-25 21:32:11 | I | collecting info in model.layers.0
24-11-25 21:32:11 | I | collecting info in model.layers.0
24-11-25 21:32:11 | I | collecting info in model.layers.0
24-11-25 21:32:11 | I | collecting info in model.layers.0
24-11-25 21:32:11 | I | collecting calibration activations in model.layers.0
24-11-25 21:32:11 | I | collecting calibration activations in model.layers.0
24-11-25 21:32:11 | I | collecting calibration activations in model.layers.0
24-11-25 21:32:11 | I | collecting calibration activations in model.layers.0
24-11-25 21:32:12 | I | - Quantizing decoder layer model.layers.0
24-11-25 21:32:12 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 21:32:12 | I |       - range scale = [    1.0000]
24-11-25 21:32:12 | I |         sum  error  = [    0.0652]
24-11-25 21:32:12 | I |         best error  = [    0.0652]
24-11-25 21:32:12 | I |     + error = [0.0652]
24-11-25 21:32:13 | I |       - range scale = [    1.0000]
24-11-25 21:32:13 | I |         sum  error  = [    0.6334]
24-11-25 21:32:13 | I |         best error  = [    0.6334]
24-11-25 21:32:13 | I |     + error = [0.6334]
24-11-25 21:32:13 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 21:32:14 | I |       - range scale = [    1.0000]
24-11-25 21:32:14 | I |         sum  error  = [    0.0592]
24-11-25 21:32:14 | I |         best error  = [    0.0592]
24-11-25 21:32:14 | I |     + error = [0.0592]
24-11-25 21:32:15 | I |       - range scale = [    1.0000]
24-11-25 21:32:15 | I |         sum  error  = [    0.5885]
24-11-25 21:32:15 | I |         best error  = [    0.5885]
24-11-25 21:32:15 | I |     + error = [0.5885]
24-11-25 21:32:15 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 21:32:16 | I |       - range scale = [    1.0000]
24-11-25 21:32:16 | I |         sum  error  = [    0.2413]
24-11-25 21:32:16 | I |         best error  = [    0.2413]
24-11-25 21:32:16 | I |     + error = [0.2413]
24-11-25 21:32:16 | I |       - range scale = [    1.0000]
24-11-25 21:32:16 | I |         sum  error  = [    1.8536]
24-11-25 21:32:16 | I |         best error  = [    1.8536]
24-11-25 21:32:16 | I |     + error = [1.8536]
24-11-25 21:32:17 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 21:32:17 | I |       - range scale = [    1.0000]
24-11-25 21:32:17 | I |         sum  error  = [    0.0621]
24-11-25 21:32:17 | I |         best error  = [    0.0621]
24-11-25 21:32:17 | I |     + error = [0.0621]
24-11-25 21:32:18 | I |       - range scale = [    1.0000]
24-11-25 21:32:18 | I |         sum  error  = [    0.5963]
24-11-25 21:32:18 | I |         best error  = [    0.5963]
24-11-25 21:32:18 | I |     + error = [0.5963]
24-11-25 21:32:18 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 21:32:19 | I |       - range scale = [    1.0000]
24-11-25 21:32:19 | I |         sum  error  = [    1.0717]
24-11-25 21:32:19 | I |         best error  = [    1.0717]
24-11-25 21:32:19 | I |     + error = [1.0717]
24-11-25 21:32:20 | I |       - range scale = [    1.0000]
24-11-25 21:32:20 | I |         sum  error  = [   11.8788]
24-11-25 21:32:20 | I |         best error  = [   11.8788]
24-11-25 21:32:20 | I |     + error = [11.8788]
24-11-25 21:32:20 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 21:32:20 | I |       - range scale = [    1.0000]
24-11-25 21:32:20 | I |         sum  error  = [    1.2422]
24-11-25 21:32:20 | I |         best error  = [    1.2422]
24-11-25 21:32:20 | I |     + error = [1.2422]
24-11-25 21:32:21 | I |       - range scale = [    1.0000]
24-11-25 21:32:21 | I |         sum  error  = [   12.2758]
24-11-25 21:32:21 | I |         best error  = [   12.2758]
24-11-25 21:32:21 | I |     + error = [12.2758]
24-11-25 21:32:21 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 21:32:22 | I |       - range scale = [    1.0000]
24-11-25 21:32:22 | I |         sum  error  = [    3.3545]
24-11-25 21:32:22 | I |         best error  = [    3.3545]
24-11-25 21:32:22 | I |     + error = [3.3545]
24-11-25 21:32:23 | I |       - range scale = [    1.0000]
24-11-25 21:32:23 | I |         sum  error  = [   18.9643]
24-11-25 21:32:23 | I |         best error  = [   18.9643]
24-11-25 21:32:23 | I |     + error = [18.9643]
24-11-25 21:32:23 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 21:32:25 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 21:32:26 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 21:32:27 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 21:32:29 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 21:32:30 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 21:32:31 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 21:32:35 | I | quantizing activations for layer model.layers.0
24-11-25 21:32:35 | I | collecting info in model.layers.0
24-11-25 21:32:35 | I | collecting info in model.layers.0
24-11-25 21:32:35 | I | collecting info in model.layers.0
24-11-25 21:32:35 | I | collecting info in model.layers.0
24-11-25 21:32:35 | I | collecting calibration activations in model.layers.0
24-11-25 21:32:35 | I | collecting calibration activations in model.layers.0
24-11-25 21:32:35 | I | collecting calibration activations in model.layers.0
24-11-25 21:32:35 | I | collecting calibration activations in model.layers.0
24-11-25 21:32:37 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 21:32:37 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 21:32:37 | I | - Evaluator: gptq
24-11-25 21:32:37 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 21:32:37 | I | - Batch_size: 8
24-11-25 21:32:37 | I |   + Max_seq_length: 2048
24-11-25 21:33:19 | I |     - Results:
24-11-25 21:33:19 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 21:33:19 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 21:33:19 | I |       |wikitext |      1|word_perplexity|7.9027|  |7.9027|
24-11-25 21:33:19 | I |       |val_valid|      1|word_perplexity|9.1794|  |9.1794|
24-11-25 21:33:19 | I |       
24-11-25 21:33:19 | I | forward this layer
24-11-25 21:33:19 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/13.pt
24-11-25 21:33:19 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/13.pt
24-11-25 21:33:19 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 21:33:19 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 21:33:19 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 21:33:19 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 21:33:19 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 21:33:19 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 21:33:19 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 21:33:19 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 21:33:19 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 21:33:19 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 21:33:19 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 21:33:19 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 21:33:19 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 21:33:19 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 21:33:19 | I | [95] done with optimizer step
24-11-25 21:33:19 | I | epoch 001:      7 / 409600000 loss=0.000118591, loss_per_token=0.242874, loss_sum=7958.48, wps=153.6, ups=0, wpb=32768, bsz=64, num_updates=96, lr=0.000149977, gnorm=50.743, clip=100, loss_scale=0.0078, train_wall=213, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=23729, lmquant_ppl_result_wikitext_in_train_no_quant=7.83615, lmquant_ppl_result_val_in_train_no_quant=9.12263, lmquant_ppl_result_wikitext_in_train_with_quant=7.90268, lmquant_ppl_result_val_in_train_with_quant=9.17937
24-11-25 21:33:19 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 21:33:19 | I | in layer model.layers.0
24-11-25 21:33:19 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 21:33:19 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 21:33:19 | I | - Evaluator: gptq
24-11-25 21:33:19 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 21:33:19 | I | - Batch_size: 8
24-11-25 21:33:19 | I |   + Max_seq_length: 2048
24-11-25 21:33:57 | I |     - Results:
24-11-25 21:33:57 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 21:33:57 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 21:33:57 | I |       |wikitext |      1|word_perplexity|7.8155|  |7.8155|
24-11-25 21:33:57 | I |       |val_valid|      1|word_perplexity|9.0835|  |9.0835|
24-11-25 21:33:57 | I |       
24-11-25 21:33:57 | I | quantizing weights for layer model.layers.0
24-11-25 21:33:57 | I | collecting info in model.layers.0
24-11-25 21:33:57 | I | collecting info in model.layers.0
24-11-25 21:33:57 | I | collecting info in model.layers.0
24-11-25 21:33:57 | I | collecting info in model.layers.0
24-11-25 21:33:58 | I | collecting calibration activations in model.layers.0
24-11-25 21:33:58 | I | collecting calibration activations in model.layers.0
24-11-25 21:33:58 | I | collecting calibration activations in model.layers.0
24-11-25 21:33:58 | I | collecting calibration activations in model.layers.0
24-11-25 21:33:59 | I | - Quantizing decoder layer model.layers.0
24-11-25 21:33:59 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 21:33:59 | I |       - range scale = [    1.0000]
24-11-25 21:33:59 | I |         sum  error  = [    0.0706]
24-11-25 21:33:59 | I |         best error  = [    0.0706]
24-11-25 21:33:59 | I |     + error = [0.0706]
24-11-25 21:34:00 | I |       - range scale = [    1.0000]
24-11-25 21:34:00 | I |         sum  error  = [    0.6272]
24-11-25 21:34:00 | I |         best error  = [    0.6272]
24-11-25 21:34:00 | I |     + error = [0.6272]
24-11-25 21:34:00 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 21:34:01 | I |       - range scale = [    1.0000]
24-11-25 21:34:01 | I |         sum  error  = [    0.0627]
24-11-25 21:34:01 | I |         best error  = [    0.0627]
24-11-25 21:34:01 | I |     + error = [0.0627]
24-11-25 21:34:02 | I |       - range scale = [    1.0000]
24-11-25 21:34:02 | I |         sum  error  = [    0.5937]
24-11-25 21:34:02 | I |         best error  = [    0.5937]
24-11-25 21:34:02 | I |     + error = [0.5937]
24-11-25 21:34:02 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 21:34:03 | I |       - range scale = [    1.0000]
24-11-25 21:34:03 | I |         sum  error  = [    0.2472]
24-11-25 21:34:03 | I |         best error  = [    0.2472]
24-11-25 21:34:03 | I |     + error = [0.2472]
24-11-25 21:34:03 | I |       - range scale = [    1.0000]
24-11-25 21:34:03 | I |         sum  error  = [    1.8825]
24-11-25 21:34:03 | I |         best error  = [    1.8825]
24-11-25 21:34:03 | I |     + error = [1.8825]
24-11-25 21:34:03 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 21:34:04 | I |       - range scale = [    1.0000]
24-11-25 21:34:04 | I |         sum  error  = [    0.0642]
24-11-25 21:34:04 | I |         best error  = [    0.0642]
24-11-25 21:34:04 | I |     + error = [0.0642]
24-11-25 21:34:05 | I |       - range scale = [    1.0000]
24-11-25 21:34:05 | I |         sum  error  = [    0.6145]
24-11-25 21:34:05 | I |         best error  = [    0.6145]
24-11-25 21:34:05 | I |     + error = [0.6145]
24-11-25 21:34:05 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 21:34:06 | I |       - range scale = [    1.0000]
24-11-25 21:34:06 | I |         sum  error  = [    1.0737]
24-11-25 21:34:06 | I |         best error  = [    1.0737]
24-11-25 21:34:06 | I |     + error = [1.0737]
24-11-25 21:34:06 | I |       - range scale = [    1.0000]
24-11-25 21:34:06 | I |         sum  error  = [   11.9283]
24-11-25 21:34:06 | I |         best error  = [   11.9283]
24-11-25 21:34:06 | I |     + error = [11.9283]
24-11-25 21:34:07 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 21:34:07 | I |       - range scale = [    1.0000]
24-11-25 21:34:07 | I |         sum  error  = [    1.2477]
24-11-25 21:34:07 | I |         best error  = [    1.2477]
24-11-25 21:34:07 | I |     + error = [1.2477]
24-11-25 21:34:08 | I |       - range scale = [    1.0000]
24-11-25 21:34:08 | I |         sum  error  = [   12.3214]
24-11-25 21:34:08 | I |         best error  = [   12.3214]
24-11-25 21:34:08 | I |     + error = [12.3214]
24-11-25 21:34:08 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 21:34:09 | I |       - range scale = [    1.0000]
24-11-25 21:34:09 | I |         sum  error  = [    3.7027]
24-11-25 21:34:09 | I |         best error  = [    3.7027]
24-11-25 21:34:09 | I |     + error = [3.7027]
24-11-25 21:34:10 | I |       - range scale = [    1.0000]
24-11-25 21:34:10 | I |         sum  error  = [   21.0264]
24-11-25 21:34:10 | I |         best error  = [   21.0264]
24-11-25 21:34:10 | I |     + error = [21.0264]
24-11-25 21:34:10 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 21:34:11 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 21:34:13 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 21:34:14 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 21:34:15 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 21:34:17 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 21:34:18 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 21:34:22 | I | quantizing activations for layer model.layers.0
24-11-25 21:34:22 | I | collecting info in model.layers.0
24-11-25 21:34:22 | I | collecting info in model.layers.0
24-11-25 21:34:22 | I | collecting info in model.layers.0
24-11-25 21:34:22 | I | collecting info in model.layers.0
24-11-25 21:34:22 | I | collecting calibration activations in model.layers.0
24-11-25 21:34:22 | I | collecting calibration activations in model.layers.0
24-11-25 21:34:22 | I | collecting calibration activations in model.layers.0
24-11-25 21:34:22 | I | collecting calibration activations in model.layers.0
24-11-25 21:34:24 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 21:34:24 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 21:34:24 | I | - Evaluator: gptq
24-11-25 21:34:24 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 21:34:24 | I | - Batch_size: 8
24-11-25 21:34:24 | I |   + Max_seq_length: 2048
24-11-25 21:35:06 | I |     - Results:
24-11-25 21:35:06 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 21:35:06 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 21:35:06 | I |       |wikitext |      1|word_perplexity|7.8645|  |7.8645|
24-11-25 21:35:06 | I |       |val_valid|      1|word_perplexity|9.1375|  |9.1375|
24-11-25 21:35:06 | I |       
24-11-25 21:35:06 | I | forward this layer
24-11-25 21:35:06 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/14.pt
24-11-25 21:35:06 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/14.pt
24-11-25 21:35:06 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 21:35:06 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 21:35:06 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 21:35:06 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 21:35:06 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 21:35:06 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 21:35:06 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 21:35:06 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 21:35:06 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 21:35:06 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 21:35:06 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 21:35:06 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 21:35:06 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 21:35:06 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 21:35:06 | I | in layer model.layers.0
24-11-25 21:35:06 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 21:35:06 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 21:35:06 | I | - Evaluator: gptq
24-11-25 21:35:06 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 21:35:06 | I | - Batch_size: 8
24-11-25 21:35:06 | I |   + Max_seq_length: 2048
24-11-25 21:35:44 | I |     - Results:
24-11-25 21:35:44 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 21:35:44 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 21:35:44 | I |       |wikitext |      1|word_perplexity|7.8155|  |7.8155|
24-11-25 21:35:44 | I |       |val_valid|      1|word_perplexity|9.0835|  |9.0835|
24-11-25 21:35:44 | I |       
24-11-25 21:35:44 | I | quantizing weights for layer model.layers.0
24-11-25 21:35:44 | I | collecting info in model.layers.0
24-11-25 21:35:44 | I | collecting info in model.layers.0
24-11-25 21:35:44 | I | collecting info in model.layers.0
24-11-25 21:35:44 | I | collecting info in model.layers.0
24-11-25 21:35:45 | I | collecting calibration activations in model.layers.0
24-11-25 21:35:45 | I | collecting calibration activations in model.layers.0
24-11-25 21:35:45 | I | collecting calibration activations in model.layers.0
24-11-25 21:35:45 | I | collecting calibration activations in model.layers.0
24-11-25 21:35:45 | I | - Quantizing decoder layer model.layers.0
24-11-25 21:35:45 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 21:35:46 | I |       - range scale = [    1.0000]
24-11-25 21:35:46 | I |         sum  error  = [    0.0731]
24-11-25 21:35:46 | I |         best error  = [    0.0731]
24-11-25 21:35:46 | I |     + error = [0.0731]
24-11-25 21:35:47 | I |       - range scale = [    1.0000]
24-11-25 21:35:47 | I |         sum  error  = [    0.6345]
24-11-25 21:35:47 | I |         best error  = [    0.6345]
24-11-25 21:35:47 | I |     + error = [0.6345]
24-11-25 21:35:47 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 21:35:48 | I |       - range scale = [    1.0000]
24-11-25 21:35:48 | I |         sum  error  = [    0.0627]
24-11-25 21:35:48 | I |         best error  = [    0.0627]
24-11-25 21:35:48 | I |     + error = [0.0627]
24-11-25 21:35:48 | I |       - range scale = [    1.0000]
24-11-25 21:35:48 | I |         sum  error  = [    0.6086]
24-11-25 21:35:48 | I |         best error  = [    0.6086]
24-11-25 21:35:48 | I |     + error = [0.6086]
24-11-25 21:35:49 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 21:35:49 | I |       - range scale = [    1.0000]
24-11-25 21:35:49 | I |         sum  error  = [    0.2470]
24-11-25 21:35:49 | I |         best error  = [    0.2470]
24-11-25 21:35:49 | I |     + error = [0.2470]
24-11-25 21:35:50 | I |       - range scale = [    1.0000]
24-11-25 21:35:50 | I |         sum  error  = [    1.8812]
24-11-25 21:35:50 | I |         best error  = [    1.8812]
24-11-25 21:35:50 | I |     + error = [1.8812]
24-11-25 21:35:50 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 21:35:51 | I |       - range scale = [    1.0000]
24-11-25 21:35:51 | I |         sum  error  = [    0.0667]
24-11-25 21:35:51 | I |         best error  = [    0.0667]
24-11-25 21:35:51 | I |     + error = [0.0667]
24-11-25 21:35:52 | I |       - range scale = [    1.0000]
24-11-25 21:35:52 | I |         sum  error  = [    0.6416]
24-11-25 21:35:52 | I |         best error  = [    0.6416]
24-11-25 21:35:52 | I |     + error = [0.6416]
24-11-25 21:35:52 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 21:35:52 | I |       - range scale = [    1.0000]
24-11-25 21:35:52 | I |         sum  error  = [    1.0583]
24-11-25 21:35:52 | I |         best error  = [    1.0583]
24-11-25 21:35:52 | I |     + error = [1.0583]
24-11-25 21:35:53 | I |       - range scale = [    1.0000]
24-11-25 21:35:53 | I |         sum  error  = [   11.7573]
24-11-25 21:35:53 | I |         best error  = [   11.7573]
24-11-25 21:35:53 | I |     + error = [11.7573]
24-11-25 21:35:53 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 21:35:54 | I |       - range scale = [    1.0000]
24-11-25 21:35:54 | I |         sum  error  = [    1.2280]
24-11-25 21:35:54 | I |         best error  = [    1.2280]
24-11-25 21:35:54 | I |     + error = [1.2280]
24-11-25 21:35:55 | I |       - range scale = [    1.0000]
24-11-25 21:35:55 | I |         sum  error  = [   12.1420]
24-11-25 21:35:55 | I |         best error  = [   12.1420]
24-11-25 21:35:55 | I |     + error = [12.1420]
24-11-25 21:35:55 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 21:35:56 | I |       - range scale = [    1.0000]
24-11-25 21:35:56 | I |         sum  error  = [    3.5071]
24-11-25 21:35:56 | I |         best error  = [    3.5071]
24-11-25 21:35:56 | I |     + error = [3.5071]
24-11-25 21:35:57 | I |       - range scale = [    1.0000]
24-11-25 21:35:57 | I |         sum  error  = [   19.7859]
24-11-25 21:35:57 | I |         best error  = [   19.7859]
24-11-25 21:35:57 | I |     + error = [19.7859]
24-11-25 21:35:57 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 21:35:58 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 21:35:59 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 21:36:01 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 21:36:02 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 21:36:04 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 21:36:05 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 21:36:08 | I | quantizing activations for layer model.layers.0
24-11-25 21:36:08 | I | collecting info in model.layers.0
24-11-25 21:36:08 | I | collecting info in model.layers.0
24-11-25 21:36:08 | I | collecting info in model.layers.0
24-11-25 21:36:08 | I | collecting info in model.layers.0
24-11-25 21:36:09 | I | collecting calibration activations in model.layers.0
24-11-25 21:36:09 | I | collecting calibration activations in model.layers.0
24-11-25 21:36:09 | I | collecting calibration activations in model.layers.0
24-11-25 21:36:09 | I | collecting calibration activations in model.layers.0
24-11-25 21:36:11 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 21:36:11 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 21:36:11 | I | - Evaluator: gptq
24-11-25 21:36:11 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 21:36:11 | I | - Batch_size: 8
24-11-25 21:36:11 | I |   + Max_seq_length: 2048
24-11-25 21:36:52 | I |     - Results:
24-11-25 21:36:52 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 21:36:52 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 21:36:52 | I |       |wikitext |      1|word_perplexity|7.8274|  |7.8274|
24-11-25 21:36:52 | I |       |val_valid|      1|word_perplexity|9.1266|  |9.1266|
24-11-25 21:36:52 | I |       
24-11-25 21:36:52 | I | forward this layer
24-11-25 21:36:52 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/15.pt
24-11-25 21:36:52 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/15.pt
24-11-25 21:36:53 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 21:36:53 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 21:36:53 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 21:36:53 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 21:36:53 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 21:36:53 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 21:36:53 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 21:36:53 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 21:36:53 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 21:36:53 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 21:36:53 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 21:36:53 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 21:36:53 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 21:36:53 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 21:36:53 | I | [96] done with optimizer step
24-11-25 21:36:53 | I | epoch 001:      8 / 409600000 loss=7.50077e-05, loss_per_token=0.153616, loss_sum=5033.68, wps=153.4, ups=0, wpb=32768, bsz=64, num_updates=97, lr=0.000149976, gnorm=12.41, clip=100, loss_scale=0.0078, train_wall=213, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=23943, lmquant_ppl_result_wikitext_in_train_no_quant=7.81551, lmquant_ppl_result_val_in_train_no_quant=9.08351, lmquant_ppl_result_wikitext_in_train_with_quant=7.82739, lmquant_ppl_result_val_in_train_with_quant=9.12665
24-11-25 21:36:53 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 21:36:53 | I | in layer model.layers.0
24-11-25 21:36:53 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 21:36:53 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 21:36:53 | I | - Evaluator: gptq
24-11-25 21:36:53 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 21:36:53 | I | - Batch_size: 8
24-11-25 21:36:53 | I |   + Max_seq_length: 2048
24-11-25 21:37:31 | I |     - Results:
24-11-25 21:37:31 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 21:37:31 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 21:37:31 | I |       |wikitext |      1|word_perplexity|7.7874|  |7.7874|
24-11-25 21:37:31 | I |       |val_valid|      1|word_perplexity|9.0420|  |9.0420|
24-11-25 21:37:31 | I |       
24-11-25 21:37:31 | I | quantizing weights for layer model.layers.0
24-11-25 21:37:31 | I | collecting info in model.layers.0
24-11-25 21:37:31 | I | collecting info in model.layers.0
24-11-25 21:37:31 | I | collecting info in model.layers.0
24-11-25 21:37:31 | I | collecting info in model.layers.0
24-11-25 21:37:32 | I | collecting calibration activations in model.layers.0
24-11-25 21:37:32 | I | collecting calibration activations in model.layers.0
24-11-25 21:37:32 | I | collecting calibration activations in model.layers.0
24-11-25 21:37:32 | I | collecting calibration activations in model.layers.0
24-11-25 21:37:32 | I | - Quantizing decoder layer model.layers.0
24-11-25 21:37:32 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 21:37:33 | I |       - range scale = [    1.0000]
24-11-25 21:37:33 | I |         sum  error  = [    0.0716]
24-11-25 21:37:33 | I |         best error  = [    0.0716]
24-11-25 21:37:33 | I |     + error = [0.0716]
24-11-25 21:37:34 | I |       - range scale = [    1.0000]
24-11-25 21:37:34 | I |         sum  error  = [    0.6391]
24-11-25 21:37:34 | I |         best error  = [    0.6391]
24-11-25 21:37:34 | I |     + error = [0.6391]
24-11-25 21:37:34 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 21:37:35 | I |       - range scale = [    1.0000]
24-11-25 21:37:35 | I |         sum  error  = [    0.0633]
24-11-25 21:37:35 | I |         best error  = [    0.0633]
24-11-25 21:37:35 | I |     + error = [0.0633]
24-11-25 21:37:35 | I |       - range scale = [    1.0000]
24-11-25 21:37:35 | I |         sum  error  = [    0.5881]
24-11-25 21:37:35 | I |         best error  = [    0.5881]
24-11-25 21:37:35 | I |     + error = [0.5881]
24-11-25 21:37:36 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 21:37:36 | I |       - range scale = [    1.0000]
24-11-25 21:37:36 | I |         sum  error  = [    0.2431]
24-11-25 21:37:36 | I |         best error  = [    0.2431]
24-11-25 21:37:36 | I |     + error = [0.2431]
24-11-25 21:37:37 | I |       - range scale = [    1.0000]
24-11-25 21:37:37 | I |         sum  error  = [    1.8681]
24-11-25 21:37:37 | I |         best error  = [    1.8681]
24-11-25 21:37:37 | I |     + error = [1.8681]
24-11-25 21:37:37 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 21:37:38 | I |       - range scale = [    1.0000]
24-11-25 21:37:38 | I |         sum  error  = [    0.0659]
24-11-25 21:37:38 | I |         best error  = [    0.0659]
24-11-25 21:37:38 | I |     + error = [0.0659]
24-11-25 21:37:38 | I |       - range scale = [    1.0000]
24-11-25 21:37:38 | I |         sum  error  = [    0.6304]
24-11-25 21:37:38 | I |         best error  = [    0.6304]
24-11-25 21:37:38 | I |     + error = [0.6304]
24-11-25 21:37:39 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 21:37:39 | I |       - range scale = [    1.0000]
24-11-25 21:37:39 | I |         sum  error  = [    1.0737]
24-11-25 21:37:39 | I |         best error  = [    1.0737]
24-11-25 21:37:39 | I |     + error = [1.0737]
24-11-25 21:37:40 | I |       - range scale = [    1.0000]
24-11-25 21:37:40 | I |         sum  error  = [   11.9065]
24-11-25 21:37:40 | I |         best error  = [   11.9065]
24-11-25 21:37:40 | I |     + error = [11.9065]
24-11-25 21:37:40 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 21:37:41 | I |       - range scale = [    1.0000]
24-11-25 21:37:41 | I |         sum  error  = [    1.2463]
24-11-25 21:37:41 | I |         best error  = [    1.2463]
24-11-25 21:37:41 | I |     + error = [1.2463]
24-11-25 21:37:42 | I |       - range scale = [    1.0000]
24-11-25 21:37:42 | I |         sum  error  = [   12.3031]
24-11-25 21:37:42 | I |         best error  = [   12.3031]
24-11-25 21:37:42 | I |     + error = [12.3031]
24-11-25 21:37:42 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 21:37:43 | I |       - range scale = [    1.0000]
24-11-25 21:37:43 | I |         sum  error  = [    3.4734]
24-11-25 21:37:43 | I |         best error  = [    3.4734]
24-11-25 21:37:43 | I |     + error = [3.4734]
24-11-25 21:37:43 | I |       - range scale = [    1.0000]
24-11-25 21:37:43 | I |         sum  error  = [   19.7127]
24-11-25 21:37:43 | I |         best error  = [   19.7127]
24-11-25 21:37:43 | I |     + error = [19.7127]
24-11-25 21:37:44 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 21:37:45 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 21:37:46 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 21:37:48 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 21:37:49 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 21:37:51 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 21:37:52 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 21:37:55 | I | quantizing activations for layer model.layers.0
24-11-25 21:37:55 | I | collecting info in model.layers.0
24-11-25 21:37:55 | I | collecting info in model.layers.0
24-11-25 21:37:55 | I | collecting info in model.layers.0
24-11-25 21:37:55 | I | collecting info in model.layers.0
24-11-25 21:37:56 | I | collecting calibration activations in model.layers.0
24-11-25 21:37:56 | I | collecting calibration activations in model.layers.0
24-11-25 21:37:56 | I | collecting calibration activations in model.layers.0
24-11-25 21:37:56 | I | collecting calibration activations in model.layers.0
24-11-25 21:37:58 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 21:37:58 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 21:37:58 | I | - Evaluator: gptq
24-11-25 21:37:58 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 21:37:58 | I | - Batch_size: 8
24-11-25 21:37:58 | I |   + Max_seq_length: 2048
24-11-25 21:38:39 | I |     - Results:
24-11-25 21:38:40 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 21:38:40 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 21:38:40 | I |       |wikitext |      1|word_perplexity|7.8132|  |7.8132|
24-11-25 21:38:40 | I |       |val_valid|      1|word_perplexity|9.0985|  |9.0985|
24-11-25 21:38:40 | I |       
24-11-25 21:38:40 | I | forward this layer
24-11-25 21:38:40 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/16.pt
24-11-25 21:38:40 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/16.pt
24-11-25 21:38:40 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 21:38:40 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 21:38:40 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 21:38:40 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 21:38:40 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 21:38:40 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 21:38:40 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 21:38:40 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 21:38:40 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 21:38:40 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 21:38:40 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 21:38:40 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 21:38:40 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 21:38:40 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 21:38:40 | I | in layer model.layers.0
24-11-25 21:38:40 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 21:38:40 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 21:38:40 | I | - Evaluator: gptq
24-11-25 21:38:40 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 21:38:40 | I | - Batch_size: 8
24-11-25 21:38:40 | I |   + Max_seq_length: 2048
24-11-25 21:39:18 | I |     - Results:
24-11-25 21:39:18 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 21:39:18 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 21:39:18 | I |       |wikitext |      1|word_perplexity|7.7874|  |7.7874|
24-11-25 21:39:18 | I |       |val_valid|      1|word_perplexity|9.0420|  |9.0420|
24-11-25 21:39:18 | I |       
24-11-25 21:39:18 | I | quantizing weights for layer model.layers.0
24-11-25 21:39:18 | I | collecting info in model.layers.0
24-11-25 21:39:18 | I | collecting info in model.layers.0
24-11-25 21:39:18 | I | collecting info in model.layers.0
24-11-25 21:39:18 | I | collecting info in model.layers.0
24-11-25 21:39:19 | I | collecting calibration activations in model.layers.0
24-11-25 21:39:19 | I | collecting calibration activations in model.layers.0
24-11-25 21:39:19 | I | collecting calibration activations in model.layers.0
24-11-25 21:39:19 | I | collecting calibration activations in model.layers.0
24-11-25 21:39:19 | I | - Quantizing decoder layer model.layers.0
24-11-25 21:39:19 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 21:39:20 | I |       - range scale = [    1.0000]
24-11-25 21:39:20 | I |         sum  error  = [    0.0702]
24-11-25 21:39:20 | I |         best error  = [    0.0702]
24-11-25 21:39:20 | I |     + error = [0.0702]
24-11-25 21:39:21 | I |       - range scale = [    1.0000]
24-11-25 21:39:21 | I |         sum  error  = [    0.6178]
24-11-25 21:39:21 | I |         best error  = [    0.6178]
24-11-25 21:39:21 | I |     + error = [0.6178]
24-11-25 21:39:21 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 21:39:21 | I |       - range scale = [    1.0000]
24-11-25 21:39:21 | I |         sum  error  = [    0.0630]
24-11-25 21:39:21 | I |         best error  = [    0.0630]
24-11-25 21:39:21 | I |     + error = [0.0630]
24-11-25 21:39:22 | I |       - range scale = [    1.0000]
24-11-25 21:39:22 | I |         sum  error  = [    0.5876]
24-11-25 21:39:22 | I |         best error  = [    0.5876]
24-11-25 21:39:22 | I |     + error = [0.5876]
24-11-25 21:39:22 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 21:39:23 | I |       - range scale = [    1.0000]
24-11-25 21:39:23 | I |         sum  error  = [    0.2379]
24-11-25 21:39:23 | I |         best error  = [    0.2379]
24-11-25 21:39:23 | I |     + error = [0.2379]
24-11-25 21:39:24 | I |       - range scale = [    1.0000]
24-11-25 21:39:24 | I |         sum  error  = [    1.8350]
24-11-25 21:39:24 | I |         best error  = [    1.8350]
24-11-25 21:39:24 | I |     + error = [1.8350]
24-11-25 21:39:24 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 21:39:25 | I |       - range scale = [    1.0000]
24-11-25 21:39:25 | I |         sum  error  = [    0.0637]
24-11-25 21:39:25 | I |         best error  = [    0.0637]
24-11-25 21:39:25 | I |     + error = [0.0637]
24-11-25 21:39:25 | I |       - range scale = [    1.0000]
24-11-25 21:39:25 | I |         sum  error  = [    0.6076]
24-11-25 21:39:25 | I |         best error  = [    0.6076]
24-11-25 21:39:25 | I |     + error = [0.6076]
24-11-25 21:39:26 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 21:39:26 | I |       - range scale = [    1.0000]
24-11-25 21:39:26 | I |         sum  error  = [    1.0518]
24-11-25 21:39:26 | I |         best error  = [    1.0518]
24-11-25 21:39:26 | I |     + error = [1.0518]
24-11-25 21:39:27 | I |       - range scale = [    1.0000]
24-11-25 21:39:27 | I |         sum  error  = [   11.6790]
24-11-25 21:39:27 | I |         best error  = [   11.6790]
24-11-25 21:39:27 | I |     + error = [11.6790]
24-11-25 21:39:27 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 21:39:28 | I |       - range scale = [    1.0000]
24-11-25 21:39:28 | I |         sum  error  = [    1.2202]
24-11-25 21:39:28 | I |         best error  = [    1.2202]
24-11-25 21:39:28 | I |     + error = [1.2202]
24-11-25 21:39:29 | I |       - range scale = [    1.0000]
24-11-25 21:39:29 | I |         sum  error  = [   12.0445]
24-11-25 21:39:29 | I |         best error  = [   12.0445]
24-11-25 21:39:29 | I |     + error = [12.0445]
24-11-25 21:39:29 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 21:39:30 | I |       - range scale = [    1.0000]
24-11-25 21:39:30 | I |         sum  error  = [    2.9269]
24-11-25 21:39:30 | I |         best error  = [    2.9269]
24-11-25 21:39:30 | I |     + error = [2.9269]
24-11-25 21:39:30 | I |       - range scale = [    1.0000]
24-11-25 21:39:30 | I |         sum  error  = [   17.0282]
24-11-25 21:39:30 | I |         best error  = [   17.0282]
24-11-25 21:39:30 | I |     + error = [17.0282]
24-11-25 21:39:31 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 21:39:32 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 21:39:33 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 21:39:35 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 21:39:36 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 21:39:37 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 21:39:39 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 21:39:42 | I | quantizing activations for layer model.layers.0
24-11-25 21:39:42 | I | collecting info in model.layers.0
24-11-25 21:39:42 | I | collecting info in model.layers.0
24-11-25 21:39:42 | I | collecting info in model.layers.0
24-11-25 21:39:42 | I | collecting info in model.layers.0
24-11-25 21:39:43 | I | collecting calibration activations in model.layers.0
24-11-25 21:39:43 | I | collecting calibration activations in model.layers.0
24-11-25 21:39:43 | I | collecting calibration activations in model.layers.0
24-11-25 21:39:43 | I | collecting calibration activations in model.layers.0
24-11-25 21:39:45 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 21:39:45 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 21:39:45 | I | - Evaluator: gptq
24-11-25 21:39:45 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 21:39:45 | I | - Batch_size: 8
24-11-25 21:39:45 | I |   + Max_seq_length: 2048
24-11-25 21:40:26 | I |     - Results:
24-11-25 21:40:26 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 21:40:26 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 21:40:26 | I |       |wikitext |      1|word_perplexity|7.8221|  |7.8221|
24-11-25 21:40:26 | I |       |val_valid|      1|word_perplexity|9.1075|  |9.1075|
24-11-25 21:40:26 | I |       
24-11-25 21:40:26 | I | forward this layer
24-11-25 21:40:26 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/17.pt
24-11-25 21:40:26 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/17.pt
24-11-25 21:40:27 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 21:40:27 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 21:40:27 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 21:40:27 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 21:40:27 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 21:40:27 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 21:40:27 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 21:40:27 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 21:40:27 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 21:40:27 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 21:40:27 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 21:40:27 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 21:40:27 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 21:40:27 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 21:40:27 | I | [97] done with optimizer step
24-11-25 21:40:27 | I | epoch 001:      9 / 409600000 loss=0.000136539, loss_per_token=0.279631, loss_sum=9162.95, wps=153.1, ups=0, wpb=32768, bsz=64, num_updates=98, lr=0.000149976, gnorm=39.966, clip=100, loss_scale=0.0078, train_wall=214, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=24157, lmquant_ppl_result_wikitext_in_train_no_quant=7.78741, lmquant_ppl_result_val_in_train_no_quant=9.04201, lmquant_ppl_result_wikitext_in_train_with_quant=7.82213, lmquant_ppl_result_val_in_train_with_quant=9.10753
24-11-25 21:40:27 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 21:40:27 | I | in layer model.layers.0
24-11-25 21:40:27 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 21:40:27 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 21:40:27 | I | - Evaluator: gptq
24-11-25 21:40:27 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 21:40:27 | I | - Batch_size: 8
24-11-25 21:40:27 | I |   + Max_seq_length: 2048
24-11-25 21:41:05 | I |     - Results:
24-11-25 21:41:05 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 21:41:05 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 21:41:05 | I |       |wikitext |      1|word_perplexity|7.7805|  |7.7805|
24-11-25 21:41:05 | I |       |val_valid|      1|word_perplexity|9.0334|  |9.0334|
24-11-25 21:41:05 | I |       
24-11-25 21:41:05 | I | quantizing weights for layer model.layers.0
24-11-25 21:41:05 | I | collecting info in model.layers.0
24-11-25 21:41:05 | I | collecting info in model.layers.0
24-11-25 21:41:05 | I | collecting info in model.layers.0
24-11-25 21:41:05 | I | collecting info in model.layers.0
24-11-25 21:41:06 | I | collecting calibration activations in model.layers.0
24-11-25 21:41:06 | I | collecting calibration activations in model.layers.0
24-11-25 21:41:06 | I | collecting calibration activations in model.layers.0
24-11-25 21:41:06 | I | collecting calibration activations in model.layers.0
24-11-25 21:41:06 | I | - Quantizing decoder layer model.layers.0
24-11-25 21:41:06 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 21:41:07 | I |       - range scale = [    1.0000]
24-11-25 21:41:07 | I |         sum  error  = [    0.0693]
24-11-25 21:41:07 | I |         best error  = [    0.0693]
24-11-25 21:41:07 | I |     + error = [0.0693]
24-11-25 21:41:08 | I |       - range scale = [    1.0000]
24-11-25 21:41:08 | I |         sum  error  = [    0.6289]
24-11-25 21:41:08 | I |         best error  = [    0.6289]
24-11-25 21:41:08 | I |     + error = [0.6289]
24-11-25 21:41:08 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 21:41:09 | I |       - range scale = [    1.0000]
24-11-25 21:41:09 | I |         sum  error  = [    0.0622]
24-11-25 21:41:09 | I |         best error  = [    0.0622]
24-11-25 21:41:09 | I |     + error = [0.0622]
24-11-25 21:41:09 | I |       - range scale = [    1.0000]
24-11-25 21:41:09 | I |         sum  error  = [    0.5789]
24-11-25 21:41:09 | I |         best error  = [    0.5789]
24-11-25 21:41:09 | I |     + error = [0.5789]
24-11-25 21:41:09 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 21:41:10 | I |       - range scale = [    1.0000]
24-11-25 21:41:10 | I |         sum  error  = [    0.2541]
24-11-25 21:41:10 | I |         best error  = [    0.2541]
24-11-25 21:41:10 | I |     + error = [0.2541]
24-11-25 21:41:11 | I |       - range scale = [    1.0000]
24-11-25 21:41:11 | I |         sum  error  = [    1.8483]
24-11-25 21:41:11 | I |         best error  = [    1.8483]
24-11-25 21:41:11 | I |     + error = [1.8483]
24-11-25 21:41:11 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 21:41:12 | I |       - range scale = [    1.0000]
24-11-25 21:41:12 | I |         sum  error  = [    0.0651]
24-11-25 21:41:12 | I |         best error  = [    0.0651]
24-11-25 21:41:12 | I |     + error = [0.0651]
24-11-25 21:41:12 | I |       - range scale = [    1.0000]
24-11-25 21:41:12 | I |         sum  error  = [    0.6226]
24-11-25 21:41:12 | I |         best error  = [    0.6226]
24-11-25 21:41:12 | I |     + error = [0.6226]
24-11-25 21:41:13 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 21:41:13 | I |       - range scale = [    1.0000]
24-11-25 21:41:13 | I |         sum  error  = [    0.9760]
24-11-25 21:41:13 | I |         best error  = [    0.9760]
24-11-25 21:41:13 | I |     + error = [0.9760]
24-11-25 21:41:14 | I |       - range scale = [    1.0000]
24-11-25 21:41:14 | I |         sum  error  = [   10.8266]
24-11-25 21:41:14 | I |         best error  = [   10.8266]
24-11-25 21:41:14 | I |     + error = [10.8266]
24-11-25 21:41:14 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 21:41:15 | I |       - range scale = [    1.0000]
24-11-25 21:41:15 | I |         sum  error  = [    1.1358]
24-11-25 21:41:15 | I |         best error  = [    1.1358]
24-11-25 21:41:15 | I |     + error = [1.1358]
24-11-25 21:41:16 | I |       - range scale = [    1.0000]
24-11-25 21:41:16 | I |         sum  error  = [   11.1754]
24-11-25 21:41:16 | I |         best error  = [   11.1754]
24-11-25 21:41:16 | I |     + error = [11.1754]
24-11-25 21:41:16 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 21:41:17 | I |       - range scale = [    1.0000]
24-11-25 21:41:17 | I |         sum  error  = [    3.0119]
24-11-25 21:41:17 | I |         best error  = [    3.0119]
24-11-25 21:41:17 | I |     + error = [3.0119]
24-11-25 21:41:17 | I |       - range scale = [    1.0000]
24-11-25 21:41:17 | I |         sum  error  = [   17.1324]
24-11-25 21:41:17 | I |         best error  = [   17.1324]
24-11-25 21:41:17 | I |     + error = [17.1324]
24-11-25 21:41:18 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 21:41:19 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 21:41:20 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 21:41:22 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 21:41:23 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 21:41:25 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 21:41:26 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 21:41:29 | I | quantizing activations for layer model.layers.0
24-11-25 21:41:29 | I | collecting info in model.layers.0
24-11-25 21:41:29 | I | collecting info in model.layers.0
24-11-25 21:41:29 | I | collecting info in model.layers.0
24-11-25 21:41:29 | I | collecting info in model.layers.0
24-11-25 21:41:30 | I | collecting calibration activations in model.layers.0
24-11-25 21:41:30 | I | collecting calibration activations in model.layers.0
24-11-25 21:41:30 | I | collecting calibration activations in model.layers.0
24-11-25 21:41:30 | I | collecting calibration activations in model.layers.0
24-11-25 21:41:32 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 21:41:32 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 21:41:32 | I | - Evaluator: gptq
24-11-25 21:41:32 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 21:41:32 | I | - Batch_size: 8
24-11-25 21:41:32 | I |   + Max_seq_length: 2048
24-11-25 21:42:13 | I |     - Results:
24-11-25 21:42:13 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 21:42:13 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 21:42:13 | I |       |wikitext |      1|word_perplexity|7.7945|  |7.7945|
24-11-25 21:42:13 | I |       |val_valid|      1|word_perplexity|9.0854|  |9.0854|
24-11-25 21:42:13 | I |       
24-11-25 21:42:13 | I | forward this layer
24-11-25 21:42:13 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/18.pt
24-11-25 21:42:13 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/18.pt
24-11-25 21:42:14 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 21:42:14 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 21:42:14 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 21:42:14 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 21:42:14 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 21:42:14 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 21:42:14 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 21:42:14 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 21:42:14 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 21:42:14 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 21:42:14 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 21:42:14 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 21:42:14 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 21:42:14 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 21:42:14 | I | in layer model.layers.0
24-11-25 21:42:14 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 21:42:14 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 21:42:14 | I | - Evaluator: gptq
24-11-25 21:42:14 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 21:42:14 | I | - Batch_size: 8
24-11-25 21:42:14 | I |   + Max_seq_length: 2048
24-11-25 21:42:52 | I |     - Results:
24-11-25 21:42:52 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 21:42:52 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 21:42:52 | I |       |wikitext |      1|word_perplexity|7.7805|  |7.7805|
24-11-25 21:42:52 | I |       |val_valid|      1|word_perplexity|9.0334|  |9.0334|
24-11-25 21:42:52 | I |       
24-11-25 21:42:52 | I | quantizing weights for layer model.layers.0
24-11-25 21:42:52 | I | collecting info in model.layers.0
24-11-25 21:42:52 | I | collecting info in model.layers.0
24-11-25 21:42:52 | I | collecting info in model.layers.0
24-11-25 21:42:52 | I | collecting info in model.layers.0
24-11-25 21:42:52 | I | collecting calibration activations in model.layers.0
24-11-25 21:42:53 | I | collecting calibration activations in model.layers.0
24-11-25 21:42:53 | I | collecting calibration activations in model.layers.0
24-11-25 21:42:53 | I | collecting calibration activations in model.layers.0
24-11-25 21:42:53 | I | - Quantizing decoder layer model.layers.0
24-11-25 21:42:53 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 21:42:54 | I |       - range scale = [    1.0000]
24-11-25 21:42:54 | I |         sum  error  = [    0.0684]
24-11-25 21:42:54 | I |         best error  = [    0.0684]
24-11-25 21:42:54 | I |     + error = [0.0684]
24-11-25 21:42:54 | I |       - range scale = [    1.0000]
24-11-25 21:42:54 | I |         sum  error  = [    0.6087]
24-11-25 21:42:54 | I |         best error  = [    0.6087]
24-11-25 21:42:54 | I |     + error = [0.6087]
24-11-25 21:42:55 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 21:42:55 | I |       - range scale = [    1.0000]
24-11-25 21:42:55 | I |         sum  error  = [    0.0550]
24-11-25 21:42:55 | I |         best error  = [    0.0550]
24-11-25 21:42:55 | I |     + error = [0.0550]
24-11-25 21:42:56 | I |       - range scale = [    1.0000]
24-11-25 21:42:56 | I |         sum  error  = [    0.5372]
24-11-25 21:42:56 | I |         best error  = [    0.5372]
24-11-25 21:42:56 | I |     + error = [0.5372]
24-11-25 21:42:56 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 21:42:57 | I |       - range scale = [    1.0000]
24-11-25 21:42:57 | I |         sum  error  = [    0.2439]
24-11-25 21:42:57 | I |         best error  = [    0.2439]
24-11-25 21:42:57 | I |     + error = [0.2439]
24-11-25 21:42:58 | I |       - range scale = [    1.0000]
24-11-25 21:42:58 | I |         sum  error  = [    1.8287]
24-11-25 21:42:58 | I |         best error  = [    1.8287]
24-11-25 21:42:58 | I |     + error = [1.8287]
24-11-25 21:42:58 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 21:42:58 | I |       - range scale = [    1.0000]
24-11-25 21:42:58 | I |         sum  error  = [    0.0602]
24-11-25 21:42:58 | I |         best error  = [    0.0602]
24-11-25 21:42:58 | I |     + error = [0.0602]
24-11-25 21:42:59 | I |       - range scale = [    1.0000]
24-11-25 21:42:59 | I |         sum  error  = [    0.5694]
24-11-25 21:42:59 | I |         best error  = [    0.5694]
24-11-25 21:42:59 | I |     + error = [0.5694]
24-11-25 21:42:59 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 21:43:00 | I |       - range scale = [    1.0000]
24-11-25 21:43:00 | I |         sum  error  = [    1.0299]
24-11-25 21:43:00 | I |         best error  = [    1.0299]
24-11-25 21:43:00 | I |     + error = [1.0299]
24-11-25 21:43:01 | I |       - range scale = [    1.0000]
24-11-25 21:43:01 | I |         sum  error  = [   11.4096]
24-11-25 21:43:01 | I |         best error  = [   11.4096]
24-11-25 21:43:01 | I |     + error = [11.4096]
24-11-25 21:43:01 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 21:43:02 | I |       - range scale = [    1.0000]
24-11-25 21:43:02 | I |         sum  error  = [    1.1919]
24-11-25 21:43:02 | I |         best error  = [    1.1919]
24-11-25 21:43:02 | I |     + error = [1.1919]
24-11-25 21:43:02 | I |       - range scale = [    1.0000]
24-11-25 21:43:02 | I |         sum  error  = [   11.7696]
24-11-25 21:43:02 | I |         best error  = [   11.7696]
24-11-25 21:43:02 | I |     + error = [11.7696]
24-11-25 21:43:03 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 21:43:03 | I |       - range scale = [    1.0000]
24-11-25 21:43:03 | I |         sum  error  = [    3.1808]
24-11-25 21:43:03 | I |         best error  = [    3.1808]
24-11-25 21:43:03 | I |     + error = [3.1808]
24-11-25 21:43:04 | I |       - range scale = [    1.0000]
24-11-25 21:43:04 | I |         sum  error  = [   18.3414]
24-11-25 21:43:04 | I |         best error  = [   18.3414]
24-11-25 21:43:04 | I |     + error = [18.3414]
24-11-25 21:43:04 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 21:43:06 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 21:43:07 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 21:43:09 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 21:43:10 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 21:43:11 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 21:43:13 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 21:43:16 | I | quantizing activations for layer model.layers.0
24-11-25 21:43:16 | I | collecting info in model.layers.0
24-11-25 21:43:16 | I | collecting info in model.layers.0
24-11-25 21:43:16 | I | collecting info in model.layers.0
24-11-25 21:43:16 | I | collecting info in model.layers.0
24-11-25 21:43:17 | I | collecting calibration activations in model.layers.0
24-11-25 21:43:17 | I | collecting calibration activations in model.layers.0
24-11-25 21:43:17 | I | collecting calibration activations in model.layers.0
24-11-25 21:43:17 | I | collecting calibration activations in model.layers.0
24-11-25 21:43:19 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 21:43:19 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 21:43:19 | I | - Evaluator: gptq
24-11-25 21:43:19 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 21:43:19 | I | - Batch_size: 8
24-11-25 21:43:19 | I |   + Max_seq_length: 2048
24-11-25 21:44:00 | I |     - Results:
24-11-25 21:44:00 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 21:44:00 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 21:44:00 | I |       |wikitext |      1|word_perplexity|7.8104|  |7.8104|
24-11-25 21:44:00 | I |       |val_valid|      1|word_perplexity|9.0979|  |9.0979|
24-11-25 21:44:00 | I |       
24-11-25 21:44:00 | I | forward this layer
24-11-25 21:44:00 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/19.pt
24-11-25 21:44:00 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/19.pt
24-11-25 21:44:00 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 21:44:00 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 21:44:00 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 21:44:00 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 21:44:00 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 21:44:00 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 21:44:00 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 21:44:00 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 21:44:00 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 21:44:00 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 21:44:00 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 21:44:00 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 21:44:00 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 21:44:00 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 21:44:00 | I | [98] done with optimizer step
24-11-25 21:44:00 | I | epoch 001:     10 / 409600000 loss=0.000108515, loss_per_token=0.222239, loss_sum=7282.33, wps=153.3, ups=0, wpb=32768, bsz=64, num_updates=99, lr=0.000149975, gnorm=16.371, clip=100, loss_scale=0.0078, train_wall=213, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=24371, lmquant_ppl_result_wikitext_in_train_no_quant=7.78051, lmquant_ppl_result_val_in_train_no_quant=9.03341, lmquant_ppl_result_wikitext_in_train_with_quant=7.81036, lmquant_ppl_result_val_in_train_with_quant=9.09795
24-11-25 21:44:01 | I | TRAIN CURRENT LAYER_IDX = 0
24-11-25 21:44:01 | I | in layer model.layers.0
24-11-25 21:44:01 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 21:44:01 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 21:44:01 | I | - Evaluator: gptq
24-11-25 21:44:01 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 21:44:01 | I | - Batch_size: 8
24-11-25 21:44:01 | I |   + Max_seq_length: 2048
24-11-25 21:44:39 | I |     - Results:
24-11-25 21:44:39 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 21:44:39 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 21:44:39 | I |       |wikitext |      1|word_perplexity|7.7756|  |7.7756|
24-11-25 21:44:39 | I |       |val_valid|      1|word_perplexity|9.0290|  |9.0290|
24-11-25 21:44:39 | I |       
24-11-25 21:44:39 | I | quantizing weights for layer model.layers.0
24-11-25 21:44:39 | I | collecting info in model.layers.0
24-11-25 21:44:39 | I | collecting info in model.layers.0
24-11-25 21:44:39 | I | collecting info in model.layers.0
24-11-25 21:44:39 | I | collecting info in model.layers.0
24-11-25 21:44:39 | I | collecting calibration activations in model.layers.0
24-11-25 21:44:40 | I | collecting calibration activations in model.layers.0
24-11-25 21:44:40 | I | collecting calibration activations in model.layers.0
24-11-25 21:44:40 | I | collecting calibration activations in model.layers.0
24-11-25 21:44:40 | I | - Quantizing decoder layer model.layers.0
24-11-25 21:44:40 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 21:44:41 | I |       - range scale = [    1.0000]
24-11-25 21:44:41 | I |         sum  error  = [    0.0707]
24-11-25 21:44:41 | I |         best error  = [    0.0707]
24-11-25 21:44:41 | I |     + error = [0.0707]
24-11-25 21:44:41 | I |       - range scale = [    1.0000]
24-11-25 21:44:41 | I |         sum  error  = [    0.6434]
24-11-25 21:44:41 | I |         best error  = [    0.6434]
24-11-25 21:44:41 | I |     + error = [0.6434]
24-11-25 21:44:42 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 21:44:42 | I |       - range scale = [    1.0000]
24-11-25 21:44:42 | I |         sum  error  = [    0.0632]
24-11-25 21:44:42 | I |         best error  = [    0.0632]
24-11-25 21:44:42 | I |     + error = [0.0632]
24-11-25 21:44:43 | I |       - range scale = [    1.0000]
24-11-25 21:44:43 | I |         sum  error  = [    0.5751]
24-11-25 21:44:43 | I |         best error  = [    0.5751]
24-11-25 21:44:43 | I |     + error = [0.5751]
24-11-25 21:44:43 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 21:44:44 | I |       - range scale = [    1.0000]
24-11-25 21:44:44 | I |         sum  error  = [    0.2445]
24-11-25 21:44:44 | I |         best error  = [    0.2445]
24-11-25 21:44:44 | I |     + error = [0.2445]
24-11-25 21:44:45 | I |       - range scale = [    1.0000]
24-11-25 21:44:45 | I |         sum  error  = [    1.8612]
24-11-25 21:44:45 | I |         best error  = [    1.8612]
24-11-25 21:44:45 | I |     + error = [1.8612]
24-11-25 21:44:45 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 21:44:45 | I |       - range scale = [    1.0000]
24-11-25 21:44:45 | I |         sum  error  = [    0.0666]
24-11-25 21:44:45 | I |         best error  = [    0.0666]
24-11-25 21:44:45 | I |     + error = [0.0666]
24-11-25 21:44:46 | I |       - range scale = [    1.0000]
24-11-25 21:44:46 | I |         sum  error  = [    0.6333]
24-11-25 21:44:46 | I |         best error  = [    0.6333]
24-11-25 21:44:46 | I |     + error = [0.6333]
24-11-25 21:44:46 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 21:44:47 | I |       - range scale = [    1.0000]
24-11-25 21:44:47 | I |         sum  error  = [    1.0724]
24-11-25 21:44:47 | I |         best error  = [    1.0724]
24-11-25 21:44:47 | I |     + error = [1.0724]
24-11-25 21:44:48 | I |       - range scale = [    1.0000]
24-11-25 21:44:48 | I |         sum  error  = [   11.8658]
24-11-25 21:44:48 | I |         best error  = [   11.8658]
24-11-25 21:44:48 | I |     + error = [11.8658]
24-11-25 21:44:48 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 21:44:49 | I |       - range scale = [    1.0000]
24-11-25 21:44:49 | I |         sum  error  = [    1.2417]
24-11-25 21:44:49 | I |         best error  = [    1.2417]
24-11-25 21:44:49 | I |     + error = [1.2417]
24-11-25 21:44:49 | I |       - range scale = [    1.0000]
24-11-25 21:44:49 | I |         sum  error  = [   12.2521]
24-11-25 21:44:49 | I |         best error  = [   12.2521]
24-11-25 21:44:49 | I |     + error = [12.2521]
24-11-25 21:44:50 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 21:44:50 | I |       - range scale = [    1.0000]
24-11-25 21:44:50 | I |         sum  error  = [    3.8206]
24-11-25 21:44:50 | I |         best error  = [    3.8206]
24-11-25 21:44:50 | I |     + error = [3.8206]
24-11-25 21:44:51 | I |       - range scale = [    1.0000]
24-11-25 21:44:51 | I |         sum  error  = [   21.7426]
24-11-25 21:44:51 | I |         best error  = [   21.7426]
24-11-25 21:44:51 | I |     + error = [21.7426]
24-11-25 21:44:51 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 21:44:53 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 21:44:54 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 21:44:55 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 21:44:57 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 21:44:58 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 21:45:00 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 21:45:03 | I | quantizing activations for layer model.layers.0
24-11-25 21:45:03 | I | collecting info in model.layers.0
24-11-25 21:45:03 | I | collecting info in model.layers.0
24-11-25 21:45:03 | I | collecting info in model.layers.0
24-11-25 21:45:03 | I | collecting info in model.layers.0
24-11-25 21:45:03 | I | collecting calibration activations in model.layers.0
24-11-25 21:45:04 | I | collecting calibration activations in model.layers.0
24-11-25 21:45:04 | I | collecting calibration activations in model.layers.0
24-11-25 21:45:04 | I | collecting calibration activations in model.layers.0
24-11-25 21:45:06 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 21:45:06 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 21:45:06 | I | - Evaluator: gptq
24-11-25 21:45:06 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 21:45:06 | I | - Batch_size: 8
24-11-25 21:45:06 | I |   + Max_seq_length: 2048
24-11-25 21:45:47 | I |     - Results:
24-11-25 21:45:47 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 21:45:47 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 21:45:47 | I |       |wikitext |      1|word_perplexity|7.8034|  |7.8034|
24-11-25 21:45:47 | I |       |val_valid|      1|word_perplexity|9.0774|  |9.0774|
24-11-25 21:45:47 | I |       
24-11-25 21:45:47 | I | forward this layer
24-11-25 21:45:47 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/20.pt
24-11-25 21:45:47 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/20.pt
24-11-25 21:45:47 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 21:45:47 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 21:45:47 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 21:45:47 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 21:45:47 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 21:45:47 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 21:45:47 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 21:45:47 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 21:45:47 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 21:45:47 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 21:45:47 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 21:45:47 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 21:45:47 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 21:45:47 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 21:45:47 | I | in layer model.layers.0
24-11-25 21:45:47 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 21:45:47 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 21:45:47 | I | - Evaluator: gptq
24-11-25 21:45:47 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 21:45:47 | I | - Batch_size: 8
24-11-25 21:45:47 | I |   + Max_seq_length: 2048
24-11-25 21:46:26 | I |     - Results:
24-11-25 21:46:26 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 21:46:26 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 21:46:26 | I |       |wikitext |      1|word_perplexity|7.7756|  |7.7756|
24-11-25 21:46:26 | I |       |val_valid|      1|word_perplexity|9.0290|  |9.0290|
24-11-25 21:46:26 | I |       
24-11-25 21:46:26 | I | quantizing weights for layer model.layers.0
24-11-25 21:46:26 | I | collecting info in model.layers.0
24-11-25 21:46:26 | I | collecting info in model.layers.0
24-11-25 21:46:26 | I | collecting info in model.layers.0
24-11-25 21:46:26 | I | collecting info in model.layers.0
24-11-25 21:46:26 | I | collecting calibration activations in model.layers.0
24-11-25 21:46:26 | I | collecting calibration activations in model.layers.0
24-11-25 21:46:26 | I | collecting calibration activations in model.layers.0
24-11-25 21:46:26 | I | collecting calibration activations in model.layers.0
24-11-25 21:46:27 | I | - Quantizing decoder layer model.layers.0
24-11-25 21:46:27 | I |   - Calibrating model.layers.0.self_attn.q_proj.weight
24-11-25 21:46:27 | I |       - range scale = [    1.0000]
24-11-25 21:46:27 | I |         sum  error  = [    0.0718]
24-11-25 21:46:27 | I |         best error  = [    0.0718]
24-11-25 21:46:27 | I |     + error = [0.0718]
24-11-25 21:46:28 | I |       - range scale = [    1.0000]
24-11-25 21:46:28 | I |         sum  error  = [    0.6421]
24-11-25 21:46:28 | I |         best error  = [    0.6421]
24-11-25 21:46:28 | I |     + error = [0.6421]
24-11-25 21:46:28 | I |   - Calibrating model.layers.0.self_attn.k_proj.weight
24-11-25 21:46:29 | I |       - range scale = [    1.0000]
24-11-25 21:46:29 | I |         sum  error  = [    0.0641]
24-11-25 21:46:29 | I |         best error  = [    0.0641]
24-11-25 21:46:29 | I |     + error = [0.0641]
24-11-25 21:46:30 | I |       - range scale = [    1.0000]
24-11-25 21:46:30 | I |         sum  error  = [    0.5846]
24-11-25 21:46:30 | I |         best error  = [    0.5846]
24-11-25 21:46:30 | I |     + error = [0.5846]
24-11-25 21:46:30 | I |   - Calibrating model.layers.0.self_attn.v_proj.weight
24-11-25 21:46:31 | I |       - range scale = [    1.0000]
24-11-25 21:46:31 | I |         sum  error  = [    0.2469]
24-11-25 21:46:31 | I |         best error  = [    0.2469]
24-11-25 21:46:31 | I |     + error = [0.2469]
24-11-25 21:46:31 | I |       - range scale = [    1.0000]
24-11-25 21:46:31 | I |         sum  error  = [    1.8693]
24-11-25 21:46:31 | I |         best error  = [    1.8693]
24-11-25 21:46:31 | I |     + error = [1.8693]
24-11-25 21:46:32 | I |   - Calibrating model.layers.0.self_attn.o_proj.weight
24-11-25 21:46:32 | I |       - range scale = [    1.0000]
24-11-25 21:46:32 | I |         sum  error  = [    0.0654]
24-11-25 21:46:32 | I |         best error  = [    0.0654]
24-11-25 21:46:32 | I |     + error = [0.0654]
24-11-25 21:46:33 | I |       - range scale = [    1.0000]
24-11-25 21:46:33 | I |         sum  error  = [    0.6204]
24-11-25 21:46:33 | I |         best error  = [    0.6204]
24-11-25 21:46:33 | I |     + error = [0.6204]
24-11-25 21:46:33 | I |   - Calibrating model.layers.0.mlp.up_proj.weight
24-11-25 21:46:34 | I |       - range scale = [    1.0000]
24-11-25 21:46:34 | I |         sum  error  = [    1.0572]
24-11-25 21:46:34 | I |         best error  = [    1.0572]
24-11-25 21:46:34 | I |     + error = [1.0572]
24-11-25 21:46:35 | I |       - range scale = [    1.0000]
24-11-25 21:46:35 | I |         sum  error  = [   11.7011]
24-11-25 21:46:35 | I |         best error  = [   11.7011]
24-11-25 21:46:35 | I |     + error = [11.7011]
24-11-25 21:46:35 | I |   - Calibrating model.layers.0.mlp.gate_proj.weight
24-11-25 21:46:35 | I |       - range scale = [    1.0000]
24-11-25 21:46:35 | I |         sum  error  = [    1.2217]
24-11-25 21:46:35 | I |         best error  = [    1.2217]
24-11-25 21:46:35 | I |     + error = [1.2217]
24-11-25 21:46:36 | I |       - range scale = [    1.0000]
24-11-25 21:46:36 | I |         sum  error  = [   12.0760]
24-11-25 21:46:36 | I |         best error  = [   12.0760]
24-11-25 21:46:36 | I |     + error = [12.0760]
24-11-25 21:46:36 | I |   - Calibrating model.layers.0.mlp.down_proj.weight
24-11-25 21:46:37 | I |       - range scale = [    1.0000]
24-11-25 21:46:37 | I |         sum  error  = [    3.1084]
24-11-25 21:46:37 | I |         best error  = [    3.1084]
24-11-25 21:46:37 | I |     + error = [3.1084]
24-11-25 21:46:38 | I |       - range scale = [    1.0000]
24-11-25 21:46:38 | I |         sum  error  = [   17.7612]
24-11-25 21:46:38 | I |         best error  = [   17.7612]
24-11-25 21:46:38 | I |     + error = [17.7612]
24-11-25 21:46:38 | I |   - Quantizing model.layers.0.self_attn.q_proj.weight
24-11-25 21:46:39 | I |   - Quantizing model.layers.0.self_attn.k_proj.weight
24-11-25 21:46:41 | I |   - Quantizing model.layers.0.self_attn.v_proj.weight
24-11-25 21:46:42 | I |   - Quantizing model.layers.0.self_attn.o_proj.weight
24-11-25 21:46:44 | I |   - Quantizing model.layers.0.mlp.up_proj.weight
24-11-25 21:46:45 | I |   - Quantizing model.layers.0.mlp.gate_proj.weight
24-11-25 21:46:46 | I |   - Quantizing model.layers.0.mlp.down_proj.weight
24-11-25 21:46:50 | I | quantizing activations for layer model.layers.0
24-11-25 21:46:50 | I | collecting info in model.layers.0
24-11-25 21:46:50 | I | collecting info in model.layers.0
24-11-25 21:46:50 | I | collecting info in model.layers.0
24-11-25 21:46:50 | I | collecting info in model.layers.0
24-11-25 21:46:50 | I | collecting calibration activations in model.layers.0
24-11-25 21:46:50 | I | collecting calibration activations in model.layers.0
24-11-25 21:46:50 | I | collecting calibration activations in model.layers.0
24-11-25 21:46:51 | I | collecting calibration activations in model.layers.0
24-11-25 21:46:52 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 21:46:52 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 21:46:52 | I | - Evaluator: gptq
24-11-25 21:46:52 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 21:46:52 | I | - Batch_size: 8
24-11-25 21:46:52 | I |   + Max_seq_length: 2048
24-11-25 21:47:34 | I |     - Results:
24-11-25 21:47:34 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 21:47:34 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 21:47:34 | I |       |wikitext |      1|word_perplexity|7.8002|  |7.8002|
24-11-25 21:47:34 | I |       |val_valid|      1|word_perplexity|9.0844|  |9.0844|
24-11-25 21:47:34 | I |       
24-11-25 21:47:34 | I | forward this layer
24-11-25 21:47:34 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_0/21.pt
24-11-25 21:47:34 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_0/21.pt
24-11-25 21:47:34 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has nan: False
24-11-25 21:47:34 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.q_proj has inf: False
24-11-25 21:47:34 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has nan: False
24-11-25 21:47:34 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.k_proj has inf: False
24-11-25 21:47:34 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has nan: False
24-11-25 21:47:34 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.v_proj has inf: False
24-11-25 21:47:34 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has nan: False
24-11-25 21:47:34 | I | In layer model.layers.0, gradient of model.layers.0.self_attn.o_proj has inf: False
24-11-25 21:47:34 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has nan: False
24-11-25 21:47:34 | I | In layer model.layers.0, gradient of model.layers.0.mlp.up_proj has inf: False
24-11-25 21:47:34 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has nan: False
24-11-25 21:47:34 | I | In layer model.layers.0, gradient of model.layers.0.mlp.gate_proj has inf: False
24-11-25 21:47:34 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has nan: False
24-11-25 21:47:34 | I | In layer model.layers.0, gradient of model.layers.0.mlp.down_proj has inf: False
24-11-25 21:47:34 | I | [99] done with optimizer step
24-11-25 21:47:34 | I | epoch 001:     11 / 409600000 loss=0.000136146, loss_per_token=0.278828, loss_sum=9136.62, wps=153.3, ups=0, wpb=32768, bsz=64, num_updates=100, lr=0.000149975, gnorm=41.329, clip=100, loss_scale=0.0078, train_wall=213, cuda_gb_allocated=12.3, cuda_gb_reserved=13.8, cuda_gb_free=11.4, wall=24584, lmquant_ppl_result_wikitext_in_train_no_quant=7.77562, lmquant_ppl_result_val_in_train_no_quant=9.02901, lmquant_ppl_result_wikitext_in_train_with_quant=7.80024, lmquant_ppl_result_val_in_train_with_quant=9.08436
24-11-25 21:47:34 | I | Stopping training due to num_updates: 100 >= max_update: 100
24-11-25 21:47:34 | I | end of epoch 1 (average epoch stats below)
24-11-25 21:47:34 | I | epoch 001 | loss 9.72015e-05 | loss_per_token 0.199069 | loss_sum 6523.08 | wps 153.3 | ups 0 | wpb 32768 | bsz 64 | num_updates 100 | lr 0.000149975 | gnorm 28.101 | clip 100 | loss_scale 0.0078 | train_wall 2349 | cuda_gb_allocated 12.3 | cuda_gb_reserved 13.8 | cuda_gb_free 11.4 | wall 24584
24-11-25 21:47:34 | I | done training in 24339.2 seconds
24-11-25 21:47:34 | I | LlamaModelDecoderLayer(
  (decoder): LlamaDecoderLayerInFairseq(
    (model): LlamaDecoderLayer(
      (self_attn): LlamaSdpaAttention(
        (q_proj): Linear(in_features=2048, out_features=2048, bias=False)
        (k_proj): Linear(in_features=2048, out_features=256, bias=False)
        (v_proj): Linear(in_features=2048, out_features=256, bias=False)
        (o_proj): Linear(in_features=2048, out_features=2048, bias=False)
        (rotary_emb): LlamaRotaryEmbedding()
        (q_rotary_emb): RotaryEmbedding()
        (k_rotary_emb): RotaryEmbedding()
      )
      (mlp): LlamaMLP(
        (gate_proj): Linear(in_features=2048, out_features=5632, bias=False)
        (up_proj): Linear(in_features=2048, out_features=5632, bias=False)
        (down_proj): Linear(in_features=5632, out_features=2048, bias=False)
        (act_fn): SiLU()
      )
      (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)
      (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)
    )
  )
  (model): LlamaDecoderLayerInFairseq(
    (model): LlamaDecoderLayer(
      (self_attn): LlamaSdpaAttention(
        (q_proj): Linear(in_features=2048, out_features=2048, bias=False)
        (k_proj): Linear(in_features=2048, out_features=256, bias=False)
        (v_proj): Linear(in_features=2048, out_features=256, bias=False)
        (o_proj): Linear(in_features=2048, out_features=2048, bias=False)
        (rotary_emb): LlamaRotaryEmbedding()
        (q_rotary_emb): RotaryEmbedding()
        (k_rotary_emb): RotaryEmbedding()
      )
      (mlp): LlamaMLP(
        (gate_proj): Linear(in_features=2048, out_features=5632, bias=False)
        (up_proj): Linear(in_features=2048, out_features=5632, bias=False)
        (down_proj): Linear(in_features=5632, out_features=2048, bias=False)
        (act_fn): SiLU()
      )
      (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)
      (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)
    )
  )
)
24-11-25 21:47:34 | I | task: KDTask
24-11-25 21:47:34 | I | model: LlamaModelDecoderLayer
24-11-25 21:47:34 | I | criterion: CrossEntropyCriterion
24-11-25 21:47:34 | I | num. non-expert model params: 44,044,288 (num. trained: 44,044,288)
24-11-25 21:47:34 | I | num. expert model params: 0 (num. trained: 0)
24-11-25 21:47:34 | I | nvidia-smi stats: {'gpu_0_mem_used_gb': 0.0, 'gpu_1_mem_used_gb': 0.0, 'gpu_2_mem_used_gb': 0.001953125, 'gpu_3_mem_used_gb': 0.0, 'gpu_4_mem_used_gb': 0.0, 'gpu_5_mem_used_gb': 0.0, 'gpu_6_mem_used_gb': 14.23828125, 'gpu_7_mem_used_gb': 0.001953125}
24-11-25 21:47:34 | I | detected shared parameter: decoder.model.self_attn.q_proj.weight <- model.model.self_attn.q_proj.weight
24-11-25 21:47:34 | I | detected shared parameter: decoder.model.self_attn.q_proj.bias <- decoder.model.self_attn.k_proj.bias
24-11-25 21:47:34 | I | detected shared parameter: decoder.model.self_attn.q_proj.bias <- decoder.model.self_attn.v_proj.bias
24-11-25 21:47:34 | I | detected shared parameter: decoder.model.self_attn.q_proj.bias <- decoder.model.self_attn.o_proj.bias
24-11-25 21:47:34 | I | detected shared parameter: decoder.model.self_attn.q_proj.bias <- decoder.model.mlp.gate_proj.bias
24-11-25 21:47:34 | I | detected shared parameter: decoder.model.self_attn.q_proj.bias <- decoder.model.mlp.up_proj.bias
24-11-25 21:47:34 | I | detected shared parameter: decoder.model.self_attn.q_proj.bias <- decoder.model.mlp.down_proj.bias
24-11-25 21:47:34 | I | detected shared parameter: decoder.model.self_attn.q_proj.bias <- model.model.self_attn.q_proj.bias
24-11-25 21:47:34 | I | detected shared parameter: decoder.model.self_attn.q_proj.bias <- model.model.self_attn.k_proj.bias
24-11-25 21:47:34 | I | detected shared parameter: decoder.model.self_attn.q_proj.bias <- model.model.self_attn.v_proj.bias
24-11-25 21:47:34 | I | detected shared parameter: decoder.model.self_attn.q_proj.bias <- model.model.self_attn.o_proj.bias
24-11-25 21:47:34 | I | detected shared parameter: decoder.model.self_attn.q_proj.bias <- model.model.mlp.gate_proj.bias
24-11-25 21:47:34 | I | detected shared parameter: decoder.model.self_attn.q_proj.bias <- model.model.mlp.up_proj.bias
24-11-25 21:47:34 | I | detected shared parameter: decoder.model.self_attn.q_proj.bias <- model.model.mlp.down_proj.bias
24-11-25 21:47:34 | I | detected shared parameter: decoder.model.self_attn.k_proj.weight <- model.model.self_attn.k_proj.weight
24-11-25 21:47:34 | I | detected shared parameter: decoder.model.self_attn.v_proj.weight <- model.model.self_attn.v_proj.weight
24-11-25 21:47:34 | I | detected shared parameter: decoder.model.self_attn.o_proj.weight <- model.model.self_attn.o_proj.weight
24-11-25 21:47:34 | I | detected shared parameter: decoder.model.mlp.gate_proj.weight <- model.model.mlp.gate_proj.weight
24-11-25 21:47:34 | I | detected shared parameter: decoder.model.mlp.up_proj.weight <- model.model.mlp.up_proj.weight
24-11-25 21:47:34 | I | detected shared parameter: decoder.model.mlp.down_proj.weight <- model.model.mlp.down_proj.weight
24-11-25 21:47:34 | I | detected shared parameter: decoder.model.input_layernorm.weight <- model.model.input_layernorm.weight
24-11-25 21:47:34 | I | detected shared parameter: decoder.model.post_attention_layernorm.weight <- model.model.post_attention_layernorm.weight
24-11-25 21:47:34 | I | nvidia-smi stats: {'gpu_0_mem_used_gb': 0.0, 'gpu_1_mem_used_gb': 0.0, 'gpu_2_mem_used_gb': 0.001953125, 'gpu_3_mem_used_gb': 0.0, 'gpu_4_mem_used_gb': 0.0, 'gpu_5_mem_used_gb': 0.0, 'gpu_6_mem_used_gb': 14.23828125, 'gpu_7_mem_used_gb': 0.001953125}
24-11-25 21:47:34 | I | ***********************CUDA enviroments for all 1 workers***********************
24-11-25 21:47:34 | I | rank   0: capabilities =  8.6  ; total memory = 23.691 GB ; name = NVIDIA GeForce RTX 3090                 
24-11-25 21:47:34 | I | ***********************CUDA enviroments for all 1 workers***********************
24-11-25 21:47:34 | I | training on 1 devices (GPUs/TPUs)
24-11-25 21:47:34 | I | max tokens per GPU = None and batch size per GPU = 32
24-11-25 21:47:34 | I | nvidia-smi stats: {'gpu_0_mem_used_gb': 0.0, 'gpu_1_mem_used_gb': 0.0, 'gpu_2_mem_used_gb': 0.001953125, 'gpu_3_mem_used_gb': 0.0, 'gpu_4_mem_used_gb': 0.0, 'gpu_5_mem_used_gb': 0.0, 'gpu_6_mem_used_gb': 14.23828125, 'gpu_7_mem_used_gb': 0.001953125}
24-11-25 21:47:34 | I | loading train data for epoch 1
24-11-25 21:47:36 | I | *** 
 now in /data/gyy/YOCO/data_without_preprocess/shard/val/0.jsonl 
 ***
24-11-25 21:47:36 | I | *** 
 total_rows = 700 
 ***
24-11-25 21:47:36 | I | current row num = 0
24-11-25 21:47:36 | I | in forward_and_gen_teacher_outputs, Start iterating over samples
24-11-25 21:47:36 | I | current row num = 32
24-11-25 21:47:36 | I | current row num = 64
24-11-25 21:47:37 | I | current row num = 96
24-11-25 21:47:37 | I | current row num = 128
24-11-25 21:47:38 | I | current row num = 160
24-11-25 21:47:39 | I | current row num = 192
24-11-25 21:47:40 | I | current row num = 224
24-11-25 21:47:40 | I | current row num = 256
24-11-25 21:47:41 | I | current row num = 288
24-11-25 21:47:42 | I | current row num = 320
24-11-25 21:47:43 | I | current row num = 352
24-11-25 21:47:43 | I | current row num = 384
24-11-25 21:47:44 | I | current row num = 416
24-11-25 21:47:45 | I | current row num = 448
24-11-25 21:47:46 | I | current row num = 480
24-11-25 21:47:46 | I | current row num = 512
24-11-25 21:47:47 | I | current row num = 544
24-11-25 21:47:48 | I | current row num = 576
24-11-25 21:47:49 | I | current row num = 608
24-11-25 21:47:49 | I | current row num = 640
24-11-25 21:47:51 | I | *** 
 now in /data/gyy/YOCO/data_without_preprocess/shard/val/1.jsonl 
 ***
24-11-25 21:47:51 | I | *** 
 total_rows = 241 
 ***
24-11-25 21:47:51 | I | current row num = 0
24-11-25 21:47:51 | I | current row num = 32
24-11-25 21:47:52 | I | current row num = 64
24-11-25 21:47:53 | I | current row num = 96
24-11-25 21:47:53 | I | current row num = 128
24-11-25 21:47:54 | I | current row num = 160
24-11-25 21:47:55 | I | current row num = 192
24-11-25 21:47:56 | I | current row num = 224
24-11-25 21:47:57 | I | *** 
 now in /data/gyy/YOCO/data_without_preprocess/shard/val/2.jsonl 
 ***
24-11-25 21:47:57 | I | *** 
 total_rows = 509 
 ***
24-11-25 21:47:57 | I | current row num = 0
24-11-25 21:47:57 | I | current row num = 32
24-11-25 21:47:58 | I | current row num = 64
24-11-25 21:47:59 | I | current row num = 96
24-11-25 21:48:00 | I | current row num = 128
24-11-25 21:48:00 | I | current row num = 160
24-11-25 21:48:01 | I | current row num = 192
24-11-25 21:48:02 | I | current row num = 224
24-11-25 21:48:03 | I | current row num = 256
24-11-25 21:48:03 | I | current row num = 288
24-11-25 21:48:04 | I | current row num = 320
24-11-25 21:48:05 | I | current row num = 352
24-11-25 21:48:06 | I | current row num = 384
24-11-25 21:48:07 | I | current row num = 416
24-11-25 21:48:07 | I | current row num = 448
24-11-25 21:48:08 | I | current row num = 480
24-11-25 21:48:09 | I | *** 
 now in /data/gyy/YOCO/data_without_preprocess/shard/val/3.jsonl 
 ***
24-11-25 21:48:09 | I | *** 
 total_rows = 274 
 ***
24-11-25 21:48:09 | I | current row num = 0
24-11-25 21:48:10 | I | current row num = 32
24-11-25 21:48:10 | I | current row num = 64
24-11-25 21:48:11 | I | current row num = 96
24-11-25 21:48:14 | I | current row num = 128
24-11-25 21:48:16 | I | current row num = 160
24-11-25 21:48:19 | I | current row num = 192
24-11-25 21:48:20 | I | current row num = 224
24-11-25 21:48:21 | I | *** 
 now in /data/gyy/YOCO/data_without_preprocess/shard/val/4.jsonl 
 ***
24-11-25 21:48:21 | I | *** 
 total_rows = 191 
 ***
24-11-25 21:48:21 | I | current row num = 0
24-11-25 21:48:21 | I | current row num = 32
24-11-25 21:48:22 | I | current row num = 64
24-11-25 21:48:23 | I | current row num = 96
24-11-25 21:48:23 | I | current row num = 128
24-11-25 21:48:24 | I | current row num = 160
24-11-25 21:48:26 | I | *** 
 now in /data/gyy/YOCO/data_without_preprocess/shard/val/5.jsonl 
 ***
24-11-25 21:48:26 | I | *** 
 total_rows = 211 
 ***
24-11-25 21:48:26 | I | current row num = 0
24-11-25 21:48:28 | I | current row num = 32
24-11-25 21:48:29 | I | current row num = 64
24-11-25 21:48:31 | I | current row num = 96
24-11-25 21:48:34 | I | current row num = 128
24-11-25 21:48:34 | I | current row num = 160
24-11-25 21:48:35 | I | current row num = 192
24-11-25 21:48:36 | I | *** 
 now in /data/gyy/YOCO/data_without_preprocess/shard/val/6.jsonl 
 ***
24-11-25 21:48:36 | I | *** 
 total_rows = 241 
 ***
24-11-25 21:48:36 | I | current row num = 0
24-11-25 21:48:37 | I | current row num = 32
24-11-25 21:48:37 | I | current row num = 64
24-11-25 21:48:38 | I | current row num = 96
24-11-25 21:48:41 | I | current row num = 128
24-11-25 21:48:43 | I | current row num = 160
24-11-25 21:48:44 | I | current row num = 192
24-11-25 21:48:46 | I | *** 
 now in /data/gyy/YOCO/data_without_preprocess/shard/val/7.jsonl 
 ***
24-11-25 21:48:46 | I | *** 
 total_rows = 279 
 ***
24-11-25 21:48:46 | I | current row num = 0
24-11-25 21:48:46 | I | current row num = 32
24-11-25 21:48:47 | I | current row num = 64
24-11-25 21:48:47 | I | current row num = 96
24-11-25 21:48:48 | I | current row num = 128
24-11-25 21:48:49 | I | current row num = 160
24-11-25 21:48:50 | I | current row num = 192
24-11-25 21:48:50 | I | current row num = 224
24-11-25 21:48:51 | I | current row num = 256
24-11-25 21:48:52 | I | *** 
 now in /data/gyy/YOCO/data_without_preprocess/shard/val/8.jsonl 
 ***
24-11-25 21:48:52 | I | *** 
 total_rows = 186 
 ***
24-11-25 21:48:52 | I | current row num = 0
24-11-25 21:48:53 | I | current row num = 32
24-11-25 21:48:53 | I | current row num = 64
24-11-25 21:48:56 | I | current row num = 96
24-11-25 21:48:58 | I | current row num = 128
24-11-25 21:48:59 | I | current row num = 160
24-11-25 21:49:01 | I | *** 
 now in /data/gyy/YOCO/data_without_preprocess/shard/val/9.jsonl 
 ***
24-11-25 21:49:01 | I | *** 
 total_rows = 770 
 ***
24-11-25 21:49:01 | I | current row num = 0
24-11-25 21:49:02 | I | current row num = 32
24-11-25 21:49:02 | I | current row num = 64
24-11-25 21:49:03 | I | current row num = 96
24-11-25 21:49:04 | I | current row num = 128
24-11-25 21:49:05 | I | current row num = 160
24-11-25 21:49:05 | I | current row num = 192
24-11-25 21:49:06 | I | current row num = 224
24-11-25 21:49:07 | I | current row num = 256
24-11-25 21:49:08 | I | current row num = 288
24-11-25 21:49:10 | I | current row num = 320
24-11-25 21:49:11 | I | current row num = 352
24-11-25 21:49:12 | I | current row num = 384
24-11-25 21:49:12 | I | current row num = 416
24-11-25 21:49:13 | I | current row num = 448
24-11-25 21:49:14 | I | current row num = 480
24-11-25 21:49:15 | I | current row num = 512
24-11-25 21:49:15 | I | current row num = 544
24-11-25 21:49:16 | I | current row num = 576
24-11-25 21:49:17 | I | current row num = 608
24-11-25 21:49:18 | I | current row num = 640
24-11-25 21:49:19 | I | current row num = 672
24-11-25 21:49:19 | I | current row num = 704
24-11-25 21:49:20 | I | current row num = 736
24-11-25 21:49:21 | I | *** 
 now in /data/gyy/YOCO/data_without_preprocess/shard/val/10.jsonl 
 ***
24-11-25 21:49:21 | I | *** 
 total_rows = 271 
 ***
24-11-25 21:49:21 | I | current row num = 0
24-11-25 21:49:22 | I | current row num = 32
24-11-25 21:49:22 | I | current row num = 64
24-11-25 21:49:25 | I | current row num = 96
24-11-25 21:49:27 | I | current row num = 128
24-11-25 21:49:28 | I | current row num = 160
24-11-25 21:49:29 | I | current row num = 192
24-11-25 21:49:29 | I | current row num = 224
24-11-25 21:49:30 | I | current row num = 256
24-11-25 21:49:31 | I | *** 
 now in /data/gyy/YOCO/data_without_preprocess/shard/val/11.jsonl 
 ***
24-11-25 21:49:31 | I | *** 
 total_rows = 273 
 ***
24-11-25 21:49:31 | I | current row num = 0
24-11-25 21:49:32 | I | current row num = 32
24-11-25 21:49:34 | I | current row num = 64
24-11-25 21:49:35 | I | current row num = 96
24-11-25 21:49:36 | I | current row num = 128
24-11-25 21:49:36 | I | current row num = 160
24-11-25 21:49:37 | I | current row num = 192
24-11-25 21:49:38 | I | current row num = 224
24-11-25 21:49:39 | I | *** 
 now in /data/gyy/YOCO/data_without_preprocess/shard/val/12.jsonl 
 ***
24-11-25 21:49:39 | I | *** 
 total_rows = 301 
 ***
24-11-25 21:49:39 | I | current row num = 0
24-11-25 21:49:40 | I | current row num = 32
24-11-25 21:49:40 | I | current row num = 64
24-11-25 21:49:41 | I | current row num = 96
24-11-25 21:49:44 | I | current row num = 128
24-11-25 21:49:46 | I | current row num = 160
24-11-25 21:49:46 | I | current row num = 192
24-11-25 21:49:47 | I | current row num = 224
24-11-25 21:49:48 | I | current row num = 256
24-11-25 21:49:49 | I | *** 
 now in /data/gyy/YOCO/data_without_preprocess/shard/val/13.jsonl 
 ***
24-11-25 21:49:49 | I | *** 
 total_rows = 239 
 ***
24-11-25 21:49:49 | I | current row num = 0
24-11-25 21:49:49 | I | current row num = 32
24-11-25 21:49:50 | I | current row num = 64
24-11-25 21:49:51 | I | current row num = 96
24-11-25 21:49:53 | I | current row num = 128
24-11-25 21:49:56 | I | current row num = 160
24-11-25 21:49:57 | I | current row num = 192
24-11-25 21:49:57 | I | current row num = 224
24-11-25 21:49:59 | I | *** 
 now in /data/gyy/YOCO/data_without_preprocess/shard/val/14.jsonl 
 ***
24-11-25 21:49:59 | I | *** 
 total_rows = 262 
 ***
24-11-25 21:49:59 | I | current row num = 0
24-11-25 21:49:59 | I | current row num = 32
24-11-25 21:50:00 | I | current row num = 64
24-11-25 21:50:00 | I | current row num = 96
24-11-25 21:50:02 | I | current row num = 128
24-11-25 21:50:03 | I | current row num = 160
24-11-25 21:50:03 | I | current row num = 192
24-11-25 21:50:04 | I | current row num = 224
24-11-25 21:50:06 | I | *** 
 now in /data/gyy/YOCO/data_without_preprocess/shard/val/15.jsonl 
 ***
24-11-25 21:50:06 | I | *** 
 total_rows = 253 
 ***
24-11-25 21:50:06 | I | current row num = 0
24-11-25 21:50:06 | I | current row num = 32
24-11-25 21:50:07 | I | current row num = 64
24-11-25 21:50:07 | I | current row num = 96
24-11-25 21:50:08 | I | current row num = 128
24-11-25 21:50:09 | I | current row num = 160
24-11-25 21:50:11 | I | current row num = 192
24-11-25 21:50:12 | I | current row num = 224
24-11-25 21:50:14 | I | *** 
 now in /data/gyy/YOCO/data_without_preprocess/shard/val/16.jsonl 
 ***
24-11-25 21:50:14 | I | *** 
 total_rows = 523 
 ***
24-11-25 21:50:14 | I | current row num = 0
24-11-25 21:50:14 | I | current row num = 32
24-11-25 21:50:15 | I | current row num = 64
24-11-25 21:50:16 | I | current row num = 96
24-11-25 21:50:16 | I | current row num = 128
24-11-25 21:50:17 | I | current row num = 160
24-11-25 21:50:18 | I | current row num = 192
24-11-25 21:50:19 | I | current row num = 224
24-11-25 21:50:21 | I | current row num = 256
24-11-25 21:50:23 | I | current row num = 288
24-11-25 21:50:23 | I | current row num = 320
24-11-25 21:50:24 | I | current row num = 352
24-11-25 21:50:25 | I | current row num = 384
24-11-25 21:50:26 | I | current row num = 416
24-11-25 21:50:26 | I | current row num = 448
24-11-25 21:50:28 | I | current row num = 480
24-11-25 21:50:29 | I | *** 
 now in /data/gyy/YOCO/data_without_preprocess/shard/val/17.jsonl 
 ***
24-11-25 21:50:29 | I | *** 
 total_rows = 251 
 ***
24-11-25 21:50:29 | I | current row num = 0
24-11-25 21:50:29 | I | current row num = 32
24-11-25 21:50:30 | I | current row num = 64
24-11-25 21:50:31 | I | current row num = 96
24-11-25 21:50:31 | I | current row num = 128
24-11-25 21:50:32 | I | current row num = 160
24-11-25 21:50:35 | I | current row num = 192
24-11-25 21:50:36 | I | current row num = 224
24-11-25 21:50:37 | I | *** 
 now in /data/gyy/YOCO/data_without_preprocess/shard/val/18.jsonl 
 ***
24-11-25 21:50:37 | I | *** 
 total_rows = 274 
 ***
24-11-25 21:50:37 | I | current row num = 0
24-11-25 21:50:39 | I | current row num = 32
24-11-25 21:50:40 | I | current row num = 64
24-11-25 21:50:40 | I | current row num = 96
24-11-25 21:50:41 | I | current row num = 128
24-11-25 21:50:42 | I | current row num = 160
24-11-25 21:50:43 | I | current row num = 192
24-11-25 21:50:43 | I | current row num = 224
24-11-25 21:50:46 | I | current row num = 256
24-11-25 21:50:48 | I | *** 
 now in /data/gyy/YOCO/data_without_preprocess/shard/val/19.jsonl 
 ***
24-11-25 21:50:48 | I | *** 
 total_rows = 315 
 ***
24-11-25 21:50:48 | I | current row num = 0
24-11-25 21:50:48 | I | current row num = 32
24-11-25 21:50:49 | I | current row num = 64
24-11-25 21:50:49 | I | current row num = 96
24-11-25 21:50:50 | I | current row num = 128
24-11-25 21:50:51 | I | current row num = 160
24-11-25 21:50:53 | I | current row num = 192
24-11-25 21:50:54 | I | current row num = 224
24-11-25 21:50:55 | I | current row num = 256
24-11-25 21:50:56 | I | current row num = 288
24-11-25 21:50:57 | I | current row num = 320
24-11-25 21:50:58 | I | loading train data for epoch 1
24-11-25 21:50:59 | I | *** 
 now in /data/gyy/YOCO/data_without_preprocess/shard/val/0.jsonl 
 ***
24-11-25 21:50:59 | I | *** 
 total_rows = 700 
 ***
24-11-25 21:50:59 | I | current row num = 0
24-11-25 21:50:59 | I | in forward_and_gen_args_and_kwargs, Start iterating over samples
24-11-25 21:50:59 | I | quantize weights when generating student args and kwargs
24-11-25 21:51:01 | W | Repo card metadata block was not found. Setting CardData to empty.
24-11-25 21:51:18 | I |       - range scale = [    1.0000]
24-11-25 21:51:18 | I |         sum  error  = [    0.1867]
24-11-25 21:51:18 | I |         best error  = [    0.1867]
24-11-25 21:51:18 | I |     + error = [0.1867]
24-11-25 21:51:19 | I |       - range scale = [    1.0000]
24-11-25 21:51:19 | I |         sum  error  = [    1.6803]
24-11-25 21:51:19 | I |         best error  = [    1.6803]
24-11-25 21:51:19 | I |     + error = [1.6803]
24-11-25 21:51:21 | I |       - range scale = [    1.0000]
24-11-25 21:51:21 | I |         sum  error  = [    0.1752]
24-11-25 21:51:21 | I |         best error  = [    0.1752]
24-11-25 21:51:21 | I |     + error = [0.1752]
24-11-25 21:51:22 | I |       - range scale = [    1.0000]
24-11-25 21:51:22 | I |         sum  error  = [    1.6061]
24-11-25 21:51:22 | I |         best error  = [    1.6061]
24-11-25 21:51:22 | I |     + error = [1.6061]
24-11-25 21:51:23 | I |       - range scale = [    1.0000]
24-11-25 21:51:23 | I |         sum  error  = [    0.2434]
24-11-25 21:51:23 | I |         best error  = [    0.2434]
24-11-25 21:51:23 | I |     + error = [0.2434]
24-11-25 21:51:23 | I |       - range scale = [    1.0000]
24-11-25 21:51:23 | I |         sum  error  = [    1.8157]
24-11-25 21:51:23 | I |         best error  = [    1.8157]
24-11-25 21:51:23 | I |     + error = [1.8157]
24-11-25 21:51:24 | I |       - range scale = [    1.0000]
24-11-25 21:51:24 | I |         sum  error  = [    0.0643]
24-11-25 21:51:24 | I |         best error  = [    0.0643]
24-11-25 21:51:24 | I |     + error = [0.0643]
24-11-25 21:51:25 | I |       - range scale = [    1.0000]
24-11-25 21:51:25 | I |         sum  error  = [    0.6052]
24-11-25 21:51:25 | I |         best error  = [    0.6052]
24-11-25 21:51:25 | I |     + error = [0.6052]
24-11-25 21:51:26 | I |       - range scale = [    1.0000]
24-11-25 21:51:26 | I |         sum  error  = [    1.0879]
24-11-25 21:51:26 | I |         best error  = [    1.0879]
24-11-25 21:51:26 | I |     + error = [1.0879]
24-11-25 21:51:27 | I |       - range scale = [    1.0000]
24-11-25 21:51:27 | I |         sum  error  = [   12.0185]
24-11-25 21:51:27 | I |         best error  = [   12.0185]
24-11-25 21:51:27 | I |     + error = [12.0185]
24-11-25 21:51:27 | I |       - range scale = [    1.0000]
24-11-25 21:51:27 | I |         sum  error  = [    1.2514]
24-11-25 21:51:27 | I |         best error  = [    1.2514]
24-11-25 21:51:27 | I |     + error = [1.2514]
24-11-25 21:51:28 | I |       - range scale = [    1.0000]
24-11-25 21:51:29 | I |         sum  error  = [   12.4319]
24-11-25 21:51:29 | I |         best error  = [   12.4319]
24-11-25 21:51:29 | I |     + error = [12.4319]
24-11-25 21:51:30 | I |       - range scale = [    1.0000]
24-11-25 21:51:30 | I |         sum  error  = [    3.7527]
24-11-25 21:51:30 | I |         best error  = [    3.7527]
24-11-25 21:51:30 | I |     + error = [3.7527]
24-11-25 21:51:31 | I |       - range scale = [    1.0000]
24-11-25 21:51:31 | I |         sum  error  = [   21.4311]
24-11-25 21:51:31 | I |         best error  = [   21.4311]
24-11-25 21:51:31 | I |     + error = [21.4311]
24-11-25 21:51:49 | I |       - range scale = [    1.0000]
24-11-25 21:51:49 | I |         sum  error  = [    0.5811]
24-11-25 21:51:49 | I |         best error  = [    0.5811]
24-11-25 21:51:49 | I |     + error = [0.5811]
24-11-25 21:51:50 | I |       - range scale = [    1.0000]
24-11-25 21:51:50 | I |         sum  error  = [    6.5220]
24-11-25 21:51:50 | I |         best error  = [    6.5220]
24-11-25 21:51:50 | I |     + error = [6.5220]
24-11-25 21:51:52 | I |       - range scale = [    1.0000]
24-11-25 21:51:52 | I |         sum  error  = [    0.3210]
24-11-25 21:51:52 | I |         best error  = [    0.3210]
24-11-25 21:51:52 | I |     + error = [0.3210]
24-11-25 21:51:52 | I |       - range scale = [    1.0000]
24-11-25 21:51:52 | I |         sum  error  = [    3.5498]
24-11-25 21:51:52 | I |         best error  = [    3.5498]
24-11-25 21:51:52 | I |     + error = [3.5498]
24-11-25 21:51:53 | I |       - range scale = [    1.0000]
24-11-25 21:51:53 | I |         sum  error  = [    0.3753]
24-11-25 21:51:53 | I |         best error  = [    0.3753]
24-11-25 21:51:53 | I |     + error = [0.3753]
24-11-25 21:51:54 | I |       - range scale = [    1.0000]
24-11-25 21:51:54 | I |         sum  error  = [    4.0504]
24-11-25 21:51:54 | I |         best error  = [    4.0504]
24-11-25 21:51:54 | I |     + error = [4.0504]
24-11-25 21:51:55 | I |       - range scale = [    1.0000]
24-11-25 21:51:55 | I |         sum  error  = [    0.0841]
24-11-25 21:51:55 | I |         best error  = [    0.0841]
24-11-25 21:51:55 | I |     + error = [0.0841]
24-11-25 21:51:56 | I |       - range scale = [    1.0000]
24-11-25 21:51:56 | I |         sum  error  = [    0.8080]
24-11-25 21:51:56 | I |         best error  = [    0.8080]
24-11-25 21:51:56 | I |     + error = [0.8080]
24-11-25 21:51:57 | I |       - range scale = [    1.0000]
24-11-25 21:51:57 | I |         sum  error  = [    1.4346]
24-11-25 21:51:57 | I |         best error  = [    1.4346]
24-11-25 21:51:57 | I |     + error = [1.4346]
24-11-25 21:51:58 | I |       - range scale = [    1.0000]
24-11-25 21:51:58 | I |         sum  error  = [   15.8885]
24-11-25 21:51:58 | I |         best error  = [   15.8885]
24-11-25 21:51:58 | I |     + error = [15.8885]
24-11-25 21:51:58 | I |       - range scale = [    1.0000]
24-11-25 21:51:58 | I |         sum  error  = [    1.5141]
24-11-25 21:51:58 | I |         best error  = [    1.5141]
24-11-25 21:51:58 | I |     + error = [1.5141]
24-11-25 21:51:59 | I |       - range scale = [    1.0000]
24-11-25 21:51:59 | I |         sum  error  = [   16.6732]
24-11-25 21:51:59 | I |         best error  = [   16.6732]
24-11-25 21:51:59 | I |     + error = [16.6732]
24-11-25 21:52:00 | I |       - range scale = [    1.0000]
24-11-25 21:52:00 | I |         sum  error  = [    0.6553]
24-11-25 21:52:00 | I |         best error  = [    0.6553]
24-11-25 21:52:00 | I |     + error = [0.6553]
24-11-25 21:52:01 | I |       - range scale = [    1.0000]
24-11-25 21:52:01 | I |         sum  error  = [    6.1562]
24-11-25 21:52:01 | I |         best error  = [    6.1562]
24-11-25 21:52:01 | I |     + error = [6.1562]
24-11-25 21:52:20 | I |       - range scale = [    1.0000]
24-11-25 21:52:20 | I |         sum  error  = [    1.3479]
24-11-25 21:52:20 | I |         best error  = [    1.3479]
24-11-25 21:52:20 | I |     + error = [1.3479]
24-11-25 21:52:21 | I |       - range scale = [    1.0000]
24-11-25 21:52:21 | I |         sum  error  = [   11.8809]
24-11-25 21:52:21 | I |         best error  = [   11.8809]
24-11-25 21:52:21 | I |     + error = [11.8809]
24-11-25 21:52:22 | I |       - range scale = [    1.0000]
24-11-25 21:52:22 | I |         sum  error  = [    0.6238]
24-11-25 21:52:22 | I |         best error  = [    0.6238]
24-11-25 21:52:22 | I |     + error = [0.6238]
24-11-25 21:52:23 | I |       - range scale = [    1.0000]
24-11-25 21:52:23 | I |         sum  error  = [    6.3572]
24-11-25 21:52:23 | I |         best error  = [    6.3572]
24-11-25 21:52:23 | I |     + error = [6.3572]
24-11-25 21:52:24 | I |       - range scale = [    1.0000]
24-11-25 21:52:24 | I |         sum  error  = [    0.5138]
24-11-25 21:52:24 | I |         best error  = [    0.5138]
24-11-25 21:52:24 | I |     + error = [0.5138]
24-11-25 21:52:25 | I |       - range scale = [    1.0000]
24-11-25 21:52:25 | I |         sum  error  = [    5.8770]
24-11-25 21:52:25 | I |         best error  = [    5.8770]
24-11-25 21:52:25 | I |     + error = [5.8770]
24-11-25 21:52:26 | I |       - range scale = [    1.0000]
24-11-25 21:52:26 | I |         sum  error  = [    0.0885]
24-11-25 21:52:26 | I |         best error  = [    0.0885]
24-11-25 21:52:26 | I |     + error = [0.0885]
24-11-25 21:52:27 | I |       - range scale = [    1.0000]
24-11-25 21:52:27 | I |         sum  error  = [    0.8800]
24-11-25 21:52:27 | I |         best error  = [    0.8800]
24-11-25 21:52:27 | I |     + error = [0.8800]
24-11-25 21:52:28 | I |       - range scale = [    1.0000]
24-11-25 21:52:28 | I |         sum  error  = [    1.6268]
24-11-25 21:52:28 | I |         best error  = [    1.6268]
24-11-25 21:52:28 | I |     + error = [1.6268]
24-11-25 21:52:28 | I |       - range scale = [    1.0000]
24-11-25 21:52:28 | I |         sum  error  = [   18.2109]
24-11-25 21:52:28 | I |         best error  = [   18.2109]
24-11-25 21:52:28 | I |     + error = [18.2109]
24-11-25 21:52:29 | I |       - range scale = [    1.0000]
24-11-25 21:52:29 | I |         sum  error  = [    1.7138]
24-11-25 21:52:29 | I |         best error  = [    1.7138]
24-11-25 21:52:29 | I |     + error = [1.7138]
24-11-25 21:52:30 | I |       - range scale = [    1.0000]
24-11-25 21:52:30 | I |         sum  error  = [   18.9712]
24-11-25 21:52:30 | I |         best error  = [   18.9712]
24-11-25 21:52:30 | I |     + error = [18.9712]
24-11-25 21:52:31 | I |       - range scale = [    1.0000]
24-11-25 21:52:31 | I |         sum  error  = [    0.1191]
24-11-25 21:52:31 | I |         best error  = [    0.1191]
24-11-25 21:52:31 | I |     + error = [0.1191]
24-11-25 21:52:32 | I |       - range scale = [    1.0000]
24-11-25 21:52:32 | I |         sum  error  = [    1.1874]
24-11-25 21:52:32 | I |         best error  = [    1.1874]
24-11-25 21:52:32 | I |     + error = [1.1874]
24-11-25 21:52:52 | I |       - range scale = [    1.0000]
24-11-25 21:52:52 | I |         sum  error  = [    1.2618]
24-11-25 21:52:52 | I |         best error  = [    1.2618]
24-11-25 21:52:52 | I |     + error = [1.2618]
24-11-25 21:52:53 | I |       - range scale = [    1.0000]
24-11-25 21:52:53 | I |         sum  error  = [   13.6978]
24-11-25 21:52:53 | I |         best error  = [   13.6978]
24-11-25 21:52:53 | I |     + error = [13.6978]
24-11-25 21:52:54 | I |       - range scale = [    1.0000]
24-11-25 21:52:54 | I |         sum  error  = [    0.7732]
24-11-25 21:52:54 | I |         best error  = [    0.7732]
24-11-25 21:52:54 | I |     + error = [0.7732]
24-11-25 21:52:55 | I |       - range scale = [    1.0000]
24-11-25 21:52:55 | I |         sum  error  = [    6.9983]
24-11-25 21:52:55 | I |         best error  = [    6.9983]
24-11-25 21:52:55 | I |     + error = [6.9983]
24-11-25 21:52:56 | I |       - range scale = [    1.0000]
24-11-25 21:52:56 | I |         sum  error  = [    0.6370]
24-11-25 21:52:56 | I |         best error  = [    0.6370]
24-11-25 21:52:56 | I |     + error = [0.6370]
24-11-25 21:52:57 | I |       - range scale = [    1.0000]
24-11-25 21:52:57 | I |         sum  error  = [    6.6031]
24-11-25 21:52:57 | I |         best error  = [    6.6031]
24-11-25 21:52:57 | I |     + error = [6.6031]
24-11-25 21:52:58 | I |       - range scale = [    1.0000]
24-11-25 21:52:58 | I |         sum  error  = [    0.0886]
24-11-25 21:52:58 | I |         best error  = [    0.0886]
24-11-25 21:52:58 | I |     + error = [0.0886]
24-11-25 21:52:59 | I |       - range scale = [    1.0000]
24-11-25 21:52:59 | I |         sum  error  = [    0.9306]
24-11-25 21:52:59 | I |         best error  = [    0.9306]
24-11-25 21:52:59 | I |     + error = [0.9306]
24-11-25 21:53:00 | I |       - range scale = [    1.0000]
24-11-25 21:53:00 | I |         sum  error  = [    1.7721]
24-11-25 21:53:00 | I |         best error  = [    1.7721]
24-11-25 21:53:00 | I |     + error = [1.7721]
24-11-25 21:53:00 | I |       - range scale = [    1.0000]
24-11-25 21:53:00 | I |         sum  error  = [   19.8690]
24-11-25 21:53:00 | I |         best error  = [   19.8690]
24-11-25 21:53:00 | I |     + error = [19.8690]
24-11-25 21:53:01 | I |       - range scale = [    1.0000]
24-11-25 21:53:01 | I |         sum  error  = [    1.9395]
24-11-25 21:53:01 | I |         best error  = [    1.9395]
24-11-25 21:53:01 | I |     + error = [1.9395]
24-11-25 21:53:02 | I |       - range scale = [    1.0000]
24-11-25 21:53:02 | I |         sum  error  = [   21.7778]
24-11-25 21:53:02 | I |         best error  = [   21.7778]
24-11-25 21:53:02 | I |     + error = [21.7778]
24-11-25 21:53:03 | I |       - range scale = [    1.0000]
24-11-25 21:53:03 | I |         sum  error  = [    0.1437]
24-11-25 21:53:03 | I |         best error  = [    0.1437]
24-11-25 21:53:03 | I |     + error = [0.1437]
24-11-25 21:53:04 | I |       - range scale = [    1.0000]
24-11-25 21:53:04 | I |         sum  error  = [    1.4426]
24-11-25 21:53:04 | I |         best error  = [    1.4426]
24-11-25 21:53:04 | I |     + error = [1.4426]
24-11-25 21:53:23 | I |       - range scale = [    1.0000]
24-11-25 21:53:23 | I |         sum  error  = [    1.5962]
24-11-25 21:53:23 | I |         best error  = [    1.5962]
24-11-25 21:53:23 | I |     + error = [1.5962]
24-11-25 21:53:24 | I |       - range scale = [    1.0000]
24-11-25 21:53:24 | I |         sum  error  = [   13.7637]
24-11-25 21:53:24 | I |         best error  = [   13.7637]
24-11-25 21:53:24 | I |     + error = [13.7637]
24-11-25 21:53:25 | I |       - range scale = [    1.0000]
24-11-25 21:53:25 | I |         sum  error  = [    0.8736]
24-11-25 21:53:25 | I |         best error  = [    0.8736]
24-11-25 21:53:25 | I |     + error = [0.8736]
24-11-25 21:53:26 | I |       - range scale = [    1.0000]
24-11-25 21:53:26 | I |         sum  error  = [    6.7343]
24-11-25 21:53:26 | I |         best error  = [    6.7343]
24-11-25 21:53:26 | I |     + error = [6.7343]
24-11-25 21:53:27 | I |       - range scale = [    1.0000]
24-11-25 21:53:27 | I |         sum  error  = [    0.6164]
24-11-25 21:53:27 | I |         best error  = [    0.6164]
24-11-25 21:53:27 | I |     + error = [0.6164]
24-11-25 21:53:28 | I |       - range scale = [    1.0000]
24-11-25 21:53:28 | I |         sum  error  = [    6.8328]
24-11-25 21:53:28 | I |         best error  = [    6.8328]
24-11-25 21:53:28 | I |     + error = [6.8328]
24-11-25 21:53:29 | I |       - range scale = [    1.0000]
24-11-25 21:53:29 | I |         sum  error  = [    0.0932]
24-11-25 21:53:29 | I |         best error  = [    0.0932]
24-11-25 21:53:29 | I |     + error = [0.0932]
24-11-25 21:53:30 | I |       - range scale = [    1.0000]
24-11-25 21:53:30 | I |         sum  error  = [    1.0235]
24-11-25 21:53:30 | I |         best error  = [    1.0235]
24-11-25 21:53:30 | I |     + error = [1.0235]
24-11-25 21:53:31 | I |       - range scale = [    1.0000]
24-11-25 21:53:31 | I |         sum  error  = [    1.9696]
24-11-25 21:53:31 | I |         best error  = [    1.9696]
24-11-25 21:53:31 | I |     + error = [1.9696]
24-11-25 21:53:31 | I |       - range scale = [    1.0000]
24-11-25 21:53:31 | I |         sum  error  = [   22.1430]
24-11-25 21:53:31 | I |         best error  = [   22.1430]
24-11-25 21:53:31 | I |     + error = [22.1430]
24-11-25 21:53:32 | I |       - range scale = [    1.0000]
24-11-25 21:53:32 | I |         sum  error  = [    2.1524]
24-11-25 21:53:32 | I |         best error  = [    2.1524]
24-11-25 21:53:32 | I |     + error = [2.1524]
24-11-25 21:53:33 | I |       - range scale = [    1.0000]
24-11-25 21:53:33 | I |         sum  error  = [   24.1677]
24-11-25 21:53:33 | I |         best error  = [   24.1677]
24-11-25 21:53:33 | I |     + error = [24.1677]
24-11-25 21:53:34 | I |       - range scale = [    1.0000]
24-11-25 21:53:34 | I |         sum  error  = [    0.1703]
24-11-25 21:53:34 | I |         best error  = [    0.1703]
24-11-25 21:53:34 | I |     + error = [0.1703]
24-11-25 21:53:35 | I |       - range scale = [    1.0000]
24-11-25 21:53:35 | I |         sum  error  = [    1.7382]
24-11-25 21:53:35 | I |         best error  = [    1.7382]
24-11-25 21:53:35 | I |     + error = [1.7382]
24-11-25 21:53:54 | I |       - range scale = [    1.0000]
24-11-25 21:53:54 | I |         sum  error  = [    1.5830]
24-11-25 21:53:54 | I |         best error  = [    1.5830]
24-11-25 21:53:54 | I |     + error = [1.5830]
24-11-25 21:53:55 | I |       - range scale = [    1.0000]
24-11-25 21:53:55 | I |         sum  error  = [   14.6859]
24-11-25 21:53:55 | I |         best error  = [   14.6859]
24-11-25 21:53:55 | I |     + error = [14.6859]
24-11-25 21:53:56 | I |       - range scale = [    1.0000]
24-11-25 21:53:56 | I |         sum  error  = [    0.9315]
24-11-25 21:53:56 | I |         best error  = [    0.9315]
24-11-25 21:53:56 | I |     + error = [0.9315]
24-11-25 21:53:57 | I |       - range scale = [    1.0000]
24-11-25 21:53:57 | I |         sum  error  = [    9.1806]
24-11-25 21:53:57 | I |         best error  = [    9.1806]
24-11-25 21:53:57 | I |     + error = [9.1806]
24-11-25 21:53:58 | I |       - range scale = [    1.0000]
24-11-25 21:53:58 | I |         sum  error  = [    0.5943]
24-11-25 21:53:58 | I |         best error  = [    0.5943]
24-11-25 21:53:58 | I |     + error = [0.5943]
24-11-25 21:53:59 | I |       - range scale = [    1.0000]
24-11-25 21:53:59 | I |         sum  error  = [    6.6722]
24-11-25 21:53:59 | I |         best error  = [    6.6722]
24-11-25 21:53:59 | I |     + error = [6.6722]
24-11-25 21:54:00 | I |       - range scale = [    1.0000]
24-11-25 21:54:00 | I |         sum  error  = [    0.1073]
24-11-25 21:54:00 | I |         best error  = [    0.1073]
24-11-25 21:54:00 | I |     + error = [0.1073]
24-11-25 21:54:00 | I |       - range scale = [    1.0000]
24-11-25 21:54:00 | I |         sum  error  = [    1.1402]
24-11-25 21:54:00 | I |         best error  = [    1.1402]
24-11-25 21:54:00 | I |     + error = [1.1402]
24-11-25 21:54:01 | I |       - range scale = [    1.0000]
24-11-25 21:54:01 | I |         sum  error  = [    2.1868]
24-11-25 21:54:01 | I |         best error  = [    2.1868]
24-11-25 21:54:01 | I |     + error = [2.1868]
24-11-25 21:54:02 | I |       - range scale = [    1.0000]
24-11-25 21:54:02 | I |         sum  error  = [   24.4353]
24-11-25 21:54:02 | I |         best error  = [   24.4353]
24-11-25 21:54:02 | I |     + error = [24.4353]
24-11-25 21:54:03 | I |       - range scale = [    1.0000]
24-11-25 21:54:03 | I |         sum  error  = [    2.3747]
24-11-25 21:54:03 | I |         best error  = [    2.3747]
24-11-25 21:54:03 | I |     + error = [2.3747]
24-11-25 21:54:04 | I |       - range scale = [    1.0000]
24-11-25 21:54:04 | I |         sum  error  = [   26.4715]
24-11-25 21:54:04 | I |         best error  = [   26.4715]
24-11-25 21:54:04 | I |     + error = [26.4715]
24-11-25 21:54:05 | I |       - range scale = [    1.0000]
24-11-25 21:54:05 | I |         sum  error  = [    0.2027]
24-11-25 21:54:05 | I |         best error  = [    0.2027]
24-11-25 21:54:05 | I |     + error = [0.2027]
24-11-25 21:54:06 | I |       - range scale = [    1.0000]
24-11-25 21:54:06 | I |         sum  error  = [    2.0872]
24-11-25 21:54:06 | I |         best error  = [    2.0872]
24-11-25 21:54:06 | I |     + error = [2.0872]
24-11-25 21:54:26 | I |       - range scale = [    1.0000]
24-11-25 21:54:26 | I |         sum  error  = [    2.3522]
24-11-25 21:54:26 | I |         best error  = [    2.3522]
24-11-25 21:54:26 | I |     + error = [2.3522]
24-11-25 21:54:27 | I |       - range scale = [    1.0000]
24-11-25 21:54:27 | I |         sum  error  = [   20.1829]
24-11-25 21:54:27 | I |         best error  = [   20.1829]
24-11-25 21:54:27 | I |     + error = [20.1829]
24-11-25 21:54:28 | I |       - range scale = [    1.0000]
24-11-25 21:54:28 | I |         sum  error  = [    1.3853]
24-11-25 21:54:28 | I |         best error  = [    1.3853]
24-11-25 21:54:28 | I |     + error = [1.3853]
24-11-25 21:54:29 | I |       - range scale = [    1.0000]
24-11-25 21:54:29 | I |         sum  error  = [   15.0073]
24-11-25 21:54:29 | I |         best error  = [   15.0073]
24-11-25 21:54:29 | I |     + error = [15.0073]
24-11-25 21:54:30 | I |       - range scale = [    1.0000]
24-11-25 21:54:30 | I |         sum  error  = [    0.6197]
24-11-25 21:54:30 | I |         best error  = [    0.6197]
24-11-25 21:54:30 | I |     + error = [0.6197]
24-11-25 21:54:31 | I |       - range scale = [    1.0000]
24-11-25 21:54:31 | I |         sum  error  = [    6.9941]
24-11-25 21:54:31 | I |         best error  = [    6.9941]
24-11-25 21:54:31 | I |     + error = [6.9941]
24-11-25 21:54:32 | I |       - range scale = [    1.0000]
24-11-25 21:54:32 | I |         sum  error  = [    0.1262]
24-11-25 21:54:32 | I |         best error  = [    0.1262]
24-11-25 21:54:32 | I |     + error = [0.1262]
24-11-25 21:54:33 | I |       - range scale = [    1.0000]
24-11-25 21:54:33 | I |         sum  error  = [    1.3477]
24-11-25 21:54:33 | I |         best error  = [    1.3477]
24-11-25 21:54:33 | I |     + error = [1.3477]
24-11-25 21:54:34 | I |       - range scale = [    1.0000]
24-11-25 21:54:34 | I |         sum  error  = [    2.4462]
24-11-25 21:54:34 | I |         best error  = [    2.4462]
24-11-25 21:54:34 | I |     + error = [2.4462]
24-11-25 21:54:34 | I |       - range scale = [    1.0000]
24-11-25 21:54:34 | I |         sum  error  = [   27.1367]
24-11-25 21:54:35 | I |         best error  = [   27.1367]
24-11-25 21:54:35 | I |     + error = [27.1367]
24-11-25 21:54:35 | I |       - range scale = [    1.0000]
24-11-25 21:54:35 | I |         sum  error  = [    2.7862]
24-11-25 21:54:35 | I |         best error  = [    2.7862]
24-11-25 21:54:35 | I |     + error = [2.7862]
24-11-25 21:54:36 | I |       - range scale = [    1.0000]
24-11-25 21:54:36 | I |         sum  error  = [   30.2774]
24-11-25 21:54:36 | I |         best error  = [   30.2774]
24-11-25 21:54:36 | I |     + error = [30.2774]
24-11-25 21:54:37 | I |       - range scale = [    1.0000]
24-11-25 21:54:37 | I |         sum  error  = [    0.3474]
24-11-25 21:54:37 | I |         best error  = [    0.3474]
24-11-25 21:54:37 | I |     + error = [0.3474]
24-11-25 21:54:38 | I |       - range scale = [    1.0000]
24-11-25 21:54:38 | I |         sum  error  = [    3.4032]
24-11-25 21:54:38 | I |         best error  = [    3.4032]
24-11-25 21:54:38 | I |     + error = [3.4032]
24-11-25 21:54:57 | I |       - range scale = [    1.0000]
24-11-25 21:54:57 | I |         sum  error  = [    2.8211]
24-11-25 21:54:57 | I |         best error  = [    2.8211]
24-11-25 21:54:57 | I |     + error = [2.8211]
24-11-25 21:54:58 | I |       - range scale = [    1.0000]
24-11-25 21:54:58 | I |         sum  error  = [   21.7577]
24-11-25 21:54:58 | I |         best error  = [   21.7577]
24-11-25 21:54:58 | I |     + error = [21.7577]
24-11-25 21:54:59 | I |       - range scale = [    1.0000]
24-11-25 21:54:59 | I |         sum  error  = [    2.2110]
24-11-25 21:54:59 | I |         best error  = [    2.2110]
24-11-25 21:54:59 | I |     + error = [2.2110]
24-11-25 21:55:00 | I |       - range scale = [    1.0000]
24-11-25 21:55:00 | I |         sum  error  = [   20.7650]
24-11-25 21:55:00 | I |         best error  = [   20.7650]
24-11-25 21:55:00 | I |     + error = [20.7650]
24-11-25 21:55:01 | I |       - range scale = [    1.0000]
24-11-25 21:55:01 | I |         sum  error  = [    0.6402]
24-11-25 21:55:01 | I |         best error  = [    0.6402]
24-11-25 21:55:01 | I |     + error = [0.6402]
24-11-25 21:55:02 | I |       - range scale = [    1.0000]
24-11-25 21:55:02 | I |         sum  error  = [    6.6584]
24-11-25 21:55:02 | I |         best error  = [    6.6584]
24-11-25 21:55:02 | I |     + error = [6.6584]
24-11-25 21:55:03 | I |       - range scale = [    1.0000]
24-11-25 21:55:03 | I |         sum  error  = [    0.2107]
24-11-25 21:55:03 | I |         best error  = [    0.2107]
24-11-25 21:55:03 | I |     + error = [0.2107]
24-11-25 21:55:03 | I |       - range scale = [    1.0000]
24-11-25 21:55:03 | I |         sum  error  = [    2.1412]
24-11-25 21:55:03 | I |         best error  = [    2.1412]
24-11-25 21:55:03 | I |     + error = [2.1412]
24-11-25 21:55:04 | I |       - range scale = [    1.0000]
24-11-25 21:55:04 | I |         sum  error  = [    2.6128]
24-11-25 21:55:04 | I |         best error  = [    2.6128]
24-11-25 21:55:04 | I |     + error = [2.6128]
24-11-25 21:55:05 | I |       - range scale = [    1.0000]
24-11-25 21:55:05 | I |         sum  error  = [   28.6927]
24-11-25 21:55:05 | I |         best error  = [   28.6927]
24-11-25 21:55:05 | I |     + error = [28.6927]
24-11-25 21:55:06 | I |       - range scale = [    1.0000]
24-11-25 21:55:06 | I |         sum  error  = [    2.9666]
24-11-25 21:55:06 | I |         best error  = [    2.9666]
24-11-25 21:55:06 | I |     + error = [2.9666]
24-11-25 21:55:07 | I |       - range scale = [    1.0000]
24-11-25 21:55:07 | I |         sum  error  = [   32.2672]
24-11-25 21:55:07 | I |         best error  = [   32.2672]
24-11-25 21:55:07 | I |     + error = [32.2672]
24-11-25 21:55:08 | I |       - range scale = [    1.0000]
24-11-25 21:55:08 | I |         sum  error  = [    2.1205]
24-11-25 21:55:08 | I |         best error  = [    2.1205]
24-11-25 21:55:08 | I |     + error = [2.1205]
24-11-25 21:55:09 | I |       - range scale = [    1.0000]
24-11-25 21:55:09 | I |         sum  error  = [   20.0159]
24-11-25 21:55:09 | I |         best error  = [   20.0159]
24-11-25 21:55:09 | I |     + error = [20.0159]
24-11-25 21:55:26 | I |       - range scale = [    1.0000]
24-11-25 21:55:26 | I |         sum  error  = [    4.0223]
24-11-25 21:55:26 | I |         best error  = [    4.0223]
24-11-25 21:55:26 | I |     + error = [4.0223]
24-11-25 21:55:27 | I |       - range scale = [    1.0000]
24-11-25 21:55:27 | I |         sum  error  = [   34.7578]
24-11-25 21:55:27 | I |         best error  = [   34.7578]
24-11-25 21:55:27 | I |     + error = [34.7578]
24-11-25 21:55:28 | I |       - range scale = [    1.0000]
24-11-25 21:55:28 | I |         sum  error  = [    2.8534]
24-11-25 21:55:28 | I |         best error  = [    2.8534]
24-11-25 21:55:28 | I |     + error = [2.8534]
24-11-25 21:55:29 | I |       - range scale = [    1.0000]
24-11-25 21:55:29 | I |         sum  error  = [   27.5804]
24-11-25 21:55:29 | I |         best error  = [   27.5804]
24-11-25 21:55:29 | I |     + error = [27.5804]
24-11-25 21:55:30 | I |       - range scale = [    1.0000]
24-11-25 21:55:30 | I |         sum  error  = [    0.6552]
24-11-25 21:55:30 | I |         best error  = [    0.6552]
24-11-25 21:55:30 | I |     + error = [0.6552]
24-11-25 21:55:31 | I |       - range scale = [    1.0000]
24-11-25 21:55:31 | I |         sum  error  = [    7.0958]
24-11-25 21:55:31 | I |         best error  = [    7.0958]
24-11-25 21:55:31 | I |     + error = [7.0958]
24-11-25 21:55:32 | I |       - range scale = [    1.0000]
24-11-25 21:55:32 | I |         sum  error  = [    0.2447]
24-11-25 21:55:32 | I |         best error  = [    0.2447]
24-11-25 21:55:32 | I |     + error = [0.2447]
24-11-25 21:55:33 | I |       - range scale = [    1.0000]
24-11-25 21:55:33 | I |         sum  error  = [    2.5897]
24-11-25 21:55:33 | I |         best error  = [    2.5897]
24-11-25 21:55:33 | I |     + error = [2.5897]
24-11-25 21:55:34 | I |       - range scale = [    1.0000]
24-11-25 21:55:34 | I |         sum  error  = [    2.7537]
24-11-25 21:55:34 | I |         best error  = [    2.7537]
24-11-25 21:55:34 | I |     + error = [2.7537]
24-11-25 21:55:34 | I |       - range scale = [    1.0000]
24-11-25 21:55:34 | I |         sum  error  = [   30.7487]
24-11-25 21:55:34 | I |         best error  = [   30.7487]
24-11-25 21:55:34 | I |     + error = [30.7487]
24-11-25 21:55:35 | I |       - range scale = [    1.0000]
24-11-25 21:55:35 | I |         sum  error  = [    2.9926]
24-11-25 21:55:35 | I |         best error  = [    2.9926]
24-11-25 21:55:35 | I |     + error = [2.9926]
24-11-25 21:55:36 | I |       - range scale = [    1.0000]
24-11-25 21:55:36 | I |         sum  error  = [   33.0672]
24-11-25 21:55:36 | I |         best error  = [   33.0672]
24-11-25 21:55:36 | I |     + error = [33.0672]
24-11-25 21:55:37 | I |       - range scale = [    1.0000]
24-11-25 21:55:37 | I |         sum  error  = [    0.3377]
24-11-25 21:55:37 | I |         best error  = [    0.3377]
24-11-25 21:55:37 | I |     + error = [0.3377]
24-11-25 21:55:38 | I |       - range scale = [    1.0000]
24-11-25 21:55:38 | I |         sum  error  = [    3.3277]
24-11-25 21:55:38 | I |         best error  = [    3.3277]
24-11-25 21:55:38 | I |     + error = [3.3277]
24-11-25 21:55:55 | I |       - range scale = [    1.0000]
24-11-25 21:55:55 | I |         sum  error  = [    3.4828]
24-11-25 21:55:55 | I |         best error  = [    3.4828]
24-11-25 21:55:55 | I |     + error = [3.4828]
24-11-25 21:55:56 | I |       - range scale = [    1.0000]
24-11-25 21:55:56 | I |         sum  error  = [   28.7275]
24-11-25 21:55:56 | I |         best error  = [   28.7275]
24-11-25 21:55:56 | I |     + error = [28.7275]
24-11-25 21:55:57 | I |       - range scale = [    1.0000]
24-11-25 21:55:57 | I |         sum  error  = [    2.6159]
24-11-25 21:55:57 | I |         best error  = [    2.6159]
24-11-25 21:55:57 | I |     + error = [2.6159]
24-11-25 21:55:58 | I |       - range scale = [    1.0000]
24-11-25 21:55:58 | I |         sum  error  = [   19.8414]
24-11-25 21:55:58 | I |         best error  = [   19.8414]
24-11-25 21:55:58 | I |     + error = [19.8414]
24-11-25 21:55:59 | I |       - range scale = [    1.0000]
24-11-25 21:55:59 | I |         sum  error  = [    0.6986]
24-11-25 21:55:59 | I |         best error  = [    0.6986]
24-11-25 21:55:59 | I |     + error = [0.6986]
24-11-25 21:55:59 | I |       - range scale = [    1.0000]
24-11-25 21:55:59 | I |         sum  error  = [    7.7157]
24-11-25 21:55:59 | I |         best error  = [    7.7157]
24-11-25 21:55:59 | I |     + error = [7.7157]
24-11-25 21:56:00 | I |       - range scale = [    1.0000]
24-11-25 21:56:00 | I |         sum  error  = [    0.3201]
24-11-25 21:56:00 | I |         best error  = [    0.3201]
24-11-25 21:56:00 | I |     + error = [0.3201]
24-11-25 21:56:01 | I |       - range scale = [    1.0000]
24-11-25 21:56:01 | I |         sum  error  = [    3.2943]
24-11-25 21:56:01 | I |         best error  = [    3.2943]
24-11-25 21:56:01 | I |     + error = [3.2943]
24-11-25 21:56:02 | I |       - range scale = [    1.0000]
24-11-25 21:56:02 | I |         sum  error  = [    2.9067]
24-11-25 21:56:02 | I |         best error  = [    2.9067]
24-11-25 21:56:02 | I |     + error = [2.9067]
24-11-25 21:56:03 | I |       - range scale = [    1.0000]
24-11-25 21:56:03 | I |         sum  error  = [   31.8721]
24-11-25 21:56:03 | I |         best error  = [   31.8721]
24-11-25 21:56:03 | I |     + error = [31.8721]
24-11-25 21:56:04 | I |       - range scale = [    1.0000]
24-11-25 21:56:04 | I |         sum  error  = [    3.1468]
24-11-25 21:56:04 | I |         best error  = [    3.1468]
24-11-25 21:56:04 | I |     + error = [3.1468]
24-11-25 21:56:04 | I |       - range scale = [    1.0000]
24-11-25 21:56:04 | I |         sum  error  = [   34.3441]
24-11-25 21:56:04 | I |         best error  = [   34.3441]
24-11-25 21:56:04 | I |     + error = [34.3441]
24-11-25 21:56:05 | I |       - range scale = [    1.0000]
24-11-25 21:56:05 | I |         sum  error  = [    0.3470]
24-11-25 21:56:05 | I |         best error  = [    0.3470]
24-11-25 21:56:05 | I |     + error = [0.3470]
24-11-25 21:56:06 | I |       - range scale = [    1.0000]
24-11-25 21:56:06 | I |         sum  error  = [    3.4965]
24-11-25 21:56:06 | I |         best error  = [    3.4965]
24-11-25 21:56:06 | I |     + error = [3.4965]
24-11-25 21:56:24 | I |       - range scale = [    1.0000]
24-11-25 21:56:24 | I |         sum  error  = [    5.2885]
24-11-25 21:56:24 | I |         best error  = [    5.2885]
24-11-25 21:56:24 | I |     + error = [5.2885]
24-11-25 21:56:25 | I |       - range scale = [    1.0000]
24-11-25 21:56:25 | I |         sum  error  = [   45.4736]
24-11-25 21:56:25 | I |         best error  = [   45.4736]
24-11-25 21:56:25 | I |     + error = [45.4736]
24-11-25 21:56:26 | I |       - range scale = [    1.0000]
24-11-25 21:56:26 | I |         sum  error  = [    4.7327]
24-11-25 21:56:26 | I |         best error  = [    4.7327]
24-11-25 21:56:26 | I |     + error = [4.7327]
24-11-25 21:56:27 | I |       - range scale = [    1.0000]
24-11-25 21:56:27 | I |         sum  error  = [   39.4966]
24-11-25 21:56:27 | I |         best error  = [   39.4966]
24-11-25 21:56:27 | I |     + error = [39.4966]
24-11-25 21:56:28 | I |       - range scale = [    1.0000]
24-11-25 21:56:28 | I |         sum  error  = [    0.7828]
24-11-25 21:56:28 | I |         best error  = [    0.7828]
24-11-25 21:56:28 | I |     + error = [0.7828]
24-11-25 21:56:29 | I |       - range scale = [    1.0000]
24-11-25 21:56:29 | I |         sum  error  = [    8.5106]
24-11-25 21:56:29 | I |         best error  = [    8.5106]
24-11-25 21:56:29 | I |     + error = [8.5106]
24-11-25 21:56:30 | I |       - range scale = [    1.0000]
24-11-25 21:56:30 | I |         sum  error  = [    0.3348]
24-11-25 21:56:30 | I |         best error  = [    0.3348]
24-11-25 21:56:30 | I |     + error = [0.3348]
24-11-25 21:56:30 | I |       - range scale = [    1.0000]
24-11-25 21:56:30 | I |         sum  error  = [    3.3897]
24-11-25 21:56:30 | I |         best error  = [    3.3897]
24-11-25 21:56:30 | I |     + error = [3.3897]
24-11-25 21:56:31 | I |       - range scale = [    1.0000]
24-11-25 21:56:31 | I |         sum  error  = [    2.9686]
24-11-25 21:56:31 | I |         best error  = [    2.9686]
24-11-25 21:56:31 | I |     + error = [2.9686]
24-11-25 21:56:32 | I |       - range scale = [    1.0000]
24-11-25 21:56:32 | I |         sum  error  = [   33.1176]
24-11-25 21:56:32 | I |         best error  = [   33.1176]
24-11-25 21:56:32 | I |     + error = [33.1176]
24-11-25 21:56:33 | I |       - range scale = [    1.0000]
24-11-25 21:56:33 | I |         sum  error  = [    3.4336]
24-11-25 21:56:33 | I |         best error  = [    3.4336]
24-11-25 21:56:33 | I |     + error = [3.4336]
24-11-25 21:56:34 | I |       - range scale = [    1.0000]
24-11-25 21:56:34 | I |         sum  error  = [   38.2658]
24-11-25 21:56:34 | I |         best error  = [   38.2658]
24-11-25 21:56:34 | I |     + error = [38.2658]
24-11-25 21:56:35 | I |       - range scale = [    1.0000]
24-11-25 21:56:35 | I |         sum  error  = [    0.4442]
24-11-25 21:56:35 | I |         best error  = [    0.4442]
24-11-25 21:56:35 | I |     + error = [0.4442]
24-11-25 21:56:36 | I |       - range scale = [    1.0000]
24-11-25 21:56:36 | I |         sum  error  = [    4.4640]
24-11-25 21:56:36 | I |         best error  = [    4.4640]
24-11-25 21:56:36 | I |     + error = [4.4640]
24-11-25 21:56:53 | I |       - range scale = [    1.0000]
24-11-25 21:56:53 | I |         sum  error  = [    4.5124]
24-11-25 21:56:53 | I |         best error  = [    4.5124]
24-11-25 21:56:53 | I |     + error = [4.5124]
24-11-25 21:56:53 | I |       - range scale = [    1.0000]
24-11-25 21:56:53 | I |         sum  error  = [   36.4622]
24-11-25 21:56:53 | I |         best error  = [   36.4622]
24-11-25 21:56:54 | I |     + error = [36.4622]
24-11-25 21:56:55 | I |       - range scale = [    1.0000]
24-11-25 21:56:55 | I |         sum  error  = [    2.9162]
24-11-25 21:56:55 | I |         best error  = [    2.9162]
24-11-25 21:56:55 | I |     + error = [2.9162]
24-11-25 21:56:56 | I |       - range scale = [    1.0000]
24-11-25 21:56:56 | I |         sum  error  = [   26.4066]
24-11-25 21:56:56 | I |         best error  = [   26.4066]
24-11-25 21:56:56 | I |     + error = [26.4066]
24-11-25 21:56:57 | I |       - range scale = [    1.0000]
24-11-25 21:56:57 | I |         sum  error  = [    0.8554]
24-11-25 21:56:57 | I |         best error  = [    0.8554]
24-11-25 21:56:57 | I |     + error = [0.8554]
24-11-25 21:56:57 | I |       - range scale = [    1.0000]
24-11-25 21:56:57 | I |         sum  error  = [    9.6040]
24-11-25 21:56:57 | I |         best error  = [    9.6040]
24-11-25 21:56:57 | I |     + error = [9.6040]
24-11-25 21:56:58 | I |       - range scale = [    1.0000]
24-11-25 21:56:58 | I |         sum  error  = [    0.3443]
24-11-25 21:56:58 | I |         best error  = [    0.3443]
24-11-25 21:56:58 | I |     + error = [0.3443]
24-11-25 21:56:59 | I |       - range scale = [    1.0000]
24-11-25 21:56:59 | I |         sum  error  = [    3.5116]
24-11-25 21:56:59 | I |         best error  = [    3.5116]
24-11-25 21:56:59 | I |     + error = [3.5116]
24-11-25 21:57:00 | I |       - range scale = [    1.0000]
24-11-25 21:57:00 | I |         sum  error  = [    3.0999]
24-11-25 21:57:00 | I |         best error  = [    3.0999]
24-11-25 21:57:00 | I |     + error = [3.0999]
24-11-25 21:57:01 | I |       - range scale = [    1.0000]
24-11-25 21:57:01 | I |         sum  error  = [   34.7524]
24-11-25 21:57:01 | I |         best error  = [   34.7524]
24-11-25 21:57:01 | I |     + error = [34.7524]
24-11-25 21:57:02 | I |       - range scale = [    1.0000]
24-11-25 21:57:02 | I |         sum  error  = [    3.7725]
24-11-25 21:57:02 | I |         best error  = [    3.7725]
24-11-25 21:57:02 | I |     + error = [3.7725]
24-11-25 21:57:02 | I |       - range scale = [    1.0000]
24-11-25 21:57:02 | I |         sum  error  = [   42.0327]
24-11-25 21:57:02 | I |         best error  = [   42.0327]
24-11-25 21:57:02 | I |     + error = [42.0327]
24-11-25 21:57:03 | I |       - range scale = [    1.0000]
24-11-25 21:57:03 | I |         sum  error  = [    0.4389]
24-11-25 21:57:03 | I |         best error  = [    0.4389]
24-11-25 21:57:03 | I |     + error = [0.4389]
24-11-25 21:57:04 | I |       - range scale = [    1.0000]
24-11-25 21:57:04 | I |         sum  error  = [    4.5234]
24-11-25 21:57:04 | I |         best error  = [    4.5234]
24-11-25 21:57:04 | I |     + error = [4.5234]
24-11-25 21:57:21 | I |       - range scale = [    1.0000]
24-11-25 21:57:21 | I |         sum  error  = [    5.0719]
24-11-25 21:57:21 | I |         best error  = [    5.0719]
24-11-25 21:57:21 | I |     + error = [5.0719]
24-11-25 21:57:22 | I |       - range scale = [    1.0000]
24-11-25 21:57:22 | I |         sum  error  = [   43.1319]
24-11-25 21:57:22 | I |         best error  = [   43.1319]
24-11-25 21:57:22 | I |     + error = [43.1319]
24-11-25 21:57:23 | I |       - range scale = [    1.0000]
24-11-25 21:57:23 | I |         sum  error  = [    3.6529]
24-11-25 21:57:23 | I |         best error  = [    3.6529]
24-11-25 21:57:23 | I |     + error = [3.6529]
24-11-25 21:57:24 | I |       - range scale = [    1.0000]
24-11-25 21:57:24 | I |         sum  error  = [   29.2715]
24-11-25 21:57:24 | I |         best error  = [   29.2715]
24-11-25 21:57:24 | I |     + error = [29.2715]
24-11-25 21:57:25 | I |       - range scale = [    1.0000]
24-11-25 21:57:25 | I |         sum  error  = [    0.8353]
24-11-25 21:57:25 | I |         best error  = [    0.8353]
24-11-25 21:57:25 | I |     + error = [0.8353]
24-11-25 21:57:26 | I |       - range scale = [    1.0000]
24-11-25 21:57:26 | I |         sum  error  = [    9.2259]
24-11-25 21:57:26 | I |         best error  = [    9.2259]
24-11-25 21:57:26 | I |     + error = [9.2259]
24-11-25 21:57:27 | I |       - range scale = [    1.0000]
24-11-25 21:57:27 | I |         sum  error  = [    0.3881]
24-11-25 21:57:27 | I |         best error  = [    0.3881]
24-11-25 21:57:27 | I |     + error = [0.3881]
24-11-25 21:57:27 | I |       - range scale = [    1.0000]
24-11-25 21:57:27 | I |         sum  error  = [    4.0254]
24-11-25 21:57:27 | I |         best error  = [    4.0254]
24-11-25 21:57:27 | I |     + error = [4.0254]
24-11-25 21:57:28 | I |       - range scale = [    1.0000]
24-11-25 21:57:28 | I |         sum  error  = [    3.2794]
24-11-25 21:57:28 | I |         best error  = [    3.2794]
24-11-25 21:57:28 | I |     + error = [3.2794]
24-11-25 21:57:29 | I |       - range scale = [    1.0000]
24-11-25 21:57:29 | I |         sum  error  = [   36.4134]
24-11-25 21:57:29 | I |         best error  = [   36.4134]
24-11-25 21:57:29 | I |     + error = [36.4134]
24-11-25 21:57:30 | I |       - range scale = [    1.0000]
24-11-25 21:57:30 | I |         sum  error  = [    4.0049]
24-11-25 21:57:30 | I |         best error  = [    4.0049]
24-11-25 21:57:30 | I |     + error = [4.0049]
24-11-25 21:57:31 | I |       - range scale = [    1.0000]
24-11-25 21:57:31 | I |         sum  error  = [   44.2259]
24-11-25 21:57:31 | I |         best error  = [   44.2259]
24-11-25 21:57:31 | I |     + error = [44.2259]
24-11-25 21:57:32 | I |       - range scale = [    1.0000]
24-11-25 21:57:32 | I |         sum  error  = [    0.5084]
24-11-25 21:57:32 | I |         best error  = [    0.5084]
24-11-25 21:57:32 | I |     + error = [0.5084]
24-11-25 21:57:32 | I |       - range scale = [    1.0000]
24-11-25 21:57:32 | I |         sum  error  = [    5.1512]
24-11-25 21:57:32 | I |         best error  = [    5.1512]
24-11-25 21:57:32 | I |     + error = [5.1512]
24-11-25 21:57:52 | I |       - range scale = [    1.0000]
24-11-25 21:57:52 | I |         sum  error  = [    5.4540]
24-11-25 21:57:52 | I |         best error  = [    5.4540]
24-11-25 21:57:52 | I |     + error = [5.4540]
24-11-25 21:57:53 | I |       - range scale = [    1.0000]
24-11-25 21:57:53 | I |         sum  error  = [   47.8791]
24-11-25 21:57:53 | I |         best error  = [   47.8791]
24-11-25 21:57:53 | I |     + error = [47.8791]
24-11-25 21:57:54 | I |       - range scale = [    1.0000]
24-11-25 21:57:54 | I |         sum  error  = [    4.0370]
24-11-25 21:57:54 | I |         best error  = [    4.0370]
24-11-25 21:57:54 | I |     + error = [4.0370]
24-11-25 21:57:55 | I |       - range scale = [    1.0000]
24-11-25 21:57:55 | I |         sum  error  = [   34.4098]
24-11-25 21:57:55 | I |         best error  = [   34.4098]
24-11-25 21:57:55 | I |     + error = [34.4098]
24-11-25 21:57:56 | I |       - range scale = [    1.0000]
24-11-25 21:57:56 | I |         sum  error  = [    0.7322]
24-11-25 21:57:56 | I |         best error  = [    0.7322]
24-11-25 21:57:56 | I |     + error = [0.7322]
24-11-25 21:57:57 | I |       - range scale = [    1.0000]
24-11-25 21:57:57 | I |         sum  error  = [    8.2192]
24-11-25 21:57:57 | I |         best error  = [    8.2192]
24-11-25 21:57:57 | I |     + error = [8.2192]
24-11-25 21:57:57 | I |       - range scale = [    1.0000]
24-11-25 21:57:57 | I |         sum  error  = [    0.4788]
24-11-25 21:57:57 | I |         best error  = [    0.4788]
24-11-25 21:57:57 | I |     + error = [0.4788]
24-11-25 21:57:58 | I |       - range scale = [    1.0000]
24-11-25 21:57:58 | I |         sum  error  = [    4.8984]
24-11-25 21:57:58 | I |         best error  = [    4.8984]
24-11-25 21:57:58 | I |     + error = [4.8984]
24-11-25 21:57:59 | I |       - range scale = [    1.0000]
24-11-25 21:57:59 | I |         sum  error  = [    3.4899]
24-11-25 21:57:59 | I |         best error  = [    3.4899]
24-11-25 21:57:59 | I |     + error = [3.4899]
24-11-25 21:58:00 | I |       - range scale = [    1.0000]
24-11-25 21:58:00 | I |         sum  error  = [   38.1268]
24-11-25 21:58:00 | I |         best error  = [   38.1268]
24-11-25 21:58:00 | I |     + error = [38.1268]
24-11-25 21:58:01 | I |       - range scale = [    1.0000]
24-11-25 21:58:01 | I |         sum  error  = [    4.0476]
24-11-25 21:58:01 | I |         best error  = [    4.0476]
24-11-25 21:58:01 | I |     + error = [4.0476]
24-11-25 21:58:02 | I |       - range scale = [    1.0000]
24-11-25 21:58:02 | I |         sum  error  = [   44.1165]
24-11-25 21:58:02 | I |         best error  = [   44.1165]
24-11-25 21:58:02 | I |     + error = [44.1165]
24-11-25 21:58:03 | I |       - range scale = [    1.0000]
24-11-25 21:58:03 | I |         sum  error  = [    0.5576]
24-11-25 21:58:03 | I |         best error  = [    0.5576]
24-11-25 21:58:03 | I |     + error = [0.5576]
24-11-25 21:58:03 | I |       - range scale = [    1.0000]
24-11-25 21:58:03 | I |         sum  error  = [    5.6191]
24-11-25 21:58:03 | I |         best error  = [    5.6191]
24-11-25 21:58:03 | I |     + error = [5.6191]
24-11-25 21:58:22 | I |       - range scale = [    1.0000]
24-11-25 21:58:22 | I |         sum  error  = [    6.1654]
24-11-25 21:58:22 | I |         best error  = [    6.1654]
24-11-25 21:58:22 | I |     + error = [6.1654]
24-11-25 21:58:23 | I |       - range scale = [    1.0000]
24-11-25 21:58:23 | I |         sum  error  = [   53.0835]
24-11-25 21:58:23 | I |         best error  = [   53.0835]
24-11-25 21:58:23 | I |     + error = [53.0835]
24-11-25 21:58:24 | I |       - range scale = [    1.0000]
24-11-25 21:58:24 | I |         sum  error  = [    5.5594]
24-11-25 21:58:24 | I |         best error  = [    5.5594]
24-11-25 21:58:24 | I |     + error = [5.5594]
24-11-25 21:58:25 | I |       - range scale = [    1.0000]
24-11-25 21:58:25 | I |         sum  error  = [   46.5730]
24-11-25 21:58:25 | I |         best error  = [   46.5730]
24-11-25 21:58:25 | I |     + error = [46.5730]
24-11-25 21:58:26 | I |       - range scale = [    1.0000]
24-11-25 21:58:26 | I |         sum  error  = [    1.0782]
24-11-25 21:58:26 | I |         best error  = [    1.0782]
24-11-25 21:58:26 | I |     + error = [1.0782]
24-11-25 21:58:27 | I |       - range scale = [    1.0000]
24-11-25 21:58:27 | I |         sum  error  = [   10.5662]
24-11-25 21:58:27 | I |         best error  = [   10.5662]
24-11-25 21:58:27 | I |     + error = [10.5662]
24-11-25 21:58:28 | I |       - range scale = [    1.0000]
24-11-25 21:58:28 | I |         sum  error  = [    0.5002]
24-11-25 21:58:28 | I |         best error  = [    0.5002]
24-11-25 21:58:28 | I |     + error = [0.5002]
24-11-25 21:58:29 | I |       - range scale = [    1.0000]
24-11-25 21:58:29 | I |         sum  error  = [    4.8011]
24-11-25 21:58:29 | I |         best error  = [    4.8011]
24-11-25 21:58:29 | I |     + error = [4.8011]
24-11-25 21:58:30 | I |       - range scale = [    1.0000]
24-11-25 21:58:30 | I |         sum  error  = [    3.7287]
24-11-25 21:58:30 | I |         best error  = [    3.7287]
24-11-25 21:58:30 | I |     + error = [3.7287]
24-11-25 21:58:30 | I |       - range scale = [    1.0000]
24-11-25 21:58:30 | I |         sum  error  = [   41.3937]
24-11-25 21:58:30 | I |         best error  = [   41.3937]
24-11-25 21:58:30 | I |     + error = [41.3937]
24-11-25 21:58:31 | I |       - range scale = [    1.0000]
24-11-25 21:58:31 | I |         sum  error  = [    4.3815]
24-11-25 21:58:31 | I |         best error  = [    4.3815]
24-11-25 21:58:31 | I |     + error = [4.3815]
24-11-25 21:58:32 | I |       - range scale = [    1.0000]
24-11-25 21:58:32 | I |         sum  error  = [   48.2926]
24-11-25 21:58:32 | I |         best error  = [   48.2926]
24-11-25 21:58:32 | I |     + error = [48.2926]
24-11-25 21:58:33 | I |       - range scale = [    1.0000]
24-11-25 21:58:33 | I |         sum  error  = [    0.7208]
24-11-25 21:58:33 | I |         best error  = [    0.7208]
24-11-25 21:58:33 | I |     + error = [0.7208]
24-11-25 21:58:34 | I |       - range scale = [    1.0000]
24-11-25 21:58:34 | I |         sum  error  = [    7.1504]
24-11-25 21:58:34 | I |         best error  = [    7.1504]
24-11-25 21:58:34 | I |     + error = [7.1504]
24-11-25 21:58:53 | I |       - range scale = [    1.0000]
24-11-25 21:58:53 | I |         sum  error  = [    6.4642]
24-11-25 21:58:53 | I |         best error  = [    6.4642]
24-11-25 21:58:53 | I |     + error = [6.4642]
24-11-25 21:58:54 | I |       - range scale = [    1.0000]
24-11-25 21:58:54 | I |         sum  error  = [   51.1352]
24-11-25 21:58:54 | I |         best error  = [   51.1352]
24-11-25 21:58:54 | I |     + error = [51.1352]
24-11-25 21:58:55 | I |       - range scale = [    1.0000]
24-11-25 21:58:55 | I |         sum  error  = [    4.3784]
24-11-25 21:58:55 | I |         best error  = [    4.3784]
24-11-25 21:58:55 | I |     + error = [4.3784]
24-11-25 21:58:56 | I |       - range scale = [    1.0000]
24-11-25 21:58:56 | I |         sum  error  = [   39.4242]
24-11-25 21:58:56 | I |         best error  = [   39.4242]
24-11-25 21:58:56 | I |     + error = [39.4242]
24-11-25 21:58:57 | I |       - range scale = [    1.0000]
24-11-25 21:58:57 | I |         sum  error  = [    1.1242]
24-11-25 21:58:57 | I |         best error  = [    1.1242]
24-11-25 21:58:57 | I |     + error = [1.1242]
24-11-25 21:58:58 | I |       - range scale = [    1.0000]
24-11-25 21:58:58 | I |         sum  error  = [   11.6487]
24-11-25 21:58:58 | I |         best error  = [   11.6487]
24-11-25 21:58:58 | I |     + error = [11.6487]
24-11-25 21:58:58 | I |       - range scale = [    1.0000]
24-11-25 21:58:58 | I |         sum  error  = [    0.4953]
24-11-25 21:58:58 | I |         best error  = [    0.4953]
24-11-25 21:58:58 | I |     + error = [0.4953]
24-11-25 21:58:59 | I |       - range scale = [    1.0000]
24-11-25 21:58:59 | I |         sum  error  = [    4.7929]
24-11-25 21:58:59 | I |         best error  = [    4.7929]
24-11-25 21:58:59 | I |     + error = [4.7929]
24-11-25 21:59:00 | I |       - range scale = [    1.0000]
24-11-25 21:59:00 | I |         sum  error  = [    4.0182]
24-11-25 21:59:00 | I |         best error  = [    4.0182]
24-11-25 21:59:00 | I |     + error = [4.0182]
24-11-25 21:59:01 | I |       - range scale = [    1.0000]
24-11-25 21:59:01 | I |         sum  error  = [   44.4456]
24-11-25 21:59:01 | I |         best error  = [   44.4456]
24-11-25 21:59:01 | I |     + error = [44.4456]
24-11-25 21:59:02 | I |       - range scale = [    1.0000]
24-11-25 21:59:02 | I |         sum  error  = [    4.5086]
24-11-25 21:59:02 | I |         best error  = [    4.5086]
24-11-25 21:59:02 | I |     + error = [4.5086]
24-11-25 21:59:03 | I |       - range scale = [    1.0000]
24-11-25 21:59:03 | I |         sum  error  = [   50.2025]
24-11-25 21:59:03 | I |         best error  = [   50.2025]
24-11-25 21:59:03 | I |     + error = [50.2025]
24-11-25 21:59:04 | I |       - range scale = [    1.0000]
24-11-25 21:59:04 | I |         sum  error  = [    0.9112]
24-11-25 21:59:04 | I |         best error  = [    0.9112]
24-11-25 21:59:04 | I |     + error = [0.9112]
24-11-25 21:59:04 | I |       - range scale = [    1.0000]
24-11-25 21:59:04 | I |         sum  error  = [    8.8539]
24-11-25 21:59:04 | I |         best error  = [    8.8539]
24-11-25 21:59:04 | I |     + error = [8.8539]
24-11-25 21:59:24 | I |       - range scale = [    1.0000]
24-11-25 21:59:24 | I |         sum  error  = [    6.4327]
24-11-25 21:59:24 | I |         best error  = [    6.4327]
24-11-25 21:59:24 | I |     + error = [6.4327]
24-11-25 21:59:25 | I |       - range scale = [    1.0000]
24-11-25 21:59:25 | I |         sum  error  = [   58.3137]
24-11-25 21:59:25 | I |         best error  = [   58.3137]
24-11-25 21:59:25 | I |     + error = [58.3137]
24-11-25 21:59:26 | I |       - range scale = [    1.0000]
24-11-25 21:59:26 | I |         sum  error  = [    4.9022]
24-11-25 21:59:26 | I |         best error  = [    4.9022]
24-11-25 21:59:26 | I |     + error = [4.9022]
24-11-25 21:59:27 | I |       - range scale = [    1.0000]
24-11-25 21:59:27 | I |         sum  error  = [   51.3327]
24-11-25 21:59:27 | I |         best error  = [   51.3327]
24-11-25 21:59:27 | I |     + error = [51.3327]
24-11-25 21:59:28 | I |       - range scale = [    1.0000]
24-11-25 21:59:28 | I |         sum  error  = [    1.0242]
24-11-25 21:59:28 | I |         best error  = [    1.0242]
24-11-25 21:59:28 | I |     + error = [1.0242]
24-11-25 21:59:29 | I |       - range scale = [    1.0000]
24-11-25 21:59:29 | I |         sum  error  = [   11.4926]
24-11-25 21:59:29 | I |         best error  = [   11.4926]
24-11-25 21:59:29 | I |     + error = [11.4926]
24-11-25 21:59:29 | I |       - range scale = [    1.0000]
24-11-25 21:59:29 | I |         sum  error  = [    0.6868]
24-11-25 21:59:29 | I |         best error  = [    0.6868]
24-11-25 21:59:29 | I |     + error = [0.6868]
24-11-25 21:59:30 | I |       - range scale = [    1.0000]
24-11-25 21:59:30 | I |         sum  error  = [    6.9187]
24-11-25 21:59:30 | I |         best error  = [    6.9187]
24-11-25 21:59:30 | I |     + error = [6.9187]
24-11-25 21:59:31 | I |       - range scale = [    1.0000]
24-11-25 21:59:31 | I |         sum  error  = [    4.3644]
24-11-25 21:59:31 | I |         best error  = [    4.3644]
24-11-25 21:59:31 | I |     + error = [4.3644]
24-11-25 21:59:32 | I |       - range scale = [    1.0000]
24-11-25 21:59:32 | I |         sum  error  = [   48.4239]
24-11-25 21:59:32 | I |         best error  = [   48.4239]
24-11-25 21:59:32 | I |     + error = [48.4239]
24-11-25 21:59:33 | I |       - range scale = [    1.0000]
24-11-25 21:59:33 | I |         sum  error  = [    4.9476]
24-11-25 21:59:33 | I |         best error  = [    4.9476]
24-11-25 21:59:33 | I |     + error = [4.9476]
24-11-25 21:59:34 | I |       - range scale = [    1.0000]
24-11-25 21:59:34 | I |         sum  error  = [   54.5329]
24-11-25 21:59:34 | I |         best error  = [   54.5329]
24-11-25 21:59:34 | I |     + error = [54.5329]
24-11-25 21:59:35 | I |       - range scale = [    1.0000]
24-11-25 21:59:35 | I |         sum  error  = [    1.0717]
24-11-25 21:59:35 | I |         best error  = [    1.0717]
24-11-25 21:59:35 | I |     + error = [1.0717]
24-11-25 21:59:36 | I |       - range scale = [    1.0000]
24-11-25 21:59:36 | I |         sum  error  = [   10.4571]
24-11-25 21:59:36 | I |         best error  = [   10.4571]
24-11-25 21:59:36 | I |     + error = [10.4571]
24-11-25 21:59:55 | I |       - range scale = [    1.0000]
24-11-25 21:59:55 | I |         sum  error  = [    7.1265]
24-11-25 21:59:55 | I |         best error  = [    7.1265]
24-11-25 21:59:55 | I |     + error = [7.1265]
24-11-25 21:59:55 | I |       - range scale = [    1.0000]
24-11-25 21:59:55 | I |         sum  error  = [   57.9311]
24-11-25 21:59:55 | I |         best error  = [   57.9311]
24-11-25 21:59:55 | I |     + error = [57.9311]
24-11-25 21:59:57 | I |       - range scale = [    1.0000]
24-11-25 21:59:57 | I |         sum  error  = [    5.8778]
24-11-25 21:59:57 | I |         best error  = [    5.8778]
24-11-25 21:59:57 | I |     + error = [5.8778]
24-11-25 21:59:58 | I |       - range scale = [    1.0000]
24-11-25 21:59:58 | I |         sum  error  = [   45.5834]
24-11-25 21:59:58 | I |         best error  = [   45.5834]
24-11-25 21:59:58 | I |     + error = [45.5834]
24-11-25 21:59:59 | I |       - range scale = [    1.0000]
24-11-25 21:59:59 | I |         sum  error  = [    1.1937]
24-11-25 21:59:59 | I |         best error  = [    1.1937]
24-11-25 21:59:59 | I |     + error = [1.1937]
24-11-25 21:59:59 | I |       - range scale = [    1.0000]
24-11-25 21:59:59 | I |         sum  error  = [   12.8451]
24-11-25 21:59:59 | I |         best error  = [   12.8451]
24-11-25 21:59:59 | I |     + error = [12.8451]
24-11-25 22:00:00 | I |       - range scale = [    1.0000]
24-11-25 22:00:00 | I |         sum  error  = [    0.6050]
24-11-25 22:00:00 | I |         best error  = [    0.6050]
24-11-25 22:00:00 | I |     + error = [0.6050]
24-11-25 22:00:01 | I |       - range scale = [    1.0000]
24-11-25 22:00:01 | I |         sum  error  = [    6.2688]
24-11-25 22:00:01 | I |         best error  = [    6.2688]
24-11-25 22:00:01 | I |     + error = [6.2688]
24-11-25 22:00:02 | I |       - range scale = [    1.0000]
24-11-25 22:00:02 | I |         sum  error  = [    4.8822]
24-11-25 22:00:02 | I |         best error  = [    4.8822]
24-11-25 22:00:02 | I |     + error = [4.8822]
24-11-25 22:00:03 | I |       - range scale = [    1.0000]
24-11-25 22:00:03 | I |         sum  error  = [   54.3135]
24-11-25 22:00:03 | I |         best error  = [   54.3135]
24-11-25 22:00:03 | I |     + error = [54.3135]
24-11-25 22:00:04 | I |       - range scale = [    1.0000]
24-11-25 22:00:04 | I |         sum  error  = [    5.5843]
24-11-25 22:00:04 | I |         best error  = [    5.5843]
24-11-25 22:00:04 | I |     + error = [5.5843]
24-11-25 22:00:04 | I |       - range scale = [    1.0000]
24-11-25 22:00:04 | I |         sum  error  = [   61.9645]
24-11-25 22:00:04 | I |         best error  = [   61.9645]
24-11-25 22:00:04 | I |     + error = [61.9645]
24-11-25 22:00:05 | I |       - range scale = [    1.0000]
24-11-25 22:00:05 | I |         sum  error  = [    1.3683]
24-11-25 22:00:05 | I |         best error  = [    1.3683]
24-11-25 22:00:05 | I |     + error = [1.3683]
24-11-25 22:00:06 | I |       - range scale = [    1.0000]
24-11-25 22:00:06 | I |         sum  error  = [   13.6952]
24-11-25 22:00:06 | I |         best error  = [   13.6952]
24-11-25 22:00:06 | I |     + error = [13.6952]
24-11-25 22:00:25 | I |       - range scale = [    1.0000]
24-11-25 22:00:25 | I |         sum  error  = [    9.1289]
24-11-25 22:00:25 | I |         best error  = [    9.1289]
24-11-25 22:00:25 | I |     + error = [9.1289]
24-11-25 22:00:26 | I |       - range scale = [    1.0000]
24-11-25 22:00:26 | I |         sum  error  = [   74.6546]
24-11-25 22:00:26 | I |         best error  = [   74.6546]
24-11-25 22:00:26 | I |     + error = [74.6546]
24-11-25 22:00:28 | I |       - range scale = [    1.0000]
24-11-25 22:00:28 | I |         sum  error  = [    8.0362]
24-11-25 22:00:28 | I |         best error  = [    8.0362]
24-11-25 22:00:28 | I |     + error = [8.0362]
24-11-25 22:00:29 | I |       - range scale = [    1.0000]
24-11-25 22:00:29 | I |         sum  error  = [   68.7662]
24-11-25 22:00:29 | I |         best error  = [   68.7662]
24-11-25 22:00:29 | I |     + error = [68.7662]
24-11-25 22:00:29 | I |       - range scale = [    1.0000]
24-11-25 22:00:29 | I |         sum  error  = [    1.4890]
24-11-25 22:00:29 | I |         best error  = [    1.4890]
24-11-25 22:00:29 | I |     + error = [1.4890]
24-11-25 22:00:30 | I |       - range scale = [    1.0000]
24-11-25 22:00:30 | I |         sum  error  = [   15.7868]
24-11-25 22:00:30 | I |         best error  = [   15.7868]
24-11-25 22:00:30 | I |     + error = [15.7868]
24-11-25 22:00:31 | I |       - range scale = [    1.0000]
24-11-25 22:00:31 | I |         sum  error  = [    0.5865]
24-11-25 22:00:31 | I |         best error  = [    0.5865]
24-11-25 22:00:31 | I |     + error = [0.5865]
24-11-25 22:00:32 | I |       - range scale = [    1.0000]
24-11-25 22:00:32 | I |         sum  error  = [    6.0065]
24-11-25 22:00:32 | I |         best error  = [    6.0065]
24-11-25 22:00:32 | I |     + error = [6.0065]
24-11-25 22:00:33 | I |       - range scale = [    1.0000]
24-11-25 22:00:33 | I |         sum  error  = [    5.2836]
24-11-25 22:00:33 | I |         best error  = [    5.2836]
24-11-25 22:00:33 | I |     + error = [5.2836]
24-11-25 22:00:34 | I |       - range scale = [    1.0000]
24-11-25 22:00:34 | I |         sum  error  = [   59.4523]
24-11-25 22:00:34 | I |         best error  = [   59.4523]
24-11-25 22:00:34 | I |     + error = [59.4523]
24-11-25 22:00:35 | I |       - range scale = [    1.0000]
24-11-25 22:00:35 | I |         sum  error  = [    5.9919]
24-11-25 22:00:35 | I |         best error  = [    5.9919]
24-11-25 22:00:35 | I |     + error = [5.9919]
24-11-25 22:00:35 | I |       - range scale = [    1.0000]
24-11-25 22:00:35 | I |         sum  error  = [   66.7692]
24-11-25 22:00:35 | I |         best error  = [   66.7692]
24-11-25 22:00:35 | I |     + error = [66.7692]
24-11-25 22:00:36 | I |       - range scale = [    1.0000]
24-11-25 22:00:36 | I |         sum  error  = [    1.5176]
24-11-25 22:00:36 | I |         best error  = [    1.5176]
24-11-25 22:00:36 | I |     + error = [1.5176]
24-11-25 22:00:37 | I |       - range scale = [    1.0000]
24-11-25 22:00:37 | I |         sum  error  = [   15.0638]
24-11-25 22:00:37 | I |         best error  = [   15.0638]
24-11-25 22:00:37 | I |     + error = [15.0638]
24-11-25 22:00:58 | I |       - range scale = [    1.0000]
24-11-25 22:00:58 | I |         sum  error  = [    9.4888]
24-11-25 22:00:58 | I |         best error  = [    9.4888]
24-11-25 22:00:58 | I |     + error = [9.4888]
24-11-25 22:00:59 | I |       - range scale = [    1.0000]
24-11-25 22:00:59 | I |         sum  error  = [   78.0500]
24-11-25 22:00:59 | I |         best error  = [   78.0500]
24-11-25 22:00:59 | I |     + error = [78.0500]
24-11-25 22:01:00 | I |       - range scale = [    1.0000]
24-11-25 22:01:00 | I |         sum  error  = [    7.9815]
24-11-25 22:01:00 | I |         best error  = [    7.9815]
24-11-25 22:01:00 | I |     + error = [7.9815]
24-11-25 22:01:01 | I |       - range scale = [    1.0000]
24-11-25 22:01:01 | I |         sum  error  = [   67.3280]
24-11-25 22:01:01 | I |         best error  = [   67.3280]
24-11-25 22:01:01 | I |     + error = [67.3280]
24-11-25 22:01:02 | I |       - range scale = [    1.0000]
24-11-25 22:01:02 | I |         sum  error  = [    1.1996]
24-11-25 22:01:02 | I |         best error  = [    1.1996]
24-11-25 22:01:02 | I |     + error = [1.1996]
24-11-25 22:01:03 | I |       - range scale = [    1.0000]
24-11-25 22:01:03 | I |         sum  error  = [   13.6103]
24-11-25 22:01:03 | I |         best error  = [   13.6103]
24-11-25 22:01:03 | I |     + error = [13.6103]
24-11-25 22:01:04 | I |       - range scale = [    1.0000]
24-11-25 22:01:04 | I |         sum  error  = [    0.8524]
24-11-25 22:01:04 | I |         best error  = [    0.8524]
24-11-25 22:01:04 | I |     + error = [0.8524]
24-11-25 22:01:05 | I |       - range scale = [    1.0000]
24-11-25 22:01:05 | I |         sum  error  = [    9.0224]
24-11-25 22:01:05 | I |         best error  = [    9.0224]
24-11-25 22:01:05 | I |     + error = [9.0224]
24-11-25 22:01:06 | I |       - range scale = [    1.0000]
24-11-25 22:01:06 | I |         sum  error  = [    5.8154]
24-11-25 22:01:06 | I |         best error  = [    5.8154]
24-11-25 22:01:06 | I |     + error = [5.8154]
24-11-25 22:01:06 | I |       - range scale = [    1.0000]
24-11-25 22:01:06 | I |         sum  error  = [   65.1999]
24-11-25 22:01:06 | I |         best error  = [   65.1999]
24-11-25 22:01:06 | I |     + error = [65.1999]
24-11-25 22:01:07 | I |       - range scale = [    1.0000]
24-11-25 22:01:07 | I |         sum  error  = [    6.4617]
24-11-25 22:01:07 | I |         best error  = [    6.4617]
24-11-25 22:01:07 | I |     + error = [6.4617]
24-11-25 22:01:08 | I |       - range scale = [    1.0000]
24-11-25 22:01:08 | I |         sum  error  = [   71.2086]
24-11-25 22:01:08 | I |         best error  = [   71.2086]
24-11-25 22:01:08 | I |     + error = [71.2086]
24-11-25 22:01:09 | I |       - range scale = [    1.0000]
24-11-25 22:01:09 | I |         sum  error  = [    3.7214]
24-11-25 22:01:09 | I |         best error  = [    3.7214]
24-11-25 22:01:09 | I |     + error = [3.7214]
24-11-25 22:01:10 | I |       - range scale = [    1.0000]
24-11-25 22:01:10 | I |         sum  error  = [   33.8329]
24-11-25 22:01:10 | I |         best error  = [   33.8329]
24-11-25 22:01:10 | I |     + error = [33.8329]
24-11-25 22:01:29 | I |       - range scale = [    1.0000]
24-11-25 22:01:29 | I |         sum  error  = [   14.8605]
24-11-25 22:01:29 | I |         best error  = [   14.8605]
24-11-25 22:01:29 | I |     + error = [14.8605]
24-11-25 22:01:30 | I |       - range scale = [    1.0000]
24-11-25 22:01:30 | I |         sum  error  = [  132.8769]
24-11-25 22:01:30 | I |         best error  = [  132.8769]
24-11-25 22:01:30 | I |     + error = [132.8769]
24-11-25 22:01:31 | I |       - range scale = [    1.0000]
24-11-25 22:01:31 | I |         sum  error  = [   22.2556]
24-11-25 22:01:31 | I |         best error  = [   22.2556]
24-11-25 22:01:31 | I |     + error = [22.2556]
24-11-25 22:01:32 | I |       - range scale = [    1.0000]
24-11-25 22:01:32 | I |         sum  error  = [  158.5984]
24-11-25 22:01:32 | I |         best error  = [  158.5984]
24-11-25 22:01:32 | I |     + error = [158.5984]
24-11-25 22:01:33 | I |       - range scale = [    1.0000]
24-11-25 22:01:33 | I |         sum  error  = [    2.6607]
24-11-25 22:01:33 | I |         best error  = [    2.6607]
24-11-25 22:01:33 | I |     + error = [2.6607]
24-11-25 22:01:33 | I |       - range scale = [    1.0000]
24-11-25 22:01:33 | I |         sum  error  = [   27.6887]
24-11-25 22:01:33 | I |         best error  = [   27.6887]
24-11-25 22:01:33 | I |     + error = [27.6887]
24-11-25 22:01:34 | I |       - range scale = [    1.0000]
24-11-25 22:01:34 | I |         sum  error  = [    1.1678]
24-11-25 22:01:34 | I |         best error  = [    1.1678]
24-11-25 22:01:34 | I |     + error = [1.1678]
24-11-25 22:01:35 | I |       - range scale = [    1.0000]
24-11-25 22:01:35 | I |         sum  error  = [   11.6384]
24-11-25 22:01:35 | I |         best error  = [   11.6384]
24-11-25 22:01:35 | I |     + error = [11.6384]
24-11-25 22:01:36 | I |       - range scale = [    1.0000]
24-11-25 22:01:36 | I |         sum  error  = [    6.2299]
24-11-25 22:01:36 | I |         best error  = [    6.2299]
24-11-25 22:01:36 | I |     + error = [6.2299]
24-11-25 22:01:37 | I |       - range scale = [    1.0000]
24-11-25 22:01:37 | I |         sum  error  = [   69.7473]
24-11-25 22:01:37 | I |         best error  = [   69.7473]
24-11-25 22:01:37 | I |     + error = [69.7473]
24-11-25 22:01:38 | I |       - range scale = [    1.0000]
24-11-25 22:01:38 | I |         sum  error  = [    6.7718]
24-11-25 22:01:38 | I |         best error  = [    6.7718]
24-11-25 22:01:38 | I |     + error = [6.7718]
24-11-25 22:01:39 | I |       - range scale = [    1.0000]
24-11-25 22:01:39 | I |         sum  error  = [   74.7116]
24-11-25 22:01:39 | I |         best error  = [   74.7116]
24-11-25 22:01:39 | I |     + error = [74.7116]
24-11-25 22:01:39 | I |       - range scale = [    1.0000]
24-11-25 22:01:39 | I |         sum  error  = [    2.5548]
24-11-25 22:01:39 | I |         best error  = [    2.5548]
24-11-25 22:01:39 | I |     + error = [2.5548]
24-11-25 22:01:40 | I |       - range scale = [    1.0000]
24-11-25 22:01:40 | I |         sum  error  = [   25.1661]
24-11-25 22:01:40 | I |         best error  = [   25.1661]
24-11-25 22:01:40 | I |     + error = [25.1661]
24-11-25 22:01:59 | I |       - range scale = [    1.0000]
24-11-25 22:01:59 | I |         sum  error  = [   13.7900]
24-11-25 22:01:59 | I |         best error  = [   13.7900]
24-11-25 22:01:59 | I |     + error = [13.7900]
24-11-25 22:02:00 | I |       - range scale = [    1.0000]
24-11-25 22:02:00 | I |         sum  error  = [  114.2908]
24-11-25 22:02:00 | I |         best error  = [  114.2908]
24-11-25 22:02:00 | I |     + error = [114.2908]
24-11-25 22:02:01 | I |       - range scale = [    1.0000]
24-11-25 22:02:01 | I |         sum  error  = [   13.5731]
24-11-25 22:02:01 | I |         best error  = [   13.5731]
24-11-25 22:02:01 | I |     + error = [13.5731]
24-11-25 22:02:02 | I |       - range scale = [    1.0000]
24-11-25 22:02:02 | I |         sum  error  = [  103.7638]
24-11-25 22:02:02 | I |         best error  = [  103.7638]
24-11-25 22:02:02 | I |     + error = [103.7638]
24-11-25 22:02:03 | I |       - range scale = [    1.0000]
24-11-25 22:02:03 | I |         sum  error  = [    1.6982]
24-11-25 22:02:03 | I |         best error  = [    1.6982]
24-11-25 22:02:03 | I |     + error = [1.6982]
24-11-25 22:02:04 | I |       - range scale = [    1.0000]
24-11-25 22:02:04 | I |         sum  error  = [   18.7904]
24-11-25 22:02:04 | I |         best error  = [   18.7904]
24-11-25 22:02:04 | I |     + error = [18.7904]
24-11-25 22:02:05 | I |       - range scale = [    1.0000]
24-11-25 22:02:05 | I |         sum  error  = [    1.3936]
24-11-25 22:02:05 | I |         best error  = [    1.3936]
24-11-25 22:02:05 | I |     + error = [1.3936]
24-11-25 22:02:06 | I |       - range scale = [    1.0000]
24-11-25 22:02:06 | I |         sum  error  = [   14.9532]
24-11-25 22:02:06 | I |         best error  = [   14.9532]
24-11-25 22:02:06 | I |     + error = [14.9532]
24-11-25 22:02:07 | I |       - range scale = [    1.0000]
24-11-25 22:02:07 | I |         sum  error  = [    6.7331]
24-11-25 22:02:07 | I |         best error  = [    6.7331]
24-11-25 22:02:07 | I |     + error = [6.7331]
24-11-25 22:02:07 | I |       - range scale = [    1.0000]
24-11-25 22:02:07 | I |         sum  error  = [   72.0301]
24-11-25 22:02:07 | I |         best error  = [   72.0301]
24-11-25 22:02:07 | I |     + error = [72.0301]
24-11-25 22:02:08 | I |       - range scale = [    1.0000]
24-11-25 22:02:08 | I |         sum  error  = [    8.1596]
24-11-25 22:02:08 | I |         best error  = [    8.1596]
24-11-25 22:02:08 | I |     + error = [8.1596]
24-11-25 22:02:09 | I |       - range scale = [    1.0000]
24-11-25 22:02:09 | I |         sum  error  = [   88.3159]
24-11-25 22:02:09 | I |         best error  = [   88.3159]
24-11-25 22:02:09 | I |     + error = [88.3159]
24-11-25 22:02:10 | I |       - range scale = [    1.0000]
24-11-25 22:02:10 | I |         sum  error  = [    5.5547]
24-11-25 22:02:10 | I |         best error  = [    5.5547]
24-11-25 22:02:10 | I |     + error = [5.5547]
24-11-25 22:02:11 | I |       - range scale = [    1.0000]
24-11-25 22:02:11 | I |         sum  error  = [   50.7354]
24-11-25 22:02:11 | I |         best error  = [   50.7354]
24-11-25 22:02:11 | I |     + error = [50.7354]
24-11-25 22:02:28 | I | quantize activations when generating student args and kwargs
24-11-25 22:02:29 | W | Repo card metadata block was not found. Setting CardData to empty.
24-11-25 22:04:32 | I | current row num = 32
24-11-25 22:04:34 | I | current row num = 64
24-11-25 22:04:35 | I | current row num = 96
24-11-25 22:04:37 | I | current row num = 128
24-11-25 22:04:38 | I | current row num = 160
24-11-25 22:04:40 | I | current row num = 192
24-11-25 22:04:41 | I | current row num = 224
24-11-25 22:04:43 | I | current row num = 256
24-11-25 22:04:44 | I | current row num = 288
24-11-25 22:04:46 | I | current row num = 320
24-11-25 22:04:47 | I | current row num = 352
24-11-25 22:04:49 | I | current row num = 384
24-11-25 22:04:50 | I | current row num = 416
24-11-25 22:04:52 | I | current row num = 448
24-11-25 22:04:53 | I | current row num = 480
24-11-25 22:04:55 | I | current row num = 512
24-11-25 22:04:56 | I | current row num = 544
24-11-25 22:04:58 | I | current row num = 576
24-11-25 22:04:59 | I | current row num = 608
24-11-25 22:05:01 | I | current row num = 640
24-11-25 22:05:03 | I | *** 
 now in /data/gyy/YOCO/data_without_preprocess/shard/val/1.jsonl 
 ***
24-11-25 22:05:03 | I | *** 
 total_rows = 241 
 ***
24-11-25 22:05:03 | I | current row num = 0
24-11-25 22:05:04 | I | current row num = 32
24-11-25 22:05:06 | I | current row num = 64
24-11-25 22:05:07 | I | current row num = 96
24-11-25 22:05:09 | I | current row num = 128
24-11-25 22:05:10 | I | current row num = 160
24-11-25 22:05:12 | I | current row num = 192
24-11-25 22:05:13 | I | current row num = 224
24-11-25 22:05:16 | I | *** 
 now in /data/gyy/YOCO/data_without_preprocess/shard/val/2.jsonl 
 ***
24-11-25 22:05:16 | I | *** 
 total_rows = 509 
 ***
24-11-25 22:05:16 | I | current row num = 0
24-11-25 22:05:17 | I | current row num = 32
24-11-25 22:05:19 | I | current row num = 64
24-11-25 22:05:20 | I | current row num = 96
24-11-25 22:05:22 | I | current row num = 128
24-11-25 22:05:24 | I | current row num = 160
24-11-25 22:05:26 | I | current row num = 192
24-11-25 22:05:27 | I | current row num = 224
24-11-25 22:05:29 | I | current row num = 256
24-11-25 22:05:30 | I | current row num = 288
24-11-25 22:05:32 | I | current row num = 320
24-11-25 22:05:33 | I | current row num = 352
24-11-25 22:05:35 | I | current row num = 384
24-11-25 22:05:36 | I | current row num = 416
24-11-25 22:05:38 | I | current row num = 448
24-11-25 22:05:39 | I | current row num = 480
24-11-25 22:05:41 | I | *** 
 now in /data/gyy/YOCO/data_without_preprocess/shard/val/3.jsonl 
 ***
24-11-25 22:05:41 | I | *** 
 total_rows = 274 
 ***
24-11-25 22:05:41 | I | current row num = 0
24-11-25 22:05:43 | I | current row num = 32
24-11-25 22:05:44 | I | current row num = 64
24-11-25 22:05:46 | I | current row num = 96
24-11-25 22:05:47 | I | current row num = 128
24-11-25 22:05:49 | I | current row num = 160
24-11-25 22:05:50 | I | current row num = 192
24-11-25 22:05:52 | I | current row num = 224
24-11-25 22:05:54 | I | *** 
 now in /data/gyy/YOCO/data_without_preprocess/shard/val/4.jsonl 
 ***
24-11-25 22:05:54 | I | *** 
 total_rows = 191 
 ***
24-11-25 22:05:54 | I | current row num = 0
24-11-25 22:05:55 | I | current row num = 32
24-11-25 22:05:57 | I | current row num = 64
24-11-25 22:05:58 | I | current row num = 96
24-11-25 22:06:00 | I | current row num = 128
24-11-25 22:06:01 | I | current row num = 160
24-11-25 22:06:03 | I | *** 
 now in /data/gyy/YOCO/data_without_preprocess/shard/val/5.jsonl 
 ***
24-11-25 22:06:03 | I | *** 
 total_rows = 211 
 ***
24-11-25 22:06:03 | I | current row num = 0
24-11-25 22:06:05 | I | current row num = 32
24-11-25 22:06:06 | I | current row num = 64
24-11-25 22:06:08 | I | current row num = 96
24-11-25 22:06:09 | I | current row num = 128
24-11-25 22:06:11 | I | current row num = 160
24-11-25 22:06:12 | I | current row num = 192
24-11-25 22:06:14 | I | *** 
 now in /data/gyy/YOCO/data_without_preprocess/shard/val/6.jsonl 
 ***
24-11-25 22:06:14 | I | *** 
 total_rows = 241 
 ***
24-11-25 22:06:14 | I | current row num = 0
24-11-25 22:06:16 | I | current row num = 32
24-11-25 22:06:18 | I | current row num = 64
24-11-25 22:06:19 | I | current row num = 96
24-11-25 22:06:21 | I | current row num = 128
24-11-25 22:06:22 | I | current row num = 160
24-11-25 22:06:24 | I | current row num = 192
24-11-25 22:06:26 | I | *** 
 now in /data/gyy/YOCO/data_without_preprocess/shard/val/7.jsonl 
 ***
24-11-25 22:06:26 | I | *** 
 total_rows = 279 
 ***
24-11-25 22:06:26 | I | current row num = 0
24-11-25 22:06:27 | I | current row num = 32
24-11-25 22:06:29 | I | current row num = 64
24-11-25 22:06:30 | I | current row num = 96
24-11-25 22:06:32 | I | current row num = 128
24-11-25 22:06:33 | I | current row num = 160
24-11-25 22:06:35 | I | current row num = 192
24-11-25 22:06:36 | I | current row num = 224
24-11-25 22:06:38 | I | current row num = 256
24-11-25 22:06:40 | I | *** 
 now in /data/gyy/YOCO/data_without_preprocess/shard/val/8.jsonl 
 ***
24-11-25 22:06:40 | I | *** 
 total_rows = 186 
 ***
24-11-25 22:06:40 | I | current row num = 0
24-11-25 22:06:41 | I | current row num = 32
24-11-25 22:06:43 | I | current row num = 64
24-11-25 22:06:44 | I | current row num = 96
24-11-25 22:06:46 | I | current row num = 128
24-11-25 22:06:47 | I | current row num = 160
24-11-25 22:06:50 | I | *** 
 now in /data/gyy/YOCO/data_without_preprocess/shard/val/9.jsonl 
 ***
24-11-25 22:06:50 | I | *** 
 total_rows = 770 
 ***
24-11-25 22:06:50 | I | current row num = 0
24-11-25 22:06:52 | I | current row num = 32
24-11-25 22:06:53 | I | current row num = 64
24-11-25 22:06:55 | I | current row num = 96
24-11-25 22:06:56 | I | current row num = 128
24-11-25 22:06:58 | I | current row num = 160
24-11-25 22:07:00 | I | current row num = 192
24-11-25 22:07:01 | I | current row num = 224
24-11-25 22:07:03 | I | current row num = 256
24-11-25 22:07:04 | I | current row num = 288
24-11-25 22:07:06 | I | current row num = 320
24-11-25 22:07:07 | I | current row num = 352
24-11-25 22:07:09 | I | current row num = 384
24-11-25 22:07:10 | I | current row num = 416
24-11-25 22:07:12 | I | current row num = 448
24-11-25 22:07:13 | I | current row num = 480
24-11-25 22:07:15 | I | current row num = 512
24-11-25 22:07:16 | I | current row num = 544
24-11-25 22:07:18 | I | current row num = 576
24-11-25 22:07:19 | I | current row num = 608
24-11-25 22:07:21 | I | current row num = 640
24-11-25 22:07:22 | I | current row num = 672
24-11-25 22:07:24 | I | current row num = 704
24-11-25 22:07:25 | I | current row num = 736
24-11-25 22:07:28 | I | *** 
 now in /data/gyy/YOCO/data_without_preprocess/shard/val/10.jsonl 
 ***
24-11-25 22:07:28 | I | *** 
 total_rows = 271 
 ***
24-11-25 22:07:28 | I | current row num = 0
24-11-25 22:07:29 | I | current row num = 32
24-11-25 22:07:31 | I | current row num = 64
24-11-25 22:07:32 | I | current row num = 96
24-11-25 22:07:34 | I | current row num = 128
24-11-25 22:07:35 | I | current row num = 160
24-11-25 22:07:37 | I | current row num = 192
24-11-25 22:07:38 | I | current row num = 224
24-11-25 22:07:40 | I | current row num = 256
24-11-25 22:07:42 | I | *** 
 now in /data/gyy/YOCO/data_without_preprocess/shard/val/11.jsonl 
 ***
24-11-25 22:07:42 | I | *** 
 total_rows = 273 
 ***
24-11-25 22:07:42 | I | current row num = 0
24-11-25 22:07:43 | I | current row num = 32
24-11-25 22:07:45 | I | current row num = 64
24-11-25 22:07:46 | I | current row num = 96
24-11-25 22:07:48 | I | current row num = 128
24-11-25 22:07:49 | I | current row num = 160
24-11-25 22:07:51 | I | current row num = 192
24-11-25 22:07:52 | I | current row num = 224
24-11-25 22:07:54 | I | *** 
 now in /data/gyy/YOCO/data_without_preprocess/shard/val/12.jsonl 
 ***
24-11-25 22:07:54 | I | *** 
 total_rows = 301 
 ***
24-11-25 22:07:54 | I | current row num = 0
24-11-25 22:07:56 | I | current row num = 32
24-11-25 22:07:57 | I | current row num = 64
24-11-25 22:07:59 | I | current row num = 96
24-11-25 22:08:00 | I | current row num = 128
24-11-25 22:08:02 | I | current row num = 160
24-11-25 22:08:03 | I | current row num = 192
24-11-25 22:08:05 | I | current row num = 224
24-11-25 22:08:06 | I | current row num = 256
24-11-25 22:08:09 | I | *** 
 now in /data/gyy/YOCO/data_without_preprocess/shard/val/13.jsonl 
 ***
24-11-25 22:08:09 | I | *** 
 total_rows = 239 
 ***
24-11-25 22:08:09 | I | current row num = 0
24-11-25 22:08:10 | I | current row num = 32
24-11-25 22:08:12 | I | current row num = 64
24-11-25 22:08:13 | I | current row num = 96
24-11-25 22:08:15 | I | current row num = 128
24-11-25 22:08:16 | I | current row num = 160
24-11-25 22:08:18 | I | current row num = 192
24-11-25 22:08:19 | I | current row num = 224
24-11-25 22:08:21 | I | *** 
 now in /data/gyy/YOCO/data_without_preprocess/shard/val/14.jsonl 
 ***
24-11-25 22:08:21 | I | *** 
 total_rows = 262 
 ***
24-11-25 22:08:21 | I | current row num = 0
24-11-25 22:08:23 | I | current row num = 32
24-11-25 22:08:24 | I | current row num = 64
24-11-25 22:08:26 | I | current row num = 96
24-11-25 22:08:27 | I | current row num = 128
24-11-25 22:08:29 | I | current row num = 160
24-11-25 22:08:30 | I | current row num = 192
24-11-25 22:08:32 | I | current row num = 224
24-11-25 22:08:34 | I | *** 
 now in /data/gyy/YOCO/data_without_preprocess/shard/val/15.jsonl 
 ***
24-11-25 22:08:34 | I | *** 
 total_rows = 253 
 ***
24-11-25 22:08:34 | I | current row num = 0
24-11-25 22:08:35 | I | current row num = 32
24-11-25 22:08:37 | I | current row num = 64
24-11-25 22:08:38 | I | current row num = 96
24-11-25 22:08:40 | I | current row num = 128
24-11-25 22:08:41 | I | current row num = 160
24-11-25 22:08:43 | I | current row num = 192
24-11-25 22:08:44 | I | current row num = 224
24-11-25 22:08:47 | I | *** 
 now in /data/gyy/YOCO/data_without_preprocess/shard/val/16.jsonl 
 ***
24-11-25 22:08:47 | I | *** 
 total_rows = 523 
 ***
24-11-25 22:08:47 | I | current row num = 0
24-11-25 22:08:48 | I | current row num = 32
24-11-25 22:08:50 | I | current row num = 64
24-11-25 22:08:51 | I | current row num = 96
24-11-25 22:08:53 | I | current row num = 128
24-11-25 22:08:54 | I | current row num = 160
24-11-25 22:08:56 | I | current row num = 192
24-11-25 22:08:57 | I | current row num = 224
24-11-25 22:08:59 | I | current row num = 256
24-11-25 22:09:00 | I | current row num = 288
24-11-25 22:09:02 | I | current row num = 320
24-11-25 22:09:03 | I | current row num = 352
24-11-25 22:09:05 | I | current row num = 384
24-11-25 22:09:06 | I | current row num = 416
24-11-25 22:09:08 | I | current row num = 448
24-11-25 22:09:09 | I | current row num = 480
24-11-25 22:09:11 | I | *** 
 now in /data/gyy/YOCO/data_without_preprocess/shard/val/17.jsonl 
 ***
24-11-25 22:09:11 | I | *** 
 total_rows = 251 
 ***
24-11-25 22:09:11 | I | current row num = 0
24-11-25 22:09:13 | I | current row num = 32
24-11-25 22:09:14 | I | current row num = 64
24-11-25 22:09:16 | I | current row num = 96
24-11-25 22:09:18 | I | current row num = 128
24-11-25 22:09:19 | I | current row num = 160
24-11-25 22:09:21 | I | current row num = 192
24-11-25 22:09:22 | I | current row num = 224
24-11-25 22:09:24 | I | *** 
 now in /data/gyy/YOCO/data_without_preprocess/shard/val/18.jsonl 
 ***
24-11-25 22:09:24 | I | *** 
 total_rows = 274 
 ***
24-11-25 22:09:24 | I | current row num = 0
24-11-25 22:09:26 | I | current row num = 32
24-11-25 22:09:27 | I | current row num = 64
24-11-25 22:09:29 | I | current row num = 96
24-11-25 22:09:30 | I | current row num = 128
24-11-25 22:09:32 | I | current row num = 160
24-11-25 22:09:33 | I | current row num = 192
24-11-25 22:09:35 | I | current row num = 224
24-11-25 22:09:37 | I | current row num = 256
24-11-25 22:09:39 | I | *** 
 now in /data/gyy/YOCO/data_without_preprocess/shard/val/19.jsonl 
 ***
24-11-25 22:09:39 | I | *** 
 total_rows = 315 
 ***
24-11-25 22:09:39 | I | current row num = 0
24-11-25 22:09:40 | I | current row num = 32
24-11-25 22:09:42 | I | current row num = 64
24-11-25 22:09:43 | I | current row num = 96
24-11-25 22:09:45 | I | current row num = 128
24-11-25 22:09:46 | I | current row num = 160
24-11-25 22:09:48 | I | current row num = 192
24-11-25 22:09:49 | I | current row num = 224
24-11-25 22:09:51 | I | current row num = 256
24-11-25 22:09:52 | I | current row num = 288
24-11-25 22:09:54 | I | current row num = 320
24-11-25 22:09:55 | I | No existing checkpoint found checkpoints/checkpoint_last.pt
24-11-25 22:09:55 | I | loading train data for epoch 1
24-11-25 22:09:55 | I | loading valid data for epoch 1
24-11-25 22:09:55 | I | begin training epoch 1
24-11-25 22:09:55 | I | Start iterating over samples
24-11-25 22:09:55 | I | TRAIN CURRENT LAYER_IDX = 1
24-11-25 22:09:55 | I | in layer model.layers.1
24-11-25 22:09:55 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 22:09:55 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 22:09:55 | I | - Evaluator: gptq
24-11-25 22:09:55 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 22:09:55 | I | - Batch_size: 8
24-11-25 22:09:55 | I |   + Max_seq_length: 2048
24-11-25 22:10:33 | I |     - Results:
24-11-25 22:10:33 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 22:10:33 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 22:10:33 | I |       |wikitext |      1|word_perplexity|7.7799|  |7.7799|
24-11-25 22:10:33 | I |       |val_valid|      1|word_perplexity|9.0327|  |9.0327|
24-11-25 22:10:33 | I |       
24-11-25 22:10:33 | I | quantizing weights for layer model.layers.1
24-11-25 22:10:33 | I | collecting info in model.layers.1
24-11-25 22:10:33 | I | collecting info in model.layers.1
24-11-25 22:10:33 | I | collecting info in model.layers.1
24-11-25 22:10:33 | I | collecting info in model.layers.1
24-11-25 22:10:34 | I | collecting calibration activations in model.layers.1
24-11-25 22:10:34 | I | collecting calibration activations in model.layers.1
24-11-25 22:10:34 | I | collecting calibration activations in model.layers.1
24-11-25 22:10:34 | I | collecting calibration activations in model.layers.1
24-11-25 22:10:34 | I | - Quantizing decoder layer model.layers.1
24-11-25 22:10:34 | I |   - Calibrating model.layers.1.self_attn.q_proj.weight
24-11-25 22:10:35 | I |       - range scale = [    1.0000]
24-11-25 22:10:35 | I |         sum  error  = [    0.1836]
24-11-25 22:10:35 | I |         best error  = [    0.1836]
24-11-25 22:10:35 | I |     + error = [0.1836]
24-11-25 22:10:35 | I |       - range scale = [    1.0000]
24-11-25 22:10:35 | I |         sum  error  = [    1.9927]
24-11-25 22:10:35 | I |         best error  = [    1.9927]
24-11-25 22:10:35 | I |     + error = [1.9927]
24-11-25 22:10:36 | I |   - Calibrating model.layers.1.self_attn.k_proj.weight
24-11-25 22:10:36 | I |       - range scale = [    1.0000]
24-11-25 22:10:36 | I |         sum  error  = [    0.1018]
24-11-25 22:10:36 | I |         best error  = [    0.1018]
24-11-25 22:10:36 | I |     + error = [0.1018]
24-11-25 22:10:37 | I |       - range scale = [    1.0000]
24-11-25 22:10:37 | I |         sum  error  = [    1.0778]
24-11-25 22:10:37 | I |         best error  = [    1.0778]
24-11-25 22:10:37 | I |     + error = [1.0778]
24-11-25 22:10:37 | I |   - Calibrating model.layers.1.self_attn.v_proj.weight
24-11-25 22:10:38 | I |       - range scale = [    1.0000]
24-11-25 22:10:38 | I |         sum  error  = [    0.3755]
24-11-25 22:10:38 | I |         best error  = [    0.3755]
24-11-25 22:10:38 | I |     + error = [0.3755]
24-11-25 22:10:39 | I |       - range scale = [    1.0000]
24-11-25 22:10:39 | I |         sum  error  = [    4.0196]
24-11-25 22:10:39 | I |         best error  = [    4.0196]
24-11-25 22:10:39 | I |     + error = [4.0196]
24-11-25 22:10:39 | I |   - Calibrating model.layers.1.self_attn.o_proj.weight
24-11-25 22:10:40 | I |       - range scale = [    1.0000]
24-11-25 22:10:40 | I |         sum  error  = [    0.0673]
24-11-25 22:10:40 | I |         best error  = [    0.0673]
24-11-25 22:10:40 | I |     + error = [0.0673]
24-11-25 22:10:40 | I |       - range scale = [    1.0000]
24-11-25 22:10:40 | I |         sum  error  = [    0.6352]
24-11-25 22:10:40 | I |         best error  = [    0.6352]
24-11-25 22:10:40 | I |     + error = [0.6352]
24-11-25 22:10:40 | I |   - Calibrating model.layers.1.mlp.up_proj.weight
24-11-25 22:10:41 | I |       - range scale = [    1.0000]
24-11-25 22:10:41 | I |         sum  error  = [    1.4245]
24-11-25 22:10:41 | I |         best error  = [    1.4245]
24-11-25 22:10:41 | I |     + error = [1.4245]
24-11-25 22:10:42 | I |       - range scale = [    1.0000]
24-11-25 22:10:42 | I |         sum  error  = [   15.7869]
24-11-25 22:10:42 | I |         best error  = [   15.7869]
24-11-25 22:10:42 | I |     + error = [15.7869]
24-11-25 22:10:42 | I |   - Calibrating model.layers.1.mlp.gate_proj.weight
24-11-25 22:10:43 | I |       - range scale = [    1.0000]
24-11-25 22:10:43 | I |         sum  error  = [    1.5055]
24-11-25 22:10:43 | I |         best error  = [    1.5055]
24-11-25 22:10:43 | I |     + error = [1.5055]
24-11-25 22:10:44 | I |       - range scale = [    1.0000]
24-11-25 22:10:44 | I |         sum  error  = [   16.5654]
24-11-25 22:10:44 | I |         best error  = [   16.5654]
24-11-25 22:10:44 | I |     + error = [16.5654]
24-11-25 22:10:44 | I |   - Calibrating model.layers.1.mlp.down_proj.weight
24-11-25 22:10:44 | I |       - range scale = [    1.0000]
24-11-25 22:10:44 | I |         sum  error  = [    0.3227]
24-11-25 22:10:44 | I |         best error  = [    0.3227]
24-11-25 22:10:44 | I |     + error = [0.3227]
24-11-25 22:10:45 | I |       - range scale = [    1.0000]
24-11-25 22:10:45 | I |         sum  error  = [    3.1187]
24-11-25 22:10:45 | I |         best error  = [    3.1187]
24-11-25 22:10:45 | I |     + error = [3.1187]
24-11-25 22:10:45 | I |   - Quantizing model.layers.1.self_attn.q_proj.weight
24-11-25 22:10:47 | I |   - Quantizing model.layers.1.self_attn.k_proj.weight
24-11-25 22:10:48 | I |   - Quantizing model.layers.1.self_attn.v_proj.weight
24-11-25 22:10:50 | I |   - Quantizing model.layers.1.self_attn.o_proj.weight
24-11-25 22:10:51 | I |   - Quantizing model.layers.1.mlp.up_proj.weight
24-11-25 22:10:52 | I |   - Quantizing model.layers.1.mlp.gate_proj.weight
24-11-25 22:10:54 | I |   - Quantizing model.layers.1.mlp.down_proj.weight
24-11-25 22:10:57 | I | quantizing activations for layer model.layers.1
24-11-25 22:10:57 | I | collecting info in model.layers.1
24-11-25 22:10:57 | I | collecting info in model.layers.1
24-11-25 22:10:57 | I | collecting info in model.layers.1
24-11-25 22:10:57 | I | collecting info in model.layers.1
24-11-25 22:10:58 | I | collecting calibration activations in model.layers.1
24-11-25 22:10:58 | I | collecting calibration activations in model.layers.1
24-11-25 22:10:58 | I | collecting calibration activations in model.layers.1
24-11-25 22:10:58 | I | collecting calibration activations in model.layers.1
24-11-25 22:11:00 | W |   `pretrained` model kwarg is not of type `str`. Many other model arguments may be ignored. Please do not launch via accelerate or use `parallelize=True` if passing an existing model this way.
24-11-25 22:11:00 | W |   Passed an already-initialized model through `pretrained`, assuming single-process call to evaluate() or custom distributed integration
24-11-25 22:11:00 | I | - Evaluator: gptq
24-11-25 22:11:00 | I | - Tasks: ['wikitext', 'val_valid']
24-11-25 22:11:00 | I | - Batch_size: 8
24-11-25 22:11:00 | I |   + Max_seq_length: 2048
24-11-25 22:11:41 | I |     - Results:
24-11-25 22:11:41 | I |       |  Task   |Version|    Metric     |Value |   |Stderr|
24-11-25 22:11:41 | I |       |---------|------:|---------------|-----:|---|-----:|
24-11-25 22:11:41 | I |       |wikitext |      1|word_perplexity|7.9874|  |7.9874|
24-11-25 22:11:41 | I |       |val_valid|      1|word_perplexity|9.1658|  |9.1658|
24-11-25 22:11:41 | I |       
24-11-25 22:11:41 | I | forward this layer
24-11-25 22:11:41 | I | input_file: /data/gyy/YOCO/data_without_preprocess/shard/val_input_args_layer_1/00.pt
24-11-25 22:11:41 | I | output_file: /data/gyy/YOCO/data_without_preprocess/shard/val_teacher_output_layer_1/00.pt
